{"config":{"lang":["zh"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"Index","text":""},{"location":"#_1","title":"\u4e2a\u4eba\u7b80\u4ecb","text":"<p>\u6d77\u6ee8\uff0cCV\u7b97\u6cd5\u5de5\u7a0b\u5e08\uff0c\u7814\u7a76\u9886\u57df\u5305\u62ec\u57fa\u7840\u89c6\u89c9\u9886\u57df\uff08\u56fe\u50cf\u5206\u7c7b/\u5206\u5272/\u68c0\u6d4b\uff0c\u89c6\u9891\u5206\u7c7b/\u65f6\u5e8f\u52a8\u4f5c\u5b9a\u4f4d\u7b49\uff09\uff0c\u6a21\u578b\u8f7b\u91cf\u5316\u90e8\u7f72\u52a0\u901f\u7b49\uff0c\u76ee\u524d\u4e3b\u8981\u4ece\u4e8b\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u5de5\u4e1a\u9886\u57df\u5e94\u7528\u7814\u7a76\u7684\u76f8\u5173\u5de5\u4f5c\u3002</p> <p>\u6280\u672f\u5408\u4f5c\u4e0e\u4ea4\u6d41\u8bf7\u8054\u7cfb Email: haibintian@foxmail.com</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2021%E5%B9%B412%E6%9C%8826%E6%97%A5%2015%E6%97%B630%E5%88%8611%E7%A7%92/","title":"Pytorch\u4e0b\u7684\u591a\u5361\u95f4\u53d8\u91cf\u540c\u6b65\u64cd\u4f5c","text":"<p>\u57fa\u4e8etorch\u7684\u65e0\u8bba\u662f\u591a\u673a\u591a\u5361\u8fd8\u662f\u5355\u673a\u591a\u5361\u90fd\u6709\u591a\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff0c\u53e6\u5916\u4e5f\u6709\u4e00\u4e9b\u4f18\u79c0\u7684\u6846\u67b6\u5bf9\u8be5\u8fc7\u7a0b\u8fdb\u884c\u5c01\u88c5\uff0c\u8fd9\u91cc\u63a8\u8350\u4e0bPytorch Lightning \u5c3d\u7ba1\u6846\u67b6\u5df2\u7ecf\u5c01\u88c5\u7684\u5f88\u662f\u5b8c\u5584\uff0c\u4f46\u8fd8\u662f\u514d\u4e0d\u4e86\u81ea\u5df1\u5199\u4e00\u4e9b\u7ec4\u4ef6\u6765\u3002\u5728\u591a\u5361\u7684\u73af\u5883\u4e0b\uff0c\u5982\u4f55\u5bf9\u67d0\u4e2a\u53d8\u91cf\u8fdb\u884creduce\u548cbroadcast\u64cd\u4f5c\u662f\u907f\u514d\u4e0d\u4e86\u7684\u95ee\u9898\u3002\u4e0b\u9762\u7ed9\u51fa\u5982\u4e0bdemo\u6f14\u793a\u5982\u4f55\u5355\u673a\u591a\u5361\u5b9e\u73b0\u4ee5\u4e0a\u64cd\u4f5c\u3002</p> <pre><code>import torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport os\ndef reduce_tensor(tensor):\n    rt = tensor.detach().clone()\n    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n    got_world_size = torch.distributed.get_world_size()\n    rt /= got_world_size\n    return rt\ndef broadcast_tensor(tensor, rank):\n    # rank \u8868\u793abroadcast\u54ea\u4e2arank\u7684\u6570\u636e\u5230\u5176\u4ed6rank\n    rt = tensor.detach().clone()\n    dist.broadcast(rt, src=rank)\n    return rt\ndef main_worker(gpu, ngpus_per_node):\n        print('gpu', gpu)\n        # \u8fd9\u91cc\u7684rank\u5b9e\u9645\u4e0a\u5e94\u8be5\u662f\u673a\u5668\u7f16\u53f7\uff0c\u4f46\u662f\u6211\u4eec\u662f\u5355\u673a\u591a\u5361\uff0c\u6240\u4ee5\u56fa\u5b9a\u4e3a 0\n        rank = 0\n        if True:\n            # For multiprocessing distributed training, rank needs to be the\n            # global rank among all the processes\n            rank = rank * ngpus_per_node + gpu\n        print('rank', rank)\n        dist.init_process_group(backend=\"nccl\", init_method=\"tcp://127.0.0.1:8124\", world_size=2, rank=rank)\n        got_rand = torch.distributed.get_rank()\n        print('got_rand', got_rand)\n        got_world_size = torch.distributed.get_world_size()\n        print('got_world_size', got_world_size)\n        # tensor_list = []\n        local_rank = rank\n        torch.cuda.set_device('cuda:%d' % local_rank)\n        t = torch.rand((10,)).cuda()\n        torch.distributed.barrier()\n        print('t',t)\n        reduce_t = reduce_tensor(t)\n        print('reduce_t', reduce_t)\n        boardcasted_t = broadcast_tensor(t, 0)\n        print('boardcasted_t', boardcasted_t)\ndef main():\n    # Use torch.multiprocessing.spawn to launch distributed processes: the\n    # main_worker process function\n    # \u5047\u8bbe\u673a\u5668\u4e00\u79cd\u6709\u56db\u5f20\u5361\uff0c\u8fd9\u91cc\u91c7\u7528\u524d\u4e24\u5f20\n    ngpus_per_node = torch.cuda.device_count() // 2\n    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, ))\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8807%E6%97%A5%2020%E6%97%B633%E5%88%8650%E7%A7%92/","title":"\u81ea\u52a8\u5fae\u5206autograd\u539f\u7406-\u7b80\u5355demo","text":""},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8807%E6%97%A5%2020%E6%97%B633%E5%88%8650%E7%A7%92/#_1","title":"\u9700\u6c42","text":"<p>\u5b9e\u73b0\u4e00\u4e2a\u7c7b\u4f3cpytorch\u7684\u7b80\u7565\u7248\u81ea\u52a8\u5fae\u5206mini\u6846\u67b6\uff0c\u652f\u6301\u52a0\u51cf\u4e58\u9664\uff0capi\u8bbe\u8ba1\u53c2\u8003pytorch\u5373\u53ef\u3002\u8fd9\u4e2a\u5b9e\u9645\u4e0a\u662f\u67d0\u8282\u7684\u4e00\u9053\u9762\u8bd5\u9898\u7684\u7cbe\u7b80\u7248\uff0c\u4e0d\u77e5\u9053\u4eca\u5e74\u8fd8\u51fa\u4e0d\u51fa\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8807%E6%97%A5%2020%E6%97%B633%E5%88%8650%E7%A7%92/#_2","title":"\u5206\u6790","text":"<ol> <li>\u9700\u8981\u6784\u9020\u8ba1\u7b97\u56fe\uff0c\u4ee5z = func(x,y) \u4e3a\u4f8b\uff0c\u6267\u884c<code>z.backward</code>\u65f6\u5019\u9700\u8981\u627e\u5230x\u548cy,\u56e0\u6b64\u6784\u9020\u7684z\u5bf9\u8c61\u5bf9\u5e94\u7684\u7c7b\u9700\u8981\u6709\u5b58\u50a8x\u548cy\u5bf9\u8c61\u5f15\u7528\u7684\u8bbe\u8ba1</li> <li>\u51fd\u6570\u6307\u9488\u3002\u9700\u8981\u6784\u9020\u524d\u5411\u4f20\u64ad\u51fd\u6570\u4e0e\u53cd\u5411\u4f20\u64ad\u51fd\u6570\uff0c\u663e\u7136\u6bcf\u4e2a\u51fd\u6570\u9700\u8981\u5f53\u505a\u53c2\u6570\u4f20\u9012\u7ed9\u53c2\u4e0e\u8ba1\u7b97\u7684\u53d8\u91cf\u4f7f\u7528</li> <li>\u63a5\u53e3\u8bbe\u8ba1\u53c2\u8003<code>torch.autograd.Function</code></li> </ol>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8807%E6%97%A5%2020%E6%97%B633%E5%88%8650%E7%A7%92/#_3","title":"\u4ee3\u7801","text":"<pre><code>import abc\nfrom copy import copy\nclass Function(metaclass=abc.ABCMeta):\n    def __init__(self) -&gt; None:\n        self._buffer = list()\n    @classmethod\n    @abc.abstractmethod\n    def forward(cls, *args, **kwargs):\n        pass\n    @classmethod\n    @abc.abstractmethod\n    def backward(cls, *args, **kwargs):\n        pass\n    def saved_for_backward(self, *args):\n        self._buffer.append(args)\n    def get_saved_buffer(self):\n        return self._buffer.pop(-1)\n    @classmethod\n    def apply(cls, *args, **kwargs):\n        obj = cls()\n        result = obj.forward(*args, **kwargs)\n        # add grad func for args\n        if result.required_grad:\n            result.saved_ctx = (args, obj.backward)\n        return result\ndef as_var(data):\n    if isinstance(data, Varible):\n        return data\n    return Varible(float(data), required_grad=False)\nclass Varible(object):\n    def __init__(self, value, required_grad = False) -&gt; None:\n        self.required_grad = required_grad\n        self.grad = None\n        self.data = value\n        self.saved_ctx = None\n    def backward(self, grad = None, retain_graph = False):\n        grad = grad or 1.0\n        if not self.required_grad:\n            return\n        if self.saved_ctx is not None:\n            vars, backward_func = self.saved_ctx\n            grads = backward_func(grad)\n            for var, var_grad in zip(vars, grads):\n                if var.required_grad:\n                    var.grad = var.grad or 0.0\n                    var.grad += var_grad\n                    var.backward(var_grad, retain_graph)\n            if not retain_graph:\n                self.saved_ctx = None\n    def copy_(self, other):\n        self.data = copy(other.data)\n        self.required_grad = copy(other.required_grad)\n        self.grad = copy(other.grad)\n        self.saved_ctx = copy(other.saved_ctx)\n    def __iadd__(self, other):\n        ret = self.__add__(other)\n        self.copy_(ret)\n    def __isub__(self, other):\n        ret = self.__sub__(other)\n        self.copy_(ret)\n    def __imul__(self, other):\n        ret = self.__mul__(other)\n        self.copy_(ret)\n    def __idiv__(self, other):\n        ret = self.__div__(other)\n        self.copy_(ret)\n    def __radd__(self, other):\n        return self.__add__(other)\n    def __rsub__(self, other):\n        return self.__sub__(other)\n    def __rmul__(self, other):\n        return self.__mul__(other)\n    def __rtruediv__(self, other):\n        return self.__truediv__(other)\n    def __add__(self, other):\n        return AddFunction.apply(self, as_var(other))\n    def __sub__(self, other):\n        return SubFunction.apply(self, as_var(other))\n    def __mul__(self, other):\n        return MulFunction.apply(self, as_var(other))\n    def __truediv__(self, other):\n        return DivFunction.apply(self, as_var(other))\n    def __str__(self) -&gt; str:\n        return f\"data={self.data}, required_grad={self.required_grad}, grad={self.grad}\"\n    def __repr__(self) -&gt; str:\n        return self.__str__()\nclass AddFunction(Function):\n    def forward(ctx, x, y):\n        required_grad = x.required_grad or y.required_grad\n        result_data = x.data + y.data\n        result = Varible(result_data, required_grad=required_grad)\n        return result\n    def backward(ctx, grad):\n        # grad for x and y\n        return grad, grad\nclass SubFunction(Function):\n    def forward(ctx, x, y):\n        required_grad = x.required_grad or y.required_grad\n        result_data = x.data - y.data\n\n        result = Varible(result_data, required_grad=required_grad)\n        return result\n    def backward(ctx, grad):\n        # grad for x and y\n        return grad, -grad\nclass MulFunction(Function):\n    def forward(ctx, x, y):\n        required_grad = x.required_grad or y.required_grad\n        result_data = x.data * y.data\n        ctx.saved_for_backward(x.data, y.data)\n        result = Varible(result_data, required_grad=required_grad)\n        return result\n    def backward(ctx, grad):\n        # grad for x and y\n        x, y = ctx.get_saved_buffer()\n        return grad * y, grad * x\nclass DivFunction(Function):\n    def forward(ctx, x, y):\n        required_grad = x.required_grad or y.required_grad\n        result_data = x.data / y.data\n        ctx.saved_for_backward(x.data, y.data)\n        result = Varible(result_data, required_grad=required_grad)\n        return result\n    def backward(ctx, grad):\n        # grad for x and y\n        x, y = ctx.get_saved_buffer()\n        return grad / y, - grad * x * (y ** -2)\n\nif __name__ == \"__main__\":\n    a = Varible(1.0, required_grad=True)\n    b = Varible(2.0, required_grad=True)\n    y = 2 * a / b + 3 * a * a\n    y.backward()\n    print(y)\n    print(b)\n    print(a)\n</code></pre>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8807%E6%97%A5%2020%E6%97%B633%E5%88%8650%E7%A7%92/#_4","title":"\u603b\u7ed3","text":"<p>\u4ee5\u4e0a\u4ee3\u7801\u65e2\u5b9e\u73b0\u4e86\u6807\u91cf\u7684\u81ea\u52a8\u5fae\u5206\uff0c\u4e3b\u8981\u662f\u4e24\u4e2a\u7c7b\uff0c<code>Function</code>\u548c<code>Variable</code>\u3002\u6838\u5fc3\u662f\u4e00\u4e2a\u65b9\u6cd5<code>backward</code>\uff0c\u91cc\u5934\u4f1a\u94fe\u5f0f\u8c03\u7528\u5b50\u8282\u70b9\u7684<code>backward</code>\u65b9\u6cd5\uff0c\u5b9e\u73b0\u94fe\u5f0f\u7684\u53cd\u5411\u4f20\u64ad\u529f\u80fd\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/","title":"TensorFlow\u4e2dckpt\u3001frozen model\u3001keras\u3001onnx\u4e4b\u95f4\u6d89\u53ca\u7684\u8f6c\u6362","text":""},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#tf","title":"tf\u4e0b\u7684\u4e09\u79cd\u5b58\u50a8\u683c\u5f0f","text":"<p>TensorFlow\u4e2d\u6709\u4e09\u79cd\u6a21\u578b\u548c\u6570\u636e\u5b58\u50a8\u683c\u5f0f</p> <ul> <li>saved model\u683c\u5f0f\u3002\u5728tf2.x\u7248\u672c\u4e2d\u7ecf\u5e38\u4f7f\u7528\uff0ctf2\u4e0b\u539f\u751fapi\u548ckeras\u5c01\u88c5\u4ee5\u540e\u7684api\u90fd\u652f\u6301\u5bfc\u51fa\u8be5\u7c7b\u683c\u5f0f\u3002saved model\u683c\u5f0f\u5bf9\u5e94\u4e00\u4e2a\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u5206\u522b\u5b58\u50a8\u6a21\u578b\u7684\u7ed3\u6784\u4fe1\u606f\u548c\u53c2\u6570\u4fe1\u606f\u3002</li> <li>frozen graph\u683c\u5f0f\u3002\u5728tf1.x\u7248\u672c\u4e2d\u7ecf\u5e38\u4f7f\u7528\uff0ctf1\u4e0b\u5b9a\u4e49\u7684graph\u53ef\u4ee5\u76f4\u63a5\u5bfc\u51fa\u3002frozen graph\u683c\u5f0f\u4ec5\u5305\u542b\u5355\u4e2apb\u6587\u4ef6\uff0c\u91cc\u9762\u6709\u6a21\u578b\u7684\u6240\u6709\u4fe1\u606f\uff0c\u4e00\u822c\u4e3a\u4e86\u65b9\u4fbf\u63a8\u7406\u4f1a\u628atraining\u76f8\u5173\u4fe1\u606f\u53bb\u9664\u3002</li> <li>ckpt\u683c\u5f0f\u3002\u7528\u4e8e\u4fdd\u5b58\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u7684\u8ba1\u7b97\u56fe\u548c\u6743\u91cd\u4fe1\u606f\uff0ckeras\u8bad\u7ec3\u65f6\u9ed8\u8ba4\u4f1a\u5bfc\u51fa\u8fd9\u79cd\u683c\u5f0f\u3002</li> </ul> <p>\u4e00\u822c\u7684\u63a8\u7406\u6846\u67b6\u8fc7\u53bb\u90fd\u4f1a\u5bf9frozen model\u683c\u5f0f\u8fdb\u884c\u652f\u6301\uff0c\u65b0\u7684\u7248\u672c\u4f1a\u9010\u6e10\u5411onnx\u8fd9\u79cd\u901a\u7528\u683c\u5f0f\u8fc1\u79fb\u3002 \u8fd9\u65f6\uff0cckpt\u683c\u5f0f\u7684\u5b58\u50a8\u65b9\u6cd5\u4ec5\u4ec5\u5f53\u505acheckpoint\u6765\u7528\uff0c\u4e0d\u518d\u5177\u5907\u90e8\u7f72\u7684\u5c5e\u6027\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#1-keras-onnx-frozen-graph","title":"1 keras \u8f6c onnx \u6216 frozen graph","text":""},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#11-keras-model-onnx","title":"1.1 keras model \u8f6c onnx","text":"<p>\u5bf9\u4e8ekeras\u6a21\u578b\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u5de5\u5177\u8f6c\u6210onnx\u683c\u5f0f</p> <ul> <li>tf2onnx \u94fe\u63a5\uff1ahttps://github.com/onnx/tensorflow-onnx</li> </ul> <p>\u8fd9\u91cc\u53ef\u80fd\u6d89\u53ca\u5230\u7b97\u5b50\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u5efa\u8bae\u4ed4\u7ec6\u770b\u4e0bonnx\u7684\u5b98\u65b9\u6587\u6863\uff0c\u6ce8\u610fonnx\u7684opset version\u3002\u91cd\u70b9\u5173\u6ce8resize\u7b97\u5b50\u7684\u53c2\u6570\u662f\u5426\u4e0ekeras\u4e2d\u7684\u5bf9\u9f50\u3002\u5982\u679c\u662ftf1\u7248\u672c\u9700\u8981\u91cd\u70b9\u5173\u6ce8resize\u7b97\u5b50\u53c2\u6570\u4e2d\u662f\u5426\u5305\u542b\u4e86\u9488\u5bf9tf1\u65e7\u7248\u672c\u7684\u7279\u6b8a\u8bbe\u7f6e\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#12-keras-model-frozen-graph","title":"1.2 keras model \u8f6c frozen graph","text":"<p>keras model \u8f6c frozen graph\u6709\u4e24\u79cd\u65b9\u6cd5\u3002\u7b2c\u4e00\u4e2a\u4fdd\u5b58\u4e3asaved model\u6216\u8005ckpt\u683c\u5f0f\uff0c\u7136\u540e\u52a0\u8f7d\u901a\u8fc7tf2onnx\u8f6c\u4e3aonnx\u3002 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u66f4\u4e3a\u76f4\u63a5\uff0c\u4ee3\u7801\u5982\u4e0b\uff0c\u8fd9\u91cc\u76f4\u63a5\u7ed9\u51fa\u591a\u8f93\u51fa\u591a\u8f93\u51fa\u4e0b\u7684\u8f6c\u6362\u4ee3\u7801\uff0c\u5728<code>tf2.3</code>\u7248\u672c\u6d4b\u8bd5\u901a\u8fc7\u3002\u4e3b\u8981\u539f\u7406\u662f\u901a\u8fc7<code>tf.function</code>\u518d\u5c01\u88c5\u4e00\u5c42</p> <pre><code># convert model to pb\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\nimport tensorflow as tf\nimport os\nfrom tensorflow.python.framework import importer\ndef freeze_keras_model2pb(keras_model, pb_filepath, input_vaiablename_list=None, output_vaiablename_list=None):\n    \"\"\"\n    karas \u6a21\u578b\u8f6cpb\n    :param keras_model:\n    :param pb_filepath:\n    :param input_vaiablename_list:\n    :param output_vaiablename_list:\n    :return:\n    \"\"\"\n    assert hasattr(keras_model,'inputs'), \"the keras model must be built with functional api or sequential\"\n    # save pb\n    if input_vaiablename_list is None:\n        input_vaiablename_list = list()\n    if output_vaiablename_list is None:\n        output_vaiablename_list = list()\n    if len(input_vaiablename_list) == len(keras_model.inputs):\n        input_vaiable_list = input_vaiablename_list\n    else:\n        input_vaiable_list = ['x%d' % i for i in range(len(keras_model.inputs))]\n    input_funcsignature_list = [tf.TensorSpec(item.shape, dtype=item.dtype, name=name) for name, item in\n                                zip(input_vaiable_list, keras_model.inputs)]\n    full_model = tf.function(lambda *x: keras_model(x,training=False))\n    # To obtain an individual graph, use the get_concrete_function method of the callable created by tf.function.\n    # It can be called with the same arguments as func and returns a special tf.Graph object\n    concrete_func = full_model.get_concrete_function(input_funcsignature_list)\n    # Get frozen ConcreteFunction\n    frozen_graph = convert_variables_to_constants_v2(concrete_func)\n    graph_def = frozen_graph.graph.as_graph_def()\n    out_idx = 0\n    #  and len(output_vaiablename_list) &gt; out_idx\n    # node.name = output_vaiablename_list[out_idx]\n    for node in graph_def.node:\n        node.device = \"\"\n        if node.name.startswith('Identity'):\n            out_idx += 1\n    if len(output_vaiablename_list) == out_idx:\n        ouput_vaiable_list = output_vaiablename_list\n    else:\n        ouput_vaiable_list = ['y%d' % i for i in range(out_idx)]\n    out_idx = 0\n    for node in graph_def.node:\n        node.device = \"\"\n        if node.name.startswith('Identity'):\n            node.name = ouput_vaiable_list[out_idx]\n            out_idx += 1\n    new_graph = tf.Graph()\n    with new_graph.as_default():\n        importer.import_graph_def(graph_def, name=\"\")\n#     output_graph_def = tf.compat.v1.graph_util.remove_training_nodes(new_graph.as_graph_def())\n    return tf.io.write_graph(graph_or_graph_def=new_graph,\n                             logdir=os.path.dirname(pb_filepath),\n                             name=os.path.basename(pb_filepath),\n                             as_text=False), input_vaiable_list, ouput_vaiable_list\n# test pb file\ndef wrap_frozen_graph(graph_def, inputs, outputs, print_graph=False):\n    graph = tf.Graph()\n    def _imports_graph_def():\n        tf.graph_util.import_graph_def(graph_def, name=\"\")\n    with graph.as_default():\n        wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\n    import_graph = wrapped_import.graph\n    if print_graph:\n        print(\"-\" * 50)\n        print(\"Frozen model layers: \")\n        layers = [op.name for op in import_graph.get_operations()]\n        for layer in layers:\n            print(layer)\n        print(\"-\" * 50)\n    return wrapped_import.prune(tf.nest.map_structure(import_graph.as_graph_element, inputs),tf.nest.map_structure(import_graph.as_graph_element, outputs))\ndef pbfile2concrete_function(pbfile,inputs,outputs,print_graph = False):\n    \"\"\"\n    pbfile \u8f6c concrete function\n    :param pbfile:\n    :param inputs:\n    :param outputs:\n    :param print_graph:\n    :return:\n    \"\"\"\n    with tf.io.gfile.GFile(pbfile, \"rb\") as f:\n        graph_def = tf.compat.v1.GraphDef()\n        graph_def.ParseFromString(f.read())\n        frozen_func = wrap_frozen_graph(graph_def=graph_def,\n                                        inputs=inputs,\n                                        outputs=outputs,\n                                        print_graph=print_graph)\n        return graph_def, frozen_func\nif __name__ == '__main__':\n    model1 = tf.keras.Sequential([\n        tf.keras.Input([128]),\n        tf.keras.layers.Dense(256,activation=\"relu\"),\n        tf.keras.layers.Dense(256,activation=\"relu\"),\n        tf.keras.layers.Dense(10,activation=\"softmax\"),\n    ])\n    model2 = tf.keras.Sequential([\n        tf.keras.Input([128]),\n        tf.keras.layers.Dense(256, activation=\"relu\"),\n        tf.keras.layers.Dense(256, activation=\"relu\"),\n        tf.keras.layers.Dense(10, activation=\"softmax\"),\n    ])\n    x1 = tf.keras.layers.Input([128])\n    x2 = tf.keras.layers.Input([128])\n    model = tf.keras.Model(inputs = [x1,x2], outputs=[model1(x1), model2(x2)])\n    _, input_vaiable_list, ouput_vaiable_list = freeze_keras_model2pb(model,\"test.pb\")\n    input_vaiable_list = [x+':0' for x in input_vaiable_list]\n    ouput_vaiable_list = [x+':0' for x in ouput_vaiable_list]\n    concrete_func_frompb = pbfile2concrete_function(\"test.pb\",input_vaiable_list,ouput_vaiable_list)\n    x0 = tf.random.normal((2,128), 0, 1)\n    x1 = tf.random.normal((2,128), 0, 1)\n    predictions = concrete_func_frompb(x0,x1)\n    outputs = model((x0,x1))\n    for item1,item2 in zip(predictions, outputs):\n        print(item1, item2)\n</code></pre>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#2-ckptonnxfrozen-model","title":"2 ckpt\u8f6connx\u6216frozen model","text":""},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#21-ckptonnx","title":"2.1 ckpt\u8f6connx","text":"<p>\u76f4\u63a5\u4f7f\u7528tf2onnx\u53ef\u4ee5\u8f6c\u6362</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#22-ckptfrozen-model","title":"2.2 ckpt\u8f6cfrozen model","text":"<pre><code>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.python.tools import freeze_graph\ndef freeze_graph(input_checkpoint, output_graph, output_node_names = \"Tanh\"):\n    '''\n    :param input_checkpoint:\n    :param output_graph: PB\u6a21\u578b\u4fdd\u5b58\u8def\u5f84\n    :output_node_names: \u591a\u8f93\u51fa\u4f7f\u7528\u4f7f\u7528\u9017\u53f7\u9694\u5f00\n    :return:\n    '''\n    # checkpoint = tf.train.get_checkpoint_state(model_folder) #\u68c0\u67e5\u76ee\u5f55\u4e0bckpt\u6587\u4ef6\u72b6\u6001\u662f\u5426\u53ef\u7528\n    # input_checkpoint = checkpoint.model_checkpoint_path #\u5f97ckpt\u6587\u4ef6\u8def\u5f84\n    # \u6307\u5b9a\u8f93\u51fa\u7684\u8282\u70b9\u540d\u79f0,\u8be5\u8282\u70b9\u540d\u79f0\u5fc5\u987b\u662f\u539f\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u8282\u70b9\n    g= tf.Graph() # \u83b7\u5f97\u9ed8\u8ba4\u7684\u56fe\n    with g.as_default():\n        with tf.Session(graph=g) as sess:\n            saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=True)\n            saver.restore(sess, input_checkpoint) #\u6062\u590d\u56fe\u5e76\u5f97\u5230\u6570\u636e\n#             input_graph_def = g.as_graph_def()  # \u8fd4\u56de\u4e00\u4e2a\u5e8f\u5217\u5316\u7684\u56fe\u4ee3\u8868\u5f53\u524d\u7684\u56fe\n            output_graph_def = tf.graph_util.convert_variables_to_constants(  # \u6a21\u578b\u6301\u4e45\u5316\uff0c\u5c06\u53d8\u91cf\u503c\u56fa\u5b9a\n                sess=sess,\n                input_graph_def=sess.graph_def,# \u7b49\u4e8e:sess.graph_def\n                output_node_names=output_node_names.split(\",\"))# \u5982\u679c\u6709\u591a\u4e2a\u8f93\u51fa\u8282\u70b9\uff0c\u4ee5\u9017\u53f7\u9694\u5f00\n            output_graph_def = tf.graph_util.remove_training_nodes(output_graph_def)\n            with tf.gfile.GFile(output_graph, \"wb\") as f: #\u4fdd\u5b58\u6a21\u578b\n                f.write(output_graph_def.SerializeToString()) #\u5e8f\u5217\u5316\u8f93\u51fa\n            print(\"%d ops in the final graph.\" % len(output_graph_def.node)) #\u5f97\u5230\u5f53\u524d\u56fe\u6709\u51e0\u4e2a\u64cd\u4f5c\u8282\u70b9\n            for i,n in enumerate(output_graph_def.node):\n                print(\"Name of the node - %s\" % n.name)\n</code></pre> <p>\u8c03\u7528\u793a\u4f8b\uff0c\u6ce8\u610f\u8fd9\u91ccckpt\u53ea\u5199\u5230ckpt\uff0c\u4e0d\u5199\u540e\u9762\u7684<code>.meta</code></p> <pre><code>freeze_graph('cpktpath.ckpt','pbpath.pb')\n</code></pre> <p>\u4e0a\u9762\u65b9\u5f0f\u751f\u6210\u7684pb\u6587\u4ef6\u53ef\u80fd\u4f1a\u6709\u4e9b\u95ee\u9898\uff0c\u6bd4\u5982bn\u7684<code>training</code>\u4e0d\u5e94\u8be5\u4f5c\u4e3a\u8f93\u5165\u800c\u662f\u4e00\u4e2a<code>constant</code>\uff0c\u4e0b\u9762\u7ed9\u51fa\u66ff\u6362bn\u7b97\u5b50\u7684\u89e3\u51b3\u65b9\u6848\u3002</p> <pre><code>import sys\nfrom tensorflow.core.framework import graph_pb2\nimport copy\n# load our graph\ndef load_graph(grapf_filepath):\n    tf.reset_default_graph()\n    graph_def = tf.GraphDef()\n    with tf.gfile.FastGFile(grapf_filepath, 'rb') as f:\n        graph_def.ParseFromString(f.read())\n    return graph_def\ndef replace_placeholder_with_constant(input_grapf_filepath, output_grapf_filepath,\n                                      target_node_name, replace_const = None):\n    if replace_const is None:\n        replace_const = tf.constant(False, dtype=bool, shape=[], name=target_node_name)\n    graph_def = load_graph(input_grapf_filepath)\n    # Create new graph, and rebuild it from original one\n    # replacing phase train node def with constant\n    new_graph_def = graph_pb2.GraphDef()\n    for node in graph_def.node:\n        if node.name == target_node_name:\n            new_graph_def.node.extend([replace_const.op.node_def])\n        else:\n            new_graph_def.node.extend([copy.deepcopy(node)])\n    # save new graph\n    with tf.gfile.GFile(output_grapf_filepath, \"wb\") as f:\n        f.write(new_graph_def.SerializeToString())\n</code></pre> <p>\u8c03\u7528\u793a\u4f8b\uff0c\u5b9e\u73b0\u628a\u540d\u5b57<code>Placeholder_2</code>\u7684\u8f93\u5165\u53bb\u9664\uff0c\u6539\u4e3a\u503c\u4e3a<code>False</code>\u7684<code>constant</code></p> <pre><code>replace_placeholder_with_constant('./original.pb','new.pb','Placeholder_2')\n</code></pre>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B403%E6%9C%8811%E6%97%A5%2015%E6%97%B614%E5%88%8655%E7%A7%92/#3","title":"3 \u603b\u7ed3","text":"<p>\u5728\u5b9e\u9645\u73af\u5883\u4e0b\uff0c\u5f80\u5f80\u6709\u517c\u5bb9\u65e7\u8bbe\u5907\u6216\u8005\u65e7\u7248\u672c\u7684\u9700\u6c42\uff0cfrozen graph\u5c3d\u7ba1\u5728\u65b0\u7684\u8bbe\u5907\u4e0a\u4e0d\u600e\u4e48\u5e38\u7528\u4f46\u8fd8\u662f\u9700\u8981\u7167\u987e\u4e00\u4e0b\u3002 \u6b64\u5916\uff0c\u5bf9\u4e8epb\u7684\u5904\u7406\u8fd9\u79cdhack\u65b9\u5f0f\u53ef\u80fd\u4e5f\u662f\u89e3\u51b3\u517c\u5bb9\u95ee\u9898\u7684\u4e00\u79cd\u9014\u5f84\uff0c\u6bd4\u5982\u5f53\u4f60\u4f7f\u7528\u65b0\u7684\u7248\u672c\u5bf9\u4e4b\u524d\u7248\u672c\u91cd\u6784\u4ee5\u540e\u4f1a\u51fa\u73b0\u8f93\u5165\u548c\u8f93\u51fa\u540d\u5b57\u4e0d\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u9700\u8981\u5bf9pb\u6587\u4ef6\u201c\u505a\u624b\u672f\u201d onnx\u4f5c\u4e3a\u73b0\u5728\u8f83\u4e3a\u901a\u7528\u7684\u90e8\u7f72\u683c\u5f0f\uff0c\u5c3d\u7ba1\u6709\u4e9b\u5927\u4f6c\u4e0d\u559c\u6b22\uff0c\u4f46\u4f9d\u7136\u963b\u6321\u4e0d\u4f4f\u5176\u88ab\u5404\u5927\u63a8\u7406\u6846\u67b6\u652f\u6301\u7684\u811a\u6b65\u3002\u4f46\u662fonnx\u4e2d\u7684\u7b97\u5b50\u548c\u63a8\u7406\u6846\u67b6\u4e2d\u7684\u7b97\u5b50\u53ea\u80fd\u8bf4\u6709\u4ea4\u96c6\uff0c\u9488\u5bf9\u63a8\u7406\u6846\u67b6\u4e2d\u4e0d\u652f\u6301\u7684\u7b97\u5b50\uff0c\u4f9d\u7136\u9700\u8981\u5199plugin\u6216\u8005\u62c6\u6210\u4e24\u4e2aonnx\uff0c\u4e2d\u95f4\u4e0d\u652f\u6301\u90e8\u5206\u91c7\u7528\u539f\u751f\u65b9\u5f0f\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\u3002 \u603b\u800c\u8a00\u4e4b\uff0c\u78b0\u5230\u95ee\u9898\u89e3\u51b3\u95ee\u9898\u5c31\u662f\u4e86\uff0c\u81f3\u4e8e\u600e\u4e48\u89e3\u51b3\uff0c\u5982\u4f55\u89e3\u51b3\u624d\u662f\u66f4\u5feb\u66f4\u597d\u7684\u65b9\u6848\uff0c\u8fd9\u5c31\u662f\u7ecf\u9a8c\u6240\u5728\u4e86\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/","title":"\u518d\u8c08\u81ea\u52a8\u5fae\u5206\uff1a\u81ea\u52a8\u5fae\u5206\u4e2d\u7684\u524d\u5411\u6a21\u5f0f\u4e0e\u53cd\u5411\u6a21\u5f0f","text":""},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/#_2","title":"\u4ec0\u4e48\u662f\u81ea\u52a8\u5fae\u5206","text":"<p>\u81ea\u52a8\u5fae\u5206(Automatic Differentiation)\u662f\u4ec0\u4e48\uff1f\u5fae\u5206\u662f\u51fd\u6570\u5728\u67d0\u4e00\u5904\u7684\u5bfc\u6570\u503c\uff0c\u81ea\u52a8\u5fae\u5206\u5c31\u662f\u4f7f\u7528\u8ba1\u7b97\u673a\u7a0b\u5e8f\u81ea\u52a8\u6c42\u89e3\u51fd\u6570\u5728\u67d0\u4e00\u5904\u7684\u5bfc\u6570\u503c\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/#_3","title":"\u8ba1\u7b97\u5fae\u5206\u7684\u56db\u79cd\u65b9\u5f0f","text":"<p>\u5e38\u89c1\u7684\u6c42\u89e3\u5fae\u5206\u7684\u65b9\u5f0f\uff0c\u53ef\u5206\u4e3a\u4ee5\u4e0b\u56db\u79cd\uff1a</p> <ul> <li>\u624b\u52a8\u6c42\u89e3\u6cd5(Manual Differentiation)</li> </ul> <p>\u6240\u8c13\u624b\u52a8\u6c42\u89e3\u6cd5\u5c31\u662f\u624b\u52a8\u7b97\u51fa\u6c42\u5bfc\u516c\u5f0f\uff0c\u7136\u540e\u5c06\u516c\u5f0f\u7f16\u5199\u6210\u8ba1\u7b97\u673a\u4ee3\u7801\u5b8c\u6210\u8ba1\u7b97\u3002\u6bd4\u5982\u5bf9\u4e8e\u51fd\u6570  \\(f(x) = x^2\\)  \u6c42\u5fae\u5206\uff0c\u9996\u5148\u6839\u636e\u6c42\u5bfc\u516c\u5f0f\u8868\u627e\u51fa\u5176\u5bfc\u6570\u51fd\u6570</p> \\[ f'(x) = 2x \\] <ul> <li>\u6570\u503c\u5fae\u5206\u6cd5(Numerical Differentiation)</li> </ul> <p>\u6570\u503c\u5fae\u5206\u6cd5\u76f4\u63a5\u6839\u636e\u5fae\u5206\u7684\u6781\u9650\u5b9a\u4e49\u5f62\u5f0f\uff1a</p> \\[ f'(x)=\\frac{df}{dx}=\\lim_{\\\\Delta x \\to 0}\\frac{f(x+ \\\\Delta x) - f(x)}{\\\\Delta x} \\] <p>\u5f53\u7136\u6781\u9650\u7684\u5b9a\u4e49\u91cc\u0394x\u662f\u8d8b\u4e8e0\u7684\uff0c\u6211\u4eec\u5b9e\u9645\u6570\u503c\u8ba1\u7b97\u7684\u65f6\u5019\u53ef\u4ee5\u627e\u4e00\u4e2a\u5f88\u5c0f\u7684\u6570h\uff1a</p> \\[ f'(x)=D_+(h)=\\frac{f(x+h) - f(x)}{h} \\] <ul> <li>\u7b26\u53f7\u5fae\u5206\u6cd5(Symbolic Differentiation)</li> </ul> <p>\u7b26\u53f7\u5fae\u5206\u5c31\u662f\u6211\u4eec\u5728\u5927\u5b66\u5fae\u79ef\u5206\u91cc\u5b66\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b26\u53f7\uff08\u5305\u62ec\u5206\u90e8\u79ef\u5206\u6cd5\u8fd9\u79cdtrick\uff09\u8ba1\u7b97\u76f4\u63a5\u6c42\u51fa\u5fae\u5206\u7684\u201c\u89e3\u6790\u201d\u5f62\u5f0f\u3002\u7136\u540e\u518d\u5e26\u5165\u81ea\u53d8\u91cf\u7684\u503c\u53bb\u6c42\u89e3\u5bfc\u6570\u3002</p> <ul> <li>\u81ea\u52a8\u5fae\u5206\u6cd5(Automatic Differentiation)</li> </ul>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/#_4","title":"\u524d\u5411\u6a21\u5f0f","text":"<p>\u8fd9\u91cc\u4ee5\u56fe\u7247\u4e2d\u7684 \\(f(x_1,x_2)\\) \u4e3a\u4f8b  \u56fe\u4e2d\u6c42\u5bfc\u8fc7\u7a0b\u7684\u6bcf\u4e00\u6b65\u90fd\u662f\u5728\u6c42 \\(v_{i}\\)  \u5bf9  \\(v_{-1}\\) \u7684\u5bfc\u6570\uff0c\u8fd9\u79cd\u65b9\u5f0f\u53ef\u4ee5\u5f88\u65b9\u4fbf\u7684\u6c42\u5f97\u591a\u4e2a\u8f93\u51fa\u5bf9\u5355\u4e2a\u8f93\u5165\u7684\u5bfc\u6570\uff0c\u51c6\u5219\u662f\u94fe\u5f0f\u6cd5\u5219\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/#_5","title":"\u53cd\u5411\u6a21\u5f0f","text":"<p>\u8fd9\u91cc\u4ee5\u56fe\u7247\u4e2d\u7684 \\(f(x_1,x_2)\\) \u4e3a\u4f8b  \u56fe\u4e2d\u6c42\u5bfc\u8fc7\u7a0b\u7684\u6bcf\u4e00\u6b65\u90fd\u662f\u5728\u6c42 \\(y\\)  \u5bf9  \\(v_{i}\\) \u7684\u5bfc\u6570\uff0c\u5373\u5355\u4e2a\u8f93\u51fa\u5bf9\u6240\u6709\u8f93\u5165\u7684\u5bfc\u6570\uff0c\u51c6\u5219\u4e5f\u662f\u94fe\u5f0f\u6cd5\u5219\u3002 \u53cd\u5411\u5fae\u5206\u7684\u597d\u5904\u662f\u4e00\u6b21\u53ef\u4ee5\u7b97\u51fa\u6240\u6709\u8f93\u5165\u53c2\u6570\u7684\u504f\u5bfc\u6570\u3002 \u5bf9\u4e8e\u795e\u7ecf\u7f51\u7edc\u6765\u8bf4\uff0c\u635f\u5931\u51fd\u6570\u7684\u8f93\u51fa\u503c\u4e3a\u6807\u91cf\uff0c\u4f46\u662f\u53c2\u6570\u77e9\u9635\u975e\u5e38\u591a\uff0c\u9488\u5bf9\u8fd9\u79cd\u60c5\u51b5\u4e00\u822c\u91c7\u7528\u53cd\u5411\u5fae\u5206\u8ba1\u7b97\u8f83\u4e3a\u5408\u9002\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/#_6","title":"\u590d\u6742\u5ea6\u5206\u6790","text":"<p> \u5982\u4e0a\u56fe\u6240\u8ff0\uff0c\u9488\u5bf9\u4ecen\u7ef4\u5230m\u7ef4\u7684\u6620\u5c04\uff0c\u91c7\u7528\u524d\u5411\u6a21\u5f0f\u5fae\u5206\u6216\u53cd\u5411\u6a21\u5f0f\u5fae\u5206\u8981\u770bn\u548cm\u7684\u5927\u5c0f\u800c\u5b9a\u3002\u6bd4\u5982\u4e0b\u9762\u7684\u4f8b\u5b50   \u8fd9\u91ccy\u5bf9x1\u7684\u5bfc\u6570\u662f\u4e00\u4e2a\u4e0ex1\u76f8\u540c\u5f62\u72b6\u7684\u5411\u91cf\uff0c\u524d\u5411\u6a21\u5f0f\u8ba1\u7b97\u5fae\u5206\u77e9\u9635\u4e58\u6cd5\u4ece\u5de6\u81f3\u53f3\uff0c\u53cd\u5411\u6a21\u5f0f\u8ba1\u7b97\u5fae\u5206\u77e9\u9635\u4e58\u6cd5\u4ece\u53f3\u81f3\u5de6\uff0c\u7b97\u6cd5\u590d\u6742\u5ea6\u4e00\u76ee\u4e86\u7136\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/#_7","title":"\u603b\u7ed3","text":"<p>\u4efb\u4f55\u4e00\u4e2a\u77e5\u8bc6\u70b9\u90fd\u503c\u5f97\u6df1\u6316\uff0c\u8fd9\u91cc\u8fd8\u6d89\u53ca\u8ba1\u7b97\u56fe\u7684\u5e76\u884c\u8ba1\u7b97\u76f8\u5173\u5185\u5bb9\uff0c\u6bd4\u5982\u5982\u4f55\u5e76\u884c\u7684\u5bf9\u8282\u70b9\u7684\u68af\u5ea6\u8fdb\u884c\u8ba1\u7b97\uff0c\u7531\u4e8e\u8fd9\u4e0d\u662f\u672c\u4eba\u7684\u4e13\u4e1a\u5728\u6b64\u5c31\u4e0d\u5728\u6df1\u5165\u7814\u7a76\u3002 \u5f15\u7528\u9a6c\u54f2\u4e2d\u7684\u4e00\u4e2a\u7406\u8bba\uff1a\u5bf9\u4e00\u4e2a\u4e8b\u7269\u7684\u8ba4\u8bc6\u5f80\u5f80\u9700\u8981\u4ece\u5b9e\u8df5\u5230\u8ba4\u8bc6\u3001\u518d\u7531\u8ba4\u8bc6\u5230\u5b9e\u8df5\u7684\u591a\u6b21\u53cd\u590d\uff0c\u624d\u80fd\u5b8c\u6210\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/2022%E5%B9%B404%E6%9C%8801%E6%97%A5%2023%E6%97%B630%E5%88%8626%E7%A7%92/#_8","title":"\u53c2\u8003\u94fe\u63a5","text":"<ul> <li>https://zhuanlan.zhihu.com/p/161635270</li> <li>https://zhuanlan.zhihu.com/p/61103504</li> <li>https://www.bilibili.com/video/BV1ZA411H7BU</li> <li>http://fancyerii.github.io/books/autodiff/</li> <li>https://arxiv.org/pdf/1502.05767.pdf</li> </ul>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/","title":"\u5206\u5e03\u5f0f\u8bad\u7ec3\u573a\u666f\u4e0bModelEMA\u7684\u4f18\u5316","text":"<p>\u672c\u6587\u5199\u4e8e2024\u5e749\u67089\u53f7\u665a22\u70b9</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#_1","title":"\u4e00\u3001\u524d\u8a00","text":"<p>\u6709\u4e00\u5929\u767d\u5929\u559d\u8336\u996e\u6599\u559d\u591a\u4e86\uff0c\u600e\u4e48\u4e5f\u7761\u4e0d\u7740\u3002\u4e8e\u662f\u5c1d\u8bd5\u60f3\u4e00\u60f3ModelEMA\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u7248\u672c\uff0c\u7531\u4e8e\u4e0d\u6ee1\u8db3\u4e8e\u8fd9\u79cd\u7cfb\u7edf\u5b9e\u73b0\u4e0a\u7684\u4f18\u5316\uff0c\u624b\u63a8\u516c\u5f0f\u4e00\u987f\u8fd1\u4f3c\u5316\u7b80\u60f3\u628aModelEMA\u7684\u884c\u4e3a\u653e\u5230\u4f18\u5316\u5668\u4e2d\uff0c\u7ed3\u679c\u7b2c\u4e8c\u5929\u4e00\u65e9\u5b9e\u73b0\u540eLoss NaN\u3002</p> <p>\u5c31\u8fd9\u6837\u62d6\u4e86\u4e00\u5468\uff0c\u518d\u5230\u540e\u9762\u91cd\u65b0\u601d\u8003ModelEMA\u7684\u5206\u5e03\u5f0f\u5b9e\u73b0\uff0c\u521a\u597d\u770b\u5230torch\u5b98\u65b9zero2\u7684\u6e90\u7801\uff0c\u6240\u4ee5\u5c06\u5176\u53c2\u6570\u5e73\u5747\u5206\u914d\u5230\u5404\u4e2arank\u7684\u7b97\u6cd5\u79fb\u690d\u8fc7\u6765\uff0c\u518d\u52a0\u4e0a\u5c06\u4e0d\u8fde\u7eed\u5185\u5b58\u5408\u5e76\u7684\u4f18\u5316\uff0c\u6548\u679c\u771f\u7684\u5f88\u60ca\u8273\u3002</p> <p>\u6700\u5f00\u59cb\u7684\u60f3\u6cd5\u542f\u53d1\u4e8ezero2\uff0c\u5373\u9488\u5bf9EMA\u8fd0\u7b97\uff0c\u6bcf\u4e2a\u8ba1\u7b97\u5361\u5206\u522b\u5b58\u50a8\u548c\u8ba1\u7b97\u6a21\u578b\u6574\u4f53\u53c2\u6570\u7684\u4e00\u5c0f\u90e8\u5206\uff0c\u5728\u6a21\u578b\u8bc4\u4f30\u9636\u6bb5\u518d\u5bf9\u6240\u6709\u53c2\u6570\u8fdb\u884call gather\u64cd\u4f5c\u3002</p> <p>\u4ee58\u5361\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u4e3a\u4f8b\uff0c\u8bb0\u539f\u59cbyolov5 EMA\u66f4\u65b0\u64cd\u4f5c\u5355\u4e2atraining step 55ms\uff0c\u5f00\u542f\u5206\u5e03\u5f0fEMA\u540e\u8fbe\u52307ms\uff08\u63a5\u8fd155/8\uff09\uff0c\u5f00\u542f\u5185\u5b58\u5408\u5e76\u540e\u964d\u4e3a0.5ms\uff0c\u901f\u5ea6\u63d0\u5347\u4e86100\u591a\u500d\uff01</p> <p>\u7531\u4e8e\u5c0f\u6a21\u578b\u53c2\u6570\u91cf\u4e0d\u5927\uff0c\u6240\u4ee5\u6ca1\u6709\u8ba1\u7b97\u8282\u7701\u7684\u53c2\u6570\u91cf\u3002</p> <p>\u672c\u6587\u76f8\u5173\u4ee3\u7801\u5f00\u6e90\u5728 https://github.com/thb1314/distributed_modelema</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#_2","title":"\u4e8c\u3001\u5b9e\u73b0\u539f\u7406","text":"<p>ModelEMA\u53ef\u4ee5\u6709\u6548\u5730\u7f13\u89e3\u8fc7\u62df\u5408\u95ee\u9898\u5e76\u63d0\u5347\u6cdb\u5316\u6027\uff0c\u5728\u81ea\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff0c\u6bd4\u5982MoCO\u3001DINO\u3001BYOL\u7b49\uff0cModelEMA\u5728\u8be5\u7c7b\u8bad\u7ec3\u4efb\u52a1\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\u3002</p> <p>ModelEMA\u7684\u66f4\u65b0\u8fc7\u7a0b\u5982\u4e0b</p> \\[ \\zeta_{t+1}=\\rho \\zeta_t+(1-\\rho) \\theta_t \\] <p>\u5176\u4e2d \\(\\zeta\\) \u8868\u793aEMA\u6a21\u578b\u53c2\u6570\uff08\u521d\u59cb\u5316\u4e3a\u6a21\u578b\u53c2\u6570\uff09\uff0c \\(\\theta_t\\) \u8868\u793aoptimizer\u66f4\u65b0\u540e\u7684\u6a21\u578b\u53c2\u6570\u3002</p> <p>\u542f\u53d1\u4e8eZERO2\uff0c\u9488\u5bf9\u4e0a\u8ff0\u8fd0\u7b97\uff0c\u5047\u8bbe\u603b\u5171\u7684\u8ba1\u7b97\u5355\u5143\u6709world_size\u4e2a\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u539f\u7248\u6a21\u578b\u7684\u53c2\u6570\u5206\u4e3aworld_size\u7ec4\uff0c\u6bcf\u7ec4\u53c2\u6570\u5206\u522b\u5728\u5404\u81ea\u7684\u8ba1\u7b97\u5355\u5143\u4e2d\u6267\u884cEMA\u64cd\u4f5c\uff0c\u6700\u540e\u5728\u6709\u9700\u8981\u7684\u65f6\u5019\u518d\u5c06\u53c2\u6570all gather\u5230\u6240\u6709\u673a\u5668\u4e2d\u3002</p> <p>\u90a3\u4e48\u4ec0\u4e48\u65f6\u5019\u662f\u201c\u6709\u9700\u8981\u7684\u65f6\u5019\u201d\u5462\uff1f\u5373\u201c\u9700\u8981\u91c7\u7528EMA\u540e\u7684\u6a21\u578b\u505a\u8bc4\u4f30\u7684\u65f6\u5019\u201d</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#_3","title":"\u4e09\u3001\u5b9e\u73b0\u7ec6\u8282","text":"<p>\u82e5\u8981\u5b9e\u73b0\u5206\u5e03\u5f0f\u7248\u672cEMA\uff0c\u53c2\u6570\u5206\u914d\u7b97\u6cd5\u548c\u53c2\u6570\u540c\u6b65\u76f4\u89c2\u91cd\u8981\u3002\u672c\u6587\u63d0\u51fa\u7684\u5b9e\u73b0\uff0c\u9996\u5148\u5c06state_dict\u4e2d\u7684\u53c2\u6570\u8f6c\u6362\u4e3aparameter\u4e2d\u7684\u53c2\u6570\uff0c\u63a5\u7740\u91c7\u7528\u53c2\u6570\u5206\u914d\u7b97\u6cd5\u5c06parameter\u5212\u5206\u5230\u5404\u4e2arank\u4e2d\uff0c\u7136\u540e\u5728\u6709\u5fc5\u8981\u7684\u65f6\u5019\u6267\u884cEMA\u540c\u6b65\u64cd\u4f5c\uff0c\u540c\u65f6\u53ef\u4ee5\u6709\u9009\u62e9\u6027\u5730\u91c7\u7528Tensor\u5408\u5e76\u7b97\u6cd5\u5bf9EMA\u8fc7\u7a0b\u8fdb\u884c\u4f18\u5316\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#31","title":"3.1 \u53c2\u6570\u63a5\u53e3\u8f6c\u6362","text":"<p>\u7531\u4e8estate_dict\u4e2d\u53c2\u6570\u90fd\u662fdetach\u540e\u7684\uff0c\u5982\u4e0b\u4ee3\u7801\u7247\u6bb5\u5b9e\u73b0\u5c06<code>model.state_dict()</code>\u4e2d\u7684\u53c2\u6570\u8f6c\u6362\u4e3a\uff08\u6765\u4e0d\u53ca\u89e3\u91ca\u4e86\uff0c\u770b\u5982\u4e0b\u6e90\u7801\u5427\uff09</p> <pre><code># \u6536\u96c6\u539f\u6a21\u578b state_dict\nself._ori_state_dict:Dict[str, nn.Parameter] = de_parallel(model).state_dict()\n# replace to original parameter\n# \u539f\u6a21\u578b state_dict \u4e0e pamameter\u548cbuffer\u4e2d\u7684\u53c2\u6570data_ptr\u76f8\u540c\nori_param_dict = {param.data_ptr():param for param in de_parallel(model).parameters()}\nori_param_dict.update({buffer.data_ptr():buffer for buffer in de_parallel(model).buffers()})\n\n# \u7edf\u8ba1\u4e0d\u9700\u8981ema\u7684\u53c2\u6570\nself._no_need_ema_dict = dict()\nfor name, param in self._ori_state_dict.items():\n    if param.data_ptr() in ori_param_dict and param.dtype.is_floating_point:\n        self._ori_state_dict[name] = ori_param_dict[param.data_ptr()]\n        else:\n            self._no_need_ema_dict[name] = param\n            for rm_name in self._no_need_ema_dict:\n                self._ori_state_dict.pop(rm_name)\n</code></pre>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#32","title":"3.2 \u53c2\u6570\u5206\u914d\u7b97\u6cd5","text":"<p>\u53c2\u8003ZeroRedundancyOptimizer\u7684\u5b9e\u73b0\uff0cpartition_parameters \u65b9\u6cd5\u4f1a\u5c06\u53c2\u6570\u8fdb\u884c\u5206\u533a\uff0c\u6839\u636e\u53c2\u6570\u5927\u5c0f\uff08\u800c\u4e0d\u662f\u4f7f\u7528\u987a\u5e8f\uff09\u4ee5\u6392\u5e8f\u8d2a\u5a6a\uff08sorted-greedy\uff09\u7b97\u6cd5\u6765\u5bf9\u4f18\u5316\u5668\u72b6\u6001\u8fdb\u884c\u5206\u7247\uff0c\u5728\u6bcf\u4e2arank\u4e2d\u6253\u5305\u4e00\u4e9b\u53c2\u6570\uff0c\u8fd9\u6837\u6bcf\u4e2a\u53c2\u6570\u90fd\u5c5e\u4e8e\u4e00\u4e2arank\uff0c\u4e0d\u5728ranks\u4e4b\u95f4\u5212\u5206\u3002\u5206\u533a\u662f\u4efb\u610f\u7684\uff0c\u53ef\u80fd\u4e0e\u53c2\u6570\u6ce8\u518c\u6216\u4f7f\u7528\u987a\u5e8f\u4e0d\u5339\u914d\u3002\u8fd9\u662f\u4e3a\u4e86\u786e\u4fdd\u6bcf\u4e2arank\u5177\u6709\u51e0\u4e4e\u76f8\u540c\u5927\u5c0f\u7684\u663e\u5b58\u3002</p> <pre><code>def partition_parameters(self) -&gt; List[Dict[str, nn.Parameter]]:\n    r\"\"\"\n        Partitions parameters across distributed data parallel ranks.\n\n        Returns:\n            a list of ``param_groups`` (which is a list of dict) where each\n            element of the list contains the param_groups for a rank. Element 0\n            corresponds to rank 0, etc. We need all the ranks for the broadcast\n            inside ``get_model_state_dict()``.\n        \"\"\"\n    if len(self._partition_parameters_cache) == 0:\n        self._partition_parameters_cache = [dict() for _ in range(self.world_size)]\n        # \u751f\u6210\u4e00\u4e2a\u6570\u7ec4\uff0c\u7528\u6765\u8bb0\u5f55\u6bcf\u4e2arank\u7684\u5927\u5c0f\uff0c\u4e00\u5171\u6709world size\u4e2arank\n        sizes = [0] * self.world_size\n\n        # \u904d\u5386\u53c2\u6570\u7ec4\n        param_lists: List[List[Tuple[str, nn.Parameter]]] = [list() for _ in range(self.world_size)]\n            for name, param in self._ori_state_dict.items():\n                # add this param to rank with smallest size\n                # \u627e\u5230\u6700\u5c0f\u7684\u90a3\u4e2arank\n                rank = sizes.index(min(sizes))\n                # \u628a\u53c2\u6570\u653e\u5230\u6700\u5c0frank\u4e4b\u4e2d\n                param_lists[rank].append((name, param))\n                # \u589e\u52a0rank\u7684\u5927\u5c0f\n                sizes[rank] += param.numel()\n\n                # \u904d\u5386list\n                for rank, param_tuple_list in enumerate(param_lists):\n                    for name, param in param_tuple_list:\n                        self._partition_parameters_cache[rank][name] = param\n\n                        return self._partition_parameters_cache\n</code></pre> <p>\u8fd9\u91cc\u5c31\u5206\u533a\u597d\u4e86\uff0c\u6700\u7ec8\u8fd4\u56de\u4e00\u4e2aparam_groups \u7684\u5217\u8868\uff08\u8fd9\u662f\u4e00\u4e2adict\u5217\u8868\uff09\uff0c\u5217\u8868\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u5305\u542b\u4e00\u4e2arank\u7684param_groups\uff0c\u6bd4\u5982\u5143\u7d200\u5bf9\u5e94\u4e8erank 0\uff0c\u6bcf\u4e2arank\u7684group\u7684\u53c2\u6570\u6709\u5dee\u4e0d\u591a\u5927\u5c0f\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#33-ema","title":"3.3 \u540c\u6b65EMA\u53c2\u6570","text":"<p>\u9700\u8981\u6ce8\u610f\u7684\u662f<code>get_model_state_dict</code>\u9700\u8981\u6bcf\u4e2arank\u90fd\u5f97\u6267\u884c\uff0c\u901a\u8fc7\u5224\u65ad\u53c2\u6570\u662f\u5728\u5f53\u524drank\u4e0b\u8fd8\u662f\u5176\u4ed6rank\u4e0b\u6765\u83b7\u53d6\u6e90\u5934\u7684rank\u5730\u5740\uff0c\u4e4b\u540e\u6267\u884c<code>dist.broadcast</code>\u6765\u5e7f\u64adtensor\u5230\u5176\u4ed6rank\u3002</p> <pre><code>    def get_model_state_dict(self, strict=True):\n        ema_state_dict = OrderedDict()\n        ori_state_dict = OrderedDict()\n        handles = []\n\n        for key in self._ori_state_dict:\n            if key in self._no_need_ema_dict:\n                if not strict:\n                    continue\n                # adopt its original reference\n                ema_state_dict[key] = self._no_need_ema_dict[key]\n                ori_state_dict[key] = self._no_need_ema_dict[key]\n            elif key in self._ori_state_dict:\n                # send parameters\n                if key in self._cur_rank_param:\n                    param_value = self._cur_rank_param[key]\n                    ema_state_dict[key] = param_value\n                    ori_state_dict[key] = self._ori_cur_rank_param[key].detach().clone()\n                    if self.world_size &gt; 1:\n                        handles.append(dist.broadcast(tensor=param_value.data, src=self.rank, group=self.group, async_op=True))\n                elif key in self._other_rank_param:\n                    param_value = self._other_rank_param[key]\n                    src_rank = self._other_param2rank[param_value]\n                    ori_state_dict[key] = param_value.detach().clone()\n                    param_value = param_value.detach().clone()\n                    ema_state_dict[key] = param_value\n                    if self.world_size &gt; 1:\n                        handles.append(dist.broadcast(tensor=param_value.data, src=src_rank, group=self.group, async_op=True))\n                else:\n                    raise RuntimeError(f\"{key} not in parameter list\")\n            else:\n                raise RuntimeError(f\"{key} not in parameter list\")\n\n        _ = list(map(lambda x: x.wait(), handles))\n        return ema_state_dict, ori_state_dict\n</code></pre> <p>\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cbroadcast\u64cd\u4f5c\u662f\u5f02\u6b65\u7684\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#34-tensor","title":"3.4 Tensor\u5408\u5e76","text":"<p>\u5982\u679c\u8bbe\u7f6e\u4e86<code>parameters_as_bucket_view</code>\uff0c\u5219\u8c03\u7528\u5efa\u7acb\u82e5\u5e72buffer\u3002\u540c\u6837\u8bbe\u5907\u4e0a\u540c\u6837rank\u7684\u5f20\u91cf\u5408\u5e76\u4e00\u4e2abuffer\uff0c\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f\u4e2a\u522b\u5904\u7406\u7684\u5b57\u8282\u5bf9\u9f50\u95ee\u9898\uff0c\u672c\u6587\u5b9e\u73b0\u7684\u662f8\u5b57\u8282\u5bf9\u9f50\u7248\u672c\u3002</p> <pre><code>        if parameters_as_bucket_view and self._ori_cur_rank_param:\n            device = next(iter(self._ori_cur_rank_param.values())).device\n            dtype = next(iter(self._ori_cur_rank_param.values())).dtype\n            buffer_size = 0\n            # 8 bytes aligned\n            grid_size = 8 // item_size_dict[dtype]\n\n            # \u7edf\u8ba1\u53c2\u6570\u6392\u5e8f\u4fe1\u606f\n            for key, param in self._ori_cur_rank_param.items():\n                offset_start = buffer_size\n                buffer_size += (param.numel() + grid_size - 1) // grid_size * grid_size\n                self._bucket_data_info_dict[key] = {\n                    \"offset_start\": offset_start,\n                    \"offset_end\": buffer_size,\n                    \"real_size\": param.numel()\n                }\n               # \u521d\u59cb\u5316 bucket \u53c2\u6570\u5927\u5c0f\n            bucket = nn.Parameter(torch.empty(buffer_size, dtype=dtype, device=device), requires_grad=False)\n            self._ori_cur_rank_bucket = bucket\n\n            # \u6839\u636e\u504f\u79fb copy \u539f\u59cb\u6570\u636e\n            for key, param in self._ori_cur_rank_param.items():\n                data_info_dict = self._bucket_data_info_dict[key]\n                offset = data_info_dict['offset_start']\n                offset_next = offset + data_info_dict['real_size']\n                bucket[offset:offset_next].copy_(param.data.flatten(), non_blocking=False)\n                param.data = bucket[offset:offset_next].view_as(param.data)\n\n        self._cur_rank_param:Dict[str, nn.Parameter] = dict()\n        self._cur_rank_bucket:Optional[nn.Parameter] = None\n        if self._ori_cur_rank_bucket is not None:\n            self._cur_rank_bucket = self._ori_cur_rank_bucket.detach().clone()\n\n        # \u5982\u679c\u8bbe\u7f6e\u4e86bucket\u5219\u5c06param.data\u6307\u5411buffer\u4e2d\u7684\u533a\u57df\uff0c\u4ece\u800cparam\u7684\u66f4\u65b0\u4f1a\u81ea\u52a8\u66f4\u65b0\u5230buffer\n        for name, param in self._ori_cur_rank_param.items():\n            param = param.detach().clone()\n            self._cur_rank_param[name] = param\n            param.requires_grad_(False)\n            if self._cur_rank_bucket is not None:\n                data_info_dict = self._bucket_data_info_dict[name]\n                offset = data_info_dict[\"offset_start\"]\n                offset_next = offset + data_info_dict[\"real_size\"]\n                param.data = self._cur_rank_bucket[offset:offset_next].view_as(param.data)\n</code></pre> <p>\u5f00\u542fTensor\u5408\u5e76\u540e\uff0c\u5927\u5927\u63d0\u9ad8\u7684\u7a0b\u5e8f\u7684\u5e76\u884c\u5316\u7a0b\u5ea6\uff0c\u4ece\u800c\u83b7\u5f97\u6781\u81f4\u7684\u52a0\u901f\u6548\u679c\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#_4","title":"\u603b\u7ed3","text":"<p>ModelEMA\u7684\u5206\u5e03\u5f0f\u5b9e\u73b0\u4e0d\u7b97\u5f88\u96be\uff0c\u4e3e\u4e00\u53cd\u4e00\uff0c\u5f88\u6734\u7d20\u7684\u60f3\u6cd5\u3002</p> <p>\u5c3d\u7ba1\u601d\u8def\u7b80\u5355\uff0c\u4f46\u662f\u6548\u679c\u771f\u7684\u5f88\u60ca\u8273\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/distributed_ema/#_5","title":"\u53c2\u8003\u6587\u732e\u4e0e\u94fe\u63a5","text":"<ul> <li>PyTorch \u5206\u5e03\u5f0f\u4e4b ZeroRedundancyOptimizer</li> </ul>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/gray_image_pretrained_on_imagenet/","title":"\u7070\u5ea6\u56fe\u5206\u7c7b\u91c7\u7528Imagenet\u9884\u8bad\u7ec3\u65f6\u5377\u79ef\u6838\u538b\u7f29Trick","text":"<p>\u672c\u6587\u5199\u4e8e2023-07-20\u665a\u4e0a\u5341\u70b9</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/gray_image_pretrained_on_imagenet/#_1","title":"\u4e00\u3001\u5de5\u4e1a\u76f8\u673a\u6210\u50cf\u7684\u5b9e\u9645\u9700\u6c42","text":"<p>\u5de5\u4e1a\u76f8\u673a\u53c8\u79f0\u6444\u50cf\u673a\uff0c\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684\u6c11\u7528\u76f8\u673a\uff08\u6444\u50cf\u673a\uff09\u800c\u8a00\uff0c\u5b83\u5177\u6709\u9ad8\u7684\u56fe\u50cf\u7a33\u5b9a\u6027\u3001\u9ad8\u4f20\u8f93\u80fd\u529b\u548c\u9ad8\u6297\u5e72\u6270\u80fd\u529b\u7b49\uff0c\u76ee\u524d\u5e02\u9762\u4e0a\u7684\u5de5\u4e1a\u76f8\u673a\u5927\u591a\u662f\u57fa\u4e8e CCD\uff08Charge CoupledDevice\uff09\u6216 CMOS\uff08Complementary MetalOxide Semiconductor\uff09\u82af\u7247\u7684\u76f8\u673a\u3002</p> <p>\u5de5\u4e1a\u76f8\u673a\u6210\u50cf\u6709\u9ed1\u767d\uff08gm\uff09\u4e0e\u5f69\u8272\uff08gc\uff09\u4e24\u79cd\uff0c\u5206\u522b\u4e3a\u4e24\u79cd\u4e0d\u540c\u7684\u50cf\u7d20\u5b58\u50a8\u683c\u5f0f\u3002</p> <p>\u76f8\u6bd4\u8f83\u4e8e\u81ea\u7136\u56fe\u50cf\u57fa\u672c\u4e3a\u5f69\u8272\u56fe\u50cf\uff0c\u5de5\u4e1a\u76f8\u673a\u6210\u50cf\u4e2d\u7070\u5ea6\u56fe\u4f9d\u7136\u5360\u6709\u5f88\u5927\u6bd4\u4f8b\u3002</p> <p>\u5bf9\u4e8e\u7070\u5ea6\u56fe\u50cf\u505a\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff0c\u6211\u4eec\u5f80\u5f80\u4f1a\u91c7\u7528\u4e00\u4e9b\u6210\u719f\u7684\u6a21\u578b\u67b6\u6784\uff0c\u6bd4\u5982resnet\u3001vgg\u7b49\u3002</p> <p>\u5b9e\u8df5\u8bc1\u660e\uff0cImagenet\u9884\u8bad\u7ec3\u5bf9\u5de5\u4e1a\u4ea7\u54c1\u7684\u7070\u5ea6\u56fe\u50cf\u4f9d\u7136\u6709\u8fc1\u79fb\u5b66\u4e60\u6548\u679c\uff0c\u90a3\u4e48\u91c7\u7528\u5355\u901a\u9053\u7070\u5ea6\u56fe\u76f8\u91c7\u7528Imagenet\u9884\u8bad\u7ec3\u5c31\u5fc5\u7136\u9700\u8981\u91c7\u7528\u5176\u5bf9\u5e94\u7684\u56fe\u7247\u9884\u5904\u7406\u65b9\u5f0f\uff0c\u5373\u5c06\u56fe\u7247\u6269\u5145\u4e3a\u4e09\u901a\u9053\u7136\u540e\u51cf\u53bb\u5747\u503c\u9664\u4ee5\u6807\u51c6\u5dee\uff0c\u53ef\u662f\u7070\u5ea6\u56fe\u50cf\u662f\u5355\u901a\u9053\u7684\u5440\uff0c\u662f\u5426\u6709\u4e00\u79cd\u65b9\u6cd5\u6765\u5bf9\u6a21\u578b\u7ed3\u6784\u505a\u4e00\u6b21\u7b49\u4ef7\u4ee3\u6362\u4ece\u800c\u4f7f\u5f97\u73b0\u6709\u6a21\u578b\u76f4\u63a5\u4ece\u5355\u901a\u9053\u56fe\u50cf\u8fdb\u884c\u8ba1\u7b97\uff0c\u800c\u4e0d\u9700\u8981\u5c06\u5355\u901a\u9053\u590d\u5236\u4e3a\u4e09\u901a\u9053\u5462\uff1f</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/gray_image_pretrained_on_imagenet/#_2","title":"\u4e8c\u3001\u516c\u5f0f\u63a8\u5bfc","text":"<p>\u5176\u5b9e\u5728\u89c6\u9891\u7406\u89e3\u4efb\u52a1\u4e2d\uff0c\u5e38\u5e38\u91c7\u7528\u6269\u5145Imagenet\u9884\u8bad\u7ec32D\u5377\u79ef\u6838\u7684\u529e\u6cd5\uff0c\u5c062D\u5377\u79ef\u6269\u5145\u4e3a3D\u5377\u79ef\uff0c\u6700\u7ec8\u76ee\u6807\u662f\u4e3a\u4e86\u5b9e\u73b0\u5728\u8f93\u5165\u76f8\u540cN\u4e2a\u56fe\u7247\u7ec4\u6210\u7684\u4e00\u4e2aSequence\u4e2d\uff0c\u5f97\u5230N\u4e2a\u4e0e\u539f\u67652D Imagenet\u9884\u8bad\u7ec3\u63a8\u7406\u51fa\u7684\u76f8\u540c\u7684\u7279\u5f81\u56fe\u3002</p> <p>\u7c7b\u6bd4\u4e8e\u4e0a\u9762\u7684\u539f\u7406\uff0c\u5728\u6ca1\u6709\u51cf\u53bb\u5747\u503c\u9664\u4ee5\u6807\u51c6\u5dee\u7684\u64cd\u4f5c\u65f6\uff0c\u56e0\u4e3a\u5355\u901a\u9053\u56fe\u50cf\u4f1a\u770b\u505a\u5404\u4e2a\u901a\u9053\u503c\u90fd\u76f8\u540c\u7684\u4e09\u901a\u9053\u56fe\u50cf\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u5f88\u81ea\u7136\u7684\u5c063\u901a\u9053\u8f93\u5165\u7684\u5377\u79ef\u6838\uff0c\u5728\u8f93\u5165\u901a\u9053\u4e0a\u7d2f\u52a0\uff0c\u5b9e\u73b0\u5bf9\u5355\u901a\u9053\u56fe\u7247\u7684\u5377\u79ef\u64cd\u4f5c\u3002</p> <p>\u8bbe\u8f93\u5165\u56fe\u50cf\u4e3a  \\(\\rm{X} \\in R^{3,H,W}\\) \uff0cX\u7684\u4e09\u4e2a\u901a\u9053\u6ee1\u8db3 \\(\\rm{X_r} = \\rm{X_g} = \\rm{X_b} = \\rm{X_{gray}} \\in R^{H,W}\\) \u3002 \\(\\rm{X_{gray}}\\) \u8868\u793a\u7070\u5ea6\u56fe\u50cf\u3002\u8bbe\u5377\u79ef\u6838\u6743\u91cd\u4e3a \\(\\rm{W} \\in R^{C_{out}, C_{in}, K_h, K_w}\\) \uff0cbias\u4e3a \\(\\rm{b} \\in R^{C_{out}}\\) \u3002\u5176\u4e2d \\(\\rm{C}_{out}\\) \u4e3a\u8f93\u5165\u901a\u9053\u6570\uff0c \\(\\rm{C}_{in}\\) \u4e3a\u8f93\u5165\u901a\u9053\u6570\uff0c\u6b64\u65f6 \\(\\rm{C}_{in}=3\\) \uff0c \\(\\rm{K}_h, \\rm{K}_w\\) \u4e3a\u5377\u79ef\u6838\u7684\u9ad8\u548c\u5bbd\uff0c \\(*\\)  \u8868\u793a\u5377\u79ef\u64cd\u4f5c\uff0c\u4e0d\u8003\u8651batch\u7ef4\u5ea6\uff0c\u8f93\u51fa \\(\\rm{output} \\in R^{C_{out},H',W'}\\) </p> <p>\u5bf9\u8f93\u5165\u56fe\u50cf\u76f4\u63a5\u505a\u5377\u79ef\u64cd\u4f5c\u7684\u516c\u5f0f\u5982\u4e0b\uff0c</p> \\[ \\begin{aligned} \\rm{output} &amp;= \\rm{W} * \\rm{X} + \\rm{b} \\\\             &amp;= \\rm{reduce\\_sum}(\\rm{W}, \\rm{axis}=1, \\rm{keepdim}=true) * \\rm{X_{gray}} + \\rm{b} \\end{aligned} \\] <p>\u5176\u4e2d \\(\\rm{reduce\\_sum}\\) \u8868\u793a\u5bf9\u5f20\u91cf\u7279\u5b9a\u7ef4\u5ea6\u5f52\u7ea6\u6c42\u548c\uff0c\u4e00\u822c\u5f20\u91cf\u8fd0\u7b97\u5e93\u90fd\u652f\u6301\u8be5\u8fd0\u7b97\u3002</p> <p>\u53ef\u662f\u5728Imagenet\u9884\u8bad\u7ec3\u8981\u6c42\u7684\u9884\u5904\u7406\u6761\u4ef6\u4e0b\uff0c\u5373\u9664\u4ee5255\u540e\uff0c\u51cf\u53bb\u5747\u503c\u9664\u4ee5\u6807\u51c6\u5dee\uff0c\u6211\u4eec\u53c8\u8be5\u5316\u7b80\u8be5\u8fc7\u7a0b\u5462\uff1f</p> <p>\u8bbeImagenet\u6570\u636e\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee \\(\\rm{mean} = [0.485, 0.456, 0.406]\\) \uff0c \\(\\rm{std} = [0.229, 0.224, 0.225]\\) \u3002</p> <p>\u5377\u79ef\uff08\u53c2\u8003<code>im2col</code>\uff09\u548c\u77e9\u9635\u4e58\u6cd5\u53ef\u4ee5\u7b49\u4ef7\uff0c\u6ee1\u8db3\u7ed3\u5408\u5f8b\uff0c\u5219\u4e0a\u8ff0\u8fc7\u7a0b\u53ef\u4ee5\u5199\u51fa\u5982\u4e0b\u516c\u5f0f\uff1a</p> \\[ \\begin{aligned} \\rm{output} &amp;= \\rm{W} * \\frac{ \\frac{\\rm{X}}{255} - \\rm{mean} }{ \\rm{std} } + \\rm{b} \\\\             &amp;= \\rm{W} * \\frac{ \\rm{X} - 255 \\times \\rm{mean} }{ 255 \\times \\rm{std} } + \\rm{b} \\\\             &amp;= \\frac{\\rm{W}}{255 \\times \\rm{std}} * \\rm{X} -  \\rm{W} * \\rm{full\\_like}(\\rm{X}, \\frac{ \\rm{mean} }{ \\rm{std} }) + \\rm{b} \\\\             &amp;= \\rm{reduce\\_sum}(\\frac{\\rm{W}}{255 \\times \\rm{std}}, \\rm{axis}=1, \\rm{keepdim}=true) * \\rm{X_{gray}} + \\rm{b} \\\\             &amp;\\ \\ \\ \\ + \\rm{reduce\\_mean}(-  \\rm{W} * \\rm{full\\_like}(\\rm{X}, \\frac{ \\rm{mean} }{ \\rm{std} }), axis=[-1, -2], \\rm{keepdim}=false) \\end{aligned} \\] <p>\u5176\u4e2d \\(\\rm{full\\_like}(\\rm{X}, \\frac{ \\rm{mean} }{ \\rm{std} })\\) \u8868\u793a\u4e00\u4e2a\u4e0eX\u5f62\u72b6\u76f8\u540c\uff0c\u4e14\u4e09\u4e2a\u901a\u9053\u7684\u503c\u4e3a \\(\\frac{ \\rm{mean} }{ \\rm{std} }\\) \u7684\u5f20\u91cf\u3002  \\(\\rm{reduce\\_mean}\\) \u8868\u793a\u5bf9\u5f20\u91cf\u7279\u5b9a\u7ef4\u5ea6\u8fdb\u884c\u5f52\u7ea6\u6c42\u5e73\u5747\u3002</p> <p>\u4ece\u4e0a\u9762\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\u4e0a\u9762\u9884\u5904\u7406\u7684\u8fc7\u7a0b\u53ef\u4ee5\u878d\u5408\u5230\u5377\u79ef\u6838\uff0c\u65b0\u7684\u6743\u91cd\u662f \\(\\rm{reduce\\_sum}(\\frac{\\rm{W}}{255 \\times \\rm{std}}, \\rm{axis}=1, \\rm{keepdim}=true)\\) \uff0c\u65b0\u7684bias\u4e3a \\(\\rm{b} + \\rm{reduce\\_mean}(-  \\rm{W} * \\rm{full\\_like}(\\rm{X}, \\frac{ \\rm{mean} }{ \\rm{std} }), axis=[-1, -2], \\rm{keepdim}=false)\\)  \u3002\u5982\u4f55\u7406\u89e3bias\u9879\u4e2d\u7684\u540e\u9879\u5462\uff1f\u8bfb\u8005\u53ef\u4ee5\u8bd5\u60f3\u4e00\u4e0b\uff0c\u5728\u5377\u79ef\u6838\u53c2\u6570\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u8f93\u5165\u5f20\u91cf\u7684\u6bcf\u4e2a\u901a\u9053\u5185\u90e8\u90fd\u662f\u76f8\u540c\u7684\u503c\uff0c\u90a3\u4e48\u662f\u4e0d\u662f\u610f\u5473\u7740\u8f93\u51fa\u901a\u9053\u7684\u5185\u90e8\uff0c\u6bcf\u4e2a\u8f93\u51fa\u901a\u9053\u5185\u90e8\u503c\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u6b64\u65f6\u5bf9\u5176\u6c42mean\u5b9e\u9645\u4e0a\u7b49\u4ef7\u4e8e\u5229\u7528\u5f20\u91cf\u8fd0\u7b97\u5e93\u4e2d\u7684\u5e7f\u64ad\u673a\u5236\uff0c\u5c06\u4e00\u4e2a\u901a\u9053\u5185\u90e8\u5143\u7d20\u76f8\u540c\u7684\u5f20\u91cf\u8f6c\u6362\u4e3a\u4e00\u4e2a\u5411\u91cf\u8868\u793a\uff0c\u800c\u8fd9\u4e2a\u5411\u91cf\u5f62\u72b6\u6070\u597d\u4e0ebias\u76f8\u540c\uff0c\u4ece\u800c\u53ef\u4ee5\u5b9e\u73b0\u4e0e\u539f\u6765\u7684bias\u76f8\u52a0\u3002</p> <p>\u9057\u6f0f\u7ec6\u8282\uff1a \u901a\u5e38stage1\u7684\u5377\u79ef\u64cd\u4f5c\u90fd\u6709padding\uff0c\u4e14padding_value=0\uff0c\u6240\u4ee5\u5728\u8fb9\u754c\u5904\u5f97\u5230\u7684\u503c\u4e0d\u6ee1\u8db3\u4e0a\u8ff0\u6761\u4ef6\uff0c\u5373\u5728\u901a\u9053\u5185\u90e8\uff0c\u8fb9\u754c\u5904\u7684\u503c\u4e0e\u5185\u90e8\u7684\u503c\u4e0d\u4e00\u6837\uff08\u8f93\u5165\u8f93\u51fa\u90fd\u662f\u4e00\u6837\uff09\uff0c\u5728\u8ba1\u7b97\u7684\u65f6\u5019\u6211\u4eec\u8981\u5ffd\u7565\u6389padding\u7684\u8ba1\u7b97\u7ed3\u679c</p> <p>Tips\uff1a</p> <p>\u5728\u8ba1\u7b97 \\(-  \\rm{W} * \\rm{full\\_like}(\\rm{X}, \\frac{ \\rm{mean} }{ \\rm{std} }) + \\rm{b}\\) \u6709\u4e00\u4e2a\u6280\u5de7\uff0c\u5373\u5c06X\u8bbe\u7f6e\u4e3a\u51680\u5411\u91cf\uff0c\u5e26\u5165\u5230 \\(\\rm{W} * \\frac{ \\frac{\\rm{X}}{255} - \\rm{mean} }{ \\rm{std} } + \\rm{b}\\) \uff0c\u7136\u540e\u76f4\u63a5\u8ba1\u7b97reduce_mean\u5373\u53ef\u3002</p> <p>\u5982\u679cconv\u540e\u9762\u63a5\u7684\u662fbn\uff0cconv\u53ef\u80fd\u6ca1\u6709bias\uff0c\u8fd9\u4e2a\u65f6\u5019\u539f\u6765\u7684bias=0\u3002</p>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/gray_image_pretrained_on_imagenet/#_3","title":"\u4e09\u3001\u4ee3\u7801\u9a8c\u8bc1","text":"<pre><code>import torch\nimport numpy as np\nfrom torchvision.models import resnet18\nimport torch.nn as nn\n\n\n# \u6a21\u62df\u7070\u5ea6\u56fe\u8f93\u5165\nimage_gray = np.random.randint(0, 256, size=(1, 224, 224))\n# \u8d4b\u503c\u4e3a\u4e09\u901a\u9053\nimage_rgb = np.repeat(image_gray, 3, axis=0)\n\nmodel = resnet18(pretrained=True)\nconv1 = model.conv1\nmodel.eval()\n\n# \u67e5\u770b\u5377\u79ef\u53c2\u6570\nprint(conv1)\n\nweight = conv1.weight.data\n\nimagenet_mean = np.array([0.485, 0.456, 0.406]).astype(np.float32)\nimagenet_std = np.array([0.229, 0.224, 0.225]).astype(np.float32)\n\n\ninput_tensor = (image_rgb.astype(np.float32) / 255 - imagenet_mean.reshape(-1, 1, 1)) / imagenet_std.reshape(-1, 1, 1)\nori_output = conv1(torch.from_numpy(input_tensor).unsqueeze(dim=0))\n\nnew_weight = (weight / (255 * torch.from_numpy(imagenet_std.reshape(1, -1, 1, 1)))).sum(dim=1, keepdim=True)\n\ntmp_input = np.full_like(input_tensor, 0.0)\nfor i, (mean, std) in enumerate(zip(imagenet_mean, imagenet_std)):\n    tmp_input[i, ...] = -mean / std\n\n# \u8fc7\u6ee4\u5230padding\u90e8\u5206\u533a\u57df\nnew_bias = conv1(torch.from_numpy(tmp_input).unsqueeze(dim=0))\n# stride=(2, 2), padding=(3, 3) \u4e24\u6b65\u624d\u80fd\u4e0d\u5229\u7528padding_value\nnew_bias = new_bias[:,:,2:-2,2:-2].mean(dim=[0, -1, -2], keepdim=False)\n\n\nconv1.bias = nn.Parameter(new_bias, requires_grad=True)\nconv1.weight.data = new_weight\n\n# \u4fee\u6539\u5377\u79ef\u53c2\u6570\nconv1.in_channels = 1\n\nnew_output = conv1(torch.from_numpy(image_gray.astype(np.float32)).unsqueeze(dim=0))\n\ndiff = new_output - ori_output\n\nprint(diff[:, :, 2:-2, 2:-2].abs().max()) # tensor(1.6212e-05, grad_fn=&lt;MaxBackward1&gt;)\n</code></pre>"},{"location":"DL%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E5%B7%A7/gray_image_pretrained_on_imagenet/#_4","title":"\u56db\u3001\u603b\u7ed3","text":"<p>\u9488\u5bf9\u5b9e\u9645\u7684\u5de5\u7a0b\u95ee\u9898\uff0c\u672c\u6587\u91c7\u7528\u7b49\u4ef7\u4ee3\u6362\u7684\u529e\u6cd5\u5c06\u5bf9\u4e8e\u4e09\u901a\u9053\u7070\u5ea6\u56fe\u7684\u8fd0\u7b97\u5316\u7b80\u5230\u5355\u901a\u9053\uff0c\u4f7f\u5f97\u6a21\u578b\u7b2c\u4e00\u5c42\u5377\u79ef\u7684\u8ba1\u7b97\u91cf\u548c\u53c2\u6570\u91cf\u51cf\u5c11\u4e09\u500d\uff0c\u540c\u65f6\u7b80\u5316\u4e86\u6a21\u578b\u7684\u9884\u5904\u7406\u65b9\u5f0f\uff0c\u662f\u4e00\u79cd\u90e8\u7f72\u53cb\u597d\u7684trick\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/2022%E5%B9%B403%E6%9C%8829%E6%97%A5%2022%E6%97%B651%E5%88%8611%E7%A7%92/","title":"Pytorch\u4e2dCTC Loss\u6e90\u7801\u89e3\u6790","text":"<p>\u672c\u6587\u5199\u4e8e 2022\u5e7403\u670829\u65e5 22\u65f651\u5206</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/2022%E5%B9%B403%E6%9C%8829%E6%97%A5%2022%E6%97%B651%E5%88%8611%E7%A7%92/#ctc-loss","title":"CTC Loss \u8bf4\u660e","text":"<p>\u6700\u8fd1\u5728\u7814\u7a76CRNN\u4e2d\u7684ctc loss\uff0c\u7528\u4e8e\u89e3\u51b3\u4e0d\u5b9a\u957flabel\u4e0b\u7684\u8f93\u5165\u8f93\u51fa\u5339\u914d\u95ee\u9898\u3002 CTC Loss\u7ecf\u5e38\u7528\u4e8e\u6587\u5b57\u8bc6\u522b\u548c\u8bed\u97f3\u8bc6\u522b\uff0c\u4e2a\u4eba\u611f\u89c9\u662f\u4e00\u79cd\u5e73\u5747\u5316\u7684\u6807\u7b7e\u5339\u914dloss\u3002\u6bd4\u5982\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u4e3a\"xxxxx\"\uff0c\u7ed9\u5b9alabel\u4e3a\"abc\"\u6216\u8005\"ab\"\uff0c\u90a3\u4e48\u5982\u4f55\u8bbe\u5b9a\u4e00\u79cd\u673a\u5236\u8ba9\u7740\u4e24\u79cd\u4e0d\u540c\u957f\u5ea6\u7684\u5411\u91cf\u8fdb\u884c\u5339\u914d\u5462\uff1f\u91c7\u7528\u4ece\u5934\u5bf9\u5176\u6216\u8005\u7ed3\u5c3e\u5bf9\u9f50\u7684\u65b9\u5f0f\u90fd\u662f\u4e0d\u5408\u7406\u7684\uff0c\u4e00\u79cd\u76f4\u89c2\u7684\u611f\u89c9\u662f\u7a77\u4e3e\u6240\u6709\u7684\u9884\u6d4b\u5230label\u7684\u53ef\u80fd\u6027\uff0c\u7136\u540etrain\u8fd9\u4e2a\u795e\u7ecf\u7f51\u7edc\u5b66\u5f97\u4e00\u79cd\u5e73\u5747\u53ef\u80fd\u6027\u4e0b\u7684\u8868\u73b0\uff0c\u4e5f\u5c31\u662f\u7ed9\u51fa\u6240\u6709\u53ef\u80fd\u9884\u6d4b\u7ed3\u679c\uff0c\u8ba9pred\u5c3d\u53ef\u80fd\u63a5\u8fd1\u6240\u6709\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u5373\u6240\u8c13\u5f97\u53d6\u5f97\u201c\u5e73\u5747\u8868\u73b0\u201d\u3002 \u5173\u4e8e\u66f4\u591aCTC loss\u7684\u8bb2\u89e3\u8fd8\u8bf7\u5173\u6ce8\u4ee5\u4e0b\u94fe\u63a5</p> <ul> <li>https://xiaodu.io/ctc-explained/</li> <li>https://zhuanlan.zhihu.com/p/43534801</li> </ul> <p>\u672c\u6587\u66f4\u591a\u662f\u5bf9\u6e90\u7801\u7684\u89e3\u6790\uff0c\u8f85\u52a9\u5bf9\u539f\u8bba\u6587\u7684\u7406\u89e3\u3002\u4e3a\u4e86\u4fbf\u4e8e\u9605\u8bfb\uff0c\u8fd9\u91cc\u91c7\u7528\u5728cpu\u4e0a\u5b9e\u73b0\u7684\u6e90\u7801\u3002 \u53c2\u8003\u539f\u6587\u94fe\u63a5\uff0cpytorch\u7684\u5b98\u65b9\u4ee3\u7801\u4e5f\u662f\u57fa\u4e8e\u5982\u4e0b\u8bba\u6587\u5b9e\u73b0\u7684\uff1a Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/2022%E5%B9%B403%E6%9C%8829%E6%97%A5%2022%E6%97%B651%E5%88%8611%E7%A7%92/#_1","title":"\u76f8\u5173\u6e90\u7801","text":"<p>\u6ce8\u91ca\u90fd\u5728\u4ee3\u7801\u4e2d</p> <pre><code>// Copyright (c) 2018 MathInf GmbH, Thomas Viehmann\n// Licensed under the BSD-3-Clause license\n// This is the CPU implementation of the Connectionist Temporal Loss.\n// We mostly follow Graves.\n// 1. Graves et al: http://www.cs.toronto.edu/~graves/icml_2006.pdf\n\n// We use the equations from above link, but note that [1] has 1-based indexing and we (of course) use 0-based.\n// Graves et al call the probabilities y, we use log_probs (also calling them inputs)\n#include &lt;ATen/ATen.h&gt;\n#include &lt;ATen/Dispatch.h&gt;\n#include &lt;ATen/Parallel.h&gt;\n#include &lt;ATen/TensorUtils.h&gt;\n#include &lt;ATen/native/Fill.h&gt;\n#include &lt;c10/util/irange.h&gt;\n#include &lt;numeric&gt;\n#include &lt;type_traits&gt;\nnamespace at {\nnamespace native {\nnamespace {\n// this ad-hoc converts from targets (l in [1]) to augmented targets (l' in [1]) note that no bound-checking is done\n// \u8be5\u51fd\u6570\u7528\u4e8e\u5c06 targets \uff08\u6587\u7ae0\u4e2d\u7684l\uff09 \u8f6c\u6362\u4e3a \u589e\u5f3a\u540e\u7684 targets \uff08\u6587\u7ae0\u4e2d\u7684l'\uff09\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f \u8fd9\u91cc\u6ca1\u6709\u8fb9\u754c\u68c0\u67e5\n// \u4e3e\u4f8b\uff1aabcc-&gt; -a-b-c-c-\n// n-&gt;2n+1\n// index \u4ece 0 \u5f00\u59cb\u7684 \uff0c\u6240\u4ee5\u6240\u6709\u5076\u6570index\u90fd\u9700\u8981\u8fd4\u56deBLANK\n// &amp;target[offset] \u662f \u771f\u6b63label\u7684\u8d77\u59cb\u5730\u5740\n// stride \u662f \u6b65\u957f\uff0c\u6839\u636e target_t \u6765\u5b9a\u4e49\uff0c \u6309\u7406\u8bf4 stride = 1\n// idx \u662f \u589e\u5f3a\u540e\u7684 targets \u7684\u7d22\u5f15\n// BLANK \u9700\u8981\u8fd4\u56de\u7a7a\u767d\u65f6\u7684\u7a7a\u767d\u7b26\u6807\u8bc6\ntemplate&lt;typename target_t&gt;\nstatic inline int64_t get_target_prime(target_t* target, int64_t offset, int64_t stride, int64_t idx, int64_t BLANK) {\n  if (idx % 2 == 0) {\n    return BLANK;\n  } else {\n    return target[offset + stride * (idx / 2)];\n  }\n}\n// This kernel is a relatively straightforward implementation of the alpha calculation in the forward backward algorithm (section 4.1).\n// A (minor) twist is that we are using log-calculations to enhance numerical stability (log_probs and log_alpha).\n// The function returns the loss and the alphas, the alphas are kept for the backward step. The wrapper (ctc_loss below) hides\n// the alphas from the user by only returning the loss.\n// \u8be5\u51fd\u6570\u662f\u5bf9\u5e94\u539f\u65874.1\u8282\u4e2d alpha \u8ba1\u7b97\u8fc7\u7a0b\u7684 \u76f8\u5bf9\u76f4\u63a5\u5b9e\u73b0\n// \u4e00\u70b9\u7ec6\u5fae\u7684\u5dee\u522b\u662f\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528 \u5bf9\u6570\u8fd0\u7b97 \u4ee3\u66ff \u539f\u6709\u4e58\u6cd5 \u7528\u4e8e \u589e\u5f3a\u6570\u503c\u8ba1\u7b97\u7a33\u5b9a\u6027\n// \u8be5\u51fd\u6570\u8fd4\u56de loss \u548c alpha\u8868\uff0c alpha\u8868 \u9700\u8981\u4fdd\u5b58\u4e0b\u6765\u7528\u4e8e\u65b9\u5411\u8ba1\u7b97\u8fc7\u7a0b\n// wrapper \u4f1a\u5bf9 \u8be5\u51fd\u6570\u8fdb\u884c\u5c01\u88c5\uff0c\u6700\u7ec8\u53ea\u8fd4\u56deloss\n// log_probs \u5bf9\u6570\u6982\u7387[time_length, batch_size, num_labels]\n// targets \u4e00\u4e32\u6570\u7ec4 shape\u4e3a[batch_size,max_length] or [batch_size]\n// input_lengths \u6bcf\u4e00\u4e2a\u9884\u6d4b\u6570\u636e\u7684\u771f\u5b9e\u957f\u5ea6\n// target_lengths \u6bcf\u4e00\u4e2alabel\u6570\u636e\u7684\u771f\u5b9e\u957f\u5ea6\ntemplate&lt;typename scalar_t, ScalarType target_scalar_type&gt;\nstd::tuple&lt;Tensor, Tensor&gt; ctc_loss_cpu_template(const Tensor&amp; log_probs, const Tensor&amp; targets, IntArrayRef input_lengths, IntArrayRef target_lengths, int64_t BLANK) {\n  // log_probs: input_len x batch_size x num_labels\n  // targets [int64]: batch_size x target_length OR sum(target_lengths)\n  constexpr scalar_t neginf = -std::numeric_limits&lt;scalar_t&gt;::infinity();\n  using target_t = typename std::conditional&lt;target_scalar_type == kInt, int, int64_t&gt;::type;\n  CheckedFrom c = \"ctc_loss_cpu\";\n  auto log_probs_arg = TensorArg(log_probs, \"log_probs\", 1);\n  auto targets_arg = TensorArg(targets, \"targets\", 2);\n  checkScalarType(c, targets_arg, target_scalar_type);\n  checkDim(c, log_probs_arg, 3);\n  checkDimRange(c, targets_arg, 1, 3);\n  int64_t batch_size = log_probs.size(1);\n  int64_t num_labels = log_probs.size(2);\n  TORCH_CHECK((0 &lt;= BLANK) &amp;&amp; (BLANK &lt; num_labels), \"blank must be in label range\");\n  TORCH_CHECK((int64_t) input_lengths.size() == batch_size, \"input_lengths must be of size batch_size\");\n  TORCH_CHECK((int64_t) target_lengths.size() == batch_size, \"target_lengths must be of size batch_size\");\n  // \u53c2\u6570\u4f20\u5165\u68c0\u67e5\n  // NOLINTNEXTLINE(cppcoreguidelines-init-variables)\n  size_t tg_target_stride;\n  int64_t max_target_length = 0;\n  // \u8bb0\u5f55\u6bcf\u4e00\u4e2abatch\u7684\u8d77\u59cboffset\n  std::vector&lt;int64_t&gt; tg_batch_offsets(batch_size);\n  if (targets.dim() == 1) { // concatenated targets\n    int64_t pos = 0;\n    for (const auto i : c10::irange(batch_size)) {\n      tg_batch_offsets[i] = pos;\n      pos += target_lengths[i];\n      if (max_target_length &lt; target_lengths[i])\n         max_target_length = target_lengths[i];\n    }\n    tg_target_stride = targets.stride(0);\n    checkSize(c, targets_arg, 0, pos);\n  }\n  else { // batch x max_target_length\n    // dim is 2\n    int64_t tg_batch_stride = targets.stride(0);\n    for (const auto i : c10::irange(batch_size)) {\n      tg_batch_offsets[i] = i * tg_batch_stride;\n      if (max_target_length &lt; target_lengths[i])\n        max_target_length = target_lengths[i];\n    }\n    tg_target_stride = targets.stride(1);\n    checkSize(c, targets_arg, 0, batch_size);\n    // \u4fdd\u8bc1 target_length &gt;= max_target_length\uff0c \u5426\u5219prob\u4e0d\u53ef\u4ee5\u8868\u793a\u8fd9\u4e48\u957f\u7684\u6570\n    TORCH_CHECK(targets.size(1) &gt;= max_target_length,\n             \"Expected tensor to have size at least \", max_target_length, \" at dimension 1, but got size \", targets.size(1), \" for \", targets_arg,\n             \" (while checking arguments for \", c, \")\");\n  }\n  // \u4f20\u5165\u7684\u6700\u5927\u65f6\u95f4\u957f\u5ea6\n  int64_t max_input_length = log_probs.size(0);\n  for (const auto b : c10::irange(batch_size)) {\n    TORCH_CHECK(input_lengths[b] &lt;= max_input_length,\n             \"Expected input_lengths to have value at most \", max_input_length, \", but got value \", input_lengths[b],\n             \" (while checking arguments for \", c, \")\");\n  }\n  // log_alpha \u8868 batch_size x input_len x (2*max_target_length+1)\n  Tensor log_alpha = at::empty({batch_size, log_probs.size(0), 2*max_target_length+1}, log_probs.options());\n  // loss\n  Tensor neg_log_likelihood = at::empty({batch_size}, log_probs.options());\n  // lpp shape\u4e3a batch_size x input_len x num_labels\n  auto lpp  = log_probs.permute({1,0,2});\n  // \u83b7\u53d6\u4e00\u4e2a\u4e09\u7ef4\u6570\u7ec4\n  auto log_probs_a_global = lpp.accessor&lt;scalar_t, 3&gt;();\n  // \u83b7\u53d6\u4e00\u4e2a\u4e09\u7ef4\u6570\u7ec4\n  auto log_alpha_a_global = log_alpha.accessor&lt;scalar_t, 3&gt;();\n  auto targets_data = targets.data_ptr&lt;target_t&gt;();\n  // \u83b7\u53d6\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\n  auto neg_log_likelihood_a = neg_log_likelihood.accessor&lt;scalar_t, 1&gt;();\n  // alpha calculation for the first row, the three equations for alpha_1 above eq (6)\n  // first the default\n  // narrow\u5207\u7247\u64cd\u4f5c, Tensor.narrow(dim, start, length)\n  log_alpha.narrow(1, 0, 1).fill_(neginf);\n  at::parallel_for(0, batch_size, 0, [&amp;](int64_t start, int64_t end) {\n    for (const auto b : c10::irange(start, end)) {\n      // \u5b9e\u9645 \u9884\u6d4b \u957f\u5ea6\n      int64_t input_length = input_lengths[b];\n      // \u5b9e\u9645 target \u957f\u5ea6\n      int64_t target_length = target_lengths[b];\n      auto log_probs_a = log_probs_a_global[b];\n      auto log_alpha_a = log_alpha_a_global[b];\n      int64_t tg_batch_offset = tg_batch_offsets[b];\n      // \u586b\u5145 log_alpha \u8868\u4e2d\u7684\u524d\u4e24\u9879\n      // the first two items of alpha_t above eq (6)\n      log_alpha_a[0][0] = log_probs_a[0][BLANK];\n      if (target_length &gt; 0)\n        log_alpha_a[0][1] = log_probs_a[0][get_target_prime(targets_data, tg_batch_offset, tg_target_stride, 1, BLANK)];\n      // now the loop over the inputs\n      for (const auto t : c10::irange(1, input_length)) {\n        for (const auto s : c10::irange(2*target_length+1)) {\n          // \u904d\u5386\u8868\u7684\u6bcf\u4e00\u5217\u5143\u7d20\n          auto current_target_prime = get_target_prime(targets_data, tg_batch_offset, tg_target_stride, s, BLANK);\n          // this loop over s could be parallel/vectorized, too, but the required items are one index apart\n          // alternatively, one might consider moving s to the outer loop to cache current_target_prime more (but then it needs to be descending)\n          // for the cuda implementation, that gave a speed boost.\n          // This is eq (6) and (7), la1,2,3 are the three summands. We keep track of the maximum for the logsumexp calculation.\n          // alpha_{t - 1}(s)\n\n          scalar_t la1 = log_alpha_a[t-1][s];\n          scalar_t lamax = la1;\n          // la2 = alpha_{t - 1}(s - 1)\n\n          // la3 = alpha_{t - 1}(s - 2)\n\n          scalar_t la2, la3;\n          if (s &gt; 0) {\n            la2 = log_alpha_a[t-1][s-1];\n            if (la2 &gt; lamax)\n              lamax = la2;\n          } else {\n            la2 = neginf;\n          }\n          // \u5982\u679c \u5f53\u524d\u5143\u7d20 \u4e0d\u7b49\u4e8e \u4e0a\u4e0a\u4e2a\u5143\u7d20\n          if ((s &gt; 1) &amp;&amp; (get_target_prime(targets_data, tg_batch_offset, tg_target_stride, s-2, BLANK) !=\n                          current_target_prime)) {\n            la3 = log_alpha_a[t-1][s-2];\n            if (la3 &gt; lamax)\n              lamax = la3;\n          } else {\n            la3 = neginf;\n          }\n          if (lamax == neginf) // cannot do neginf-neginf\n            lamax = 0;\n          // lamax \u7528\u4e8e\u589e\u5f3a\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u907f\u514dexp\u4e2d\u8f93\u5165\u7684\u503c\u592a\u5c0f\n          // log(exp(-lamax)) + lamax = 0\n          // this is the assignment of eq (6)\n          log_alpha_a[t][s] = std::log(std::exp(la1-lamax)+std::exp(la2-lamax)+std::exp(la3-lamax))+lamax + log_probs_a[t][current_target_prime];\n        }\n      }\n      // \u6c42\u53d6 p(l|x)\n      // the likelihood is the the sum of the last two alphas, eq (8), the loss is the negative log likelihood\n      if (target_length == 0) {\n        // if the target is empty then there is no preceding BLANK state and hence there is no path to merge\n        neg_log_likelihood_a[b] = -log_alpha_a[input_length-1][0];\n      } else {\n        scalar_t l1 = log_alpha_a[input_length-1][target_length*2];\n        scalar_t l2 = log_alpha_a[input_length-1][target_length*2-1];\n        scalar_t m = std::max(l1, l2);\n        m = ((m == neginf) ? 0 : m);\n        scalar_t log_likelihood = std::log(std::exp(l1-m)+std::exp(l2-m))+m;\n        neg_log_likelihood_a[b] = -log_likelihood;\n      }\n    }\n  });\n  return std::make_tuple(neg_log_likelihood, log_alpha);\n}\n// This is the backward. It consists of two phases:\n// a) computing the beta analogous to the alphas in the forward (backward half of the forward-backward algorithm) (eq (10) and (11))\n// b) collecting the per-activation characters for all s and wrapping the gradient (eq (16), the collection is the sum)\n// \u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\n// a) \u6309\u7167 \u4e0a\u9762 \u8ba1\u7b97  alpha\u8868\u7684\u65b9\u5f0f \u8ba1\u7b97 beta\n// b) \u5bf9\u6240\u6709\u7684\u65f6\u95f4\u70b9s\u5bf9\u5e94\u7684\u6fc0\u6d3b\u503c\u8ba1\u7b97\u68af\u5ea6\ntemplate&lt;typename scalar_t, ScalarType target_scalar_type&gt;\nTensor ctc_loss_backward_cpu_template(const Tensor&amp; grad_out, const Tensor&amp; log_probs, const Tensor&amp; targets, IntArrayRef input_lengths, IntArrayRef target_lengths,\n                                      const Tensor&amp; neg_log_likelihood, const Tensor&amp; log_alpha, int64_t BLANK, bool zero_infinity) {\n  // ================ \u8ba1\u7b97 beta \u8868 \u5f00\u59cb ===================================\n  constexpr scalar_t neginf = -std::numeric_limits&lt;scalar_t&gt;::infinity();\n  using target_t = typename std::conditional&lt;target_scalar_type == kInt, int, int64_t&gt;::type;\n  int64_t max_input_length = log_probs.size(0);\n  int64_t batch_size = log_probs.size(1);\n  int64_t num_labels = log_probs.size(2);\n  Tensor grad = at::full_like(log_probs, neginf, LEGACY_CONTIGUOUS_MEMORY_FORMAT); // at this point, this is log of empty sum\n  // The admin bits. We don't do much checking and assume that the forward did.\n  // NOLINTNEXTLINE(cppcoreguidelines-init-variables)\n  int64_t tg_target_stride;\n  // NOLINTNEXTLINE(cppcoreguidelines-init-variables)\n  int64_t max_target_length;\n  std::vector&lt;int64_t&gt; tg_batch_offsets(batch_size);\n  if (targets.dim() == 1) { // concatenated targets\n    int64_t pos = 0;\n    max_target_length = 0;\n    for (const auto i : c10::irange(batch_size)) {\n      tg_batch_offsets[i] = pos;\n      pos += target_lengths[i];\n      if (max_target_length &lt; target_lengths[i])\n        max_target_length = target_lengths[i];\n    }\n    tg_target_stride = targets.stride(0);\n  }\n  else { // batch x max_target_length\n    // dim is 2\n    int64_t tg_batch_stride = targets.stride(0);\n    for (const auto i : c10::irange(batch_size)) {\n      tg_batch_offsets[i] = i * tg_batch_stride;\n    }\n    tg_target_stride = targets.stride(1);\n    max_target_length = targets.size(1);\n  }\n  Tensor log_beta = at::empty_like(log_alpha, LEGACY_CONTIGUOUS_MEMORY_FORMAT);  // could be optimized to use only 2 rows\n  auto lpp  = log_probs.permute({1,0,2});\n  auto log_probs_a_global = lpp.accessor&lt;scalar_t, 3&gt;();\n  auto log_alpha_a_global = log_alpha.accessor&lt;scalar_t, 3&gt;();\n  auto log_beta_a_global = log_beta.accessor&lt;scalar_t, 3&gt;();\n  auto gp = grad.permute({1,0,2});\n  auto grad_a_global = gp.accessor&lt;scalar_t, 3&gt;();\n  auto targets_data = targets.data_ptr&lt;target_t&gt;();\n  auto create_fill_iterator = [](const Tensor&amp; tensor, IntArrayRef squash_dims) {\n    return TensorIteratorConfig()\n        .set_check_mem_overlap(false)  // Fill is idempotent, so overlap is okay\n        .check_all_same_dtype(false)\n        .add_output(tensor)\n        .resize_outputs(false)\n        .declare_static_shape(tensor.sizes(), squash_dims)\n        .build();\n  };\n  const auto fill_iter = create_fill_iterator(grad, /*squash_dims=*/1);\n  const auto fill_1d_iter = create_fill_iterator(grad, /*squash_dims=*/{0, 1});\n  const auto fill_log_beta_1d_iter = create_fill_iterator(log_beta, /*squash_dims=*/{0, 1});\n  at::parallel_for(0, batch_size, 0, [&amp;](int64_t start, int64_t end) {\n    TensorIterator fill_iter_local(fill_iter);\n    TensorIterator fill_1d_iter_local(fill_1d_iter);\n    TensorIterator fill_log_beta_1d_iter_local(fill_log_beta_1d_iter);\n    for (const auto b : c10::irange(start, end)) {\n      scalar_t nll = neg_log_likelihood.accessor&lt;scalar_t, 1&gt;()[b];\n      auto grad_a = grad_a_global[b];\n      if (zero_infinity &amp;&amp; nll == std::numeric_limits&lt;scalar_t&gt;::infinity()) {\n        // grad_batch.zero_();\n        fill_iter_local.unsafe_replace_operand(0, grad_a.data());\n        fill_stub(kCPU, fill_iter_local, 0);\n        continue;\n      }\n      auto log_probs_a = log_probs_a_global[b];\n      auto log_alpha_a = log_alpha_a_global[b];\n      auto log_beta_a = log_beta_a_global[b];\n      int64_t input_length = input_lengths[b];\n      int64_t target_length = target_lengths[b];\n      int64_t tg_batch_offset = tg_batch_offsets[b];\n      // the initialization of beta before eq (10)\n      // here we do the fill for each batch item separately, as the input lengths will differ, so the t in which\n      // we start varies\n      if (input_length &gt; 0) {\n        // log_beta.select(0, b).select(1, input_length-1).fill_(neginf);\n        fill_log_beta_1d_iter_local.unsafe_replace_operand(\n            0, log_beta_a[input_length - 1].data());\n\n        fill_stub(kCPU, fill_log_beta_1d_iter_local, neginf);\n        log_beta_a[input_length-1][2*target_length] = log_probs_a[input_length-1][BLANK];\n        grad_a[input_length-1][BLANK] = log_alpha_a[input_length-1][2*target_length] + log_beta_a[input_length-1][2*target_length];\n        if (target_length &gt; 0) {\n          auto current_target_prime = get_target_prime(targets_data, tg_batch_offset, tg_target_stride, 2*target_length-1, BLANK);\n          log_beta_a[input_length-1][2*target_length-1] = log_probs_a[input_length-1][current_target_prime];\n          // the first two are a blank and a non-blank, so we know they are different and we don't need to do log+\n          grad_a[input_length-1][current_target_prime] = log_alpha_a[input_length-1][2*target_length-1] + log_beta_a[input_length-1][2*target_length-1];\n        }\n      }\n      // now loop applying eq (10) / (11)\n      for (int64_t t=input_length-2; t&gt;=0; t--) {\n        // this loop over s could be parallel/vectorized and doesn't really need to be descending...\n        // alternatively, one might consider moving s to the outer loop to cache current_target_prime more (but then it needs to be descending)\n        // for the cuda implementation, that gave a speed boost.\n        for (int64_t s=2*target_length; s&gt;=0; s--) {\n          scalar_t lb1 = log_beta_a[t+1][s];\n          scalar_t lbmax = lb1;\n          scalar_t lb2, lb3;\n          auto current_target_prime = get_target_prime(targets_data, tg_batch_offset, tg_target_stride, s, BLANK);\n          if (s &lt; 2*target_length) {\n            lb2 = log_beta_a[t+1][s+1];\n            if (lb2 &gt; lbmax)\n              lbmax = lb2;\n          } else {\n            lb2 = neginf;\n          }\n          if ((s &lt; 2*target_length-1) &amp;&amp; (get_target_prime(targets_data, tg_batch_offset, tg_target_stride, s+2, BLANK) !=\n                                          current_target_prime)) {\n            lb3 = log_beta_a[t+1][s+2];\n            if (lb3 &gt; lbmax)\n              lbmax = lb3;\n          } else {\n            lb3 = neginf;\n          }\n          if (lbmax == neginf)\n            lbmax = 0;\n          log_beta_a[t][s] = std::log(std::exp(lb1-lbmax)+std::exp(lb2-lbmax)+std::exp(lb3-lbmax))+lbmax + log_probs_a[t][current_target_prime];\n          // one might check whether one can vectorize this better when done after the t-loop...\n          // now that we have beta, we fill in the sum of alpha*beta in eq (16)\n          // in contrast to the cuda implementation, we only parallelize over the batch, so we don't have a concurrency\n          // issue (several s can map to the same target character)\n          // collected[b, t, target'[s]] \"log+=\" log_alpha[t, s]+log_beta[t, s]\n          scalar_t log_alpha_beta =  log_alpha_a[t][s] + log_beta_a[t][s];\n          scalar_t &amp;lcab = grad_a[t][current_target_prime];\n          if (lcab == neginf) {\n            lcab = log_alpha_beta;\n          } else {\n            scalar_t max = std::max(lcab, log_alpha_beta);\n            lcab = std::log(std::exp(lcab-max)+std::exp(log_alpha_beta-max))+max;\n          }\n        }\n      }\n      // ================ \u8ba1\u7b97 beta \u8868 \u7ed3\u675f ===================================\n      // now grad has the sum of eq (16)\n      // now we wrap up the calculation by adding in the remaining items of eq (16)\n      // this could be a great target for further vectorization.\n      // grad is the output gradient, nll is the loss. Note that the likelihood -nll is the Z of eq (16)\n      scalar_t gr = grad_out.accessor&lt;scalar_t, 1&gt;()[b];\n      for (const auto t : c10::irange(input_length)) { // or go for the full thing?\n        for (const auto c : c10::irange(num_labels)) {\n          // res = log(alpha_t(s)) + log(beta_t(s))\n          scalar_t&amp; res = grad_a[t][c];\n          // lp \u5373\u4e3a log(y_k^t)\n          scalar_t lp = log_probs_a[t][c];\n          // -nll \u4e3a log(Z) \uff0c nll \u4e3a log(1/Z)\n          res = (std::exp(lp)-std::exp(res + nll - lp)) * gr;\n\n        }\n      }\n      // zero the remainder\n      for (auto l : c10::irange(input_length, max_input_length)) {\n        // grad_batch.select(0, l).zero_();\n        fill_1d_iter_local.unsafe_replace_operand(0, grad_a[l].data());\n        fill_stub(kCPU, fill_1d_iter_local, 0);\n      }\n    }\n  });\n  return grad;\n}\n} // namespace\nstd::tuple&lt;Tensor, Tensor&gt; ctc_loss_cpu(const Tensor&amp; log_probs, const Tensor&amp; targets, IntArrayRef input_lengths, IntArrayRef target_lengths, int64_t BLANK, bool zero_infinity) {\n  (void)zero_infinity; // only used for backwards\n  return AT_DISPATCH_FLOATING_TYPES(log_probs.scalar_type(), \"ctc_loss_cpu\", [&amp;] {\n      if (targets.scalar_type() == kLong) {\n        return ctc_loss_cpu_template&lt;scalar_t, kLong&gt;(log_probs, targets, input_lengths, target_lengths, BLANK);\n      } else {\n        return ctc_loss_cpu_template&lt;scalar_t, kInt&gt;(log_probs, targets, input_lengths, target_lengths, BLANK);\n      }\n  });\n}\nTensor ctc_loss_backward_cpu(const Tensor&amp; grad, const Tensor&amp; log_probs, const Tensor&amp; targets, IntArrayRef input_lengths, IntArrayRef target_lengths,\n                             const Tensor&amp; neg_log_likelihood, const Tensor&amp; log_alpha, int64_t BLANK, bool zero_infinity) {\n  return AT_DISPATCH_FLOATING_TYPES(log_probs.scalar_type(), \"ctc_loss_backward_cpu\", [&amp;] {\n      if (targets.scalar_type() == kLong) {\n        return ctc_loss_backward_cpu_template&lt;scalar_t,kLong&gt;(grad, log_probs, targets, input_lengths, target_lengths, neg_log_likelihood, log_alpha, BLANK, zero_infinity);\n      } else {\n        return ctc_loss_backward_cpu_template&lt;scalar_t,kInt&gt;(grad, log_probs, targets, input_lengths, target_lengths, neg_log_likelihood, log_alpha, BLANK, zero_infinity);\n      }\n  });\n}\n} } // at::native\n</code></pre>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/","title":"360\u00b0\u65cb\u8f6c\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u5b9e\u62181\uff1a\u5168\u666f\u67b6\u6784\u8bbe\u8ba1\u4e0e\u843d\u5730\u601d\u8def","text":"<p>\u672c\u6587\u5199\u4e8e 2025\u5e743\u670831\u65e5\u665a11\u70b9\u548c2025\u5e744\u67086\u65e5\u4e0b\u53483\u70b9</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#_1","title":"\u4e00\u3001\u9700\u6c42\u4ecb\u7ecd\u4e0e\u4efb\u52a1\u7279\u70b9\u5206\u6790","text":""},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#11","title":"1.1 \u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u65cb\u8f6c\u6587\u5b57\u68c0\u6d4b\u5e7f\u6cdb\u9700\u6c42","text":"<p>\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u65cb\u8f6c\u6587\u5b57\u68c0\u6d4b\u9700\u6c42\u5e7f\u6cdb\u5b58\u5728\u4e8e\u591a\u4e2a\u9886\u57df\uff0c\u5176\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u89e3\u51b3\u81ea\u7136\u573a\u666f\u4e2d\u6587\u5b57\u65b9\u5411\u7684\u591a\u6837\u6027\uff08\u5982\u503e\u659c\u3001\u5012\u7f6e\u3001\u626d\u66f2\u7b49\uff09\u3002\u6bd4\u5982  </p> <ol> <li>\u76d1\u63a7\u89c6\u9891\u4e2d\u7684\u503e\u659c\u8def\u6807\u3001\u5e7f\u544a\u724c\u6587\u5b57\uff08\u5982\u65e0\u4eba\u673a\u822a\u62cd\u573a\u666f\uff09  </li> <li>\u751f\u4ea7\u7ebf\u4e2d\u65cb\u8f6c\u5de5\u4ef6\u8868\u9762\u7684\u6587\u5b57\u8bc6\u522b\uff08\u5982\u74f6\u8eab\u6807\u7b7e\u3001\u91d1\u5c5e\u7f50\u5e8f\u5217\u53f7\uff09  </li> <li>\u626b\u63cf\u6587\u6863\u4e2d\u7684\u7578\u53d8\u6587\u5b57\u5b9a\u4f4d\uff08\u5982\u8936\u76b1\u53d1\u7968\u3001\u5f2f\u66f2\u5408\u540c\uff09  </li> <li>\u624b\u673a\u62cd\u6444\u7684\u81ea\u7136\u573a\u666f\u6587\u5b57\u8bc6\u522b\uff08\u5982\u8857\u666f\u7ffb\u8bd1\u3001\u5546\u54c1\u6807\u7b7e\u8bc6\u522b\uff09  </li> <li>\u8eab\u4efd\u8bc1\u3001\u53d1\u7968\u7b49\u8bc1\u4ef6\u7684OCR\u8bc6\u522b\uff08\u5982\u963f\u91cc\u4e91\u201c\u65e0\u63a5\u89e6\u201d\u653f\u52a1\u670d\u52a1\uff09  </li> </ol> <p>\u8fd9\u4e9b\u9700\u6c42\u9700\u8981\u5168\u89d2\u5ea6\uff080\u00b0-360\u00b0\uff09\u65cb\u8f6c\u6846\u8868\u793a\uff0c\u4f20\u7edf\u7684\u6c34\u5e73\u68c0\u6d4b\u548c0-90\u00b0\u4ee5\u53ca0-180\u00b0\u65cb\u8f6c\u6846\u8868\u793a\u65e0\u6cd5\u6ee1\u8db3\u5bf9\u4e8e\u6587\u5b57\u65cb\u8f6c\u65b9\u5411\u7684\u7cbe\u786e\u63cf\u8ff0\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#12","title":"1.2 \u672c\u6587\u7814\u7a76\u7684\u4efb\u52a1\u7279\u70b9","text":"<p>\u672c\u6587\u7814\u7a76\u7684\u4efb\u52a1\u662f\u67d0\u5ba1\u6838\u5e73\u53f0\u4e0b\u7684\u542b\u6709\u6587\u5b57\u7684\u8868\u5355\u8bc6\u522b\u3002 \u4efb\u52a1\u7279\u70b9\u5982\u4e0b\uff1a  </p> <ol> <li>\u7eb8\u5f20\u65cb\u8f6c\u89d2\u5ea6\u8303\u56f4\u5e7f\uff1a0-360\u00b0\u65cb\u8f6c\u6846\u8868\u793a\uff0c\u6db5\u76d6\u4e86\u6587\u5b57\u7684\u6240\u6709\u53ef\u80fd\u65b9\u5411\u3002</li> <li>\u6587\u5b57\u8868\u793a\u7b80\u5355\uff1a\u6587\u5b57\u65b9\u5411\u53ef\u80fd\u503e\u659c\u3001\u5012\u7f6e\u3001\u4f46\u662f\u4e0d\u4f1a\u626d\u66f2\u53d8\u5f62\uff0c\u9700\u8981\u7cbe\u786e\u8bc6\u522b\u3002</li> <li>\u7eb8\u5f20\u80cc\u666f\u5355\u4e00\uff1a\u9488\u5bf9\u5305\u542b\u8868\u683c\u7ebf\u7684\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u573a\u666f\uff0c\u80cc\u666f\u8f83\u4e3a\u5e72\u51c0\uff0c\u57fa\u672c\u4e3a\u9875\u811a\u6216\u8005\u5370\u7ae0\u5e72\u6270\u3002</li> </ol> <p>\u672c\u6587\u91c7\u7528360\u00b0\u65cb\u8f6c\u6846\u8868\u793a\u6587\u5b57\u533a\u57df\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u83b7\u53d6\u89d2\u5ea6\u540e\u66f4\u65b9\u4fbf\u7684\u8fdb\u884c\u4eff\u5c04\u53d8\u6362\uff0c\u5c06\u65cb\u8f6c\u7684\u6587\u5b57\u533a\u57df\u77eb\u6b63\u4e3a\u6c34\u5e73\uff0c\u65b9\u4fbf\u540e\u7eed\u7684\u6587\u5b57\u8bc6\u522b\u4efb\u52a1\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#13-360","title":"1.3 360\u00b0\u65cb\u8f6c\u68c0\u6d4b\u4efb\u52a1\u7684\u6838\u5fc3\u6311\u6218","text":"<p>360\u00b0\u65cb\u8f6c\u68c0\u6d4b\u4efb\u52a1\u7684\u6838\u5fc3\u6311\u6218\u53ef\u5f52\u7eb3\u4e3a\u4ee5\u4e0b\u4e09\u70b9\uff1a</p> <ol> <li>\u65b9\u5411\u5efa\u6a21\u7684\u590d\u6742\u6027   \u5468\u671f\u6027\u89d2\u5ea6\u56de\u5f52\u96be\u9898: \u6587\u5b57/\u76ee\u6807\u53ef\u80fd\u4ee5\u4efb\u610f\u89d2\u5ea6\uff080\u00b0-360\u00b0\uff09\u5b58\u5728\uff0c\u4f20\u7edf\u56de\u5f52\u65b9\u6cd5\u6613\u9677\u5165\u89d2\u5ea6\u5468\u671f\u6027\u6b67\u4e49\uff08\u59820\u00b0\u4e0e360\u00b0\u7684\u8fb9\u754c\u8df3\u8dc3\uff09\u3002</li> <li>\u6807\u6ce8\u4e0e\u6570\u636e\u589e\u5f3a\u7684\u9ad8\u6210\u672c<ul> <li>\u6807\u6ce8\u590d\u6742\u5ea6\u6fc0\u589e\uff1a\u65cb\u8f6c\u6846\u9700\u6807\u6ce84\u4e2a\u5750\u6807\u70b9+1\u4e2a\u65cb\u8f6c\u89d2\u5ea6\uff08vs \u6c34\u5e73\u68464\u70b9\uff09\uff0c\u6807\u6ce8\u6548\u7387\u4e0b\u964d30%\uff0c\u4e14\u9700\u4e13\u4e1a\u5de5\u5177\u652f\u6301\u3002</li> <li>\u6570\u636e\u589e\u5f3a\u5c40\u9650\u6027\uff1a\u968f\u673a\u65cb\u8f6c\u53ef\u80fd\u7834\u574f\u6587\u672c\u8bed\u4e49\uff0c\u9700\u7ed3\u5408\u51e0\u4f55\u7ea6\u675f\u589e\u5f3a\u7b56\u7565\u3002</li> </ul> </li> <li>\u8ba1\u7b97\u6548\u7387\u4e0e\u786c\u4ef6\u9002\u914d\u77db\u76fe    \u65cb\u8f6c\u6846\u7684IoU\u8ba1\u7b97\u590d\u6742\u5ea6\u662f\u6c34\u5e73\u6846\u76843\u500d\u4ee5\u4e0a\uff0c\u96be\u4ee5\u76f4\u63a5\u5229\u7528GPU\u5e76\u884c\u52a0\u901f\uff0c\u5bfc\u81f4\u63a8\u7406\u5ef6\u8fdf\u589e\u52a037%</li> </ol>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#_2","title":"\u4e8c\u3001\u76ee\u524d\u4e1a\u754c\u65b9\u6848\u4e0e\u5c40\u9650\u6027","text":""},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#21","title":"2.1 \u5e38\u89c4\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1","text":"<p>\u200b\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\uff08Rotated Object Detection\uff09\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u4e2d\uff0c\u4e3b\u8981\u5173\u6ce8\u5982\u4f55\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5177\u6709\u4efb\u610f\u65b9\u5411\u548c\u59ff\u6001\u7684\u7269\u4f53\u3002\u200b\u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u6c34\u5e73\u8fb9\u754c\u6846\uff08Horizontal Bounding Box\uff0cHBB\uff09\uff0c\u5e26\u6709\u65cb\u8f6c\u89d2\u5ea6\u5c5e\u6027\u7684\u77e9\u5f62\u6216\u56db\u8fb9\u5f62\u80fd\u591f\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u7269\u4f53\u7684\u7a7a\u95f4\u4f4d\u7f6e\u548c\u65b9\u5411\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9065\u611f\u5f71\u50cf\u3001\u573a\u666f\u6587\u672c\u548c\u5176\u4ed6\u9700\u8981\u7cbe\u786e\u5b9a\u4f4d\u7684\u5e94\u7528\u573a\u666f\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#211","title":"2.1.1 \u5e38\u7528\u7684\u65cb\u8f6c\u6846\u8868\u793a\u65b9\u6cd5","text":"<ol> <li> <p>\u4e94\u53c2\u6570\u8868\u793a\u6cd5\uff085-parameter Representation\uff09</p> <p>\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e94\u4e2a\u53c2\u6570\u6765\u63cf\u8ff0\u65cb\u8f6c\u77e9\u5f62\uff1a\u200b</p> <ul> <li>(x, y)\uff1a \u77e9\u5f62\u4e2d\u5fc3\u70b9\u7684\u6a2a\u7eb5\u5750\u6807\u3002\u200b</li> <li>h\uff1a \u77e9\u5f62\u7684\u9ad8\u5ea6\u3002\u200b</li> <li>w\uff1a \u77e9\u5f62\u7684\u5bbd\u5ea6\u3002\u200b</li> <li>\u03b8\uff1a \u65cb\u8f6c\u89d2\u5ea6(\u5b9a\u4e49\u65b9\u5f0f\u6709\u6240\u5dee\u522b)</li> </ul> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u7b80\u6d01\u6027\uff1a \u4ec5\u9700\u56de\u5f52\u4e94\u4e2a\u53c2\u6570\uff0c\u8ba1\u7b97\u91cf\u76f8\u5bf9\u8f83\u5c0f\u3002\u200b</li> <li>\u6613\u4e8e\u7406\u89e3\uff1a \u76f4\u89c2\u5730\u8868\u793a\u4e86\u77e9\u5f62\u7684\u4f4d\u7f6e\u3001\u5c3a\u5bf8\u548c\u671d\u5411\u3002\u200b</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <p>\u89d2\u5ea6\u5468\u671f\u6027\u95ee\u9898\uff1a \u65cb\u8f6c\u89d2\u5ea6\u03b8\u5177\u6709\u5468\u671f\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u89d2\u5ea6\u56de\u5f52\u7684\u6b67\u4e49\u6027\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u6536\u655b\u6027\u3002\u200b</p> <p>Note</p> <p>\u6309\u7167\u65cb\u8f6c\u89d2\u5ea6\u7684\u5b9a\u4e49\u4e0d\u540c\uff0c\u8fd8\u53ef\u4ee5\u518d\u5206\u7c7b\uff0c\u8be6\u60c5\u770b\u4e0b\u9762\u4e24\u4e2a\u94fe\u63a5 1. \u5173\u4e8e\u65cb\u8f6c\u6846\u5b9a\u4e49\u7684\u4e00\u4e9b\u7406\u89e3\u548c\u611f\u60f3 2. mmrotate\u65cb\u8f6c\u89d2\u5ea6\u5b9a\u4e49</p> </li> <li> <p>\u56db\u70b9\u5750\u6807\u8868\u793a\u6cd5\uff08Four-Point Coordinate Representation\uff09\uff1a     \u8be5\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528\u65cb\u8f6c\u77e9\u5f62\u56db\u4e2a\u9876\u70b9\u7684\u5750\u6807\u6765\u8868\u793a\u8fb9\u754c\u6846\uff0c\u5171\u516b\u4e2a\u53c2\u6570\uff1a\u200b (x\u2081, y\u2081), (x\u2082, y\u2082), (x\u2083, y\u2083), (x\u2084, y\u2084)\uff1a \u77e9\u5f62\u56db\u4e2a\u9876\u70b9\u7684\u5750\u6807\uff0c\u7528\u4ee5\u8868\u793a\u56db\u8fb9\u5f62\u8fb9\u754c\u6846(Quadrilateral Bounding Box,QBB)\u3002\u200b</p> <ul> <li>\u4f18\u70b9\uff1a   \u9ad8\u8868\u8fbe\u80fd\u529b\uff1a \u80fd\u591f\u7cbe\u786e\u8868\u793a\u4efb\u610f\u65cb\u8f6c\u89d2\u5ea6\u548c\u5f62\u72b6\u7684\u77e9\u5f62\u3002\u200b</li> </ul> <ul> <li>\u7f3a\u70b9\uff1a  <ul> <li>\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff1a \u9700\u8981\u56de\u5f52\u516b\u4e2a\u53c2\u6570\uff0c\u589e\u52a0\u4e86\u6a21\u578b\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002\u200b</li> <li>\u540e\u5904\u7406\u590d\u6742\uff1a \u5728\u9884\u6d4b\u540e\u9700\u8981\u8fdb\u884c\u989d\u5916\u7684\u5904\u7406\uff0c\u5982\u6392\u5e8f\u9876\u70b9\uff0c\u4ee5\u786e\u4fdd\u6b63\u786e\u7684\u77e9\u5f62\u8868\u793a\u3002</li> </ul> </li> </ul> </li> <li> <p>\u70b9\u96c6\uff08Point Set\uff09\u8868\u793a\u6cd5\uff1a     \u57fa\u4e8e\u70b9\u96c6\u7684\u8868\u793a\u65b9\u6cd5\u662f\u901a\u8fc7\u4e00\u7ec4\u72ec\u7acb\u7684\u70b9\uff08Point Set\uff09\u6765\u8868\u793a\u76ee\u6807\u4f4d\u7f6e\u548c\u5f62\u72b6\u7684\u65b9\u5f0f\u3002\u5728\u8be5\u65b9\u6cd5\u4e2d\uff0c\u6bcf\u4e2a\u70b9\u7684\u5750\u6807\u901a\u5e38\u8868\u793a\u76ee\u6807\u5728\u7a7a\u95f4\u4e2d\u7684\u67d0\u4e2a\u5177\u4f53\u4f4d\u7f6e\u3002\u8fd9\u79cd\u8868\u793a\u65b9\u5f0f\u66f4\u7ec6\u7c92\u5ea6\u5730\u63cf\u8ff0\u4e86\u76ee\u6807\u7684\u4f4d\u7f6e\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u76ee\u6807\u4e0d\u89c4\u5219\u6216\u590d\u6742\u7684\u60c5\u51b5\u3002\u5b83\u80fd\u591f\u63d0\u4f9b\u8f83\u4e3a\u7cbe\u51c6\u7684\u76ee\u6807\u4fe1\u606f\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7cbe\u786e\u63cf\u8ff0\u76ee\u6807\u5f62\u72b6\u7684\u573a\u666f\u4e2d\u3002</p> <ul> <li>\u4f18\u70b9\uff1a<ul> <li>\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\uff1a\u901a\u8fc7\u4f7f\u7528\u4e00\u7ec4\u70b9\u96c6\uff0c\u53ef\u4ee5\u7cbe\u51c6\u5730\u8868\u793a\u76ee\u6807\u7684\u51e0\u4f55\u5f62\u72b6\u548c\u4f4d\u7f6e\uff0c\u76f8\u8f83\u4e8e\u7b80\u5355\u7684\u77e9\u5f62\u6846\uff08bounding box\uff09\u80fd\u591f\u63d0\u4f9b\u66f4\u9ad8\u7684\u7cbe\u5ea6\u3002</li> <li>\u9002\u5e94\u590d\u6742\u5f62\u72b6\uff1a\u70b9\u96c6\u80fd\u591f\u8868\u793a\u4efb\u610f\u5f62\u72b6\u7684\u76ee\u6807\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u4e0d\u89c4\u5219\u7684\u76ee\u6807\uff0c\u907f\u514d\u4e86\u8fb9\u754c\u6846\u5e26\u6765\u7684\u9650\u5236\u3002</li> <li>\u7ec6\u7c92\u5ea6\u4fe1\u606f\uff1a\u76f8\u6bd4\u8fb9\u754c\u6846\uff08bounding box\uff09\uff0c\u70b9\u96c6\u80fd\u63d0\u4f9b\u66f4\u591a\u7684\u7ec6\u8282\u4fe1\u606f\uff0c\u6709\u52a9\u4e8e\u66f4\u590d\u6742\u7684\u76ee\u6807\u5206\u6790\u3002</li> </ul> </li> </ul> <ul> <li>\u7f3a\u70b9\uff1a<ul> <li>\u8ba1\u7b97\u91cf\u5927\uff1a\u4e0e\u8fb9\u754c\u6846\u65b9\u6cd5\u76f8\u6bd4\uff0c\u70b9\u96c6\u9700\u8981\u5904\u7406\u66f4\u591a\u7684\u70b9\uff0c\u56e0\u6b64\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u9ad8\uff0c\u5c24\u5176\u662f\u5728\u76ee\u6807\u8f83\u590d\u6742\u6216\u70b9\u96c6\u8f83\u5927\u7684\u60c5\u51b5\u4e0b\u3002</li> <li>\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u5e72\u6270\uff1a\u70b9\u96c6\u8868\u793a\u65b9\u6cd5\u5bf9\u4e8e\u70b9\u7684\u9009\u62e9\u548c\u7cbe\u5ea6\u8981\u6c42\u8f83\u9ad8\uff0c\u566a\u58f0\u6216\u8bef\u5dee\u53ef\u80fd\u5bfc\u81f4\u76ee\u6807\u4f4d\u7f6e\u63cf\u8ff0\u4e0d\u51c6\u786e\u3002</li> <li>\u8fb9\u754c\u95ee\u9898\uff1a\u70b9\u96c6\u8868\u793a\u6cd5\u96be\u4ee5\u63cf\u8ff0\u76ee\u6807\u7684\u5916\u90e8\u8fb9\u754c\uff0c\u56e0\u6b64\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u65e0\u6cd5\u6709\u6548\u6355\u6349\u76ee\u6807\u7684\u6574\u4f53\u8f6e\u5ed3\u3002</li> </ul> </li> </ul> </li> </ol> <p>\u672c\u6587\u5c06\u7eb8\u5f20\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u95ee\u9898\u8f6c\u5316\u4e3a\u4e00\u4e2a360\u5ea6\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\uff0c\u91c7\u7528\u4e94\u53c2\u6570\u8868\u793a\u6cd5\uff0c\u5373(x, y, w, h, \u03b8)\uff0c\u5176\u4e2d(x, y)\u8868\u793a\u77e9\u5f62\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\uff0cw\u548ch\u8868\u793a\u77e9\u5f62\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u03b8\u8868\u793a\u77e9\u5f62\u7684\u65cb\u8f6c\u89d2\u5ea6\u3002</p> <p>\u6587\u5b57\u533a\u57df\u5728\u81ea\u7136\u573a\u666f\u4e0b\u5e38\u5e38\u5448\u73b0\u51fa\u4efb\u610f\u65b9\u5411\u6392\u5217\uff0c\u5c3a\u5bf8\u548c\u957f\u5bbd\u6bd4\u4e5f\u53ef\u80fd\u5b58\u5728\u5f88\u5927\u53d8\u5316\uff0c\u800c\u4f20\u7edf\u7684\u6c34\u5e73\u77e9\u5f62\u6846\u68c0\u6d4b\u65b9\u6cd5\u53ea\u80fd\u6355\u6349\u8fd1\u4f3c\u6c34\u5e73\u7684\u7269\u4f53\uff0c\u56e0\u6b64\u96be\u4ee5\u51c6\u786e\u5b9a\u4f4d\u8fd9\u4e9b\u6587\u5b57\u533a\u57df\u3002\u91c7\u7528360\u5ea6\u65cb\u8f6c\u77e9\u5f62\u6846\u68c0\u6d4b\u7b97\u6cd5\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u539f\u56e0\u5305\u62ec\uff1a</p> <ol> <li> <p>\u9002\u5e94\u4efb\u610f\u65b9\u5411       \u901a\u8fc7\u5f15\u5165\u65cb\u8f6c\u89d2\u5ea6\u53c2\u6570\uff08\u4f8b\u5982(x, y, w, h, \u03b8)\u8fd9\u79cd\u8868\u793a\uff09\uff0c\u65cb\u8f6c\u77e9\u5f62\u6846\u80fd\u591f\u7cbe\u786e\u8868\u793a\u4efb\u610f\u89d2\u5ea6\u7684\u6587\u5b57\u533a\u57df\uff0c\u6d88\u9664\u4e86\u7531\u4e8e\u6587\u5b57\u503e\u659c\u800c\u5bfc\u81f4\u7684\u8fb9\u754c\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u3002  </p> <p>\u91c7\u7528360\u5ea6\u8868\u793a\u4e3b\u8981\u662f\u4e3a\u4e86\u786e\u4fdd\u6587\u5b57\u68c0\u6d4b\u80fd\u591f\u8986\u76d6\u6240\u6709\u53ef\u80fd\u7684\u65b9\u5411\u3002\u5728\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u7eb8\u5f20\u6446\u653e\u53ef\u80fd\u4ee5\u4efb\u610f\u89d2\u5ea6\u51fa\u73b0\uff0c\u4e0d\u4ec5\u4ec5\u5c40\u9650\u4e8e\u6c34\u5e73\u6216\u8fd1\u4f3c\u6c34\u5e73\u7684\u72b6\u6001\u3002\u5982\u679c\u6211\u4eec\u53ea\u9650\u5b9a\u5728180\u00b0\u621690\u00b0\u8303\u56f4\u5185\uff0c\u5c31\u53ef\u80fd\u5728\u89d2\u5ea6\u4e34\u754c\u70b9\u5904\u9047\u5230\u4e0d\u8fde\u7eed\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u56de\u5f52\u8bef\u5dee\u5267\u589e\uff0c\u4ece\u800c\u5f71\u54cd\u68c0\u6d4b\u7cbe\u5ea6\u3002\u4f7f\u7528360\u5ea6\u7684\u65cb\u8f6c\u77e9\u5f62\u6846\u8868\u793a\uff0c\u53ef\u4ee5\u5b8c\u6574\u5730\u63cf\u8ff0\u6587\u5b57\u533a\u57df\u5728\u6574\u4e2a\u5706\u5468\u5185\u7684\u4efb\u610f\u671d\u5411\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u7387\u3002</p> </li> <li> <p>\u540e\u7eed\u8bc6\u522b\u5904\u7406\u66f4\u7b80\u4fbf     \u68c0\u6d4b\u51fa\u7684\u65cb\u8f6c\u77e9\u5f62\u6846\u53ef\u4ee5\u76f4\u63a5\u4e3a\u540e\u7eed\u6587\u672c\u8bc6\u522b\u6a21\u5757\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u533a\u57df\u8f93\u5165\uff0c\u7b80\u5316\u4e86\u6587\u5b57\u533a\u57df\u7684\u6821\u6b63\u8fc7\u7a0b\uff0c\u5e76\u63d0\u5347\u6574\u4e2aOCR\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002</p> </li> </ol>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#212","title":"2.1.2 \u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u9762\u4e34\u7684\u95ee\u9898\u4e0e\u6311\u6218","text":"<p>\u76ee\u524d\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u9762\u4e34\u7740\u591a\u4e2a\u65b9\u9762\u7684\u95ee\u9898\u548c\u6311\u6218\uff0c\u4e3b\u8981\u5305\u62ec\uff1a</p> <ol> <li>\u89d2\u5ea6\u56de\u5f52\u4e0e\u8fb9\u754c\u4e0d\u8fde\u7eed\u6027\u95ee\u9898     \u7531\u4e8e\u89d2\u5ea6\u5177\u6709\u5468\u671f\u6027\uff08\u4f8b\u59820\u00b0\u548c360\u00b0\u5728\u672c\u8d28\u4e0a\u662f\u76f8\u540c\u7684\uff09\uff0c\u5f53\u9884\u6d4b\u503c\u63a5\u8fd1\u8fb9\u754c\u65f6\uff0c\u6a21\u578b\u5f80\u5f80\u4f1a\u51fa\u73b0\u635f\u5931\u503c\u7a81\u7136\u589e\u5927\u7684\u60c5\u51b5\uff0c\u5bfc\u81f4\u56de\u5f52\u4e0d\u7a33\u5b9a\u3002\u8fd9\u79cd\u201c\u8fb9\u754c\u4e0d\u8fde\u7eed\u201d\u95ee\u9898\u5728\u5904\u7406\u957f\u5bbd\u6bd4\u8f83\u5927\u6216\u7ec6\u957f\u76ee\u6807\u65f6\u5c24\u4e3a\u7a81\u51fa\u3002</li> <li>\u7279\u5f81\u63d0\u53d6\u7684\u65cb\u8f6c\u4e0d\u53d8\u6027     \u4f20\u7edf\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u6355\u6349\u65cb\u8f6c\u4e0d\u53d8\u7279\u5f81\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u5982\u4f55\u63d0\u53d6\u65e2\u5bf9\u65cb\u8f6c\u654f\u611f\u53c8\u5bf9\u5206\u7c7b\u9c81\u68d2\u7684\u7279\u5f81\u662f\u5f53\u524d\u7814\u7a76\u7684\u91cd\u8981\u96be\u9898\uff0c\u5f88\u591a\u65b9\u6cd5\u5c1d\u8bd5\u8bbe\u8ba1\u4e13\u95e8\u7684\u65cb\u8f6c\u654f\u611f\u6216\u65cb\u8f6c\u4e0d\u53d8\u6a21\u5757\uff0c\u4f46\u4f9d\u7136\u5b58\u5728\u7cbe\u5ea6\u4e0e\u6548\u7387\u7684\u6743\u8861\u95ee\u9898\u3002\u200b</li> <li> <p>\u7c7b\u65b9\u5f62\u95ee\u9898     \u201c\u7c7b\u65b9\u5f62\u95ee\u9898\u201d\u6307\u7684\u662f\u5728\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u5f53\u76ee\u6807\u7684\u5bbd\u9ad8\u6bd4\u63a5\u8fd11\uff0c\u4e5f\u5c31\u662f\u76ee\u6807\u5f62\u72b6\u8fd1\u4f3c\u6b63\u65b9\u5f62\u65f6\uff0c\u65cb\u8f6c\u89d2\u5ea6\u4fe1\u606f\u4f1a\u53d8\u5f97\u6a21\u7cca\u548c\u4e0d\u786e\u5b9a\u3002\u8fd9\u662f\u56e0\u4e3a\u6b63\u65b9\u5f62\u5728\u65cb\u8f6c\u4efb\u610f\u89d2\u5ea6\u65f6\uff0c\u5176\u5916\u89c2\u51e0\u4e4e\u6ca1\u6709\u660e\u663e\u53d8\u5316\uff0c\u8fd9\u5c31\u5bfc\u81f4\u4e24\u4e2a\u95ee\u9898\uff1a</p> <ul> <li> <p>\u89d2\u5ea6\u6807\u6ce8\u6b67\u4e49     \u5bf9\u4e8e\u7c7b\u65b9\u5f62\u76ee\u6807\uff0c\u5373\u4f7f\u65cb\u8f6c\u4e86\u4e0d\u540c\u89d2\u5ea6\uff0c\u5176\u5f62\u72b6\u53d8\u5316\u5f88\u5c0f\uff0c\u4ece\u800c\u4f7f\u5f97\u89d2\u5ea6\u7684\u6807\u6ce8\u548c\u56de\u5f52\u5177\u6709\u6b67\u4e49\u6027\u3002\u6a21\u578b\u53ef\u80fd\u4f1a\u96be\u4ee5\u5b66\u4e60\u51fa\u7a33\u5b9a\u7684\u89d2\u5ea6\u7279\u5f81\uff0c\u5bfc\u81f4\u56de\u5f52\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u8f83\u5927\u6ce2\u52a8\u6216\u4e0d\u4e00\u81f4\u6027\u3002</p> </li> <li> <p>\u635f\u5931\u8ba1\u7b97\u4e0d\u654f\u611f     \u5f53\u76ee\u6807\u63a5\u8fd1\u6b63\u65b9\u5f62\u65f6\uff0c\u89d2\u5ea6\u9884\u6d4b\u7684\u5fae\u5c0f\u504f\u5dee\u5bf9IoU\u7b49\u8bc4\u4ef7\u6307\u6807\u7684\u5f71\u54cd\u8f83\u5c0f\uff0c\u4ece\u800c\u4f7f\u5f97\u89d2\u5ea6\u635f\u5931\u7684\u68af\u5ea6\u8f83\u5f31\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6a21\u578b\u5f88\u96be\u4ece\u89d2\u5ea6\u4fe1\u606f\u4e2d\u83b7\u5f97\u8db3\u591f\u7684\u4f18\u5316\u4fe1\u53f7\u3002</p> </li> </ul> </li> </ol>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#213","title":"2.1.3 \u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u4ee3\u8868\u6027\u5de5\u4f5c","text":"<p>\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u6280\u672f\u8fd1\u5e74\u6765\u53d1\u5c55\u8fc5\u901f\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u591a\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u9488\u5bf9\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u4e3b\u8981\u6709\u4e09\u4e2a\u53d1\u5c55\u65b9\u5411\uff1a\u65cb\u8f6c\u77e9\u5f62\u6846\u68c0\u6d4b\u3001\u5468\u8fb9\u5f62\u72b6\u6846\u68c0\u6d4b\u548c\u70b9\u96c6\u68c0\u6d4b\u3002\u4ee5\u4e0b\u662f\u6839\u636e\u8fd9\u4e09\u4e2a\u65b9\u5411\u6269\u5c55\u7684\u76f8\u5173\u7814\u7a76\u5de5\u4f5c\u53ca\u5176\u63cf\u8ff0\u3002</p> <ol> <li> <p>\u65cb\u8f6c\u77e9\u5f62\u6846\u68c0\u6d4b\u5206\u652f     \u8fd9\u4e00\u5206\u652f\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u65cb\u8f6c\u77e9\u5f62\u6846\u6765\u8868\u793a\u76ee\u6807\uff0c\u901a\u5e38\u7528\u4e94\u4e2a\u53c2\u6570\uff08x, y, w, h, \u03b8\uff09\u6765\u63cf\u8ff0\uff0c\u5176\u4e2d(x, y)\u8868\u793a\u4e2d\u5fc3\u70b9\uff0cw\u548ch\u8868\u793a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u03b8\u8868\u793a\u65cb\u8f6c\u89d2\u5ea6\u3002\u8be5\u5206\u652f\u7684\u7814\u7a76\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u63d0\u9ad8\u89d2\u5ea6\u56de\u5f52\u7cbe\u5ea6\u4ee5\u53ca\u4f18\u5316\u65cb\u8f6c\u8fb9\u754c\u6846\u7684\u8868\u8fbe\u3002  </p> <ul> <li> <p>RRPN\uff082017\u5e74\uff09: \u9996\u6b21\u63d0\u51fa\u65cb\u8f6c\u533a\u57df\u63d0\u8bae\u7f51\u7edc\uff08RRPN\uff09\uff0c\u901a\u8fc7\u65cb\u8f6c\u8fb9\u754c\u6846\u6765\u8868\u793a\u76ee\u6807\uff0c\u4f7f\u7528\u65cb\u8f6c\u89d2\u5ea6\u56de\u5f52\u6765\u6539\u8fdb\u533a\u57df\u63d0\u8bae\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/1703.01086</p> </li> <li> <p>ROI Transformer\uff082019\u5e74\uff09: \u8be5\u65b9\u6cd5\u5728\u4f20\u7edf\u7684\u533a\u57df\u63d0\u8bae\u7f51\u7edc\uff08RPN\uff09\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86ROI Transformer\u6a21\u5757\uff0c\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u76ee\u6807\u7684\u65cb\u8f6c\u548c\u5c3a\u5ea6\u53d8\u6362\uff0c\u9002\u7528\u4e8e\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/1812.00155</p> </li> <li> <p>SCRDet\uff082019\u5e74\uff09: \u91c7\u7528\u81ea\u9002\u5e94\u7684\u65cb\u8f6c\u89d2\u5ea6\u9884\u6d4b\u673a\u5236\uff0c\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\u6765\u5e94\u5bf9\u65cb\u8f6c\u76ee\u6807\u548c\u573a\u666f\u6587\u672c\u68c0\u6d4b\u4e2d\u7684\u590d\u6742\u60c5\u51b5\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/1811.07126</p> </li> <li> <p>CSL\uff082020\u5e74\uff09: \u63d0\u51fa\u5706\u5f62\u5149\u6ed1\u6807\u7b7e\uff08CSL\uff09\u6280\u672f\uff0c\u5c06\u89d2\u5ea6\u9884\u6d4b\u95ee\u9898\u8f6c\u5316\u4e3a\u5206\u7c7b\u95ee\u9898\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u4f20\u7edf\u56de\u5f52\u65b9\u6cd5\u4e2d\u89d2\u5ea6\u5468\u671f\u6027\u5e26\u6765\u7684\u95ee\u9898\uff0c\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/2003.05597</p> </li> <li> <p>GWD\uff082021\u5e74\uff09: Gaussian Wasserstein Distance (GWD) \u635f\u5931\u51fd\u6570\u7684\u63d0\u51fa\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u957f\u5bbd\u6bd4\u5dee\u5f02\u8f83\u5927\u7684\u76ee\u6807\u68c0\u6d4b\u4e2d\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/2103.06053</p> </li> <li> <p>G-Rep\uff082022\u5e74\uff09: \u63d0\u51fa\u4e86\u57fa\u4e8e\u9ad8\u65af\u5206\u5e03\u7684\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u65cb\u8f6c\u7684\u9ad8\u65af\u8868\u793a\u6cd5\uff0c\u6539\u8fdb\u4e86\u65cb\u8f6c\u77e9\u5f62\u6846\u7684\u8868\u8fbe\uff0c\u589e\u5f3a\u4e86\u5bf9\u5927\u957f\u5bbd\u6bd4\u76ee\u6807\u7684\u9002\u5e94\u6027\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/2205.13617</p> </li> </ul> </li> <li> <p>\u5468\u8fb9\u5f62\u72b6\u6846\u68c0\u6d4b\u5206\u652f     \u8be5\u5206\u652f\u7684\u6838\u5fc3\u601d\u60f3\u662f\u4f7f\u7528\u591a\u8fb9\u5f62\u6216\u66f4\u590d\u6742\u7684\u8fb9\u754c\u5f62\u72b6\u6765\u8868\u793a\u76ee\u6807\uff0c\u9002\u7528\u4e8e\u5f62\u72b6\u4e0d\u89c4\u5219\u6216\u8005\u5b58\u5728\u5f2f\u66f2\u3001\u900f\u89c6\u53d8\u5f62\u7684\u76ee\u6807\u3002</p> <ul> <li> <p>EAST\uff082017\u5e74\uff09: \u63d0\u51fa\u4e86Efficient and Accurate Scene Text Detection\uff08EAST\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08FCN\uff09\u76f4\u63a5\u56de\u5f52\u4efb\u610f\u65b9\u5411\u7684\u65cb\u8f6c\u77e9\u5f62\u6846\uff0c\u5c24\u5176\u5728\u573a\u666f\u6587\u672c\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/1704.00388</p> </li> <li> <p>Gliding Vertex\uff082019\u5e74\uff09: \u63d0\u51fa\u4e86\u57fa\u4e8e\u56db\u4e2a\u9876\u70b9\u7684\u8fb9\u754c\u6846\u56de\u5f52\u65b9\u6cd5\uff0c\u80fd\u591f\u5bf9\u590d\u6742\u5f62\u72b6\u7684\u76ee\u6807\u8fdb\u884c\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u68c0\u6d4b\uff0c\u7279\u522b\u662f\u5728\u9065\u611f\u56fe\u50cf\u548c\u591a\u65b9\u5411\u573a\u666f\u6587\u672c\u68c0\u6d4b\u4e2d\u8868\u73b0\u7a81\u51fa\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/1911.09358\u200b</p> </li> <li> <p>RSDet\uff082020\u5e74\uff09: \u63d0\u51fa\u4e86\u65cb\u8f6c\u56db\u8fb9\u5f62\u56de\u5f52\u7684\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u63d0\u9ad8\u5927\u957f\u5bbd\u6bd4\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u65cb\u8f6c\u8fb9\u754c\u6846\u7684\u9ad8\u9636\u51e0\u4f55\u7ea6\u675f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u573a\u666f\u4e2d\u7684\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/2003.02092</p> </li> <li> <p>CFA\uff082021\u5e74\uff09: \u901a\u8fc7\u89d2\u70b9\u7279\u5f81\u805a\u5408\uff08CFA\uff09\u6a21\u5757\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\u3002CFA\u6a21\u5757\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u4e0d\u540c\u5f62\u72b6\u3001\u5927\u5c0f\u7684\u76ee\u6807\uff0c\u5c24\u5176\u662f\u5177\u6709\u8f83\u5927\u5f62\u53d8\u7684\u76ee\u6807\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/2103.07815</p> </li> </ul> </li> <li> <p>\u70b9\u96c6\u68c0\u6d4b\u5206\u652f     \u8be5\u5206\u652f\u901a\u8fc7\u68c0\u6d4b\u5173\u952e\u70b9\u3001\u89d2\u70b9\u6216\u6781\u503c\u70b9\u6765\u8868\u793a\u76ee\u6807\u8fb9\u754c\uff0c\u9002\u7528\u4e8e\u4e0d\u89c4\u5219\u5f62\u72b6\u3001\u5f2f\u66f2\u76ee\u6807\u6216\u590d\u6742\u80cc\u666f\u4e0b\u7684\u76ee\u6807\u68c0\u6d4b\u3002</p> <ul> <li> <p>Mask TextSpotter\uff082018\u5e74\uff09: \u5229\u7528\u56fe\u50cf\u4e2d\u7684\u5173\u952e\u70b9\u4fe1\u606f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bed\u4e49\u5206\u5272\u7684\u65cb\u8f6c\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u5bf9\u590d\u6742\u5f62\u6001\u548c\u53d8\u5f62\u6587\u672c\u7684\u68c0\u6d4b\u80fd\u529b\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/1807.02242</p> </li> <li> <p>TextField\uff082018\u5e74\uff09: \u901a\u8fc7\u5b66\u4e60\u6df1\u5ea6\u65b9\u5411\u573a\uff08Direction Field\uff09\u6765\u68c0\u6d4b\u4e0d\u89c4\u5219\u573a\u666f\u6587\u672c\uff0c\u5229\u7528\u8be5\u65b9\u5411\u573a\u5bf9\u6587\u672c\u8fb9\u754c\u8fdb\u884c\u6709\u6548\u5206\u5272\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u5bf9\u66f2\u7ebf\u6587\u672c\u7684\u9002\u5e94\u6027\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/1812.01393</p> </li> <li> <p>PointNet\uff082020\u5e74\uff09: \u91c7\u7528PointNet\u67b6\u6784\uff0c\u901a\u8fc7\u63d0\u53d6\u70b9\u4e91\u4e2d\u7684\u5173\u952e\u70b9\u4fe1\u606f\u6765\u8868\u793a\u65cb\u8f6c\u76ee\u6807\uff0c\u5e76\u7ed3\u5408\u56fe\u5f62\u6a21\u578b\u8fdb\u884c\u56de\u5f52\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u65cb\u8f6c\u76ee\u6807\u7684\u68c0\u6d4b\u7cbe\u5ea6\u3002 \u8bba\u6587\u94fe\u63a5\uff1a\u200bhttps://arxiv.org/abs/2012.08692</p> </li> <li> <p>Oriented RepPoints\uff082021\u5e74\uff09: \u63d0\u51fa\u4e86\u5c06\u76ee\u6807\u8868\u793a\u4e3a\u82e5\u5e72\u5173\u952e\u70b9\u7684\u5f62\u5f0f\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u5173\u952e\u70b9\u6765\u63cf\u8ff0\u65cb\u8f6c\u76ee\u6807\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65cb\u8f6c\u76ee\u6807\u8868\u793a\u548c\u68c0\u6d4b\u65b9\u6cd5\u3002 \u8bba\u6587\u94fe\u63a5\uff1ahttps://arxiv.org/abs/2105.11111</p> </li> </ul> </li> </ol>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#22-obb360","title":"2.2 \u5e38\u89c4OBB\u68c0\u6d4b\u4e0e360\u00b0\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u7684\u5173\u7cfb","text":"<p>\u5e38\u89c4OBB\u4e0e360\u00b0\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u7684\u5173\u7cfb\u5728\u4e8e\uff0c\u4e24\u8005\u90fd\u6d89\u53ca\u76ee\u6807\u7684\u65cb\u8f6c\u89d2\u5ea6\u9884\u6d4b\u3002\u200b\u5e38\u89c4OBB\u4efb\u52a1\u901a\u5e38\u5173\u6ce8\u76ee\u6807\u5728\u4e00\u4e2a\u6709\u9650\u89d2\u5ea6\u8303\u56f4\u5185\u7684\u65cb\u8f6c\uff08\u59820\u00b0\u5230180\u00b0\uff09\uff0c\u800c360\u00b0\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u9700\u8981\u5904\u7406\u76ee\u6807\u5728\u6574\u4e2a360\u00b0\u8303\u56f4\u5185\u7684\u65cb\u8f6c\u89d2\u5ea6\u3002\u56e0\u6b64\uff0c360\u00b0\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u5728\u89d2\u5ea6\u56de\u5f52\u65b9\u6cd5\u548c\u6a21\u578b\u8bbe\u8ba1\u4e0a\u9700\u8981\u8003\u8651\u5168\u89d2\u5ea6\u7684\u5904\u7406\uff0c\u4ee5\u51c6\u786e\u9884\u6d4b\u76ee\u6807\u7684\u65cb\u8f6c\u65b9\u5411\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#_3","title":"\u4e09\u3001\u672c\u6587\u6574\u4f53\u65b9\u6848\u4ecb\u7ecd","text":"<p>\u672c\u6587\u6574\u7406\u65b9\u6848\u6d41\u7a0b\u56fe\u5982\u4e0b\uff1a  </p> <pre><code>flowchart TD\n    A[\u56fe\u7247] --&gt; B[360\u00b0\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4bDL\u6a21\u578b]\n    B --&gt; C[\u4f20\u7edf\u970d\u592b\u76f4\u7ebf\u68c0\u6d4b\u7b97\u6cd5]\n    C --&gt; D[\u89d2\u5ea6\u6295\u7968\u540e\u5904\u7406\u7b97\u6cd5]\n    D --&gt; E[\u77eb\u6b63\u56fe\u7247]\n\n    classDef dl fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef algo fill:#bbf,stroke:#333,stroke-width:2px;\n    classDef post fill:#bfb,stroke:#333,stroke-width:2px;\n\n    class B dl\n    class C algo\n    class D post\n    class E algo</code></pre> <p>\u6587\u5b57\u89e3\u91ca\u6b65\u9aa4\u5982\u4e0b\uff1a 1. \u5c06\u56fe\u7247\u8f93\u5165360\u00b0\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4bDL\u6a21\u578b\uff0c\u5f97\u5230\u6587\u5b57\u533a\u57df\u76845\u4e2a\u53c2\u6570(x, y, w, h, \u03b8)\u3002     \u8fd9\u91cc\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u91c7\u7528mmroate\u5e93\uff0c\u7531\u4e8e\u6587\u5b57\u533a\u57df\u4e00\u822c\u8f83\u5927\uff0c\u6240\u4ee5\u91c7\u7528\u4e00\u4e2a\u7b80\u5355\u7684backbone\u5373\u53ef\uff0closs\u91c7\u7528iou loss\u6216\u8005GWD Loss\u3002\u53c2\u8003PR\u5982\u4e0b https://github.com/open-mmlab/mmrotate/discussions/689 https://github.com/open-mmlab/mmrotate/pull/731 2. \u8fdb\u8fc7\u4e0a\u8ff0\u6b65\u9aa4\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u6587\u5b57\u533a\u57df\u7684\u65cb\u8f6c\u89d2\u5ea6\uff0c\u53d6\u503c\u4f4d\u4e8e[-180, +180]\u3002\u9996\u5148\u91c7\u7528\u8be5\u89d2\u5ea6\u91c7\u7528\u4eff\u5c04\u53d8\u6362\u5f97\u5230\u7c97\u7c92\u5ea6\u77eb\u6b63\u540e\u7684\u56fe\u7247\u3002\u5bf9\u4e8e\u77eb\u6b63\u540e\u7684\u56fe\u7247\u91c7\u7528\u4f20\u7edf\u970d\u592b\u76f4\u7ebf\u68c0\u6d4b\u7b97\u6cd5\uff0c\u68c0\u6d4b\u56fe\u7247\u4e2d\u7684\u6240\u6709\u76f4\u7ebf\uff0c\u53c2\u8003\u7b97\u6cd5\u89c1\u4e0b\u6587\u3002   3. \u5148\u9a8c\u77e5\u8bc6\uff1a\u7ecf\u8fc7\u6b65\u9aa41\u77eb\u6b63\u540e\u7684\u56fe\u7247\u65cb\u8f6c\u89d2\u5ea6\u5c5e\u4e8e[-45,45]\u4e4b\u95f4\u7684\u5c0f\u89d2\u5ea6\u3002     \u9996\u5148\u5bf9\u76f4\u7ebf\u659c\u7387\u6c42arctan\uff0c\u8fc7\u6ee4\u6389\u7edd\u5bf9\u503c\u5927\u4e8e45\u7684\u89d2\u5ea6\uff0c\u5bf9\u68c0\u6d4b\u5230\u7684\u76f4\u7ebf\u8fdb\u884c\u89d2\u5ea6\u4e2d\u4f4d\u6570\u6295\u7968\uff0c\u5f97\u5230\u6587\u5b57\u533a\u57df\u7684\u7ec6\u7c92\u5ea6\u89d2\u5ea6\u3002 4. \u5982\u679c\u6b65\u9aa43\u83b7\u53d6\u7684\u89d2\u5ea6\u6ee1\u8db3\u67d0\u4e2a\u6761\u4ef6\uff0c\u5219\u91c7\u7528\u6b65\u9aa43\u7684\uff0c\u5426\u5219\u65cb\u8f6c\u89d2\u5ea6\u91c7\u7528\u6b65\u9aa41\u83b7\u53d6\u7684\u3002\u91c7\u7528\u8ba1\u7b97\u7684\u65cb\u8f6c\u89d2\u5ea6\u5bf9\u4e8e\u56fe\u7247\u8fdb\u884c\u77eb\u6b63\uff0c\u5f97\u5230\u77eb\u6b63\u540e\u7684\u56fe\u7247\u3002  </p> <p>\u6b65\u9aa42 \u970d\u592b\u76f4\u7ebf\u68c0\u6d4b\u53c2\u8003\u4ee3\u7801\uff1a <pre><code>gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nkernel = np.ones((5, 5), np.uint8)\n# \u5f00\u95ed\u8fd0\u7b97\nerrode_img = cv2.erode(gray, kernel, iterations=1)\ndilate_img = cv2.dilate(errode_img, kernel, iterations=1)\n# Canny\u8fb9\u7f18\u68c0\u6d4b\nedges = cv2.Canny(dilate_img, 100, 200)\nlines = cv2.HoughLinesP(edges, 0.8, np.pi / 180, 90, minLineLength=100, maxLineGap=10)\n</code></pre></p> <p>Note</p> <p>\u4e3a\u4ec0\u4e48\u7b2c\u4e00\u6b65\u4e0d\u76f4\u63a5\u91c7\u7528\u4f20\u7edf\u56fe\u50cf\u7b97\u6cd5\u5462\uff1f  1. \u4f20\u7edf\u56fe\u50cf\u7b97\u6cd5\u4e00\u822c\u5c3d\u53ef\u4ee5\u5224\u65ad180\u5ea6\u4ee5\u5185\u7684\u65cb\u8f6c 2. \u4f20\u7edf\u56fe\u50cf\u7b97\u6cd5\u9488\u5bf9\u80cc\u666f\u53d8\u5316\u8f83\u5927\u7684\u573a\u666f\uff0c\u6548\u679c\u4e0d\u4f73\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#_4","title":"\u56db\u3001\u6700\u7ec8\u5b9e\u73b0\u6548\u679c","text":"<p>\u539f\u59cb\u56fe\u7247</p> <p></p> <p>\u7c97\u7c92\u5ea6\u77eb\u6b63\u540e\u56fe\u50cf</p> <p></p> <p>\u7ecf\u8fc7\u970d\u592b\u76f4\u7ebf\u68c0\u6d4b\u77eb\u6b63\u540e\u7684\u56fe\u7247</p> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#_5","title":"\u4e94\u3001\u603b\u7ed3","text":"<p>\u672c\u6587\u63d0\u51fa\u201c\u6df1\u5ea6\u5b66\u4e60\u7c97\u68c0+\u4f20\u7edf\u7b97\u6cd5\u7cbe\u4fee\u201d\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\uff1a</p> <ol> <li>360\u00b0\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff1a     \u91c7\u7528\u4e94\u53c2\u6570\u65cb\u8f6c\u6846\uff08x, y, w, h, \u03b8\uff09\u8868\u793a\u6587\u5b57\u533a\u57df\uff0c\u57fa\u4e8eMMRotate\u6846\u67b6\u5b9e\u73b0\u3002\u635f\u5931\u51fd\u6570\u9009\u7528IoU Loss\u6216GWD Loss\uff0c\u63d0\u5347\u957f\u5bbd\u6bd4\u5dee\u5f02\u5927\u7684\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u3002</li> <li>\u970d\u592b\u76f4\u7ebf\u68c0\u6d4b\u4e0e\u89d2\u5ea6\u6295\u7968\uff1a     \u5bf9\u7c97\u68c0\u540e\u7684\u77eb\u6b63\u56fe\u50cf\uff0c\u901a\u8fc7\u970d\u592b\u53d8\u6362\u63d0\u53d6\u76f4\u7ebf\uff0c\u8fc7\u6ee4\u65e0\u6548\u89d2\u5ea6\uff08&gt;45\u00b0\uff09\uff0c\u5229\u7528\u4e2d\u4f4d\u6570\u6295\u7968\u4f18\u5316\u7ec6\u7c92\u5ea6\u89d2\u5ea6\u3002\u7ed3\u5408\u5148\u9a8c\u77e5\u8bc6\uff08\u77eb\u6b63\u540e\u89d2\u5ea6\u8303\u56f4[-45\u00b0,45\u00b0]\uff09\uff0c\u907f\u514d\u4f20\u7edf\u7b97\u6cd5\u5728\u590d\u6742\u80cc\u666f\u4e0b\u7684\u8bef\u68c0\u3002</li> </ol> <p>\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u89e3\u51b3\u5927\u89d2\u5ea6\u65cb\u8f6c\u95ee\u9898\uff0c\u4f20\u7edf\u7b97\u6cd5\u4fee\u6b63\u5c0f\u89d2\u5ea6\u504f\u5dee\uff0c\u517c\u987e\u6548\u7387\u4e0e\u7cbe\u5ea6\uff0c\u51cf\u5c11\u5bf9\u590d\u6742\u65cb\u8f6c\u6846\u6807\u6ce8\u6570\u91cf\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u6570\u636e\u589e\u5f3a\u96be\u5ea6\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%85%A8%E6%99%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0%E6%80%9D%E8%B7%AF/#_6","title":"\u53c2\u8003\u94fe\u63a5","text":"<ol> <li>https://zhuanlan.zhihu.com/p/459018810</li> <li>https://blog.csdn.net/weixin_36670529/article/details/114553278</li> <li>https://cloud.tencent.com/developer/article/1799984</li> <li>https://blog.csdn.net/weixin_36670529/article/details/114553278</li> <li>https://zhuanlan.zhihu.com/p/679884447</li> <li>https://zhuanlan.zhihu.com/p/105881332</li> <li>https://github.com/open-mmlab/mmrotate/blob/main/docs/zh_cn/intro.md</li> <li>https://www.jb51.net/article/257527.htm</li> </ol>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/","title":"360\u00b0\u65cb\u8f6c\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u5b9e\u62182\uff1a\u9ad8\u6548\u6807\u6ce8\u5de5\u5177\u4e0e\u56e2\u961f\u534f\u4f5c\u6307\u5357","text":""},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_1","title":"\u524d\u8a00","text":"<p>\u5728\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u4e2d\uff0c\u65cb\u8f6c\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u4f5c\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u7684\u5173\u952e\u6280\u672f\uff0c\u76f4\u63a5\u5f71\u54cdOCR\uff08\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff09\u3001\u81ea\u52a8\u9a7e\u9a76\u3001\u5de5\u4e1a\u8d28\u68c0\u7b49\u573a\u666f\u7684\u843d\u5730\u6548\u679c\u3002\u968f\u7740\u6280\u672f\u590d\u6742\u5ea6\u7684\u63d0\u5347\uff0c\u4f20\u7edf\u7684\u5355\u70b9\u5f0f\u6570\u636e\u5904\u7406\u6a21\u5f0f\u5df2\u96be\u4ee5\u6ee1\u8db3\u9ad8\u7cbe\u5ea6\u6a21\u578b\u9700\u6c42\uff0c\u6570\u636e\u6807\u6ce8\u3001\u56e2\u961f\u534f\u4f5c\u4e0e\u7b97\u6cd5\u4f18\u5316\u7684\u534f\u540c\u4f5c\u7528\u6108\u53d1\u51f8\u663e\u3002</p> <p>\u5728\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u9a71\u52a8\u7684\u89c6\u89c9\u667a\u80fd\u65f6\u4ee3\uff0c\u6570\u636e\u6807\u6ce8\u7684\u91cd\u8981\u6027\u6108\u53d1\u51f8\u663e\u3002\u5c24\u5176\u662f\u5728360\u00b0\u65cb\u8f6c\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u8fd9\u4e00\u590d\u6742\u4efb\u52a1\u4e2d\uff0c\u6587\u5b57\u53ef\u80fd\u4ee5\u4efb\u610f\u89d2\u5ea6\u3001\u5f62\u6001\u548c\u80cc\u666f\u51fa\u73b0\uff0c\u53ea\u6709\u901a\u8fc7\u9ad8\u8d28\u91cf\u3001\u7cbe\u7ec6\u5316\u7684\u6807\u6ce8\uff0c\u6a21\u578b\u624d\u80fd\u51c6\u786e\u8bc6\u522b\u591a\u6837\u5316\u7684\u6587\u5b57\u533a\u57df\uff0c\u4ece\u800c\u63d0\u5347\u9c81\u68d2\u6027\u4e0e\u53ec\u56de\u7387\u3002\u65e0\u8bba\u7b97\u6cd5\u7ed3\u6784\u591a\u4e48\u5148\u8fdb\uff0c\u7f3a\u4e4f\u4e30\u5bcc\u4e14\u7cbe\u51c6\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u6a21\u578b\u6027\u80fd\u90fd\u96be\u4ee5\u8fbe\u5230\u9884\u671f\u3002</p> <p>\u9762\u5bf9\u6d77\u91cf\u7684\u6807\u6ce8\u9700\u6c42\uff0c\u5355\u4eba\u4f5c\u4e1a\u4e0d\u4ec5\u6548\u7387\u4f4e\u4e0b\uff0c\u4e14\u96be\u4ee5\u4fdd\u8bc1\u6807\u6ce8\u8d28\u91cf\u7684\u4e00\u81f4\u6027\u3002\u6b64\u65f6\uff0c\u56e2\u961f\u534f\u4f5c\u663e\u5f97\u5c24\u4e3a\u5173\u952e\u3002\u901a\u8fc7\u660e\u786e\u5206\u5de5\uff0c\u5982\u6807\u6ce8\u5458\u8d1f\u8d23\u521d\u6b65\u6807\u8bb0\uff0c\u8d28\u68c0\u5458\u8fdb\u884c\u62bd\u6837\u5ba1\u6821\uff0c\u9879\u76ee\u7ecf\u7406\u7edf\u4e00\u53cd\u9988\u4e0e\u4fee\u8ba2\u89c4\u8303\uff0c\u56e2\u961f\u53ef\u4ee5\u5f62\u6210\u9ad8\u6548\u7684\u534f\u540c\u6d41\u7a0b\u3002\u8fd9\u79cd\u591a\u89d2\u8272\u534f\u4f5c\u4e0d\u4ec5\u52a0\u5feb\u4e86\u6807\u6ce8\u8fdb\u5ea6\uff0c\u8fd8\u786e\u4fdd\u4e86\u6570\u636e\u7684\u4e00\u81f4\u6027\u548c\u9ad8\u8d28\u91cf\uff0c\u4e3a\u540e\u7eed\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\u3002</p> <p>\u7136\u800c\uff0c\u6570\u636e\u6807\u6ce8\u5e76\u975e\u4e00\u52b3\u6c38\u9038\u3002\u968f\u7740\u6a21\u578b\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u90e8\u7f72\uff0c\u65b0\u7684corner case\u548c\u672a\u8986\u76d6\u7684\u573a\u666f\u4e0d\u65ad\u6d8c\u73b0\uff0c\u5982\u7279\u6b8a\u6392\u7248\u3001\u6a21\u7cca\u6587\u5b57\u3001\u906e\u6321\u91cd\u53e0\u7b49\u3002\u6b64\u65f6\uff0c\u6301\u7eed\u7684\u6570\u636e\u8fed\u4ee3\u663e\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u901a\u8fc7\u5bf9\u6a21\u578b\u201c\u76f2\u533a\u201d\u6837\u672c\u8fdb\u884c\u8865\u5145\u6807\u6ce8\u548c\u4f18\u5316\u6807\u7b7e\u96c6\uff08\u751a\u81f3\u6539\u53d8\u6807\u6ce8\u89c4\u5219\uff09\uff0c\u56e2\u961f\u80fd\u591f\u4e0d\u65ad\u4e30\u5bcc\u6570\u636e\u5206\u5e03\uff0c\u4f7f\u6a21\u578b\u5728\u66f4\u591a\u89d2\u5ea6\u548c\u573a\u666f\u4e0b\u8fbe\u5230\u7a33\u5b9a\u3001\u9ad8\u6548\u7684\u68c0\u6d4b\u6548\u679c\u3002</p> <p>\u5728\u4f17\u591a\u6807\u6ce8\u5de5\u5177\u4e2d\uff0cLabel Studio\u4ee5\u5176\u7075\u6d3b\u7684\u914d\u7f6e\u3001\u53ef\u6269\u5c55\u7684\u63d2\u4ef6\u673a\u5236\u53ca\u56fe\u5f62\u5316\u7684\u56e2\u961f\u7ba1\u7406\u529f\u80fd\uff0c\u5c24\u5176\u9002\u5408360\u00b0\u65cb\u8f6c\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u9879\u76ee\u3002\u5b83\u652f\u6301\u81ea\u5b9a\u4e49\u6807\u7b7e\u7c7b\u578b\u3001\u65cb\u8f6c\u6846\u6807\u6ce8\u3001\u5b9e\u65f6\u534f\u540c\u5ba1\u9605\u4e0e\u81ea\u52a8\u8d28\u68c0\u811a\u672c\uff0c\u65e0\u7f1d\u96c6\u6210\u7248\u672c\u63a7\u5236\u4e0e\u5bfc\u51fa\u683c\u5f0f\uff0c\u4f7f\u56e2\u961f\u80fd\u591f\u5728\u540c\u4e00\u5e73\u53f0\u4e0a\u9ad8\u6548\u534f\u4f5c\u3001\u5feb\u901f\u8fed\u4ee3\u3002\u540e\u7eed\u7ae0\u8282\u5c06\u57fa\u4e8eLabel Studio\u7684\u5b9e\u6218\u793a\u4f8b\uff0c\u8be6\u89e3\u5982\u4f55\u642d\u5efa\u6807\u6ce8\u6d41\u6c34\u7ebf\u3001\u5236\u5b9a\u6570\u636e\u6807\u6ce8\u4e0e\u8fed\u4ee3\u7b56\u7565\uff0c\u52a0\u901f\u7b97\u6cd5\u843d\u5730\u3002</p> <p>\u5728\u6700\u540e\u672c\u6587\u8fdb\u4e00\u6b65\u5347\u534e\u4e3b\u9898\uff0c\u5728\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u5386\u7a0b\u4e2d\uff0c\u201c\u6570\u636e\u4e3a\u738b\u201d\u4e0e\u201c\u7b97\u6cd5\u4e3a\u738b\u201d\u7684\u8ba8\u8bba\u4e00\u76f4\u662f\u4e1a\u754c\u5173\u6ce8\u7684\u7126\u70b9\u3002\u8fd9\u4e24\u8005\u5e76\u975e\u5bf9\u7acb\uff0c\u800c\u662f\u76f8\u8f85\u76f8\u6210\uff0c\u5171\u540c\u63a8\u52a8AI\u6280\u672f\u7684\u8fdb\u6b65\u3002\u201c\u6570\u636e\u4e3a\u738b\u201d\u5f3a\u8c03\u7684\u662f\u9ad8\u8d28\u91cf\u6570\u636e\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u201c\u7b97\u6cd5\u4e3a\u738b\u201d\u5219\u5f3a\u8c03\u521b\u65b0\u7684\u6a21\u578b\u7ed3\u6784\u548c\u4f18\u5316\u65b9\u6cd5\u5bf9\u4e8e\u63d0\u5347AI\u7cfb\u7edf\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u7b49\u6280\u672f\u7684\u53d1\u5c55\uff0c\u65b0\u7684\u7b97\u6cd5\u4e0d\u65ad\u6d8c\u73b0\uff0c\u63a8\u52a8\u4e86AI\u5728\u5404\u4e2a\u9886\u57df\u7684\u5e94\u7528\u548c\u7a81\u7834\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#label-studio","title":"\u4e00\u3001Label Studio\u7684\u5b89\u88c5\u4e0e\u57fa\u672c\u4f7f\u7528","text":""},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#11","title":"1.1 \u5b89\u88c5\u4e0e\u542f\u52a8","text":"<ul> <li>\u73af\u5883\u51c6\u5907   \u4f7f\u7528 Anaconda \u521b\u5efa\u865a\u62df\u73af\u5883\uff08\u4ee5 Python 3.8 \u4e3a\u4f8b\uff09\uff1a  </li> </ul> <p><pre><code>conda create -n label_studio python=3.8\nconda activate label_studio\n</code></pre>   \u5b89\u88c5 Label Studio\uff1a <pre><code>pip install label-studio==1.13.1\n</code></pre>   \u542f\u52a8\u670d\u52a1\uff1a <pre><code>label-studio start\n</code></pre>   \u9ed8\u8ba4\u4f1a\u8df3\u8f6c\u81f3\u767b\u5f55\u9875\u9762\uff0c\u9996\u6b21\u4f7f\u7528\u9700\u6ce8\u518c\u8d26\u53f7\u3002</p> <p></p> <ul> <li>\u5176\u4ed6\u5b89\u88c5\u65b9\u5f0f   \u82e5\u4f7f\u7528 Docker\uff0c\u53ef\u901a\u8fc7\u5b98\u65b9 Docker Desktop\uff08Windows/macOS\uff09\u6216 Linux \u5305\u7ba1\u7406\u5668\u5b89\u88c5\u3002</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#12","title":"1.2 \u521b\u5efa\u9879\u76ee","text":"<ul> <li>\u8fdb\u5165 Web \u754c\u9762\u540e\u70b9\u51fb Create Project\uff0c\u8f93\u5165\u9879\u76ee\u540d\u79f0\u548c\u63cf\u8ff0\u3002</li> <li>\u9009\u62e9\u9002\u5408\u7684\u6807\u6ce8\u4efb\u52a1\u6a21\u677f\uff08\u5982\u56fe\u50cf\u5206\u7c7b\u3001\u5b9e\u4f53\u8bc6\u522b\u3001\u5173\u952e\u70b9\u6807\u6ce8\u7b49\uff09\u3002   \u4f8b\u5982\uff0c\u4eba\u5934\u6807\u6ce8\u9009\u62e9 Keypoint Labeling \u6a21\u677f [[4]]\u3002</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#13","title":"1.3 \u6570\u636e\u5bfc\u5165","text":"<ul> <li>\u8fdb\u5165 Data Import \u9875\u9762\uff0c\u70b9\u51fb Upload Files \u4e0a\u4f20\u672c\u5730\u6570\u636e\uff08\u652f\u6301\u56fe\u50cf\u3001\u97f3\u9891\u3001\u6587\u672c\u7b49\u683c\u5f0f\uff09\u3002</li> <li>\u6570\u636e\u4e0a\u4f20\u540e\uff0c\u53ef\u5728\u4efb\u52a1\u5217\u8868\u4e2d\u67e5\u770b\u3002</li> </ul> <p>\u4e0a\u9762\u7684\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u5c0f\u89c4\u6a21\u6570\u636e\uff0c\u5f53\u6570\u636e\u96c6\u8fc7\u5927\u65f6\uff0c\u6bd4\u5982\u4e07\u7ea7\u81f3\u767e\u4e07\u7ea7\u56fe\u7247\u6570\u636e\u9700\u8981\u6807\u6ce8\u65f6\uff0c\u5c31\u9700\u8981\u7528\u5230\u672c\u5730\u5b58\u50a8\u3002Label Studio \u91c7\u7528\u672c\u5730\u5b58\u50a8\uff08Local Storage\uff09\u65b9\u5f0f\u5bfc\u5165\u6570\u636e\uff0c\u4e3b\u8981\u662f\u4e3a\u4e86\u6ee1\u8db3\u4ee5\u4e0b\u9700\u6c42\uff1a</p> <ol> <li>\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff1a\u901a\u8fc7\u672c\u5730\u5b58\u50a8\uff0c\u53ef\u4ee5\u9ad8\u6548\u5730\u7ba1\u7406\u548c\u5bfc\u5165\u5927\u91cf\u6570\u636e\uff0c\u907f\u514d\u4e86\u901a\u8fc7 Web \u754c\u9762\u4e0a\u4f20\u5927\u6587\u4ef6\u65f6\u53ef\u80fd\u9047\u5230\u7684\u9650\u5236\u548c\u6027\u80fd\u95ee\u9898\u3002</li> <li>\u63d0\u9ad8\u6570\u636e\u8bbf\u95ee\u901f\u5ea6\uff1a\u672c\u5730\u5b58\u50a8\u7684\u6570\u636e\u8bbf\u95ee\u901f\u5ea6\u901a\u5e38\u5feb\u4e8e\u8fdc\u7a0b\u5b58\u50a8\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6807\u6ce8\u6548\u7387\u3002</li> <li>\u589e\u5f3a\u6570\u636e\u5b89\u5168\u6027\uff1a\u5c06\u6570\u636e\u4fdd\u5b58\u5728\u672c\u5730\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u63a7\u5236\u6570\u636e\u7684\u8bbf\u95ee\u6743\u9650\uff0c\u51cf\u5c11\u6570\u636e\u6cc4\u9732\u7684\u98ce\u9669\u3002</li> <li>\u7b80\u5316\u6570\u636e\u540c\u6b65\u8fc7\u7a0b\uff1a\u672c\u5730\u5b58\u50a8\u4f7f\u5f97\u6570\u636e\u7684\u540c\u6b65\u548c\u7ba1\u7406\u66f4\u52a0\u76f4\u63a5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u4e0d\u4f9d\u8d56\u4e91\u670d\u52a1\u7684\u73af\u5883\u3002</li> </ol> <p>Label Studio \u901a\u8fc7\u652f\u6301\u672c\u5730\u5b58\u50a8\u65b9\u5f0f\u5bfc\u5165\u6570\u636e\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u548c\u63a7\u5236\u529b\uff0c\u7279\u522b\u9002\u5408\u9700\u8981\u5904\u7406\u5927\u91cf\u6570\u636e\u4e14\u5bf9\u6570\u636e\u5b89\u5168\u6027\u6709\u8f83\u9ad8\u8981\u6c42\u7684\u9879\u76ee\u3002</p> <p>\u672c\u6587\u4f1a\u5728\u4e0b\u9762\u4e00\u7ae0\u4f1a\u4ecb\u7ecd\u5982\u4f55\u5f00\u542fLocal Storage\u4ee5\u53ca\u600e\u4e48\u4f7f\u7528\u5b83\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#14","title":"1.4 \u6807\u7b7e\u914d\u7f6e","text":"<ul> <li>\u70b9\u51fb Labeling Setup\uff0c\u6839\u636e\u4efb\u52a1\u9700\u6c42\u8bbe\u7f6e\u6807\u7b7e\uff1a</li> <li>\u53ef\u89c6\u5316\u65b9\u5f0f\uff1a\u901a\u8fc7\u754c\u9762\u62d6\u62fd\u914d\u7f6e\u6807\u7b7e\uff08\u5982\u6587\u672c\u5206\u7c7b\u3001\u5b9e\u4f53\u8fb9\u754c\u6846\u7b49\u3002</li> <li>\u4ee3\u7801\u65b9\u5f0f\uff1a\u76f4\u63a5\u7f16\u8f91\u914d\u7f6e\u6587\u4ef6\uff08\u5982 JSON \u6216 XML \u683c\u5f0f\uff09\uff0c\u5b9a\u4e49\u6807\u7b7e\u7c7b\u578b\u548c\u5c5e\u6027\u3002</li> <li>\u793a\u4f8b\uff1a\u4eba\u5934\u6807\u6ce8\u9700\u5b9a\u4e49\u5173\u952e\u70b9\u6807\u7b7e\uff08\u5982 \"person_head\"\u3002</li> </ul> <p>\u8fd9\u91cc\u6211\u4eec\u8fd8\u662f\u9009\u62e9\u76ee\u6807\u68c0\u6d4b\u7528\u6765\u6807\u6ce8\u65cb\u8f6c\u77e9\u5f62</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#15","title":"1.5 \u5f00\u59cb\u6807\u6ce8","text":"<ul> <li>\u914d\u7f6e\u5b8c\u6210\u540e\uff0c\u70b9\u51fb Save \u8fdb\u5165\u6807\u6ce8\u754c\u9762\u3002</li> <li>\u5bf9\u56fe\u50cf\u3001\u6587\u672c\u7b49\u6570\u636e\u8fdb\u884c\u6807\u6ce8\uff08\u5982\u70b9\u51fb\u76ee\u6807\u4f4d\u7f6e\u6dfb\u52a0\u5173\u952e\u70b9\uff09\u3002</li> <li>\u5b8c\u6210\u5355\u6761\u6570\u636e\u6807\u6ce8\u540e\uff0c\u70b9\u51fb Submit \u63d0\u4ea4\u7ed3\u679c\uff0c\u8fdb\u5165\u4e0b\u4e00\u6761\u6570\u636e\u3002</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#16","title":"1.6 \u6570\u636e\u5bfc\u51fa","text":"<ul> <li>\u6807\u6ce8\u5b8c\u6210\u540e\uff0c\u70b9\u51fb Export \u5bfc\u51fa\u7ed3\u679c\u3002</li> <li>\u652f\u6301\u591a\u79cd\u683c\u5f0f\uff08\u5982 JSON\u3001CSV\u3001YOLO \u683c\u5f0f\u7b49\uff09\uff0c\u53ef\u6839\u636e\u9700\u6c42\u9009\u62e9\u3002</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#17","title":"1.7 \u9ad8\u7ea7\u529f\u80fd","text":"<ul> <li>\u96c6\u6210\u673a\u5668\u5b66\u4e60\uff1a\u901a\u8fc7 <code>Label Studio ML</code> \u540e\u7aef\u8fde\u63a5\u6a21\u578b\uff0c\u5b9e\u73b0\u9884\u6d4b\u4e0e\u8f85\u52a9\u6807\u6ce8\uff08\u9700\u7f16\u5199 <code>predict</code> \u65b9\u6cd5\u5904\u7406\u4efb\u52a1\u6570\u636e\uff09\u3002</li> <li>\u81ea\u5b9a\u4e49\u4efb\u52a1\uff1a\u6839\u636e\u9700\u6c42\u8c03\u6574\u6807\u7b7e\u7c7b\u578b\uff08\u5982\u5206\u7c7b\u3001\u5b9e\u4f53\u8bc6\u522b\u3001\u5206\u5272\u7b49\uff09\uff0c\u6216\u7ed3\u5408\u4ee3\u7801\u793a\u4f8b\u5feb\u901f\u96c6\u6210 [[8]]\u3002</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#label-studio_1","title":"\u4e8c\u3001Label Studio \u672c\u5730\u5b58\u50a8\u65b9\u5f0f\u6784\u5efa\u6807\u6ce8\u6570\u636e\u65b9\u6cd5","text":""},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#21","title":"2.1 \u73af\u5883\u51c6\u5907","text":"<ol> <li> <p>\u5728\u8fd0\u884c Label Studio \u7684\u673a\u5668\u4e0a\uff0c\u8bbe\u7f6e\u4ee5\u4e0b\u73af\u5883\u53d8\u91cf\uff1a</p> </li> <li> <p><code>LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true</code></p> </li> <li><code>LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT</code>\uff1a\u6307\u5411\u672c\u5730\u6587\u4ef6\u6839\u76ee\u5f55\uff0c\u4f8b\u5982 <code>/home/user</code>\uff08Linux/macOS\uff09\u6216 <code>C:\\data\\media</code>\uff08Windows\uff09</li> </ol> <p>\u8bf4\u660e\uff1a</p> <ul> <li><code>LOCAL_FILES_SERVING_ENABLED</code> \u6253\u5f00\u5bf9\u672c\u5730\u6587\u4ef6\u7684\u8bbf\u95ee\u652f\u6301\uff1b</li> <li><code>DOCUMENT_ROOT</code> \u9650\u5236\u53ef\u8bbf\u95ee\u76ee\u5f55\uff0c\u786e\u4fdd\u5b89\u5168\u6027\u3002    (Label Studio)</li> </ul> <ol> <li>\u786e\u8ba4 Label Studio \u5df2\u6b63\u786e\u5b89\u88c5\u5e76\u53ef\u542f\u52a8\uff1a</li> </ol> <pre><code>LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/data/jinlong/std_data label-studio start\n</code></pre> <p><code>LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT</code> \u4e2d\u8bbe\u7f6e\u7684\u503c\u9700\u8981\u662f\u5f85\u52a0\u8f7d\u8d44\u6e90\u7684\u6839\u76ee\u5f55\u3002\u6bd4\u5982\u8d44\u6e90\u653e\u5728 <code>/data/jinlong/std_data/call_images/images</code> \u4e0b\u9762\uff0c\u5c31\u53ef\u4ee5\u8bbe\u7f6e <code>LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/data/jinlong/std_data</code> </p> <p>\u82e5\u4f7f\u7528 Docker\uff0c\u8bf7\u786e\u4fdd\u5728\u542f\u52a8\u65f6\u6302\u8f7d\u4e86\u5bf9\u5e94\u76ee\u5f55\uff0c\u5e76\u901a\u8fc7 <code>-e</code> \u4f20\u5165\u4e0a\u8ff0\u73af\u5883\u53d8\u91cf\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#22-ui-local-storage","title":"2.2 \u5728 UI \u4e2d\u6dfb\u52a0 Local Storage","text":"<ol> <li>\u6253\u5f00\u67d0\u4e2a\u9879\u76ee\uff0c\u8fdb\u5165 Settings \u2192 Cloud Storage\uff1b</li> <li>\u70b9\u51fb Add Source Storage\uff1b</li> <li>\u5728\u5f39\u7a97\u4e2d\uff1a</li> <li>Storage Type \u9009\u62e9 Local Files\uff1b</li> <li>Storage Title \u586b\u5199\u4e00\u4e2a\u6613\u8bc6\u522b\u7684\u540d\u79f0\uff1b</li> <li>Absolute local path \u586b\u5165\u4e00\u4e2a\u4ee5 <code>LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT</code> \u4e3a\u524d\u7f00\u7684\u7edd\u5bf9\u8def\u5f84\uff08\u4f8b\u5982 <code>/home/user/dataset1</code>\uff09\uff1b</li> <li>\uff08\u53ef\u9009\uff09File Filter Regex\uff1a\u7528\u6b63\u5219\u8fc7\u6ee4\u6587\u4ef6\uff0c\u9ed8\u8ba4 <code>.*</code> \u8868\u793a\u5168\u90e8\uff1b</li> <li>\uff08\u53ef\u9009\uff09Treat every bucket object as a source file\uff1a\uff08\u4e00\u822c\u9700\u8981\u9009\u4e2d\uff09<ul> <li>\u82e5\u5f00\u542f\uff0cLabel Studio \u4f1a\u628a\u76ee\u5f55\u4e0b\u7684\u6bcf\u4e2a\u6587\u4ef6\uff08\u5982 JPG/MP3\uff09\u81ea\u52a8\u751f\u6210\u5355\u6e90\u4efb\u52a1\uff1b</li> <li>\u82e5\u5173\u95ed\uff0c\u5219\u53ea\u5bfc\u5165 JSON/JSONL \u683c\u5f0f\u7684\u4efb\u52a1\u6587\u4ef6\uff0c\u9002\u5408\u590d\u6742\u591a\u6e90\u4efb\u52a1\u3002</li> </ul> </li> <li>\u70b9\u51fb Add Storage \u5b8c\u6210\u6302\u8f7d\uff1b</li> <li>\u6302\u8f7d\u540e\u70b9\u51fb Sync \u6309\u94ae\uff0cLabel Studio \u4f1a\u9012\u5f52\u626b\u63cf\u8be5\u76ee\u5f55\u5e76\u5c06\u7b26\u5408\u6761\u4ef6\u7684\u6587\u4ef6\u6216\u4efb\u52a1\u5bfc\u5165\u9879\u76ee\u4e2d\u3002</li> </ol>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#23","title":"2.3 \u5bfc\u5165\u81ea\u5b9a\u4e49\u683c\u5f0f\u7684\u4efb\u52a1","text":"<p>\u5bf9\u4e8e\u591a\u6e90\u6216\u590d\u6742\u914d\u7f6e\u7684\u4efb\u52a1\uff08\u5982\u540c\u65f6\u542b\u56fe\u50cf\u3001\u97f3\u9891\u3001\u6587\u672c\u7b49\uff09\uff0c\u901a\u5e38\uff1a</p> <ol> <li> <p>\u91cd\u590d\u4e0a\u8ff0\u300c\u6dfb\u52a0 Storage\u300d\u6b65\u9aa4\uff0c\u4f46\uff1a</p> </li> <li> <p>File Filter Regex \u7559\u7a7a\uff1b</p> </li> <li> <p>\u5173\u95ed Treat every bucket object as a source file\uff1b</p> </li> <li> <p>\u4e0d\u6267\u884c \u540c\u6b65\u64cd\u4f5c\uff08\u4e0d\u8981\u70b9 Sync\uff09\uff0c\u4ee5\u514d\u81ea\u52a8\u6309\u6587\u4ef6\u751f\u6210\u4efb\u52a1\uff1b</p> </li> <li> <p>\u5728\u4efb\u52a1 JSON \u4e2d\uff0c\u4f7f\u7528\u4ee5\u4e0b\u8def\u5f84\u683c\u5f0f\u5f15\u7528\u672c\u5730\u6587\u4ef6\uff1a</p> </li> </ol> <pre><code>[\n  {\n    \"id\": 1,\n    \"data\": {\n      \"audio\": \"/data/local-files/?d=dataset1/audio/1.wav\",\n      \"image\": \"/data/local-files/?d=dataset1/images/1.jpg\"\n    }\n  },\n  \u2026\n]\n</code></pre> <ul> <li> <p><code>/data/local-files/?d=</code> \u662f\u56fa\u5b9a\u524d\u7f00\uff0c\u540e\u9762\u8ddf\u9879\u76ee\u5185\u76f8\u5bf9\u4e8e <code>DOCUMENT_ROOT</code> \u7684\u5b50\u8def\u5f84\uff1b</p> </li> <li> <p>\u901a\u8fc7 Data Manager \u2192 Import \u754c\u9762\uff0c\u62d6\u62fd\u8be5 JSON \u6587\u4ef6\u5e76\u70b9\u51fb Import\uff0c\u5b8c\u6210\u4efb\u52a1\u521b\u5efa\u3002</p> </li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#24-docker","title":"2.4 Docker \u5316\u90e8\u7f72\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li> <p>\u5728\u542f\u52a8\u5bb9\u5668\u65f6\uff0c\u901a\u8fc7 <code>-v /\u5bbf\u4e3b\u673a/\u76ee\u5f55:/data/local-files</code>\uff08\u6216\u5176\u4ed6\u8def\u5f84\uff09\u6302\u8f7d\u672c\u5730\u6570\u636e\uff1b</p> </li> <li> <p>\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\uff1a</p> </li> </ul> <pre><code>services:\n  label-studio:\n    image: heartexlabs/label-studio:latest\n    volumes:\n      - /home/user/dataset1:/data/local-files\n    environment:\n      - LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true\n      - LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/data/local-files\n</code></pre> <ul> <li>\u5bb9\u5668\u5185\u8def\u5f84\u9700\u4e0e UI \u6216 API \u4e2d\u914d\u7f6e\u7684 <code>directoryPath</code> \u4fdd\u6301\u4e00\u81f4\u3002</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#25","title":"2.5 \u5b89\u5168\u4e0e\u6700\u4f73\u5b9e\u8df5","text":"<ul> <li>\u6700\u5c0f\u6743\u9650\uff1a\u4ec5\u5c06\u9700\u8981\u7684\u76ee\u5f55\u6302\u8f7d\u5230 <code>DOCUMENT_ROOT</code> \u4e0b\uff1b</li> <li>\u6b63\u5219\u8fc7\u6ee4\uff1a\u5c3d\u91cf\u901a\u8fc7 <code>File Filter Regex</code> \u7b5b\u9009\uff0c\u907f\u514d\u65e0\u5173\u6587\u4ef6\u5e72\u6270\uff1b</li> <li>\u7248\u672c\u7ba1\u7406\uff1a\u5bf9\u4efb\u52a1 JSON \u53ca\u6807\u6ce8\u7ed3\u679c\u4f7f\u7528 Git/\u5bf9\u8c61\u5b58\u50a8\u7b49\u65b9\u5f0f\u6301\u4e45\u5316\uff1b</li> <li>\u5b9a\u671f\u6e05\u7406\uff1a\u540c\u6b65\u5931\u8d25\u6216\u8fc7\u671f\u6587\u4ef6\u53ef\u624b\u52a8\u6e05\u7406\uff0c\u4fdd\u6301\u5b58\u50a8\u6574\u6d01\u3002</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_2","title":"\u4e09\u3001\u56e2\u961f\u5171\u4eab\u6807\u6ce8\u7684\u65b9\u6cd5","text":"<p>Label Studio\u4f5c\u4e3a\u4e00\u4e2aweb\u7aef\u7684\u6807\u6ce8\u5de5\u5177\uff0c\u53ef\u4ee5\u5f88\u65b9\u4fbf\u7684\u5b9e\u73b0\u56e2\u961f\u534f\u4f5c\u6807\u6ce8\u3002</p> <p>\u4f7f\u7528\u6570\u636e\u7ba1\u7406\u5668\u7684\u7b5b\u9009\u548c\u6807\u7b7e\u529f\u80fd\u5206\u914d\u4efb\u52a1</p> <p>\u5927\u90e8\u5206\u4eba\u4f7f\u7528\u7684\u793e\u533a\u529e\uff0c\u793e\u533a\u7248\u4e0d\u652f\u6301\u76f4\u63a5\u5c06\u4efb\u52a1\u5206\u914d\u7ed9\u7279\u5b9a\u7684\u6807\u6ce8\u8005\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u6570\u636e\u7ba1\u7406\u5668\u7684\u7b5b\u9009\u548c\u6807\u7b7e\u529f\u80fd\uff0c\u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u90e8\u5206\uff0c\u5e76\u7531\u4e0d\u540c\u7684\u6807\u6ce8\u8005\u8d1f\u8d23\u5404\u81ea\u7684\u90e8\u5206\u3002</p> <p>\u64cd\u4f5c\u6b65\u9aa4\uff1a</p> <ol> <li>\u5728\u9879\u76ee\u4e2d\uff0c\u4f7f\u7528\u7b5b\u9009\u5668\u6839\u636e\u4efb\u52a1\u7684\u67d0\u4e9b\u5c5e\u6027\uff08\u5982\u4efb\u52a1ID\u8303\u56f4\uff09\u521b\u5efa\u4e0d\u540c\u7684\u89c6\u56fe\u3002</li> <li>\u4e3a\u6bcf\u4e2a\u89c6\u56fe\u521b\u5efa\u4e00\u4e2a\u6807\u7b7e\u9875\uff0c\u5e76\u91cd\u547d\u540d\u4e3a\u7279\u5b9a\u6807\u6ce8\u8005\u7684\u540d\u5b57\u3002</li> <li>\u6807\u6ce8\u8005\u767b\u5f55\u540e\uff0c\u9009\u62e9\u5bf9\u5e94\u7684\u6807\u7b7e\u9875\uff0c\u5f00\u59cb\u6807\u6ce8\u5176\u5206\u914d\u7684\u4efb\u52a1\u3002</li> </ol> <p></p> <p></p> <p>\u5047\u8bbe\u6709\u4e00\u4e2a\u5305\u542b300\u4e2a\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u56e2\u961f\u4e2d\u67093\u540d\u6807\u6ce8\u8005\uff0c\u8ba1\u5212\u6bcf\u4eba\u8d1f\u8d23100\u4e2a\u4efb\u52a1\u3002</p> <p>\u793e\u533a\u7248\u64cd\u4f5c\u65b9\u6cd5\uff1a</p> <ol> <li>\u5728\u6570\u636e\u7ba1\u7406\u5668\u4e2d\uff0c\u521b\u5efa\u4e09\u4e2a\u7b5b\u9009\u5668\uff0c\u5206\u522b\u7b5b\u9009\u4efb\u52a1ID\u4e3a1-100\u3001101-200\u548c201-300\u7684\u4efb\u52a1\u3002</li> <li>\u4e3a\u6bcf\u4e2a\u7b5b\u9009\u5668\u521b\u5efa\u4e00\u4e2a\u6807\u7b7e\u9875\uff0c\u5e76\u547d\u540d\u4e3a\u6807\u6ce8\u8005\u7684\u540d\u5b57\u3002</li> <li>\u6807\u6ce8\u8005\u767b\u5f55\u540e\uff0c\u9009\u62e9\u5bf9\u5e94\u7684\u6807\u7b7e\u9875\uff0c\u5f00\u59cb\u6807\u6ce8\u4efb\u52a1\u3002</li> </ol>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_3","title":"\u56db\u3001\u8f85\u52a9\u6807\u6ce8","text":"<p>\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\uff08Computer Vision, CV\uff09\u4efb\u52a1\u4e2d\uff0c\u6570\u636e\u6807\u6ce8\u59cb\u7ec8\u662f\u4e00\u9879\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u6602\u7684\u5de5\u4f5c\uff0c\u5c24\u5176\u662f\u50cf\u76ee\u6807\u68c0\u6d4b\u3001\u8bed\u4e49\u5206\u5272\u7b49\u7cbe\u7ec6\u4efb\u52a1\uff0c\u6807\u6ce8\u4e00\u5f20\u56fe\u53ef\u80fd\u9700\u8981\u51e0\u5206\u949f\u751a\u81f3\u66f4\u957f\u65f6\u95f4\u3002\u4e3a\u7f13\u89e3\u6807\u6ce8\u538b\u529b\uff0c\u201c\u8f85\u52a9\u6807\u6ce8\uff08Assisted Labeling\uff09\u201d\u662f\u5de5\u4e1a\u754c\u7684\u70ed\u95e8\u6280\u672f\u3002</p> <p>\u8f85\u52a9\u6807\u6ce8\u5e76\u975e\u5b8c\u5168\u66ff\u4ee3\u4eba\u5de5\uff0c\u800c\u662f\u4ee5\u6a21\u578b\u6216\u5de5\u5177\u4e3a\u201c\u52a9\u624b\u201d\uff0c\u5e2e\u52a9\u4eba\u5de5\u66f4\u5feb\u901f\u5730\u5b8c\u6210\u6807\u6ce8\u3002\u4f8b\u5982\uff0c\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u521d\u6b65\u7684\u5206\u5272\u7ed3\u679c\uff0c\u6807\u6ce8\u5458\u53ea\u9700\u5fae\u8c03\u8fb9\u7f18\u6216\u4fee\u6b63\u9519\u8bef\uff0c\u5de5\u4f5c\u91cf\u5927\u5e45\u51cf\u5c11\u3002</p> <p>\u4e00\u4e9b\u73b0\u4ee3\u7684\u6570\u636e\u6807\u6ce8\u5e73\u53f0\uff08\u5982CVAT\u3001Label Studio\u7b49\uff09\u5df2\u7ecf\u96c6\u6210\u4e86\u8fd9\u79cd\u667a\u80fd\u9884\u6807\u6ce8\u529f\u80fd\uff0c\u751a\u81f3\u652f\u6301\u201c\u4e3b\u52a8\u5b66\u4e60\u201d\u673a\u5236\uff1a\u7cfb\u7edf\u4f1a\u4f18\u5148\u6311\u9009\u6a21\u578b\u6700\u4e0d\u786e\u5b9a\u7684\u6837\u672c\u7ed9\u4eba\u5de5\u6807\u6ce8\uff0c\u4ece\u800c\u6700\u5927\u5316\u6bcf\u4e00\u6b21\u6807\u6ce8\u7684\u4ef7\u503c\u3002</p> <p>\u8fd9\u91cc\u6211\u4eec\u4e3a\u4fdd\u8bc1\u65b9\u6cd5\u7684\u901a\u7528\u6027\uff0c\u4e0d\u5c40\u9650\u4e8e\u67d0\u4e00\u4e2a\u6570\u636e\u6807\u6ce8\u5e73\u53f0\uff0c\u91c7\u7528\u4e00\u79cd\u81ea\u5b9a\u4e49\u6807\u6ce8\u7684\u65b9\u6cd5\u6765\u7ed9\u51fa\u9884\u6d4b\u3002</p> <p>\u8fd9\u91cc\u4ee5\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4bmmroate\u4e3a\u4f8b\uff0c\u4e0b\u9762\u662f<code>bad_case.py</code>\uff0c\u91cc\u9762\u5373\u5305\u542b\u6a21\u578b\u7684\u9884\u6d4b\u4fe1\u606f\uff0c\u4fdd\u5b58\u4e3atxt\u3002</p> <pre><code>import os\nimport shutil\nimport numpy as np\nimport cv2\nfrom mmengine.runner import Runner\nfrom mmdet.apis import inference_detector, init_detector\nfrom mmdet.registry import DATASETS, VISUALIZERS\nfrom projects.RR360.evaluation import eval_rbbox_head_map\nfrom mmengine.config import Config\n\nimport os\nimport os.path as osp\n\nfrom mmdet.utils import register_all_modules as register_all_modules_mmdet\nfrom projects.RR360.structures.bbox import RotatedBoxes\n\nimport mmrotate.structures\nfrom mmrotate.utils import import register_all_modules\n\n# TODO: Refactoring with registry build\nmmrotate.structures.bbox.RotatedBoxes = RotatedBoxes\n\n# \u53c2\u6570\u914d\u7f6e\nPALETTE = 'dota'\nCONFIG_PATH = \"/mmrotate/self_script/work_dirs/360_det/360_det.py\"  # \u6a21\u578b\u914d\u7f6e\u6587\u4ef6\u8def\u5f84\nCHECKPOINT_PATH = \"/mmrotate/self_script/work_dirs/360_det/best.pth\"  # \u6a21\u578b\u6743\u91cd\u8def\u5f84\nIOU_THRESHOLD = 0.95  # IoU \u9608\u503c\nOUTPUT_DIR = \"./train_bad_case\"  # \u8f93\u51fa\u76ee\u5f55\nDEVICE = \"cuda\"  # \u4f7f\u7528\u7684\u8bbe\u5907\n\n\ndef copy_image(src_path, dst_folder, filename):\n    os.makedirs(dst_folder, exist_ok=True)\n    shutil.copy(src_path, os.path.join(dst_folder, filename))\n\n\ndef visualize_detections(img_path, gt_bboxes, pred_bboxes, output_path):\n    image = cv2.imread(img_path)\n\n    # \u7ed8\u5236 GT \u8fb9\u754c\u6846\uff08\u7eff\u8272\uff09\n    for bbox in gt_bboxes:\n        bbox = bbox.astype(int)\n        cv2.polylines(image, [bbox.reshape(-1, 2)], isClosed=True, color=(0, 255, 0), thickness=2)\n\n    # \u7ed8\u5236\u9884\u6d4b\u8fb9\u754c\u6846\uff08\u7ea2\u8272\uff09\n    for bbox in pred_bboxes:\n        bbox = bbox.astype(int)\n        cv2.polylines(image, [bbox.reshape(-1, 2)], isClosed=True, color=(0, 0, 255), thickness=2)\n\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    cv2.imwrite(output_path, image)\n\n\ndef save_bboxes_to_txt(bboxes, output_path, label):\n    \"\"\"\n    \u4fdd\u5b58\u8fb9\u754c\u6846\u5230 txt \u6587\u4ef6\u4e2d\u3002\n\n    Args:\n        bboxes (ndarray): \u8fb9\u754c\u6846\u6570\u7ec4\uff0c\u683c\u5f0f\u4e3a [x, y, w, h, angle].\n        output_path (str): \u4fdd\u5b58\u8def\u5f84\u3002\n        label (str): \u6807\u7b7e\u7c7b\u578b\uff0c\u5982 \"GT\" \u6216 \"PRED\"\u3002\n    \"\"\"\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    with open(output_path, 'w') as f:\n        for bbox in bboxes:\n            bbox_str = \" \".join(map(str, bbox))\n            f.write(f\"{label} {bbox_str}\\n\")\n\n\ndef main():\n    register_all_modules_mmdet(init_default_scope=False)\n    register_all_modules(init_default_scope=False)\n\n    # Load config\n    cfg = Config.fromfile(CONFIG_PATH)\n\n    # \u521d\u59cb\u5316\u6a21\u578b\n    model = init_detector(CONFIG_PATH, CHECKPOINT_PATH, palette=PALETTE, device=DEVICE)\n\n    # \u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e\u96c6\n    model.cfg.test_dataloader.batch_size = 1\n    model.cfg.test_dataloader.num_workers = 1\n    model.cfg.test_dataloader.persistent_workers = True\n    model.cfg.test_dataloader.dataset.data_root = model.cfg.train_dataloader.dataset.data_root\n    dirname = os.path.basename(OUTPUT_DIR)\n    mode = dirname.split(\"_\")[0]\n    model.cfg.test_dataloader.dataset.ann_file = f\"{mode}/\"\n    model.cfg.test_dataloader.dataset.data_prefix.img_path = f\"{mode}/\"\n\n    dataset = DATASETS.build(model.cfg.test_dataloader.dataset)\n\n    model.cfg.visualizer.vis_backends = [dict(type='LocalVisBackend')]\n    visualizer = VISUALIZERS.build(model.cfg.visualizer)\n    visualizer.dataset_meta = dataset.metainfo\n\n    data_loader = Runner.build_dataloader(model.cfg.test_dataloader)\n\n    # \u8f93\u51fa\u6587\u4ef6\u5939\u521d\u59cb\u5316\n    low_iou_images = []\n    folder_low_iou = os.path.join(OUTPUT_DIR, 'low_iou_images')\n    folder_visualizations = os.path.join(OUTPUT_DIR, 'visualizations')\n    folder_bboxes = os.path.join(OUTPUT_DIR, 'bboxes_txt')\n\n    # \u904d\u5386\u6570\u636e\u96c6\u5e76\u5904\u7406\n    for i, data in enumerate(data_loader):\n        # \u83b7\u53d6\u56fe\u7247\u4fe1\u606f\n        img_metas = data['data_samples'][0].metainfo\n        img_path = img_metas['img_path']\n        img_name = os.path.basename(img_path)\n\n        # \u63a8\u7406\n        result = inference_detector(model, img_path)\n\n        # \u63d0\u53d6 GT \u548c\u9884\u6d4b\u6846\n        gt_bboxes = {\n            'bboxes': data['data_samples'][0].gt_instances.bboxes.numpy(),\n            'labels': data['data_samples'][0].gt_instances.labels.numpy(),\n            'bboxes_ignore': data['data_samples'][0].ignored_instances.bboxes.numpy(),\n            'labels_ignore': data['data_samples'][0].ignored_instances.labels.numpy(),\n        }\n        pred_bboxes = result.pred_instances.cpu().bboxes.numpy()\n\n        # \u8ba1\u7b97 IoU \u5e76\u7b5b\u9009\n        mAP, eval_results = eval_rbbox_head_map(\n            [pred_bboxes],\n            [gt_bboxes],\n            scale_ranges=None,\n            iou_thr=IOU_THRESHOLD,\n            # dataset=model.CLASSES,\n            logger=None\n        )\n        ap = eval_results[0]['ap']\n        if ap &lt; 1.0:\n            low_iou_images.append(img_name)\n            copy_image(img_path, folder_low_iou, img_name)\n\n        # \u53ef\u89c6\u5316 GT \u548c\u9884\u6d4b\u6846\n        vis_output_path = os.path.join(folder_visualizations, img_name)\n        from projects.RR360.structures.bbox_rotated_boxes import rbbox2qbbox\n        gt_corners = rbbox2qbbox(RotatedBoxes(gt_bboxes['bboxes']).regularize_boxes(pattern='r360')).numpy()\n        pred_corners = rbbox2qbbox(RotatedBoxes(pred_bboxes).regularize_boxes(pattern='r360')).numpy()\n\n        visualize_detections(img_path, gt_corners, pred_corners, vis_output_path)\n\n        # \u4fdd\u5b58 GT \u548c\u9884\u6d4b\u6846\u5230 txt \u6587\u4ef6\n        save_bboxes_to_txt(\n            gt_bboxes['bboxes'],\n            os.path.join(folder_bboxes, f\"{os.path.splitext(img_name)[0]}_gt.txt\"),\n            label=\"GT\"\n        )\n        save_bboxes_to_txt(\n            pred_bboxes,\n            os.path.join(folder_bboxes, f\"{os.path.splitext(img_name)[0]}_pred.txt\"),\n            label=\"PRED\"\n        )\n\n    # \u4fdd\u5b58\u4f4e IoU \u56fe\u50cf\u5217\u8868\n    os.makedirs(folder_low_iou, exist_ok=True)\n    with open(os.path.join(folder_low_iou, 'low_iou_images.txt'), 'w') as f:\n        for img in low_iou_images:\n            f.write(f\"{img}\\n\")\n\n    print(f\"\u4f4e IoU \u56fe\u50cf\u6570\u91cf\uff1a{len(low_iou_images)}\")\n    print(f\"\u4f4e IoU \u56fe\u50cf\u5217\u8868\uff1a{folder_low_iou}\")\n    print(f\"\u53ef\u89c6\u5316\u7ed3\u679c\u5df2\u4fdd\u5b58\u5230\uff1a{folder_visualizations}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u4e0b\u9762\u9700\u8981\u5c06\u4e0a\u9762\u7684\u9884\u6d4b\u7684txt\u4fe1\u606f\u8f6c\u6362\u4e3a\u76ee\u6807\u5e73\u53f0\u7684\u6807\u6ce8\u4fe1\u606f\uff0c\u8fd9\u91cc\u4ee5label studio\u4e3a\u4f8b</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport glob\nimport json\nimport math\n\nfrom projects.RR360.structures.bbox import RotatedBoxes\nfrom projects.RR360.structures.bbox_rotated_boxes import rbbox2qbbox\nimport torch\nfrom PIL import Image\n\n# \u8f93\u5165\u548c\u8f93\u51fa\u8def\u5f84\nINPUT_TXT_FOLDER = \"/mmrotate/train_bad_case/bboxes_txt\"  # \u4fdd\u5b58 GT \u548c PRED \u7684 txt \u6587\u4ef6\u5939\nOUTPUT_JSON_PATH = \"./train_label_studio_data.json\"  # \u8f6c\u6362\u540e\u7684 JSON \u6587\u4ef6\u8def\u5f84\nIMAGE_FOLDER = \"./low_iou_images\"  # \u5bf9\u5e94\u56fe\u7247\u6587\u4ef6\u5939\uff0c\u7528\u4e8e\u751f\u6210 JSON \u4e2d\u7684 image URL\n\n\ndef center_to_topleft(x, y, width, height, rotation):\n    \"\"\"\n    \u5c06\u4e2d\u5fc3\u5750\u6807\u683c\u5f0f\u8f6c\u6362\u4e3a\u5de6\u4e0a\u89d2\u5750\u6807\u683c\u5f0f\u3002\n\n    Args:\n        x (float): \u4e2d\u5fc3 x \u5750\u6807\u3002\n        y (float): \u4e2d\u5fc3 y \u5750\u6807\u3002\n        width (float): \u77e9\u5f62\u7684\u5bbd\u3002\n        height (float): \u77e9\u5f62\u7684\u9ad8\u3002\n        rotation (float): \u65cb\u8f6c\u89d2\u5ea6\uff0c\u8303\u56f4\u4e3a -180 \u5230 180\uff0c\u8d1f\u503c\u4e3a\u9006\u65f6\u9488\u3002\n\n    Returns:\n        dict: \u5305\u542b\u5de6\u4e0a\u89d2\u5750\u6807\u548c\u89d2\u5ea6\u7684\u5b57\u5178\u3002\n    \"\"\"\n    # \u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807\n    tensor = RotatedBoxes(torch.as_tensor([[x, y, width, height, rotation]], dtype=torch.float32))\n    corners = rbbox2qbbox(tensor.regularize_boxes(pattern='r360')).numpy()[0].reshape(4, 2)\n    left_x, left_y = list(map(float, corners[0]))\n\n    # \u5904\u7406\u65cb\u8f6c\u89d2\u5ea6\n    rotation = float(tensor.tensor[0, -1]) / math.pi * 180\n    if rotation &lt; 0:\n        rotation = 360 + rotation\n\n    return {\n        \"xywh\": (x, y, width, height),\n        \"xlylx2y2x3y3x4y4\": corners.tolist(),\n        \"x\": left_x,\n        \"y\": left_y,\n        \"width\": width,\n        \"height\": height,\n        \"rotation\": rotation\n    }\n\n\ndef parse_txt_file(txt_path):\n    \"\"\"\n    \u89e3\u6790 GT \u6216 PRED \u7684 txt \u6587\u4ef6\u5185\u5bb9\uff0c\u5e76\u5c06\u4e2d\u5fc3\u5750\u6807\u8f6c\u6362\u4e3a\u5de6\u4e0a\u89d2\u5750\u6807\u3002\n\n    Args:\n        txt_path (str): txt \u6587\u4ef6\u8def\u5f84\u3002\n\n    Returns:\n        list[dict]: \u8fd4\u56de\u89e3\u6790\u540e\u7684\u6807\u6ce8\u6846\u5217\u8868\u3002\n    \"\"\"\n    bboxes = []\n    with open(txt_path, 'r') as f:\n        for line in f:\n            parts = line.strip().split()\n            label, coords = parts[0], list(map(float, parts[1:]))\n            transformed = center_to_topleft(*coords)\n            transformed[\"label\"] = label\n            bboxes.append(transformed)\n    return bboxes\n\n\ndef get_image_size(image_path):\n    \"\"\"\n    \u83b7\u53d6\u56fe\u50cf\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002\n\n    \u53c2\u6570:\n        image_path (str): \u56fe\u50cf\u6587\u4ef6\u7684\u8def\u5f84\u3002\n\n    \u8fd4\u56de:\n        tuple: \u5305\u542b\u56fe\u50cf\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5143\u7ec4\u3002\n    \"\"\"\n    try:\n        # \u6253\u5f00\u56fe\u50cf\u6587\u4ef6\n        with Image.open(image_path) as img:\n            # \u83b7\u53d6\u56fe\u50cf\u7684\u5bbd\u548c\u9ad8\n            width, height = img.size\n            return width, height\n    except IOError:\n        print(f\"\u65e0\u6cd5\u6253\u5f00\u56fe\u50cf\u6587\u4ef6\uff1a{image_path}\")\n        return None, None\n\n\ndef create_label_studio_json(image_name, gt_bboxes, pred_bboxes, image_folder):\n    \"\"\"\n    \u521b\u5efa Label Studio \u683c\u5f0f\u7684 JSON \u6570\u636e\u3002\n\n    Args:\n        image_name (str): \u56fe\u7247\u6587\u4ef6\u540d\u3002\n        gt_bboxes (list[dict]): GT \u8fb9\u754c\u6846\u5217\u8868\u3002\n        pred_bboxes (list[dict]): PRED \u8fb9\u754c\u6846\u5217\u8868\u3002\n        image_folder (str): \u56fe\u7247\u6587\u4ef6\u5939\u8def\u5f84\u3002\n\n    Returns:\n        dict: \u5355\u4e2a\u56fe\u7247\u7684 Label Studio JSON \u6570\u636e\u3002\n    \"\"\"\n    image_path = os.path.join(image_folder, image_name)\n    image_width, image_height = get_image_size(image_path)\n    if image_width is None:\n        return None\n\n    task_data = {\n        \"data\": {\n            \"image\": image_path.replace(\"/root/data/code/mmrotate/\", \"/data/local-files/?d=\").replace(\".jpg\", \".png\")  # \u53ef\u8c03\u6574\u4e3a\u670d\u52a1\u5668 URL\n        },\n        \"annotations\": [\n            {\n                \"result\": []\n            }\n        ]\n    }\n\n    for bbox in gt_bboxes:\n        task_data[\"annotations\"][0][\"result\"].append({\n            \"type\": \"rectanglelabels\",\n            \"original_width\": image_width,\n            \"original_height\": image_height,\n            \"value\": {\n                \"xywh\": bbox[\"xywh\"],\n                \"xlylx2y2x3y3x4y4\": bbox[\"xlylx2y2x3y3x4y4\"],\n                \"x\": bbox[\"x\"] / image_width * 100,\n                \"y\": bbox[\"y\"] / image_height * 100,\n                \"width\": bbox[\"width\"] / image_width * 100,\n                \"height\": bbox[\"height\"] / image_height * 100,\n                \"rotation\": bbox[\"rotation\"],\n                \"rectanglelabels\": [bbox[\"label\"]]\n            },\n            \"to_name\": \"image\",\n            \"from_name\": \"label\",\n            \"id\": f\"gt_{bbox['x']:.2f}_{bbox['y']:.2f}\",\n            \"origin\": 'manual'\n        })\n\n    for bbox in pred_bboxes:\n        task_data[\"annotations\"][0][\"result\"].append({\n            \"type\": \"rectanglelabels\",\n            \"original_width\": image_width,\n            \"original_height\": image_height,\n            \"value\": {\n                \"x\": bbox[\"x\"] / image_width * 100,\n                \"y\": bbox[\"y\"] / image_height * 100,\n                \"width\": bbox[\"width\"] / image_width * 100,\n                \"height\": bbox[\"height\"] / image_height * 100,\n                \"rotation\": bbox[\"rotation\"],\n                \"rectanglelabels\": [bbox[\"label\"]]\n            },\n            \"to_name\": \"image\",\n            \"from_name\": \"label\",\n            \"id\": f\"pred_{bbox['x']:.2f}_{bbox['y']:.2f}\",\n            \"origin\": 'manual'\n        })\n\n    return task_data\n\n\ndef gen_labelstudio_file():\n    # \u521d\u59cb\u5316\n    all_tasks = []\n\n    # \u904d\u5386\u6587\u4ef6\u5939\u4e2d\u7684 txt \u6587\u4ef6\n    txt_files = [f for f in os.listdir(INPUT_TXT_FOLDER) if f.endswith(\"_gt.txt\")]\n\n    for gt_file in txt_files:\n        base_name = os.path.splitext(gt_file)[0].replace(\"_gt\", \"\")\n        pred_file = f\"{base_name}_pred.txt\"\n\n        # \u83b7\u53d6\u5bf9\u5e94\u7684 GT \u548c PRED \u6587\u4ef6\u8def\u5f84\n        gt_path = os.path.join(INPUT_TXT_FOLDER, gt_file)\n        pred_path = os.path.join(INPUT_TXT_FOLDER, pred_file)\n\n        # \u68c0\u67e5\u5bf9\u5e94\u7684 PRED \u6587\u4ef6\u662f\u5426\u5b58\u5728\n        if not os.path.exists(pred_path):\n            print(f\"Warning: Prediction file not found for {gt_file}\")\n            continue\n\n        # \u89e3\u6790 GT \u548c PRED \u7684 bbox\n        gt_bboxes = parse_txt_file(gt_path)\n        pred_bboxes = parse_txt_file(pred_path)\n\n        # \u56fe\u7247\u540d\u63a8\u6d4b\n        image_name = f\"{base_name}.png\"\n\n        # \u521b\u5efa Label Studio JSON \u6570\u636e\n        task = create_label_studio_json(image_name, gt_bboxes, pred_bboxes, IMAGE_FOLDER)\n        if task:\n            all_tasks.append(task)\n\n    # \u4fdd\u5b58\u4e3a JSON \u6587\u4ef6\n    with open(OUTPUT_JSON_PATH, 'w') as f:\n        json.dump(all_tasks, f, indent=4)\n\n    print(f\"\u8f6c\u6362\u5b8c\u6210\uff01Label Studio \u6570\u636e\u4fdd\u5b58\u5230 {OUTPUT_JSON_PATH}.\")\n\n\n# \u8fd0\u884c\u4e3b\u51fd\u6570\ngen_labelstudio_file()\n</code></pre> <p>\u6309\u7167\u7b2c\u4e09\u7ae0\u5bfc\u5165\u6570\u636e\u4e4b\u540e\uff0c\u4fdd\u8bc1\u6570\u636e\u7684base name\u4e0e\u4e0a\u9762\u811a\u672c\u5904\u7406\u7684\u4e00\u81f4\uff0c\u4e4b\u540e\u6e05\u7a7a\u76ee\u524d\u7684\u6570\u636e\u6216\u8005\u5bfc\u51fa\u3002</p> <p>\u5c06<code>./train_label_studio_data.json</code> \u70b9\u51fb\u201cImport\u201d\u5373\u53ef\u5bfc\u5165\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u6807\u6ce8\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_4","title":"\u4e94\u3001\u6807\u6ce8\u7ed3\u679c\u7684\u5bfc\u51fa\u4e0e\u8f6c\u6362","text":"<p>\u6807\u6ce8\u5b8c\u6210\u540e\uff0c\u70b9\u51fb Export \u5bfc\u51fa\u7ed3\u679c\u3002\u5bfc\u51fa\u7684\u7ed3\u679c\u53ea\u4f1a\u5305\u542b\u6807\u6ce8\u8fc7\u7684\u6837\u672c\uff0c\u800c\u4e0d\u662f\u5305\u542b\u6240\u6709\u6837\u672c\u3002</p> <p>\u5bfc\u51fa\u4e4b\u540e\u4e00\u822c\u9700\u8981\u6267\u884c\u4e24\u4e2a\u6b65\u9aa4</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#51","title":"5.1 \u53ef\u89c6\u5316\u6807\u6ce8\u7ed3\u679c","text":"<p>\u91c7\u7528\u5982\u4e0b\u4ee3\u7801\u53ef\u89c6\u5316\u6807\u6ce8\u7ed3\u679c</p> <pre><code>import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.image as mpimg\nimport numpy as np\nimport json\nimport os\nfrom PIL import Image\n\n# ======================\n# \u6570\u636e\u5904\u7406\u90e8\u5206\n# ======================\n\nannotation_dict = {}\n\n# \u5904\u7406\u5bfc\u51fajson\u6587\u4ef6\nwith open(\"./rotated_image/export.json\", encoding='utf-8') as f:\n    rotated_image_labels = json.load(f)\n\nfor rotated_image_label in rotated_image_labels:\n    annotation_list = []\n    image_filepath = rotated_image_label['data']['image']\n\n    try:\n        for annotation in rotated_image_label['annotations']:\n            result = annotation['result']\n            for annotation_result in result:\n                original_width = annotation_result['original_width']\n                original_height = annotation_result['original_height']\n\n                value = annotation_result['value']\n                annotation_list.append({\n                    'left_corner_x': value['x'] / 100 * original_width,\n                    'left_corner_y': value['y'] / 100 * original_height,\n                    'width': value['width'] / 100 * original_width,\n                    'height': value['height'] / 100 * original_height,\n                    'rotation': value['rotation'],\n                })\n    except Exception as e:\n        print(f\"Error processing {image_filepath}: {str(e)}\")\n        continue\n\n    annotation_dict[image_filepath] = {\n        'url': image_filepath,\n        'annotation_list': annotation_list,\n        'image_path': os.path.abspath(os.path.join('./rotated_image/dst_png_files2', os.path.basename(image_filepath)))\n    }\n\n# ======================\n# \u6838\u5fc3\u529f\u80fd\u51fd\u6570\n# ======================\n\ndef plot_local_image_with_bounding_boxes(image_path, bounding_boxes):\n    \"\"\"\n    \u663e\u793a\u672c\u5730\u56fe\u7247\u5e76\u5728\u56fe\u7247\u4e0a\u7ed8\u5236\u65cb\u8f6c\u77e9\u5f62\u6846\u6807\u6ce8\n    \u53c2\u6570:\n        image_path -- \u672c\u5730\u56fe\u7247\u7684\u6587\u4ef6\u8def\u5f84\n        bounding_boxes -- \u5305\u542b\u65cb\u8f6c\u77e9\u5f62\u6846\u6807\u6ce8\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u77e9\u5f62\u6846\u5b9a\u4e49\u4e3a\uff1a\n                          [\u4e2d\u5fc3\u70b9x\u5750\u6807, \u4e2d\u5fc3\u70b9y\u5750\u6807, \u5bbd\u5ea6, \u9ad8\u5ea6, \u65cb\u8f6c\u89d2\u5ea6]\n    \"\"\"\n    img = mpimg.imread(image_path)\n\n    if len(img.shape) == 2:  # \u7070\u5ea6\u56fe\u50cf\n        height, width = img.shape\n    else:  # \u5f69\u8272\u56fe\u50cf\n        height, width, _ = img.shape\n\n    fig, ax = plt.subplots(figsize=(width/100, height/100), dpi=100)\n    ax.imshow(img)\n\n    for bbox in bounding_boxes:\n        center_x, center_y, width, height, angle = bbox\n        rect = patches.Rectangle(\n            (center_x - width/2, center_y - height/2),\n            width, height,\n            angle=angle,\n            linewidth=1,\n            edgecolor='r',\n            facecolor='none'\n        )\n        ax.add_patch(rect)\n\n    ax.axis('off')\n    plt.show()\n\ndef rotate_rectangle_to_vertices(center_x, center_y, width, height, angle):\n    \"\"\"\n    \u5c06\u65cb\u8f6c\u77e9\u5f62\u53c2\u6570\u8f6c\u6362\u4e3a\u56db\u4e2a\u9876\u70b9\u5750\u6807\n    \u53c2\u6570:\n        center_x -- \u77e9\u5f62\u4e2d\u5fc3x\u5750\u6807\n        center_y -- \u77e9\u5f62\u4e2d\u5fc3y\u5750\u6807\n        width    -- \u77e9\u5f62\u5bbd\u5ea6\n        height   -- \u77e9\u5f62\u9ad8\u5ea6\n        angle    -- \u987a\u65f6\u9488\u65cb\u8f6c\u89d2\u5ea6\uff08\u5ea6\uff09\n    \u8fd4\u56de:\n        \u5305\u542b\u56db\u4e2a\u9876\u70b9\u5750\u6807\u7684\u5217\u8868 [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]\n    \"\"\"\n    theta = np.radians(angle)\n    rotation_matrix = np.array([\n        [np.cos(theta), np.sin(theta)],\n        [-np.sin(theta), np.cos(theta)]\n    ])\n\n    half_width = width / 2\n    half_height = height / 2\n\n    # \u8ba1\u7b97\u56db\u4e2a\u9876\u70b9\u7684\u76f8\u5bf9\u5750\u6807\n    points = np.array([\n        [-half_width, -half_height],\n        [half_width, -half_height],\n        [half_width, half_height],\n        [-half_width, half_height]\n    ])\n\n    # \u5e94\u7528\u65cb\u8f6c\u77e9\u9635\n    rotated_points = np.dot(points, rotation_matrix.T).T\n\n    # \u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\n    rotated_points = rotated_points + np.array([center_x, center_y])\n    return rotated_points.tolist()\n\n# ======================\n# \u53ef\u89c6\u5316\u5904\u7406\u90e8\u5206\n# ======================\n\nfor key, item in annotation_dict.items():\n    annotations = []\n    for subitem in item['annotation_list']:\n        # \u8f6c\u6362\u6807\u6ce8\u683c\u5f0f\n        center_x = subitem['left_corner_x'] + subitem['width']/2\n        center_y = subitem['left_corner_y'] + subitem['height']/2\n        width = subitem['width']\n        height = subitem['height']\n        rotation = subitem['rotation']\n\n        # \u83b7\u53d6\u9876\u70b9\u5750\u6807\n        vertices = rotate_rectangle_to_vertices(center_x, center_y, width, height, rotation)\n        annotations.append(vertices.tolist())\n\n    # \u7b5b\u900945-90\u5ea6\u65cb\u8f6c\u7684\u6807\u6ce8\n    is_rotate = any(45 &lt;= ann[-1] &lt;= 90 for ann in annotations)\n\n    if is_rotate:\n        print(f\"Found rotated annotation in {key}\")\n        print(item['image_path'])\n\n        # \u7ed8\u5236\u56fe\u50cf\u6807\u6ce8\n        try:\n            img = Image.open(item['image_path'])\n            fig, ax = plt.subplots(figsize=(img.width/100, img.height/100), dpi=100)\n            ax.imshow(img)\n\n            for vertices in annotations:\n                polygon = patches.Polygon(\n                    vertices,\n                    closed=True,\n                    edgecolor='red',\n                    fill=False\n                )\n                ax.add_patch(polygon)\n\n            ax.axis('off')\n            plt.show()\n\n            # \u4fdd\u5b58\u7ed3\u679c\n            output_path = os.path.join('./output', os.path.basename(item['image_path']))\n            plt.savefig(output_path)\n\n            annotations = [\n                [\n                    subitem['left_corner_x'] + subitem['width'] / 2,  # \u4e2d\u5fc3\u70b9X\n                    subitem['left_corner_y'] + subitem['height'] / 2,  # \u4e2d\u5fc3\u70b9Y\n                    subitem['width'],          # \u5bbd\u5ea6\n                    subitem['height'],         # \u9ad8\u5ea6\n                    subitem['rotation']        # \u65cb\u8f6c\u89d2\u5ea6\n                ] for subitem in item['annotation_list']\n            ]\n\n            # \u8c03\u7528\u7ed8\u56fe\u51fd\u6570\uff08\u6ce8\u610f\u53c2\u6570\u987a\u5e8f\uff09\n            plot_local_image_with_bounding_boxes(\n                image_path=item['image_path'],\n                bounding_boxes=annotations\n            )\n\n        except Exception as e:\n            print(f\"Error processing {key}: {str(e)}\")\n</code></pre> <p>\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f\u6807\u6ce8\u683c\u5f0f\u662f\u7ed5\u56fe\u7247\u5de6\u4e0a\u89d2\u5b9a\u70b9\u65cb\u8f6c</p> <p>\u5bfc\u51fa\u7684\u6807\u6ce8\u662f\u7ed5\u56fe\u7247\u4e2d\u5fc3\u70b9\u65cb\u8f6c</p> <p>\u65cb\u8f6c\u89d2\u5ea6\u662f\u76f8\u540c\u7684\uff0c\u8fd9\u4e2a\u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u753b\u4e2a\u56fe\u5229\u7528\u201c\u4e24\u76f4\u7ebf\u5e73\u884c\uff0c\u5185\u9519\u89d2\u76f8\u7b49\u201d\u7b49\u539f\u7406\u6765\u8bc1\u660e\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#52","title":"5.2 \u8f6c\u6362\u4e3a\u8bad\u7ec3\u683c\u5f0f","text":"<p>\u4e00\u822c\u800c\u8a00\uff0c\u5bfc\u51fa\u7684\u683c\u5f0f\u4e0e\u8bad\u7ec3\u6240\u9700\u8981\u7684\u683c\u5f0f\u53ef\u80fd\u4e0d\u5339\u914d\uff0c\u8fd9\u91cc\u5c31\u9700\u8981\u683c\u5f0f\u8f6c\u6362\u529f\u80fd\uff0c\u4e0b\u9762\u4ee5mmroate 360\u00b0\u8981\u6c42\u7684\u683c\u5f0f\u7ed9\u51fa\u793a\u4f8b\u811a\u672c\u3002</p> <pre><code>import os\nimport shutil\nimport json\nimport numpy as np\n\n\nannotation_dict = {}\n\n# \u5904\u7406\u5bfc\u51fajson\u6587\u4ef6\nwith open(\"./rotated_image/export.json\", encoding='utf-8') as f:\n    rotated_image_labels = json.load(f)\n\nfor rotated_image_label in rotated_image_labels:\n    annotation_list = []\n    image_filepath = rotated_image_label['data']['image']\n\n    try:\n        for annotation in rotated_image_label['annotations']:\n            result = annotation['result']\n            for annotation_result in result:\n                original_width = annotation_result['original_width']\n                original_height = annotation_result['original_height']\n\n                value = annotation_result['value']\n                annotation_list.append({\n                    'left_corner_x': value['x'] / 100 * original_width,\n                    'left_corner_y': value['y'] / 100 * original_height,\n                    'width': value['width'] / 100 * original_width,\n                    'height': value['height'] / 100 * original_height,\n                    'rotation': value['rotation'],\n                })\n    except Exception as e:\n        print(f\"Error processing {image_filepath}: {str(e)}\")\n        continue\n\n    annotation_dict[image_filepath] = {\n        'url': image_filepath,\n        'annotation_list': annotation_list,\n        'image_path': os.path.abspath(os.path.join('./rotated_image/dst_png_files2', os.path.basename(image_filepath)))\n    }\n\n\ndef rotate_rectangle_to_vertices(center_x, center_y, width, height, angle):\n    \"\"\"\n    \u5c06\u65cb\u8f6c\u77e9\u5f62\u53c2\u6570\u8f6c\u6362\u4e3a\u56db\u4e2a\u9876\u70b9\u5750\u6807\n    \u53c2\u6570:\n        center_x -- \u77e9\u5f62\u4e2d\u5fc3x\u5750\u6807\n        center_y -- \u77e9\u5f62\u4e2d\u5fc3y\u5750\u6807\n        width    -- \u77e9\u5f62\u5bbd\u5ea6\n        height   -- \u77e9\u5f62\u9ad8\u5ea6\n        angle    -- \u987a\u65f6\u9488\u65cb\u8f6c\u89d2\u5ea6\uff08\u5ea6\uff09\n    \u8fd4\u56de:\n        \u5305\u542b\u56db\u4e2a\u9876\u70b9\u5750\u6807\u7684\u5217\u8868 [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]\n    \"\"\"\n    theta = np.radians(angle)\n    rotation_matrix = np.array([\n        [np.cos(theta), np.sin(theta)],\n        [-np.sin(theta), np.cos(theta)]\n    ])\n\n    half_width = width / 2\n    half_height = height / 2\n\n    # \u8ba1\u7b97\u56db\u4e2a\u9876\u70b9\u7684\u76f8\u5bf9\u5750\u6807\n    points = np.array([\n        [-half_width, -half_height],\n        [half_width, -half_height],\n        [half_width, half_height],\n        [-half_width, half_height]\n    ])\n\n    # \u5e94\u7528\u65cb\u8f6c\u77e9\u9635\n    rotated_points = np.dot(points, rotation_matrix.T).T\n\n    # \u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\n    rotated_points = rotated_points + np.array([center_x, center_y])\n    return rotated_points.tolist()\n\n\nnew_annotation_dict = {}\nfor key, item in annotation_dict.items():\n    annotations = []\n    for subitem in item['annotation_list']:\n        # \u8f6c\u6362\u6807\u6ce8\u683c\u5f0f\n        center_x = subitem['left_corner_x'] + subitem['width']/2\n        center_y = subitem['left_corner_y'] + subitem['height']/2\n        width = subitem['width']\n        height = subitem['height']\n        rotation = subitem['rotation']\n\n        # \u83b7\u53d6\u9876\u70b9\u5750\u6807\n        vertices = rotate_rectangle_to_vertices(center_x, center_y, width, height, rotation)\n        annotations.append(vertices.tolist())\n    new_annotation_dict[key] = {\n        'image_path': item['image_path'],\n        'vertices_list': annotations\n    }\n\n# \u5b9a\u4e49\u76ee\u6807\u76ee\u5f55\ndst_dir = './new_annotation_dir'\n\n# \u5220\u9664\u5df2\u5b58\u5728\u7684\u76ee\u5f55\u5e76\u91cd\u65b0\u521b\u5efa\nshutil.rmtree(dst_dir)\nos.makedirs(dst_dir, exist_ok=True)\n\n# \u521b\u5efa\u7d22\u5f15\u5217\u8868\u5e76\u6253\u4e71\u987a\u5e8f\ntrain_indexes = list(range(len(new_annotation_dict)))\nimport random\nrandom.shuffle(train_indexes)\n\n# \u8ba1\u7b97\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u957f\u5ea6\ntrain_dataset_length = len(new_annotation_dict) // 5 * 4\ntest_dataset_length = len(new_annotation_dict) - train_dataset_length\n\n# \u5206\u5272\u7d22\u5f15\ntrain_indexes = train_indexes[:train_dataset_length]\ntest_indexes = train_indexes[train_dataset_length:]\nimport shutil\n\n# \u5904\u7406\u6bcf\u4e2a\u6570\u636e\u9879\nfor i, (key, info_dict) in enumerate(new_annotation_dict.items()):\n    image_path = info_dict['image_path']\n    tmp_dst_dir = os.path.join(dst_dir, 'train') if i in train_indexes else os.path.join(dst_dir, 'test')\n    os.makedirs(tmp_dst_dir, exist_ok=True)\n    ext = os.path.splitext(image_path)[-1]\n    new_image_path = os.path.join(tmp_dst_dir, f'{i}{ext}')\n    shutil.copy(image_path, new_image_path)\n    new_txt_path = os.path.join(tmp_dst_dir, f'{i}.txt')\n    vertices_list = info_dict['vertices_list']\n\n    # \u5199\u5165\u6587\u672c\u6587\u4ef6\n    with open(new_txt_path, 'w', encoding='utf-8') as f:\n        for j, vertices in enumerate(vertices_list):\n            vertices_str = \" \".join(map(lambda x: f\"{x:.02f}\", np.asarray(vertices).reshape(-1)))\n            if j != len(vertices_list) - 1:\n                vertices_str += \"\\n\"\n            f.write(vertices_str)\n</code></pre>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_5","title":"\u516d\u3001\u6807\u6ce8\u89c4\u5219\u7684\u6784\u5efa\u4e0e\u6570\u636e\u8fed\u4ee3","text":"<p>\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09\u9886\u57df\uff0c\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u6807\u6ce8\u662f\u6a21\u578b\u6027\u80fd\u7684\u57fa\u77f3\u3002\u7136\u800c\uff0c\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u63d0\u5347\u548c\u5e94\u7528\u573a\u666f\u7684\u591a\u6837\u5316\uff0c\u5982\u4f55\u6784\u5efa\u79d1\u5b66\u7684\u6807\u6ce8\u89c4\u5219\u5e76\u5b9e\u73b0\u9ad8\u6548\u7684\u6570\u636e\u8fed\u4ee3\uff0c\u6210\u4e3aCV\u9879\u76ee\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u3002</p> <p>\u6807\u6ce8\u89c4\u5219\u7684\u5236\u5b9a\u4e0d\u4ec5\u5173\u4e4e\u6570\u636e\u7684\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\uff0c\u66f4\u76f4\u63a5\u5f71\u54cd\u6a21\u578b\u7684\u5b66\u4e60\u6548\u679c\u3002\u5728\u5b9e\u9645\u64cd\u4f5c\u4e2d\uff0c\u6807\u6ce8\u89c4\u5219\u7684\u6784\u5efa\u901a\u5e38\u7ecf\u5386\u4ee5\u4e0b\u51e0\u4e2a\u9636\u6bb5\uff1a</p> <ol> <li>\u9700\u6c42\u5206\u6790\u4e0e\u4efb\u52a1\u5b9a\u4e49\uff1a\u660e\u786e\u6a21\u578b\u7684\u5e94\u7528\u573a\u666f\u548c\u76ee\u6807\u3002\u4f8b\u5982\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\uff0c\u9700\u8981\u8bc6\u522b\u884c\u4eba\u3001\u8f66\u8f86\u3001\u4ea4\u901a\u6807\u5fd7\u7b49\u5bf9\u8c61\uff0c\u6807\u6ce8\u89c4\u5219\u9700\u6db5\u76d6\u8fd9\u4e9b\u7c7b\u522b\u7684\u5b9a\u4e49\u548c\u8fb9\u754c\u3002</li> <li>\u5236\u5b9a\u8be6\u7ec6\u7684\u6807\u6ce8\u624b\u518c\uff1a\u5305\u62ec\u6807\u6ce8\u7c7b\u522b\u7684\u5b9a\u4e49\u3001\u6807\u6ce8\u65b9\u6cd5\uff08\u5982\u77e9\u5f62\u6846\u3001\u591a\u8fb9\u5f62\u3001\u5173\u952e\u70b9\u7b49\uff09\u3001\u8fb9\u7f18\u6848\u4f8b\u7684\u5904\u7406\u65b9\u5f0f\u7b49\u3002\u4f8b\u5982\uff0c\u5728\u670d\u9970\u98ce\u683c\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u4e0d\u540c\u6807\u6ce8\u8005\u5bf9\u201c\u6b27\u7f8e\u98ce\u201d\u4e0e\u201c\u9ad8\u8d35\u98ce\u201d\u7684\u7406\u89e3\u53ef\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u901a\u8fc7\u5177\u4f53\u793a\u4f8b\u548c\u8bf4\u660e\u51cf\u5c11\u4e3b\u89c2\u6027\u3002</li> <li>\u6807\u6ce8\u4eba\u5458\u57f9\u8bad\u4e0e\u6d4b\u8bd5\uff1a\u5bf9\u6807\u6ce8\u4eba\u5458\u8fdb\u884c\u7cfb\u7edf\u57f9\u8bad\uff0c\u786e\u4fdd\u5176\u7406\u89e3\u5e76\u9075\u5faa\u6807\u6ce8\u89c4\u5219\u3002\u901a\u8fc7\u6d4b\u8bd5\u4efb\u52a1\u8bc4\u4f30\u5176\u6807\u6ce8\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\uff0c\u5fc5\u8981\u65f6\u8fdb\u884c\u53cd\u9988\u548c\u518d\u57f9\u8bad\u3002</li> <li>\u8d28\u91cf\u63a7\u5236\u4e0e\u6301\u7eed\u4f18\u5316\uff1a\u91c7\u7528\u53cc\u91cd\u6807\u6ce8\u3001\u4ea4\u53c9\u9a8c\u8bc1\u7b49\u65b9\u5f0f\u8fdb\u884c\u8d28\u91cf\u63a7\u5236\u3002\u5f15\u5165\u4e00\u81f4\u6027\u8bc4\u4f30\u6307\u6807\uff08\u5982Cohen\u2019s Kappa\u7cfb\u6570\uff09\u76d1\u63a7\u6807\u6ce8\u8d28\u91cf\uff0c\u53d1\u73b0\u95ee\u9898\u53ca\u65f6\u8c03\u6574\u6807\u6ce8\u89c4\u5219\u3002</li> </ol> <p>\u6570\u636e\u8fed\u4ee3\u662f\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u6570\u636e\u8d28\u91cf\u7684\u6709\u6548\u624b\u6bb5\u3002\u901a\u8fc7\u6a21\u578b\u7684\u53cd\u9988\uff0c\u8bc6\u522b\u6570\u636e\u4e2d\u7684\u95ee\u9898\uff0c\u6307\u5bfc\u6570\u636e\u7684\u91c7\u96c6\u548c\u6807\u6ce8\uff0c\u5b9e\u73b0\u95ed\u73af\u4f18\u5316\u3002</p> <ol> <li>\u5c0f\u6279\u91cf\u6807\u6ce8\u4e0e\u6a21\u578b\u8bad\u7ec3\uff1a\u521d\u59cb\u9636\u6bb5\uff0c\u9009\u62e9\u4ee3\u8868\u6027\u7684\u6570\u636e\u8fdb\u884c\u6807\u6ce8\uff0c\u8bad\u7ec3\u521d\u6b65\u6a21\u578b\u3002\u8be5\u6a21\u578b\u7528\u4e8e\u8bc4\u4f30\u6807\u6ce8\u8d28\u91cf\uff0c\u53d1\u73b0\u660e\u663e\u9519\u8bef\u6216\u4e0d\u4e00\u81f4\u7684\u6807\u6ce8\uff0c\u6307\u5bfc\u6807\u6ce8\u89c4\u5219\u7684\u4fee\u8ba2\u3002</li> <li>\u6a21\u578b\u9884\u6d4b\u4e0e\u4eba\u5de5\u6821\u6b63\uff1a\u5229\u7528\u6a21\u578b\u5bf9\u672a\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u9884\u6d4b\uff0c\u4eba\u5de5\u6821\u6b63\u6a21\u578b\u7684\u9519\u8bef\u9884\u6d4b\uff0c\u751f\u6210\u65b0\u7684\u6807\u6ce8\u6570\u636e\u3002\u8fd9\u79cd\u65b9\u5f0f\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u7684\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u6548\u7387\u3002</li> <li>\u8bc6\u522b\u6570\u636e\u76f2\u533a\u4e0e\u8865\u5145\u91c7\u96c6\uff1a\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u8bc6\u522b\u6570\u636e\u7684\u76f2\u533a\u6216\u4e0d\u8db3\u4e4b\u5904\uff0c\u9488\u5bf9\u6027\u5730\u91c7\u96c6\u548c\u6807\u6ce8\u76f8\u5173\u6570\u636e\uff0c\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002</li> <li>\u6301\u7eed\u8fed\u4ee3\u4e0e\u89c4\u5219\u4f18\u5316\uff1a\u5728\u6bcf\u4e00\u8f6e\u8fed\u4ee3\u4e2d\uff0c\u7ed3\u5408\u6a21\u578b\u7684\u8868\u73b0\u548c\u6807\u6ce8\u8d28\u91cf\uff0c\u6301\u7eed\u4f18\u5316\u6807\u6ce8\u89c4\u5219\u548c\u6570\u636e\u5206\u5e03\uff0c\u5f62\u6210\u826f\u6027\u7684\u4f18\u5316\u5faa\u73af\u3002</li> </ol> <p>\u5728\u5b9e\u9645\u7684\u4e1a\u52a1\u4e2d\uff0c\u9700\u6c42\u662f\u52a8\u6001\u53d8\u5316\u7684\uff0c\u751a\u81f3\u65b9\u6848\u90fd\u662f\u53ef\u53d8\u7684\uff0c\u6709\u65f6\u4e3a\u4e86\u9002\u914d\u7b97\u6cd5\uff0c</p> <p>\u4e5f\u53ef\u80fd\u51fa\u73b0\u5bf9\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u6807\u6ce8\u89c4\u5219\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_6","title":"\u4e03\u3001\u6570\u636e\u3001\u7b97\u6cd5\u4e0e\u4f26\u7406\u9053\u5fb7\u7684\u8ba8\u8bba","text":"<p>\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09\u9886\u57df\uff0c\u6280\u672f\u53d1\u5c55\u59cb\u7ec8\u56f4\u7ed5\u6570\u636e\u3001\u7b97\u6cd5\u4e0e\u4f26\u7406 \u4e09\u8005\u7684\u52a8\u6001\u5e73\u8861\u5c55\u5f00\u3002\u65e0\u8bba\u662f\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u8fd8\u662f\u751f\u6210\u5f0f\u6a21\u578b\u7684\u5e94\u7528\uff0c\u8fd9\u4e09\u8005\u7684\u5173\u7cfb\u90fd\u6df1\u523b\u5f71\u54cd\u7740\u6280\u672f\u7684\u843d\u5730\u6548\u679c\u4e0e\u793e\u4f1a\u4ef7\u503c\u3002\u4ee5\u4e0b\u4ece\u6838\u5fc3\u77db\u76fe\u51fa\u53d1\uff0c\u63a2\u8ba8\u4e09\u8005\u5728CV\u5b9e\u8df5\u4e2d\u7684\u89d2\u8272\u5b9a\u4f4d\u4e0e\u534f\u540c\u8def\u5f84\u3002</p> <p>\u201c\u6570\u636e\u662fAI\u7684\u6c27\u6c14\u201d\u8fd9\u4e00\u6bd4\u55bb\u5728CV\u9886\u57df\u5c24\u4e3a\u8d34\u5207\u3002\u4ee5ImageNet\u7b49\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u96c6\u4e3a\u57fa\u7840\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u624d\u5f97\u4ee5\u5b9e\u73b0\u4ece\u50cf\u7d20\u5230\u8bed\u4e49\u7684\u8de8\u8d8a\u3002\u7814\u7a76\u8868\u660e\uff0c80%\u7684\u6a21\u578b\u6027\u80fd\u63d0\u5347\u4f9d\u8d56\u4e8e\u6570\u636e\u8d28\u91cf \uff0c\u800c\u975e\u7b97\u6cd5\u4f18\u5316\u3002\u4f8b\u5982\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\uff0c\u82e5\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\u591c\u95f4\u6216\u6781\u7aef\u5929\u6c14\u7684\u6807\u6ce8\u6837\u672c\uff0c\u6a21\u578b\u53ef\u80fd\u56e0\u201c\u770b\u4e0d\u89c1\u957f\u5c3e\u573a\u666f\u201d\u800c\u5f15\u53d1\u5b89\u5168\u9690\u60a3\u3002\u8fd9\u79cd\u201c\u6570\u636e\u51b3\u5b9a\u8bba\u201d\u63a8\u52a8\u4e86CV\u9886\u57df\u7684\u6807\u51c6\u5316\u8fdb\u7a0b\u2014\u2014\u6570\u636e\u6e05\u6d17\u3001\u6807\u6ce8\u89c4\u8303\u3001\u6570\u636e\u589e\u5f3a\u7b49\u73af\u8282\u6210\u4e3a\u5de5\u4e1a\u754c\u7684\u5fc5\u4fee\u8bfe\u3002</p> <p>\u7136\u800c\uff0c\u6570\u636e\u7684\u201c\u738b\u6743\u201d\u4e5f\u9762\u4e34\u6311\u6218\u3002\u4e00\u65b9\u9762\uff0c\u6570\u636e\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff08\u59823D\u70b9\u4e91\u6807\u6ce8\u9700\u4e13\u4e1a\u5de5\u5177\u4e0e\u4eba\u529b\u6295\u5165\uff09\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u6570\u636e\u504f\u89c1\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u6027\u98ce\u9669\u3002\u4f8b\u5982\uff0c\u4eba\u8138\u8bc6\u522b\u6a21\u578b\u82e5\u8fc7\u5ea6\u4f9d\u8d56\u80a4\u8272\u3001\u6027\u522b\u7b49\u5173\u8054\u7279\u5f81\uff0c\u53ef\u80fd\u653e\u5927\u793e\u4f1a\u6b67\u89c6\u3002\u8fd9\u63ed\u793a\u51fa\u201c\u6570\u636e\u4e3a\u738b\u201d\u7684\u524d\u63d0\uff1a\u5fc5\u987b\u5efa\u7acb\u8d28\u91cf\u8bc4\u4f30\u4e0e\u4f26\u7406\u5ba1\u67e5\u7684\u53cc\u91cd\u673a\u5236\u3002</p> <p>\u7b97\u6cd5\u4e0e\u6a21\u578b\u7684\u7a81\u7834\u662fCV\u53d1\u5c55\u7684\u6838\u5fc3\u52a8\u529b\u3002\u4ece\u4f20\u7edfCNN\u5230Transformer\u67b6\u6784\u7684\u8fc1\u79fb\uff0c\u6a21\u578b\u5bf9\u6570\u636e\u7684\u5229\u7528\u6548\u7387\u6301\u7eed\u63d0\u5347\u3002\u4f8b\u5982\uff0cResNet\u901a\u8fc7\u6b8b\u5dee\u8fde\u63a5\u89e3\u51b3\u4e86\u6df1\u5ea6\u7f51\u7edc\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u4f7f\u6a21\u578b\u80fd\u5728\u6709\u9650\u6570\u636e\u4e0b\u8fbe\u5230\u66f4\u9ad8\u7cbe\u5ea6\uff1b\u800c\u6269\u6563\u6a21\u578b\uff08Diffusion Models\uff09\u5219\u901a\u8fc7\u9006\u5411\u53bb\u566a\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u751f\u6210\u56fe\u50cf\u7684\u7ec6\u8282\u53ef\u63a7\u6027\u3002\u8fd9\u4e9b\u521b\u65b0\u8868\u660e\uff0c\u7b97\u6cd5\u8bbe\u8ba1\u80fd\u90e8\u5206\u5f25\u8865\u6570\u636e\u7f3a\u9677 \uff0c\u4f8b\u5982\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u6316\u6398\u5c0f\u6837\u672c\u4e2d\u7684\u5173\u952e\u7279\u5f81\u3002</p> <p>\u4f46\u7b97\u6cd5\u7684\u201c\u4f18\u5148\u6027\u201d\u4e5f\u5b58\u5728\u5c40\u9650\u30022021\u5e74OpenAI\u7684DALL-E\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u91c7\u7528\u8d85\u5927\u89c4\u6a21\u53c2\u6570\u91cf\uff0c\u751f\u6210\u7ed3\u679c\u4ecd\u53ef\u80fd\u56e0\u8bad\u7ec3\u6570\u636e\u7684\u9690\u542b\u504f\u89c1\u800c\u504f\u79bb\u9884\u671f\u3002\u8fd9\u8bf4\u660e\uff0c\u7b97\u6cd5\u7684\u201c\u9b54\u6cd5\u201d\u65e0\u6cd5\u5b8c\u5168\u8131\u79bb\u6570\u636e\u571f\u58e4\uff0c\u4e8c\u8005\u9700\u5f62\u6210\u52a8\u6001\u9002\u914d\u5173\u7cfb\u3002</p> <p>\u968f\u7740CV\u6280\u672f\u6e17\u900f\u5230\u533b\u7597\u3001\u53f8\u6cd5\u7b49\u654f\u611f\u9886\u57df\uff0c\u4f26\u7406\u4e0e\u89c4\u5219\u7684\u91cd\u8981\u6027\u65e5\u76ca\u51f8\u663e\u3002\u6b27\u76df\u300a\u4eba\u5de5\u667a\u80fd\u6cd5\u6848\u300b\u5c06CV\u5e94\u7528\u5212\u5165\u9ad8\u98ce\u9669\u7c7b\u522b\uff0c\u8981\u6c42\u901a\u8fc7\u6570\u636e\u53ef\u8ffd\u6eaf\u6027\u3001\u7b97\u6cd5\u900f\u660e\u5ea6\u7b49\u6807\u51c6\u964d\u4f4e\u6ee5\u7528\u98ce\u9669\u3002\u4f8b\u5982\uff0c\u5728\u516c\u5171\u76d1\u63a7\u573a\u666f\u4e2d\uff0c\u9700\u901a\u8fc7\u6570\u636e\u533f\u540d\u5316\u5904\u7406\u5e73\u8861\u5b89\u5168\u4e0e\u9690\u79c1\uff1b\u5728\u533b\u7597\u5f71\u50cf\u8bca\u65ad\u4e2d\uff0c\u6a21\u578b\u51b3\u7b56\u9700\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u4f9d\u636e\u4ee5\u907f\u514d\u201c\u9ed1\u7bb1\u5ba1\u5224\u201d\u3002</p> <p>\u4f26\u7406\u6846\u67b6\u8fd8\u63a8\u52a8\u6280\u672f\u8303\u5f0f\u8f6c\u53d8\u3002\u8054\u90a6\u5b66\u4e60\uff08Federated Learning\uff09\u901a\u8fc7\u5206\u5e03\u5f0f\u8bad\u7ec3\u51cf\u5c11\u6570\u636e\u96c6\u4e2d\u5316\u98ce\u9669\uff1b\u56e0\u679c\u63a8\u7406\u6a21\u578b\u5c1d\u8bd5\u5265\u79bb\u6570\u636e\u4e2d\u7684\u865a\u5047\u5173\u8054\uff0c\u4ece\u6839\u6e90\u4e0a\u7f13\u89e3\u504f\u89c1\u3002\u8fd9\u4e9b\u5b9e\u8df5\u8868\u660e\uff0c\u4f26\u7406\u4e0d\u4ec5\u662f\u7ea6\u675f\uff0c\u66f4\u662f\u6280\u672f\u6f14\u8fdb\u7684\u50ac\u5316\u5242\u3002</p> <p>CV\u9886\u57df\u7684\u7ec8\u6781\u76ee\u6807\u5e76\u975e\u201c\u6570\u636e-\u7b97\u6cd5-\u4f26\u7406\u201d\u4e09\u8005\u7684\u96f6\u548c\u535a\u5f08\uff0c\u800c\u662f\u6784\u5efa\u4e00\u4e2a\u534f\u540c\u751f\u6001\uff1a</p> <ol> <li> <p>\u6570\u636e\u5c42\u9762    \u63a8\u52a8\u6807\u6ce8\u5de5\u5177\u81ea\u52a8\u5316\uff08\u5982\u534a\u76d1\u7763\u5b66\u4e60\u8f85\u52a9\u6807\u6ce8\uff09\uff0c\u964d\u4f4e\u8d28\u91cf\u6210\u672c</p> </li> <li> <p>\u7b97\u6cd5\u5c42\u9762    \u5f00\u53d1\u9c81\u68d2\u6027\u66f4\u5f3a\u7684\u6a21\u578b\u67b6\u6784\uff0c\u51cf\u5c11\u5bf9\u7279\u5b9a\u6570\u636e\u5206\u5e03\u7684\u4f9d\u8d56\uff1b</p> </li> <li> <p>\u4f26\u7406\u5c42\u9762    \u5c06\u516c\u5e73\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u7b49\u6307\u6807\u5185\u5d4c\u5230\u6a21\u578b\u8bc4\u4f30\u4f53\u7cfb\u4e2d</p> </li> </ol> <p>\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5f81\u9014\u4e2d\uff0c\u201c\u6570\u636e\u4e3a\u738b\u201d\u63d0\u9192\u6211\u4eec\u656c\u754f\u73b0\u5b9e\u590d\u6742\u6027\uff0c\u201c\u7b97\u6cd5\u4e3a\u5148\u201d\u6fc0\u52b1\u6211\u4eec\u7a81\u7834\u8ba4\u77e5\u8fb9\u754c\uff0c\u800c\u201c\u4f26\u7406\u4e3a\u672c\u201d\u5219\u8b66\u793a\u6211\u4eec\u6280\u672f\u5fc5\u987b\u670d\u52a1\u4eba\u7c7b\u798f\u7949\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_7","title":"\u603b\u7ed3","text":"<p>\u672c\u6587\u5168\u9762\u63a2\u8ba8\u4e86360\u00b0\u65cb\u8f6c\u6587\u5b57\u533a\u57df\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u73af\u8282\uff0c\u4ece\u6570\u636e\u6807\u6ce8\u5de5\u5177\u7684\u9009\u62e9\u3001\u56e2\u961f\u534f\u4f5c\u6d41\u7a0b\u7684\u6784\u5efa\u5230\u6a21\u578b\u8f85\u52a9\u6807\u6ce8\u4e0e\u6570\u636e\u8fed\u4ee3\u7b56\u7565\u7684\u5b9e\u8df5\u3002\u4ee5Label Studio\u4e3a\u6838\u5fc3\u5de5\u5177\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5176\u5b89\u88c5\u3001\u914d\u7f6e\u53ca\u672c\u5730\u5b58\u50a8\u652f\u6301\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4e3a\u5904\u7406\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002\u540c\u65f6\uff0c\u6587\u7ae0\u5f3a\u8c03\u4e86\u56e2\u961f\u534f\u4f5c\u5728\u63d0\u5347\u6807\u6ce8\u6548\u7387\u548c\u4e00\u81f4\u6027\u4e0a\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u7b5b\u9009\u5668\u7684\u4efb\u52a1\u5206\u914d\u673a\u5236\uff0c\u4f7f\u793e\u533a\u7248Label Studio\u4e5f\u80fd\u652f\u6301\u591a\u4eba\u534f\u540c\u6807\u6ce8\u3002</p> <p>\u5728\u6280\u672f\u5c42\u9762\uff0c\u6587\u7ae0\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u81ea\u5b9a\u4e49\u811a\u672c\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u53ef\u89c6\u5316\u4e0e\u8f6c\u6362\uff0c\u4ece\u800c\u5c06\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982mmrotate\uff09\u7684\u8f93\u51fa\u65e0\u7f1d\u96c6\u6210\u81f3\u6807\u6ce8\u5e73\u53f0\u3002\u6b64\u5916\uff0c\u9488\u5bf9\u6807\u6ce8\u7ed3\u679c\u7684\u5bfc\u51fa\u4e0e\u8bad\u7ec3\u683c\u5f0f\u8f6c\u6362\uff0c\u7ed9\u51fa\u4e86\u5b8c\u6574\u7684\u540e\u5904\u7406\u6d41\u7a0b\uff0c\u786e\u4fdd\u6570\u636e\u80fd\u591f\u76f4\u63a5\u670d\u52a1\u4e8e\u6a21\u578b\u8bad\u7ec3\u3002\u6700\u540e\uff0c\u6587\u7ae0\u6df1\u5165\u5256\u6790\u4e86\u6807\u6ce8\u89c4\u5219\u6784\u5efa\u3001\u6570\u636e\u8fed\u4ee3\u4f18\u5316\u4ee5\u53caCV\u9886\u57df\u4e2d\u201c\u6570\u636e\u4e3a\u738b\u201d\u3001\u201c\u7b97\u6cd5\u4e3a\u5148\u201d\u4e0e\u201c\u4f26\u7406\u4e3a\u672c\u201d\u7684\u534f\u540c\u53d1\u5c55\u8def\u5f84\uff0c\u4e3a\u6784\u5efa\u9ad8\u8d28\u91cf\u3001\u53ef\u6301\u7eed\u6f14\u8fdb\u7684\u89c6\u89c9\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u4e0e\u5b9e\u8df5\u7ecf\u9a8c\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/360%C2%B0%E6%97%8B%E8%BD%AC%E6%96%87%E5%AD%97%E5%8C%BA%E5%9F%9F%E6%A3%80%E6%B5%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E9%AB%98%E6%95%88%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%8C%87%E5%8D%97/#_8","title":"\u53c2\u8003\u94fe\u63a5","text":"<ul> <li>https://zhuanlan.zhihu.com/p/666885910</li> <li>https://labelstud.io/guide/storage.html#Local-storage</li> <li>https://www.breezedeus.com/article/label-studio-20230621</li> <li>https://blog.csdn.net/SL1029_/article/details/134190583</li> <li>https://www.breezedeus.com/article/label-studio-20230621</li> </ul>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/","title":"\u51f8\u56db\u8fb9\u5f62IoU\u7684\u8ba1\u7b97","text":"<p>\u672c\u6587\u5199\u4e8e2023\u5e7412\u670804\u65e5 \u665a\u4e0a\u516b\u70b9</p> <p>\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u4e8e\u77e9\u5f62\uff0c\u4efb\u610f\u56db\u8fb9\u5f62\u53ef\u4ee5\u5c06\u4e0d\u89c4\u5219\u5f62\u72b6\u7269\u4f53\u63cf\u8ff0\u7684\u66f4\u4e3a\u7cbe\u786e\u3002</p> <p>\u5728\u56db\u8fb9\u5f62\u8303\u56f4\u5185\uff0c\u6709\u4e00\u7c7b\u51f8\u56db\u8fb9\u5f62\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u8f83\u4e3a\u5e38\u89c1\u3002\u51f8\u56db\u8fb9\u5f62\u662f\u6307\u6ca1\u6709\u89d2\u5ea6\u6570\u5927\u4e8e180\u00b0\u7684\u56db\u8fb9\u5f62\uff0c\u4e3b\u8981\u5305\u542b\u5e73\u884c\u56db\u8fb9\u5f62\uff08\u77e9\u5f62\u3001\u83f1\u5f62\uff09\u3001\u68af\u5f62\u7b49\u3002</p> <p>\u201c\u51f8\u201d\u8fd9\u4e2a\u5b9e\u9645\u4e0a\u5bf9\u5e94\u7684\u662f\u51f8\u4f18\u5316\u4e2d\u7684\u201c\u51f8\u96c6\u201d\u7684\u6982\u5ff5\uff1a</p> <p>\u5982\u679c\u96c6\u5408  \\(C \\subseteq \\mathbb{R}^n\\)  \u4e2d\u7684\u4efb\u610f\u4e24\u70b9 \\(x\\) \uff0c \\(y\\) \uff0c\u5bf9 \\(\\lambda \\in [0, 1]\\) \u6ee1\u8db3 \\(\\lambda x + (1-\\lambda)y \\in C\\) \uff0c\u5219\u79f0\u96c6\u5408 \\(C\\) \u4e3a\u51f8\u96c6</p> <p>\u76f4\u89c2\u4e0a\uff0c\u5982\u679c\u4e00\u4e2a\u96c6\u5408\u662f\u51f8\u96c6\uff0c\u5219\u96c6\u5408\u5185\u4efb\u610f\u4e24\u70b9\u7684\u8fde\u7ebf\u4ecd\u5728\u8be5\u96c6\u5408\u5185\u3002</p> <p></p> <p>\u65e2\u7136\u6709\u51f8\u56db\u8fb9\u5f62\uff0c\u4e5f\u4f1a\u6709\u51f9\u56db\u8fb9\u5f62\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002</p> <p></p> <p>\u663e\u7136\u5176\u4e0d\u5c5e\u4e8e\u51f8\u96c6\u5408\u3002</p> <p>\u5728OCR\u9886\u57df\uff0c\u6587\u6863\u8bc6\u522b\u4f5c\u4e3a\u91cd\u8981\u7684\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u91c7\u7528\u56db\u8fb9\u5f62\u8868\u793a\u6587\u5b57\u533a\u57df\uff0c\u7136\u540e\u901a\u8fc7\u900f\u89c6\u53d8\u6362\u8f6c\u6362\u4e3a\u77e9\u5f62\u8868\u793a\u3002\u8fd9\u7c7b\u7684\u6587\u5b57\u533a\u57df\u5f80\u5f80\u53ef\u4ee5\u901a\u8fc7\u51f8\u56db\u8fb9\u5f62\u6765\u8868\u8fbe\u3002\u8868\u793a\u6b64\u7c7b\u7684\u56db\u8fb9\u5f62\u53ef\u4ee5\u91c7\u7528\u56db\u4e2a\u89d2\u70b9\u7684\u5750\u6807\u8868\u793a\uff0c\u56db\u4e2a\u70b9\u6309\u7167\u987a\u65f6\u9488\u6216\u8005\u9006\u65f6\u9488\u6392\u5217\u3002</p> <p>\u4e0b\u9762\u6211\u4eec\u4ece\u4e00\u7c7b\u7279\u6b8a\u77e9\u5f62-----\u65cb\u8f6c\u77e9\u5f62\u5165\u624b\uff0c\u770b\u770b\u5982\u4f55\u5c06\u5176\u8f6c\u6362\u4e3a\u51f8\u56db\u8fb9\u5f62\uff0c\u7d27\u63a5\u7740\u6c42\u53d6\u8fd9\u4e24\u4e2a\u56db\u8fb9\u5f62\u7684IOU\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#_1","title":"\u4e00\u3001\u65cb\u8f6c\u77e9\u5f62\u7684\u5750\u6807\u8f6c\u6362","text":""},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#11","title":"1.1 \u65cb\u8f6c\u5411\u91cf\u7684\u8868\u793a","text":"<p>\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5411\u91cf \\(v\\) \u7ed5\u539f\u70b9\u9006\u65f6\u9488\u65cb\u8f6c \\(\\theta\\) \u89d2\uff0c\u5f97\u5230\u70b9 \\(v'\\) \uff0c\u5047\u8bbe \\(v\\) \u70b9\u7684\u5750\u6807\u662f \\((x,y)\\) \uff0c\u90a3\u4e48\u53ef\u4ee5\u63a8\u5bfc\u5f97\u5230 \\(v'\\) \u70b9\u7684\u5750\u6807(x', y')(\u8bbe\u539f\u70b9\u5230v\u7684\u8ddd\u79bb\u662fr\uff0c\u539f\u70b9\u5230v\u70b9\u7684\u5411\u91cf\u4e0ex\u8f74\u7684\u5939\u89d2\u662f \\(\\Phi\\) )\u3002</p> \\[ x = r \\cos \\Phi \\\\ y = r sin \\Phi \\] \\[ x' = r \\cos (\\theta + \\phi) \\\\ y' = r \\sin (\\theta + \\phi) \\] <p>\u901a\u8fc7\u4e09\u89d2\u51fd\u6570\u5c55\u5f00\u5f97\u5230</p> \\[ x' = r \\cos (\\theta + \\phi) = r \\cos \\theta \\cos \\phi - r \\sin \\theta \\sin \\phi \\\\ y' = r \\sin (\\theta + \\phi) = r \\sin \\theta \\cos \\phi + r \\cos \\theta \\sin \\phi \\] <p>\u5e26\u5165 \\(x\\) \u548c \\(y\\) \u7684\u8868\u8fbe\u5f0f\u53ef\u4ee5\u5f97\u5230</p> \\[ x' = x \\cos \\theta - y \\sin \\theta \\\\ y' = x \\sin \\theta + y \\cos \\theta \\] <p>\u5199\u6210\u77e9\u9635\u7684\u5f62\u5f0f\u4e3a\uff1a</p> \\[ \\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix}  \\cos \\theta  &amp; -\\sin \\theta \\\\ \\sin \\theta  &amp; cos \\theta \\end{bmatrix} * \\begin{bmatrix}  x \\\\ y \\end{bmatrix} \\]"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#12","title":"1.2 \u65cb\u8f6c\u77e9\u5f62\u7684\u8868\u793a","text":"<p>\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u7ea2\u8272\u6846A'B'C'D'\u4e3a\u76ee\u6807\u659c\u6846\uff0c\u7eff\u8272\u6846ABCD\u8868\u793a\u8f74\u5411\u6846\uff0c\u8f74\u5411\u6846\u987a\u65f6\u9488\u65cb\u8f6c \\(\\theta\\) \u540e\u5f97\u5230\u76ee\u6807\u659c\u6846\uff0c\u73b0\u9700\u8981\u6c42\u51fa\u659c\u6846\u5404\u9876\u70b9A\u2032,B\u2032,C',D'\u7684\u5750\u6807\u3002</p> <p>\u4ee5(x,y,w,h, \\(\\theta\\) )\u8868\u793a\u4e0a\u8ff0\u77e9\u5f62\uff0cx\u548cy\u4ee3\u8868\u4e2d\u5fc3\u70b9\u7684\u5750\u6807\uff0c \\(\\theta\\) \u4e3a\u987a\u65f6\u9488\u7684\u89d2\u5ea6\uff0c\u6309\u71671.1\u8282\u6240\u8ff0\uff08\u9006\u65f6\u9488\uff09\uff0c\u987a\u65f6\u9488\u65cb\u8f6c\u77e9\u9635\u4e3a</p> \\[ \\begin{bmatrix}  \\cos \\theta  &amp; \\sin \\theta \\\\ -\\sin \\theta  &amp; cos \\theta \\end{bmatrix} \\] <p>\u6240\u4ee5\u5411\u91cfO'A' = T  \\(\\cdot\\)  O'A\uff0c O'B' = T  \\(\\cdot\\)  O'B\uff0cO'C' = T  \\(\\cdot\\)  O'C\uff0cO'D' = T  \\(\\cdot\\)  O'D</p> <p>\u4ee5\u5411\u91cfO'A'\u6c42\u89e3\u4e3a\u4f8b\uff0c\u5176\u6a2a\u5750\u6807\u4e3a \\(X_{O'A'} = \\cos \\theta * \\frac{w}{2} + \\sin \\theta * \\frac{h}{2}\\) \uff0c\u7eb5\u5750\u6807 \\(Y_{O'A'} = - \\sin \\theta * \\frac{w}{2} + \\cos \\theta * \\frac{h}{2}\\) </p> <p>\u6240\u4ee5</p> \\[ O'A'(w * \\cos \\theta * 0.5 + h * \\sin \\theta * 0.5, - w * \\sin \\theta * 0.5 + h * cos \\theta * 0.5) \\] <p>\u56e0\u6b64\uff0c\u9876\u70b9A'\u7684\u5750\u6807\u4e3a\uff1a</p> \\[ A'(x + w * \\cos \\theta * 0.5 + h * \\sin\\theta * 0.5, y - w * \\sin \\theta * 0.5 + h * \\cos \\theta * 0.5) \\] <p>\u540c\u7406\uff1a</p> \\[ \\begin{align*} &amp; O'B'(w * \\cos \\theta * 0.5 - h * \\sin \\theta * 0.5, - w * \\sin \\theta * 0.5 - h * cos \\theta * 0.5) \\\\ &amp; O'C'(-w * \\cos \\theta * 0.5 - h * \\sin \\theta * 0.5, w * \\sin \\theta * 0.5 - h * cos \\theta * 0.5) \\\\ &amp; O'D'(-w * \\cos \\theta * 0.5 + h * \\sin \\theta * 0.5, w * \\sin \\theta * 0.5 + h * cos \\theta * 0.5) \\end{align*} \\] <p>\u6240\u4ee5\u6709\uff1a</p> \\[ \\begin{align*} &amp; B'(x + w * \\cos \\theta * 0.5 - h * \\sin\\theta * 0.5, y - w * \\sin \\theta * 0.5 - h * \\cos \\theta * 0.5) \\\\ &amp; C'(x - w * \\cos \\theta * 0.5 - h * \\sin\\theta * 0.5, y + w * \\sin \\theta * 0.5 - h * \\cos \\theta * 0.5) \\\\ &amp; D'(x - w * \\cos \\theta * 0.5 + h * \\sin\\theta * 0.5, y + w * \\sin \\theta * 0.5 + h * \\cos \\theta * 0.5) \\\\ &amp; C'(2x - X_{A'}, 2y - Y_{A'}) \\\\ &amp; D'(2x - X_{B'}, 2y - Y_{B'}) \\end{align*} \\] <p>\u4ee3\u7801\u5b9e\u73b0</p> <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\n\n\nclass RotatedBox:\n\n    def __init__(self, x, y, w, h, theta):\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        self.theta = theta\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n\ndef main():\n    x = -5\n    y = -5\n    w = 15\n    h = 20\n    theta = 45\n    theta = theta / 180 * math.pi\n    det_box = RotatedBox(x, y, w, h, theta)\n\n    points = [Point(0, 0) for _ in range(4)]\n    cos_theta = math.cos(theta) * 0.5\n    sin_theta = math.sin(theta) * 0.5\n\n    points[0].x = det_box.x + sin_theta * det_box.h + cos_theta * det_box.w\n    points[0].y = det_box.y + cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[1].x = det_box.x - sin_theta * det_box.h + cos_theta * det_box.w\n    points[1].y = det_box.y - cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[2].x = 2 * det_box.x - points[0].x\n    points[2].y = 2 * det_box.y - points[0].y\n\n    points[3].x = 2 * det_box.x - points[1].x\n    points[3].y = 2 * det_box.y - points[1].y\n\n    for point in points:\n        print('point', point.x, point.y)\n\n    # \u7528matplotlib\u7ed8\u5236\u51fa\u6765\n\n    fig, ax = plt.subplots()\n    fig.set_figheight(6)\n    fig.set_figwidth(6)\n    # \u7ed8\u5236\u77e9\u5f62\n    # \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5de6\u4e0b\u89d2\u5750\u6807 \u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3awidth \u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3aheight\n    x_center, y_center, width, height = det_box.x, det_box.y, det_box.w, det_box.h\n    x1 = x_center - det_box.w / 2\n    y1 = y_center - det_box.h / 2\n    x2 = x_center + det_box.w / 2\n    y2 = y_center + det_box.h / 2\n\n    # print(x1, y1)\n\n    rect = plt.Rectangle((x1, y1), det_box.w, det_box.h, angle=0, fill=False, color=\"blue\")\n    ax.add_patch(rect)\n\n    # \u7ed5 center (x,y) \u65cb\u8f6c45\u5ea6\n    polygon = mptch.Polygon(xy=[(points[i].x, points[i].y) for i in range(4)], closed=True, color=\"red\", fill=False)\n    ax.add_patch(polygon)\n\n    # \u8bbe\u7f6e\u5750\u6807\u8f74\n    ax.set_xlim(-30, 30)\n    ax.set_ylim(-30, 30)\n    # \u5b9a\u4e49\u5750\u6807\n    x = np.arange(-30, 31, 5)\n    y = np.arange(-30, 31, 5)\n    ax.set_xticks(x)\n    ax.set_yticks(y)\n    ax.grid(True)\n    # \u663e\u793a\u56fe\u8c61\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n\n\"\"\"\npoint 7.374368670764582 -3.232233047033631\npoint -6.767766952966369 -17.374368670764582\npoint -17.374368670764582 -6.767766952966369\npoint -3.232233047033631 7.374368670764582\n\"\"\"\n</code></pre> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#_2","title":"\u4e8c\u3001\u7ebf\u6bb5\u76f8\u4ea4","text":"<p>\u8bb0\u4e24\u7ebf\u6bb5\u4e3aAB\u4e0eCD</p> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#21","title":"2.1 \u6cd5\u4e00","text":"<ol> <li>\u5148\u5224\u65ad\u7ebf\u6bb5\u662f\u5426\u5171\u7ebf</li> </ol> <p>\u4f9d\u636e\u5171\u7ebf\u5411\u91cf\u53c9\u4e58\u4e3a\u96f6\u5411\u91cf\u6765\u5224\u65ad</p> <p>\\(\\vec{AB} \u4e0e \\vec{CD}\\) \u53c9\u4e58\u662f\u5426\u4e3a0\uff0c\u5982\u679c\u4e3a0\u5219\u5171\u7ebf</p> <ol> <li>\u5728\u4e0d\u5171\u7ebf\u60c5\u51b5\u4e0b\u5224\u65ad\u662f\u5426\u76f8\u4ea4</li> </ol> <p>\u4f9d\u636e \\(0 \\leq t \\leq 1\\) \u4e14 \\(0 \\leq u \\leq 1\\) \u6765\u5224\u65ad\uff0c\u5176\u4e2d \\(t\\) \u548c \\(u\\) \u7684\u63a8\u5bfc\u8fc7\u7a0b\u5982\u4e0b\uff1a</p> <p></p> <p>\u5047\u8bbe\u4ea4\u70b9\u4e3aP\uff0c\u5219\u6709P=A+ \\(\\vec{AB} * t\\) \uff0c \\(t \\in [0, 1]\\) \u4e14 \\(P = C + \\vec{CD} * u\\) \uff0c  \\(u \\in [0,1]\\) \uff0c\u5373</p> \\[ \\vec{OA} + \\vec{AB} * t = \\vec{OC} + \\vec{CD} * u ===&gt; \\\\ \\vec{AB} * t = \\vec{AC} + \\vec{CD} * u \\] <p>\u7531\u4e8e\u5411\u91cf\u81ea\u8eab\u7684\u53c9\u4e58\u4e3a0\uff0c\u6240\u4ee5\u4e0a\u5f0f\u4e24\u8fb9\u540c\u65f6\u53c9\u4e58 \\(\\vec{CD}\\) \u53ef\u5f97\uff1a</p> \\[ \\vec{CD} \\times \\vec{AB} * t = \\vec{CD} \\times \\vec{AC} \\] <p>\u6c42\u5f97t\u5f97\uff1a</p> \\[ t = \\frac{\\vec{CD} \\times \\vec{AC}}{\\vec{CD} \\times \\vec{AB}}, t \\in [0, 1] \\] <p>\u540c\u7406\uff0c\u4e24\u8fb9\u540c\u65f6\u53c9\u4e58 \\(\\vec{AB}\\) \u53ef\u5f97\uff1a \\(- \\vec{AB} \\times \\vec{CD} * u = \\vec{AB} \\times \\vec{AC}\\) \uff0c\u6240\u4ee5\uff1a</p> \\[ u = \\frac{\\vec{AB} \\times \\vec{AC}}{\\vec{CD} \\times \\vec{AB}}, u \\in [0, 1] \\] <p>\u8fd9\u91cc\u9700\u8981\u8bf4\u660e\u7684\u662f\u5411\u91cf\u662f\u4e0d\u652f\u6301\u9664\u6cd5\u7684\uff0c\u8fd9\u91cc\u7531\u4e8e\u5e73\u9762\u5411\u91cf\u53c9\u4e58\u540e\u7ed3\u679c\u662f\u5782\u76f4\u4e8e\u5e73\u9762\u7684\u5411\u91cf\uff0c\u5176\u4e00\u5b9a\u65b9\u5411\u76f8\u540c\uff0c\u90fd\u4f4d\u4e8eZ\u8f74\uff0c\u6240\u4ee5\u9664\u6cd5\u4ee3\u8868\u7684\u542b\u4e49\u662f\u4e0ez\u8f74\u5171\u7ebf\u7684\u4e24\u4e2a\u5411\u91cf\u7684z\u8f74\u65b9\u5411\u7684\u5750\u6807\u503c\u76f8\u9664\u3002</p> <ol> <li>\u5728\u76f8\u4ea4\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\u4ea4\u70b9</li> </ol> <p>\u4f9d\u636e\u7b2c2\u6b65\u8ba1\u7b97\u7684t\u548cu\uff0c\u4ee3\u5165\uff1a \\(P = A + \\vec {AB} * t\\) \uff0c \\(t \\in [0, 1]\\) \u4e14 \\(P = C +\\vec{CD} * u\\) \uff0c \\(u \\in [0, 1]\\) \u5373\u53ef\u6c42\u51fa\u4ea4\u70b9P\u7684\u5750\u6807\u3002</p> <p>\u4ee3\u7801\u5b9e\u73b0</p> <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n    def __sub__(self, other: 'Point'):\n        return Point(self.x - other.x, self.y - other.y)\n\n    def __mul__(self, other_scaler):\n        return Point(self.x * other_scaler, self.y * other_scaler)\n\n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n    __repr__ = __str__\n\n\nclass Line:\n\n    def __init__(self, start_point, end_point):\n        self.start_point = start_point\n        self.end_point = end_point\n\n    def get_vector_point(self):\n        return Point(self.end_point.x - self.start_point.x, self.end_point.y - self.start_point.y)\n\n\ndef cross2d(A: Point, B: Point):\n    return A.x * B.y - B.x * A.y\n\n\ndef get_intersection_points(line1: Line, line2: Line):\n\n    line1_vec = line1.get_vector_point()\n    line2_vec = line2.get_vector_point()\n\n    det_value = cross2d(line2_vec, line1_vec)\n\n    if abs(det_value) &lt; 1e-14:\n        return False, Point(0, 0)\n\n    ac_line_vec = line2.start_point - line1.start_point\n\n    t = cross2d(line2_vec, ac_line_vec) / det_value\n    u = cross2d(line1_vec, ac_line_vec) / det_value\n\n    eps = 1e-14\n\n    if -eps &lt;= t &lt;= 1.0 + eps and -eps &lt;= u &lt;= 1.0 + eps:\n        return True, line1.start_point + line1_vec * t\n\n    return False, Point(0, 0)\n\n\ndef main():\n\n    A = Point(0, 0)\n    B = Point(2, 0)\n    C = Point(2, 2)\n    D = Point(0, 2)\n    E = Point(1, 3)\n\n    plt.plot([A.x, B.x], [A.y, B.y])\n    plt.plot([C.x, D.x], [C.y, D.y])\n    plt.plot([A.x, E.x], [A.y, E.y])\n\n    plt.scatter(A.x, A.y)\n    plt.scatter(B.x, B.y)\n    plt.scatter(C.x, C.y)\n    plt.scatter(D.x, D.y)\n    plt.scatter(E.x, E.y)\n\n    plt.text(A.x, A.y, 'A')\n    plt.text(B.x, B.y, 'B')\n    plt.text(C.x, C.y, 'C')\n    plt.text(D.x, D.y, 'D')\n    plt.text(E.x, E.y, 'E')\n\n    # \u5224\u65ad AB \u662f\u5426\u4e0e CD\u76f8\u4ea4 \u5982\u679c\u76f8\u4ea4\u6c42\u51fa\u4ea4\u70b9\n    is_intersect, intersection_point = get_intersection_points(Line(A, B), Line(C, D))\n    if is_intersect:\n        print(f'AB \u4e0e CD \u4ea4\u70b9\u4e3a {intersection_point}')\n        plt.scatter(intersection_point.x, intersection_point.y)\n        plt.text(intersection_point.x, intersection_point.y, 'ABxCD')\n    else:\n        print('AB \u4e0e CD \u6ca1\u6709\u76f8\u4ea4')\n\n    # \u5224\u65ad AE \u662f\u5426\u4e0e CD\u76f8\u4ea4 \u5982\u679c\u76f8\u4ea4\u6c42\u51fa\u4ea4\u70b9\n    is_intersect, intersection_point = get_intersection_points(Line(A, E), Line(C, D))\n    if is_intersect:\n        print(f'AE \u4e0e CD \u4ea4\u70b9\u4e3a {intersection_point}')\n        plt.scatter(intersection_point.x, intersection_point.y)\n        plt.text(intersection_point.x, intersection_point.y, 'AExCD')\n    else:\n        print('AE \u4e0e CD \u6ca1\u6709\u76f8\u4ea4')\n\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u7ed8\u5236\u7ed3\u679c</p> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#22","title":"2.2 \u6cd5\u4e8c","text":"<p>\u6cd5\u4e8c\u662f\u5229\u7528\u7ebf\u6bb5\u76f8\u4ea4\u5219\u4e00\u6761\u7ebf\u6bb5\u4e24\u7aef\u70b9\u4f4d\u4e8e\u53e6\u4e00\u7ebf\u6bb5\u4e24\u4fa7\u6765\u5224\u65ad</p> <p>1. \u5148\u5224\u65ad\u7ebf\u6bb5\u662f\u5426\u5171\u7ebf</p> <p>\u540c\u65b9\u6cd5\u4e00</p> <p>2. \u5728\u4e0d\u5171\u7ebf\u60c5\u51b5\u4e0b\u5224\u65ad\u662f\u5426\u76f8\u4ea4</p> <p>\u4f9d\u636e\u7ebf\u6bb5\u76f8\u4ea4\u5219\u4e00\u6761\u7ebf\u6bb5\u4e24\u7aef\u70b9\u4f4d\u4e8e\u53e6\u4e00\u7ebf\u6bb5\u4e24\u4fa7\u6765\u5224\u65ad \u76f8\u4ea4\u60c5\u51b5\u4e0b\u6709\u5982\u4e0b\u4e24\u79cd\u60c5\u5f62\uff1a</p> <p></p> <p>\u5224\u65ad\u662f\u5426\u5728\u4e24\u4fa7\u53ef\u4ee5\u4f9d\u636e\u4e24\u4e2a\u5411\u91cf\u7684\u53c9\u4e58(\u53f3\u624b\u6cd5\u5219)\uff0c\u5982\u4e0b\uff1a</p> <p></p> <p>\\(\\vec{OA} \\times \\vec{OB} &gt; 0\\) \uff0c\u5219 \\(\\vec{OB}\\) \u5728 \\(\\vec{OA}\\) \u7684\u9006\u65f6\u9488\u65b9\u5411</p> <p>\\(\\vec{OB} \\times \\vec{OA} &lt; 0\\) \uff0c\u5219 \\(\\vec{OA}\\) \u5728 \\(\\vec{OB}\\) \u7684\u987a\u65f6\u9488\u65b9\u5411</p> <p>\u6240\u4ee5\uff0c\u76f8\u4ea4\u7684\u4e24\u79cd\u60c5\u51b5\u4e0b\u6709\uff1a</p> <ul> <li>\u60c5\u51b51</li> </ul> <p>\u70b9C\u548cD\u5728AB\u4e24\u4fa7\uff0c\u5219\u6709\uff1a</p> <p>\\((\\vec{AC} \\times \\vec{AB}) \\cdot (\\vec{AD} \\times \\vec{AB}) &lt;0\\) </p> <p>\u70b9A\u548cB\u5728CD\u4e24\u4fa7\uff0c\u5219\u6709\uff1a</p> <p>\\((\\vec{CA} \\times \\vec{CD}) \\cdot (\\vec{CB} \\times \\vec{CD}) &lt;0\\) </p> <ul> <li>\u60c5\u51b52</li> </ul> <p>\u7531\u4e8e\u7aef\u70b9\u5728\u7ebf\u6bb5\u4e0a\uff0c\u6240\u6709\u6709\u4e00\u4e2a\u53c9\u4e58\u4e3a0\uff0c\u56e0\u6b64</p> \\[ (\\vec{AC} \\times \\vec{AB}) \\cdot (\\vec{AD} \\times \\vec{AB}) = 0 \\] <p>\u4e14</p> \\[ (\\vec{CA} \\times \\vec{CD}) \\cdot (\\vec{CB} \\times \\vec{CD}) = 0 \\] <p>\u90a3\u4e48\u5982\u4f55\u8ba1\u7b97\u4ea4\u70b9\u5462\uff1f\u9996\u5148\u53c9\u79ef\u53ef\u4ee5\u7b97\u9762\u79ef\uff0c\u6839\u636e\u9762\u79ef\u4e4b\u6bd4\uff0c\u7b97\u5f97\u4ea4\u70b9O\u5728\u7ebf\u6bb5CD\u4e0a\u7684\u6bd4\u4f8b\u4f4d\u7f6e\u3002\u7136\u540e\u7528\u8fd9\u4e2a\u6bd4\u4f8b\u63d2\u503c\u5f97\u5230\u5750\u6807\u3002</p> <p></p> \\[ \\lambda = \\frac{OC}{OD} = \\frac{area(ABC)}{area(ABD)} = \\frac{\\frac{1}{2} ||\\vec{AB} \\times \\vec{AC}|| }{ \\frac{1}{2} ||\\vec{AB} \\times \\vec{AD}|| } \\] \\[ O_x = C_x + \\frac{\\lambda}{\\lambda + 1}(D_x - C_x) \\\\ O_y = C_y + \\frac{\\lambda}{\\lambda + 1}(D_y - C_y) \\] <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n    def __sub__(self, other: 'Point'):\n        return Point(self.x - other.x, self.y - other.y)\n\n    def __mul__(self, other_scaler):\n        return Point(self.x * other_scaler, self.y * other_scaler)\n\n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n    __repr__ = __str__\n\n\nclass Line:\n\n    def __init__(self, start_point, end_point):\n        self.start_point = start_point\n        self.end_point = end_point\n\n    def get_vector_point(self):\n        return Point(self.end_point.x - self.start_point.x, self.end_point.y - self.start_point.y)\n\n\ndef cross2d(A: Point, B: Point):\n    return A.x * B.y - B.x * A.y\n\n\ndef get_intersection_points(line1: Line, line2: Line):\n\n    AB = line1.get_vector_point()\n    CD = line2.get_vector_point()\n    AC = line2.start_point - line1.start_point\n    AD = line2.end_point - line1.start_point\n    CB = line1.end_point - line2.start_point\n    CA = line1.start_point - line2.start_point\n\n    det_value = cross2d(CD, AB)\n\n    if abs(det_value) &lt; 1e-14:\n        return False, Point(0, 0)\n\n    eps = 1e-14\n    cross_AC_AB = cross2d(AC, AB)\n    cross_AD_AB = cross2d(AD, AB)\n    cross_CA_CD = cross2d(CA, CD)\n    cross_CB_CD = cross2d(CB, CD)\n\n    print('cross_AC_AB * cross_AD_AB', cross_AC_AB * cross_AD_AB)\n    print('cross_CA_CD * cross_CB_CD', cross_CA_CD * cross_CB_CD)\n    if cross_AC_AB * cross_AD_AB &lt;= eps and cross_CA_CD * cross_CB_CD &lt;= eps:\n        lambda_k = abs(cross_AC_AB / cross_AD_AB)\n        x = line2.start_point.x + (lambda_k / (lambda_k + 1)) * (line2.end_point.x - line2.start_point.x)\n        y = line2.start_point.y + (lambda_k / (lambda_k + 1)) * (line2.end_point.y - line2.start_point.y)\n        return True, Point(x, y)\n\n\n    return False, Point(0, 0)\n\n\ndef main():\n\n    A = Point(0, 0)\n    B = Point(2, 0)\n    C = Point(2, 2)\n    D = Point(0, 2)\n    E = Point(1, 3)\n\n    plt.plot([A.x, B.x], [A.y, B.y])\n    plt.plot([C.x, D.x], [C.y, D.y])\n    plt.plot([A.x, E.x], [A.y, E.y])\n\n    plt.scatter(A.x, A.y)\n    plt.scatter(B.x, B.y)\n    plt.scatter(C.x, C.y)\n    plt.scatter(D.x, D.y)\n    plt.scatter(E.x, E.y)\n\n    plt.text(A.x, A.y, 'A')\n    plt.text(B.x, B.y, 'B')\n    plt.text(C.x, C.y, 'C')\n    plt.text(D.x, D.y, 'D')\n    plt.text(E.x, E.y, 'E')\n\n    # \u5224\u65ad AB \u662f\u5426\u4e0e CD\u76f8\u4ea4 \u5982\u679c\u76f8\u4ea4\u6c42\u51fa\u4ea4\u70b9\n    is_intersect, intersection_point = get_intersection_points(Line(A, B), Line(C, D))\n    if is_intersect:\n        print(f'AB \u4e0e CD \u4ea4\u70b9\u4e3a {intersection_point}')\n        plt.scatter(intersection_point.x, intersection_point.y)\n        plt.text(intersection_point.x, intersection_point.y, 'ABxCD')\n    else:\n        print('AB \u4e0e CD \u6ca1\u6709\u76f8\u4ea4')\n\n    # \u5224\u65ad AE \u662f\u5426\u4e0e CD\u76f8\u4ea4 \u5982\u679c\u76f8\u4ea4\u6c42\u51fa\u4ea4\u70b9\n    is_intersect, intersection_point = get_intersection_points(Line(A, E), Line(C, D))\n    if is_intersect:\n        print(f'AE \u4e0e CD \u4ea4\u70b9\u4e3a {intersection_point}')\n        plt.scatter(intersection_point.x, intersection_point.y)\n        plt.text(intersection_point.x, intersection_point.y, 'AExCD')\n    else:\n        print('AE \u4e0e CD \u6ca1\u6709\u76f8\u4ea4')\n\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u53ef\u89c6\u5316\u7ed3\u679c\u4e3a</p> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#_3","title":"\u4e09\u3001\u5224\u65ad\u70b9\u662f\u5426\u5728\u51f8\u591a\u8fb9\u5f62\u5185\u90e8","text":"<p>\u4e3a\u4ec0\u4e48\u8981\u6709\u8fd9\u4e00\u6b65\u5462\uff1f\u56e0\u4e3a\u5f53\u51f8\u56db\u8fb9\u5f62\u76f8\u4ea4\u7684\u60c5\u51b5\u4f1a\u51fa\u73b0\u6709\u4e00\u4e2a\u56db\u8fb9\u5f62\u7684\u89d2\u70b9\u5728\u53e6\u5916\u4e00\u4e2a\u56db\u8fb9\u5f62\u5185\u90e8\u7684\u60c5\u51b5\uff0c\u8fd9\u6837\u6c42\u5176\u76f8\u4ea4\u533a\u57df\u5c31\u9700\u8981\u77e5\u9053\u76f8\u4ea4\u533a\u57df\u7684\u591a\u4e2a\u70b9\u3002</p> <p>\u4e0b\u56fe\u8282\u9009\u81eaRRPN\u6587\u7ae0</p> <p></p> <p>\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u60c5\u51b5b\uff0c\u77e9\u5f62A\u7684\u89d2\u70b9\u843d\u5728\u7684\u77e9\u5f62B\u7684\u5185\u90e8\u533a\u57df\u5185\uff0c\u4e24\u77e9\u5f62\u76f8\u4ea4\u7684\u591a\u8fb9\u5f62\u533a\u57df\u7684\u89d2\u70b9\u5c31\u5305\u542b\u77e9\u5f62A\u7684\u89d2\u70b9\u3002</p> <p>\u6839\u636e\u53c2\u8003\u94fe\u63a5\uff0c\u5224\u65ad\u4e00\u4e2a\u70b9\u662f\u5426\u5728\u591a\u8fb9\u5f62\u5185\u90e8\u7684\u5e38\u89c1\u65b9\u6cd5\u6709\u5982\u4e0b\u51e0\u79cd</p> <ul> <li>\u9762\u79ef\u548c\u5224\u522b\u6cd5\uff1a\u5224\u65ad\u76ee\u6807\u70b9\u4e0e\u591a\u8fb9\u5f62\u7684\u6bcf\u6761\u8fb9\u7ec4\u6210\u7684\u4e09\u89d2\u5f62\u9762\u79ef\u548c\u662f\u5426\u7b49\u4e8e\u8be5\u591a\u8fb9\u5f62\uff0c\u76f8\u7b49\u5219\u5728\u591a\u8fb9\u5f62\u5185\u90e8\u3002</li> <li>\u5939\u89d2\u548c\u5224\u522b\u6cd5\uff1a\u5224\u65ad\u76ee\u6807\u70b9\u4e0e\u6240\u6709\u8fb9\u7684\u5939\u89d2\u548c\u662f\u5426\u4e3a360\u5ea6\uff0c\u4e3a360\u5ea6\u5219\u5728\u591a\u8fb9\u5f62\u5185\u90e8\u3002</li> <li>\u5f15\u5c04\u7ebf\u6cd5\uff1a\u4ece\u76ee\u6807\u70b9\u51fa\u53d1\u5f15\u4e00\u6761\u5c04\u7ebf\uff0c\u770b\u8fd9\u6761\u5c04\u7ebf\u548c\u591a\u8fb9\u5f62\u6240\u6709\u8fb9\u7684\u4ea4\u70b9\u6570\u76ee\u3002\u5982\u679c\u6709\u5947\u6570\u4e2a\u4ea4\u70b9\uff0c\u5219\u8bf4\u660e\u5728\u5185\u90e8\uff0c\u5982\u679c\u6709\u5076\u6570\u4e2a\u4ea4\u70b9\uff0c\u5219\u8bf4\u660e\u5728\u5916\u90e8</li> </ul> <p>\u4e0b\u9762\u6211\u4eec\u8be6\u7ec6\u4ecb\u7ecd\u4e00\u4e0b\u5c04\u7ebf\u6cd5</p> <ol> <li>\u60c5\u51b51\uff1a\u663e\u793a\u4e86\u5177\u6709 14 \u6761\u8fb9\u7684\u4e25\u91cd\u51f9\u9677\u591a\u8fb9\u5f62\u7684\u5178\u578b\u60c5\u51b5</li> </ol> <p></p> <ul> <li>\u4e0a\u56fe \u663e\u793a\u4e86\u5177\u6709 14 \u6761\u8fb9\u7684\u51f9\u591a\u8fb9\u5f62\u7684\u5178\u578b\u60c5\u51b5</li> <li>\u7ea2\u70b9\u662f\u9700\u8981\u6d4b\u8bd5\u7684\u70b9\uff0c\u4ee5\u786e\u5b9a\u5b83\u662f\u5426\u4f4d\u4e8e\u591a\u8fb9\u5f62\u5185\u3002\u89e3\u6cd5\u65b9\u6848\u662f\u4ece\u6d4b\u8bd5\u70b9Y\u6cbf\u7740\u6c34\u5e73\u65b9\u5411\u5411\u5916\u5f15\u51fa\u4e00\u6761\u76f4\u7ebf\uff0c\u6570\u4e00\u4e0b\u76f4\u7ebf\u4e0e\u591a\u8fb9\u5f62\u8fb9\u7684\u4ea4\u70b9\u4e2a\u6570\u3002</li> <li>\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u591a\u8fb9\u5f62\u7684\u516b\u6761\u8fb9\u7a7f\u8fc7\u84dd\u8272\u76f4\u7ebf\uff0c\u5982\u679c\u6d4b\u8bd5\u70b9\u7684\u6bcf\u4e00\u4fa7\u90fd\u6709\u5947\u6570\u4e2a\u8282\u70b9\uff0c\u5219\u5b83\u4f4d\u4e8e\u591a\u8fb9\u5f62\u5185\u90e8;\u5982\u679c\u6d4b\u8bd5\u70b9\u7684\u6bcf\u4e00\u4fa7\u90fd\u6709\u5076\u6570\u4e2a\u8282\u70b9\uff0c\u5219\u5b83\u4f4d\u4e8e\u591a\u8fb9\u5f62\u4e4b\u5916\u3002\u5728\u6211\u4eec\u7684\u793a\u4f8b\u4e2d\uff0c\u6d4b\u8bd5\u70b9\u7684\u5de6\u4fa7\u6709\u4e94\u4e2a\u8282\u70b9\uff0c\u53f3\u4fa7\u6709\u4e09\u4e2a\u8282\u70b9\u3002\u7531\u4e8e 5 \u548c 3 \u662f\u5947\u6570\uff0c\u56e0\u6b64\u6211\u4eec\u7684\u6d4b\u8bd5\u70b9\u4f4d\u4e8e\u591a\u8fb9\u5f62\u5185\u90e8\u3002</li> <li>\u60c5\u51b52:\uff0c\u663e\u793a\u4e86\u591a\u8fb9\u5f62\u81ea\u8eab\u4ea4\u53c9\u65f6\u53d1\u751f\u7684\u60c5\u51b5</li> </ul> <p></p> <p>\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u5341\u8fb9\u5f62\u7684\u7ebf\u5f7c\u6b64\u76f8\u4ea4\u3002\u591a\u8fb9\u5f62\u4e2d\u91cd\u53e0\u7684\u90e8\u5206\u76f8\u4e92\u62b5\u6d88\u3002\u56e0\u6b64\uff0c\u6d4b\u8bd5\u70b9\u4f4d\u4e8e\u591a\u8fb9\u5f62\u4e4b\u5916\uff0c\u5982\u5176\u4e24\u4fa7\u7684\u5076\u6570\u4e2a\u8282\u70b9\uff08\u4e24\u4e2a\u548c\u4e24\u4e2a\uff09\u6240\u793a\u3002</p> <ol> <li>\u60c5\u51b53\uff1a\u516d\u8fb9\u5f62\u672c\u8eab\u4e0d\u91cd\u53e0\uff0c\u4f46\u5b83\u786e\u5b9e\u6709\u4ea4\u53c9\u7684\u7ebf</li> </ol> <p></p> <ol> <li>\u663e\u793a\u4e86\u591a\u8fb9\u5f62\u7684\u60c5\u51b5\uff0c\u5176\u4e2d\u4e00\u6761\u8fb9\u5b8c\u5168\u4f4d\u4e8e\u591a\u8fb9\u5f62\u8fb9\u7684\u7aef\u70b9\u4e0a</li> </ol> <p></p> <p>\u65e2\u7136\u8fb9a\u548c\u8fb9 b\u5171\u4eab\u7aef\u70b9\uff0c\u6070\u597d\u5f15\u51fa\u76f4\u7ebf\u53c8\u521a\u597d\u78b0\u5230\u8be5\u7aef\u70b9\uff0c\u90a3\u4e48\u8be5\u7aef\u70b9\u662f\u5426\u53ef\u4ee5\u88ab\u7edf\u8ba1\u4e24\u6b21\u5462\uff1f\u4e0d\uff0c\u56e0\u4e3a\u8fd9\u6837\u6d4b\u8bd5\u70b9\u7684\u6bcf\u4e00\u4fa7\u90fd\u4f1a\u6709\u4e24\u4e2a\u8282\u70b9\uff0c\u56e0\u6b64\u6d4b\u8bd5\u4f1a\u8bf4\u5b83\u5728\u591a\u8fb9\u5f62\u4e4b\u5916\uff0c\u800c\u663e\u7136\u4e0d\u662f\uff01</p> <p>\u89e3\u51b3\u65b9\u6848\uff1a\u4e24\u4e2a\u8fb9\u7684\u4e24\u4e2a\u7aef\u70b9\u4f4d\u4e8e\u8be5\u76f4\u7ebf\u4e24\u4fa7\uff0c\u4ec5\u9009\u62e9\u4e00\u4fa7\u4f5c\u4e3a\u4ea4\u70b9\u3002\u5047\u8bbe\u6211\u4eec\u5c06\u8be5\u7aef\u70b9\u5047\u5b9a\u4e3a\u5c5e\u4e8ea\u4e0d\u5c5e\u4e8eb\u7684\uff08\u5373\u5728\u7ebf\u6bb5\u4e24\u7aef\u70b9\u6709\u4e00\u4e2a\u4f4d\u4e8e\u76f4\u7ebf\u4e0b\u65b9\u7684\u4ea7\u751f\u4ea4\u70b9\uff09\uff0c\u90a3\u4e48\u8be5\u76f4\u7ebf\u4e0e\u4e24\u4fa7\u8fb9\u76f8\u4ea4\u70b9\u7684\u4e2a\u6570\u90fd\u662f1\uff0c\u6ee1\u8db3\u8981\u6c42\u3002</p> <ol> <li>\u663e\u793a\u4e86\u591a\u8fb9\u5f62\u7684\u60c5\u51b5\uff0c\u5176\u4e2d\u4e00\u6761\u8fb9\u5b8c\u5168\u4f4d\u4e8e\u76f4\u7ebf\u4e0a</li> </ol> <p></p> <p>\u53ea\u9700\u9075\u5faa\u6709\u5173\u60c5\u51b5\u56db\u6240\u8ff0\u7684\u89c4\u5219\u5373\u53ef\uff0c\u7ebf\u6bb5c\u4f1a\u4ea7\u751f\u4e00\u4e2a\u4ea4\u70b9\uff0c\u7ebf\u6bb5d\u4e0d\u4f1a\u4ea7\u751f\u4ea4\u70b9\uff0c\u56e0\u4e3a\u5b83\u7684\u4e24\u4e2a\u7ec8\u70b9\u90fd\u4f4d\u4e8e\u76f4\u7ebf\u4e0a\u6216\u76f4\u7ebf\u4e0a\u9762\u3002\u800c\u7aefe\u4e5f\u4e0d\u4f1a\u751f\u6210\u8282\u70b9\uff0c\u56e0\u4e3a\u5b83\u7684\u4e24\u4e2a\u7aef\u70b9\u90fd\u4f4d\u4e8e\u76f4\u7ebf\u4e0a\u6216\u4e4b\u4e0a\u3002</p> <ol> <li>\u4e00\u4e2a\u7279\u6b8a\u60c5\u51b5</li> </ol> <p></p> <ul> <li>\u591a\u8fb9\u5f62\u7684\u4e00\u4e2a\u5185\u90e8\u89d2\u70b9\u6b63\u597d\u89e6\u53ca\u76f4\u7ebf\u3002\u5728\u4e0a\u56fe\u4e2d\uff0c\u53ea\u6709\u4e00\u4fa7\uff08\u4ee5\u7ea2\u8272\u9690\u85cf\uff09\u5728\u6d4b\u8bd5\u70b9\u7684\u5de6\u4fa7\u751f\u6210\u4e00\u4e2a\u8282\u70b9\uff0c\u800c\u5728\u5e95\u90e8\u7684\u793a\u4f8b\u4e2d\uff0c\u4e09\u6761\u8fb9\u53ef\u4ee5\u3002\u65e0\u8bba\u54ea\u79cd\u65b9\u5f0f\uff0c\u8be5\u6570\u5b57\u90fd\u662f\u5947\u6570\uff0c\u5e76\u4e14\u6d4b\u8bd5\u70b9\u5c06\u88ab\u89c6\u4e3a\u5728\u591a\u8fb9\u5f62\u5185\u3002</li> <li>\u5982\u679c\u6d4b\u8bd5\u70b9\u4f4d\u4e8e\u591a\u8fb9\u5f62\u7684\u8fb9\u754c\u4e0a\uff0c\u5219\u6b64\u7b97\u6cd5\u5c06\u63d0\u4f9b\u4e0d\u53ef\u9884\u77e5\u7684\u7ed3\u679c;</li> </ul> <p>\u6211\u4eec\u56de\u987e\u4e0b\u76f4\u7ebf\u65b9\u7a0b\uff1a</p> <p>\u5e73\u9762\u76f4\u7ebf\u7684\u8868\u8fbe\u65b9\u5f0f\u6709\u56db\u79cd</p> <ol> <li>\u70b9\u659c\u5f0f\uff08\u7528\u4e8e\u5df2\u77e5\u659c\u7387\u548c\u4e00\u70b9\u5750\u6807\uff09</li> </ol> \\[ y - y_1 = k(x - x_1) \\] <ol> <li>\u659c\u622a\u5f0f\uff08\u7528\u4e8e\u5df2\u77e5\u659c\u7387\u548cy\u8f74\u622a\u8ddd\uff09</li> </ol> \\[ y = kx + b \\] <ol> <li>\u4e24\u70b9\u5f0f\uff08\u7528\u4e8e\u5df2\u77e5\u4e24\u70b9\u5750\u6807\uff09</li> </ol> \\[ \\frac{x - x_1} {x_2 - x_1} = \\frac{y - y_1} {y_2 - y_1} \\] <ol> <li>\u622a\u8ddd\u5f0f\uff08\u7528\u4e8e\u5df2\u77e5\u6240\u6709\u622a\u8ddd\uff09</li> </ol> \\[ \\frac{x}{a} + \\frac{y}{b} = 1 \\] <p>\u6211\u4eec\u8fd9\u91cc\u5bf9\u591a\u8fb9\u5f62\u8fb9\u7684\u7ebf\u6bb5\u63cf\u8ff0\u91c7\u7528\u4e24\u70b9\u5f0f\u65b9\u7a0b\uff0c\u5047\u8bbe\u6d4b\u8bd5\u70b9\u5750\u6807\u4e3a \\((x_p, y_p)\\) \uff0c\u505a\u76f4\u7ebf \\(y = y_p\\) \u4ee3\u8868\u4ece\u4ea4\u70b9\u5f15\u51fa\u7684\u5c04\u7ebf\u3002</p> <p>\u5047\u8bbe\u7ebf\u6bb5\u4e24\u4e2a\u7aef\u70b9\u5206\u522b\u4e3a \\((x_1, y_1)\\) \uff0c \\((x_2, y_2)\\) \uff0c \\(y_1 &lt; y_2\\) \u3002\u5982\u679c\u76f4\u7ebf \\(y=y_p\\) \u4e0e\u8be5\u7ebf\u6bb5\u76f8\u4ea4\uff0c\u5219\u6ee1\u8db3</p> \\[ y_1 \\le y_p \\le y_2 \\] <p>\u518d\u52a0\u4e0a\u5c04\u7ebf\u7ea6\u675f\u6761\u4ef6\uff0c\u5047\u5b9a\u6211\u4eec\u7684\u5c04\u7ebf\u53d6\u76f4\u7ebf\u7684\u5de6\u4fa7\uff0c\u5219\u5c04\u7ebf\u65b9\u7a0b\u4e3a</p> \\[ \\begin{align*} &amp; y = y_p \\\\ &amp; x &lt;= x_p \\end{align*} \\] <p>\u5219\u7ebf\u6bb5\u5982\u679c\u4e0e\u8be5\u5c04\u7ebf\u76f8\u4ea4\uff0c\u8fd8\u9700\u8981\u6ee1\u8db3</p> \\[ \\min(x_1, x_2) &lt;= x_p \\] <p>\u518d\u52a0\u4e0a\u60c5\u51b5\u56db\u7684\u9650\u5236\u6761\u4ef6\uff0c\u4fee\u6b63\u76f8\u4ea4\u9650\u5236\u6761\u4ef6\u4e3a</p> \\[ \\begin{align*} &amp; y_1 \\lt y_p \\le y_2 \\\\ &amp; \\min(x_1, x_2) &lt;= x_p \\end{align*} \\] <p>\u6b64\u5916\uff0c\u5c06 \\(y=y_p\\) \u5e26\u5165\u7ebf\u6bb5\u65b9\u7a0b\u540e\uff0c\u6c42\u5f97\u7684x\u503c\u8981\u5c0f\u4e8e \\(x_p\\) \uff0c\u5373\u8be5\u4ea4\u70b9\u9700\u8981\u4f4d\u4e8e\u8be5\u5c04\u7ebf\u4e0a\uff0c\u516c\u5f0f\u5982\u4e0b</p> \\[ \\frac{y_p - y_1} {y_2 - y_1} (x_2 - x_1) + x_1 &lt; x_p \\] <p>\u4e0d\u52a0\u7b49\u4e8e\u53f7\uff0c\u662f\u4e3a\u4e86\u6392\u9664\u6d4b\u8bd5\u70b9\u5728\u7ebf\u6bb5\u4e0a\u7684\u60c5\u51b5\u3002</p> <p>\u4ee3\u7801\u5b9e\u73b0\u5982\u4e0b</p> <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\nfrom typing import List\n\n\nclass RotatedBox:\n\n    def __init__(self, x, y, w, h, theta):\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        self.theta = theta\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n    def __sub__(self, other: 'Point'):\n        return Point(self.x - other.x, self.y - other.y)\n\n    def __mul__(self, other_scaler):\n        return Point(self.x * other_scaler, self.y * other_scaler)\n\n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n    __repr__ = __str__\n\n\nclass Line:\n\n    def __init__(self, start_point:Point, end_point:Point):\n        self.start_point:Point = start_point\n        self.end_point:Point = end_point\n\n    def get_vector_point(self):\n        return Point(self.end_point.x - self.start_point.x, self.end_point.y - self.start_point.y)\n\n\ndef in_polygon(lines: List[Line], point: Point):\n\n    odd_nodes = False\n\n    x = point.x\n    y = point.y\n\n    for line in lines:\n        y1 = line.start_point.y\n        y2 = line.end_point.y\n        x1 = line.start_point.x\n        x2 = line.end_point.x\n        if ((y1 &lt; y &lt;= y2) or (y2 &lt; y &lt;= y1)) and min(x1, x2) &lt;= x:\n            x_pred = (y - y1) / (y2 - y1) * (x2 - x1) + x1\n            if x_pred &lt; x:\n                odd_nodes = not odd_nodes\n\n    return odd_nodes\n\n\ndef main():\n\n    x = -5\n    y = -5\n    w = 15\n    h = 20\n    theta = 45\n    theta = theta / 180 * math.pi\n    det_box = RotatedBox(x, y, w, h, theta)\n\n    points = [Point(0, 0) for _ in range(4)]\n    cos_theta = math.cos(theta) * 0.5\n    sin_theta = math.sin(theta) * 0.5\n\n    points[0].x = det_box.x + sin_theta * det_box.h + cos_theta * det_box.w\n    points[0].y = det_box.y + cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[1].x = det_box.x - sin_theta * det_box.h + cos_theta * det_box.w\n    points[1].y = det_box.y - cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[2].x = 2 * det_box.x - points[0].x\n    points[2].y = 2 * det_box.y - points[0].y\n\n    points[3].x = 2 * det_box.x - points[1].x\n    points[3].y = 2 * det_box.y - points[1].y\n\n    points_1 = points + points[0:1]\n    lines = [Line(points_1[i], points_1[i+1]) for i in range(4)]\n\n    fig, ax = plt.subplots()\n    fig.set_figheight(6)\n    fig.set_figwidth(6)\n    # \u7ed8\u5236\u77e9\u5f62\n\n    # \u7ed5 center (x,y) \u65cb\u8f6c45\u5ea6\n    polygon = mptch.Polygon(xy=[(points[i].x, points[i].y) for i in range(4)], closed=True, color=\"red\", fill=False)\n    ax.add_patch(polygon)\n    np.random.seed(20)\n    test_points = [Point(np.random.uniform(-30, 30), np.random.uniform(-30, 30)) for i in range(30)]\n    for test_point in test_points:\n\n        if in_polygon(lines, test_point):\n            print(f'{test_point} \u5728\u591a\u8fb9\u5f62\u4e2d')\n            plt.scatter(test_point.x, test_point.y, color=\"red\")\n        else:\n            print(f'{test_point} \u4e0d\u5728\u591a\u8fb9\u5f62\u4e2d')\n            plt.scatter(test_point.x, test_point.y, color=\"blue\")\n\n    # \u8bbe\u7f6e\u5750\u6807\u8f74\n    ax.set_xlim(-30, 30)\n    ax.set_ylim(-30, 30)\n    # \u5b9a\u4e49\u5750\u6807\n    x = np.arange(-30, 31, 5)\n    y = np.arange(-30, 31, 5)\n    ax.set_xticks(x)\n    ax.set_yticks(y)\n    ax.grid(True)\n    # \u663e\u793a\u56fe\u8c61\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u53ef\u89c6\u5316\u7ed3\u679c\u5982\u4e0b</p> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#_4","title":"\u56db\u3001\u51f8\u5305\u7b97\u6cd5","text":""},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#41","title":"4.1 \u6c42\u53d6\u51f8\u56db\u8fb9\u5f62\u76f8\u4ea4\u540e\u7684\u591a\u8fb9\u5f62\u7684\u89d2\u70b9","text":"<p>\u6211\u4eec\u5c06\u4e24\u4e2a\u51f8\u56db\u8fb9\u5f62\u7684\u56db\u4e2a\u70b9\u6309\u7167\u987a\u5e8f\u6392\u5217\uff0c\u7136\u540e\u5199\u4e00\u4e2a\u4e24\u91cd\u5faa\u73af\uff0c\u5206\u522b\u53d6\u51f8\u56db\u8fb9\u5f62A\u4e2d\u7684\u8fb9\u548c\u51f8\u56db\u8fb9\u5f62B\u4e2d\u7684\u8fb9\u6765\u8ba1\u7b97\u4ea4\u70b9\u4ea4\u70b9\uff0c\u6700\u7ec8\u62ff\u5230\u7684\u4ea4\u70b9\u7684\u96c6\u5408\u518d\u52a0\u4e0a\u4e24\u4e2a\u56db\u8fb9\u5f62\u89d2\u70b9\u5728\u53e6\u5916\u4e00\u4e2a\u56db\u8fb9\u5f62\u533a\u57df\u5185\u7684\u89d2\u70b9\u96c6\u5408 \u5373\u4e3a\u4e24\u4e2a\u51f8\u56db\u8fb9\u5f62\u76f8\u4ea4\u540e\u591a\u8fb9\u5f62\u7684\u6240\u6709\u7684\u70b9\u3002</p> <p>\u4e0b\u56fe\u8282\u9009\u81eaRRPN\u6587\u7ae0</p> <p></p> <p>\u4ee3\u7801\u5373\u4e3a\u6574\u5408\u524d\u4e24\u7ae0\u7684\u5185\u5bb9</p> <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\nfrom typing import List\nimport math\n\n\nclass RotatedBox:\n\n    def __init__(self, x, y, w, h, theta):\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        self.theta = theta\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n    def __sub__(self, other: 'Point'):\n        return Point(self.x - other.x, self.y - other.y)\n\n    def __mul__(self, other_scaler):\n        return Point(self.x * other_scaler, self.y * other_scaler)\n\n    def __truediv__(self, other_scaler):\n        return Point(self.x / other_scaler, self.y / other_scaler)\n\n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n    __repr__ = __str__\n\n\nclass Line:\n\n    def __init__(self, start_point, end_point):\n        self.start_point = start_point\n        self.end_point = end_point\n\n    def get_vector_point(self):\n        return Point(self.end_point.x - self.start_point.x, self.end_point.y - self.start_point.y)\n\n\ndef cross2d(A: Point, B: Point):\n    return A.x * B.y - B.x * A.y\n\n\ndef get_intersection_points(line1: Line, line2: Line):\n\n    line1_vec = line1.get_vector_point()\n    line2_vec = line2.get_vector_point()\n\n    det_value = cross2d(line2_vec, line1_vec)\n\n    if abs(det_value) &lt; 1e-14:\n        return False, Point(0, 0)\n\n    ac_line_vec = line2.start_point - line1.start_point\n\n    t = cross2d(line2_vec, ac_line_vec) / det_value\n    u = cross2d(line1_vec, ac_line_vec) / det_value\n\n    eps = 1e-14\n\n    if -eps &lt;= t &lt;= 1.0 + eps and -eps &lt;= u &lt;= 1.0 + eps:\n        return True, line1.start_point + line1_vec * t\n\n    return False, Point(0, 0)\n\n\ndef in_polygon(lines: List[Line], point: Point):\n\n    odd_nodes = False\n\n    x = point.x\n    y = point.y\n\n    for line in lines:\n        y1 = line.start_point.y\n        y2 = line.end_point.y\n        x1 = line.start_point.x\n        x2 = line.end_point.x\n        if ((y1 &lt; y &lt;= y2) or (y2 &lt; y &lt;= y1)) and min(x1, x2) &lt;= x:\n            x_pred = (y - y1) / (y2 - y1) * (x2 - x1) + x1\n            print(y, x, x_pred, x1, y1, x2, y2)\n            if x_pred &lt; x:\n                odd_nodes = not odd_nodes\n\n    return odd_nodes\n\n\ndef main():\n\n    x = -5\n    y = -5\n    w = 15\n    h = 20\n    theta = 45\n    theta = theta / 180 * math.pi\n    det_box = RotatedBox(x, y, w, h, theta)\n\n    points = [Point(0, 0) for _ in range(4)]\n    cos_theta = math.cos(theta) * 0.5\n    sin_theta = math.sin(theta) * 0.5\n\n    points[0].x = det_box.x + sin_theta * det_box.h + cos_theta * det_box.w\n    points[0].y = det_box.y + cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[1].x = det_box.x - sin_theta * det_box.h + cos_theta * det_box.w\n    points[1].y = det_box.y - cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[2].x = 2 * det_box.x - points[0].x\n    points[2].y = 2 * det_box.y - points[0].y\n\n    points[3].x = 2 * det_box.x - points[1].x\n    points[3].y = 2 * det_box.y - points[1].y\n\n\n\n    x1 = x - w / 2\n    y1 = y - h / 2\n\n    x2 = x + w / 2\n    y2 = y - h / 2\n\n    x3 = x + w / 2\n    y3 = y + h / 2\n\n    x4 = x - w / 2\n    y4 = y + h / 2\n\n    # \u5224\u65ad \u5404\u4e2a\u76f4\u7ebf\u4e4b\u95f4\u662f\u5426\u6709\u4ea4\u70b9\n    A = Point(x1, y1)\n    B = Point(x2, y2)\n    C = Point(x3, y3)\n    D = Point(x4, y4)\n\n    points_1 = points + points[0:1]\n    points_2 = [A, B, C, D] + [A]\n    print('points_2', points_2)\n\n    fig, ax = plt.subplots()\n    fig.set_figheight(6)\n    fig.set_figwidth(6)\n\n    # \u7ed8\u5236\u77e9\u5f62\n    # \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5de6\u4e0b\u89d2\u5750\u6807 \u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3awidth \u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3aheight\n    x_center, y_center, width, height = det_box.x, det_box.y, det_box.w, det_box.h\n    x1 = x_center - det_box.w / 2\n    y1 = y_center - det_box.h / 2\n    x2 = x_center + det_box.w / 2\n    y2 = y_center + det_box.h / 2\n\n    rect = plt.Rectangle((x1, y1), det_box.w, det_box.h, angle=0, fill=False, color=\"blue\")\n    ax.add_patch(rect)\n\n    # \u7ed5 center (x,y) \u65cb\u8f6c45\u5ea6\n    polygon = mptch.Polygon(xy=[(points[i].x, points[i].y) for i in range(4)], closed=True, color=\"red\", fill=False)\n    ax.add_patch(polygon)\n\n    insection_points = []\n\n    for i in range(4):\n        for j in range(4):\n            line1 = points_1[i:i+2]\n            line2 = points_2[j:j+2]\n\n            is_intersect, intersection_point = get_intersection_points(Line(line1[0], line1[1]), Line(line2[0], line2[1]))\n\n            if is_intersect:\n                plt.scatter(intersection_point.x, intersection_point.y)\n                insection_points.append(intersection_point)\n\n    lines_1 = [Line(points_1[i], points_1[i+1]) for i in range(4)]\n    lines_2 = [Line(points_2[i], points_2[i+1]) for i in range(4)]\n\n    for i in range(4):\n        point = points_1[i]\n        if in_polygon(lines_2, point):\n            print(f'{point} \u5728\u591a\u8fb9\u5f62\u4e2d')\n            insection_points.append(point)\n        else:\n            print(f'{point} \u4e0d\u5728\u591a\u8fb9\u5f62\u4e2d')\n\n    for i in range(4):\n        point = points_2[i]\n        if in_polygon(lines_1, point):\n            print(f'{point} \u5728\u591a\u8fb9\u5f62\u4e2d')\n            insection_points.append(point)\n        else:\n            print(f'{point} \u4e0d\u5728\u591a\u8fb9\u5f62\u4e2d')\n\n\n    center_point = Point(0, 0)\n    for point in insection_points:\n        center_point += point\n    center_point /= len(insection_points)\n\n    vectors = [point - center_point for point in insection_points]\n    vectors_degree = [math.atan2(vector.y, vector.x) for vector in vectors]\n    vectors = list(zip(vectors, insection_points, vectors_degree))\n    vectors.sort(key=lambda x: x[-1])\n\n    for i, (_, point, _) in enumerate(vectors):\n        plt.scatter(point.x, point.y, color=\"red\")\n        plt.text(point.x, point.y, f'{i}')\n\n    # \u8bbe\u7f6e\u5750\u6807\u8f74\n    ax.set_xlim(-30, 30)\n    ax.set_ylim(-30, 30)\n    # \u5b9a\u4e49\u5750\u6807\n    x = np.arange(-30, 31, 5)\n    y = np.arange(-30, 31, 5)\n    ax.set_xticks(x)\n    ax.set_yticks(y)\n    ax.grid(True)\n    # \u663e\u793a\u56fe\u8c61\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u53ef\u89c6\u5316\u7ed3\u679c\u5982\u4e0b\uff1a</p> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#42","title":"4.2 \u6784\u9020\u70b9\u96c6\u6784\u9020\u51f8\u591a\u8fb9\u5f62","text":"<p>\u62ff\u5230\u5185\u51f8\u591a\u8fb9\u5f62\u7684\u6240\u6709\u70b9\u540e\uff0c\u6211\u4eec\u9700\u8981\u9488\u5bf9\u8fd9\u4e9b\u70b9\u6309\u7167\u987a\u65f6\u9488\u6216\u8005\u9006\u65f6\u9488\u7684\u987a\u5e8f\u505a\u4e00\u4e2a\u6392\u5e8f\u3002</p> <p>\u6839\u636e\u524d\u9762\u7684\u4ecb\u7ecd\uff0c\u6574\u7406\u987a\u5e8f\u53ef\u4ee5\u76f4\u63a5\u60f3\u5230\u7684\u601d\u8def\u662f\u6c42\u53d6\u4e2d\u5fc3\u70b9\uff0c\u7136\u540e\u8ba1\u7b97\u4e2d\u5fc3\u70b9\u6307\u5411\u6bcf\u4e2a\u89d2\u70b9\u7684\u5411\u91cf\uff0c\u56fa\u5b9a\u5176\u4e2d\u67d0\u4e00\u4e2a\u5411\u91cf\uff0c\u6309\u7167\u5411\u91cf\u95f4\u987a\u65f6\u9488\u89d2\u5ea6\u6216\u8005\u9006\u65f6\u9488\u89d2\u5ea6\u8fdb\u884c\u6392\u5e8f\u3002</p> <p>\u6b64\u65f6\u6211\u4eec\u53ef\u4ee5\u6309\u7167\u524d\u9762\u8bf4\u7684\u53c9\u4e58\u6765\u5224\u65ad\u4e24\u4e2a\u5411\u91cf\u7684\u65cb\u5411\u987a\u5e8f\uff0c\u4e0d\u8fc7\u8fd9\u4e2a\u65f6\u5019\u6211\u60f3\u4ecb\u7ecd\u53e6\u5916\u4e00\u79cd\u65b9\u6cd5\uff0c\u8fd9\u662f\u6211\u5728\u5546\u6c64\u5b9e\u4e60\u7684\u65f6\u5019\u60f3\u51fa\u6765\u7684\uff0c\u5373\u5411\u91cf\u4e4b\u95f4\u7684\u5939\u89d2\u91c7\u7528\u65b9\u4f4d\u89d2\u6765\u8868\u793a\u3002</p> <p>\u7f16\u7a0b\u4e2d\u6709\u4e00\u4e2a\u4e0e\u4e4b\u5bf9\u5e94\u7684<code>atan2</code>\u51fd\u6570</p> <p></p> <p><code>atan2</code>\u51fd\u6570\u8fd4\u56de\u7684\u662f\u539f\u70b9\u81f3\u70b9(x, y)\u7684\u65b9\u4f4d\u89d2\uff0c\u5373\u4e0ex\u8f74\u7684\u5939\u89d2\uff0c\u5355\u4f4d\u662f\u5f27\u5ea6\uff0c\u8303\u56f4 \\([-\\pi, \\pi]\\) </p> <ol> <li>y = x = 0 \u53d6\u503c\u8303\u56f4\u4e3a\u5e38\u65700</li> <li>y = 0, x &gt; 0 \u53d6\u503c\u8303\u56f4\u4e3a\u5e38\u65700</li> <li>x &gt; 0, y &gt; 0 \u53d6\u503c\u8303\u56f4 \\((0, \\frac{\\pi}{2})\\)</li> <li>x = 0, y &gt; 0 \u53d6\u503c\u8303\u56f4\u4e3a\u5e38\u6570 \\(\\frac{\\pi}{2}\\)</li> <li>x &lt; 0, y &gt; 0 \u53d6\u503c\u8303\u56f4\u4e3a \\((\\frac{\\pi}{2}, \\pi)\\)</li> <li>y = 0, x &lt; 0 \u53d6\u503c\u8303\u56f4\u4e3a\u5e38\u6570 \\(\\pi\\)</li> <li>x &lt; 0, y &lt; 0 \u53d6\u503c\u8303\u56f4\u4e3a \\((-\\pi, -\\frac{\\pi}{2})\\)</li> <li>x = 0, y &lt; 0 \u53d6\u503c\u8303\u56f4\u4e3a\u5e38\u6570 \\(\\frac{\\pi}{2}\\)</li> <li>x &gt; 0 y &lt; 0 \u53d6\u503c\u8303\u56f4\u4e3a \\((\\frac{\\pi}{2}, 0)\\)</li> </ol> <p>\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u8be5\u51fd\u6570\u6c42\u5f97\u6bcf\u4e2a\u5411\u91cf\u4e0ex\u8f74\u7684\u65b9\u5411\u89d2\uff0c\u7136\u540e\u6309\u7167\u65b9\u5411\u89d2\u8fdb\u884c\u6392\u5e8f\u3002</p> <p>\u5b9e\u73b0\u4ee3\u7801</p> <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\nfrom typing import List\nimport math\n\n\nclass RotatedBox:\n\n    def __init__(self, x, y, w, h, theta):\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        self.theta = theta\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n    def __sub__(self, other: 'Point'):\n        return Point(self.x - other.x, self.y - other.y)\n\n    def __mul__(self, other_scaler):\n        return Point(self.x * other_scaler, self.y * other_scaler)\n\n    def __truediv__(self, other_scaler):\n        return Point(self.x / other_scaler, self.y / other_scaler)\n\n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n    __repr__ = __str__\n\n\nclass Line:\n\n    def __init__(self, start_point, end_point):\n        self.start_point = start_point\n        self.end_point = end_point\n\n    def get_vector_point(self):\n        return Point(self.end_point.x - self.start_point.x, self.end_point.y - self.start_point.y)\n\n\ndef cross2d(A: Point, B: Point):\n    return A.x * B.y - B.x * A.y\n\n\ndef get_intersection_points(line1: Line, line2: Line):\n\n    line1_vec = line1.get_vector_point()\n    line2_vec = line2.get_vector_point()\n    det_value = cross2d(line1_vec, line2_vec)\n\n    if abs(det_value) &lt; 1e-14:\n        return False, Point(0, 0)\n\n    ac_line_vec = line2.end_point - line1.start_point\n\n    t = abs(cross2d(line2_vec, ac_line_vec)) / abs(det_value)\n    u = abs(cross2d(line1_vec, ac_line_vec)) / abs(det_value)\n\n    eps = 1e-14\n\n    if -eps &lt;= t &lt;= 1.0 + eps and -eps &lt;= u &lt;= 1.0 + eps:\n        return True, line1.start_point + line1_vec * t\n\n    return False, Point(0, 0)\n\n\ndef in_polygon(lines: List[Line], point: Point):\n\n    odd_nodes = False\n\n    x = point.x\n    y = point.y\n\n    for line in lines:\n        y1 = line.start_point.y\n        y2 = line.end_point.y\n        x1 = line.start_point.x\n        x2 = line.end_point.x\n        if ((y1 &lt; y &lt;= y2) or (y2 &lt; y &lt;= y1)) and min(x1, x2) &lt;= x:\n            x_pred = (y - y1) / (y2 - y1) * (x2 - x1) + x1\n            print(y, x, x_pred, x1, y1, x2, y2)\n            if x_pred &lt; x:\n                odd_nodes = not odd_nodes\n\n    return odd_nodes\n\n\ndef main():\n\n    x = -5\n    y = -5\n    w = 15\n    h = 20\n    theta = 45\n    theta = theta / 180 * math.pi\n    det_box = RotatedBox(x, y, w, h, theta)\n\n    points = [Point(0, 0) for _ in range(4)]\n    cos_theta = math.cos(theta) * 0.5\n    sin_theta = math.sin(theta) * 0.5\n\n    points[0].x = det_box.x + sin_theta * det_box.h + cos_theta * det_box.w\n    points[0].y = det_box.y + cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[1].x = det_box.x - sin_theta * det_box.h + cos_theta * det_box.w\n    points[1].y = det_box.y - cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[2].x = 2 * det_box.x - points[0].x\n    points[2].y = 2 * det_box.y - points[0].y\n\n    points[3].x = 2 * det_box.x - points[1].x\n    points[3].y = 2 * det_box.y - points[1].y\n\n\n\n    x1 = x - w / 2\n    y1 = y - h / 2\n\n    x2 = x + w / 2\n    y2 = y - h / 2\n\n    x3 = x + w / 2\n    y3 = y + h / 2\n\n    x4 = x - w / 2\n    y4 = y + h / 2\n\n    # \u5224\u65ad \u5404\u4e2a\u76f4\u7ebf\u4e4b\u95f4\u662f\u5426\u6709\u4ea4\u70b9\n    A = Point(x1, y1)\n    B = Point(x2, y2)\n    C = Point(x3, y3)\n    D = Point(x4, y4)\n\n    points_1 = points + points[0:1]\n    points_2 = [A, B, C, D] + [A]\n    print('points_2', points_2)\n\n    fig, ax = plt.subplots()\n    fig.set_figheight(6)\n    fig.set_figwidth(6)\n\n    # \u7ed8\u5236\u77e9\u5f62\n    # \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5de6\u4e0b\u89d2\u5750\u6807 \u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3awidth \u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3aheight\n    x_center, y_center, width, height = det_box.x, det_box.y, det_box.w, det_box.h\n    x1 = x_center - det_box.w / 2\n    y1 = y_center - det_box.h / 2\n    x2 = x_center + det_box.w / 2\n    y2 = y_center + det_box.h / 2\n\n    rect = plt.Rectangle((x1, y1), det_box.w, det_box.h, angle=0, fill=False, color=\"blue\")\n    ax.add_patch(rect)\n\n    # \u7ed5 center (x,y) \u65cb\u8f6c45\u5ea6\n    polygon = mptch.Polygon(xy=[(points[i].x, points[i].y) for i in range(4)], closed=True, color=\"red\", fill=False)\n    ax.add_patch(polygon)\n\n    insection_points = []\n\n    for i in range(4):\n        for j in range(4):\n            line1 = points_1[i:i+2]\n            line2 = points_2[j:j+2]\n\n            is_intersect, intersection_point = get_intersection_points(Line(line1[0], line1[1]), Line(line2[0], line2[1]))\n\n            if is_intersect:\n                plt.scatter(intersection_point.x, intersection_point.y)\n                insection_points.append(intersection_point)\n\n    lines_1 = [Line(points_1[i], points_1[i+1]) for i in range(4)]\n    lines_2 = [Line(points_2[i], points_2[i+1]) for i in range(4)]\n\n    for i in range(4):\n        point = points_1[i]\n        if in_polygon(lines_2, point):\n            print(f'{point} \u5728\u591a\u8fb9\u5f62\u4e2d')\n            insection_points.append(point)\n        else:\n            print(f'{point} \u4e0d\u5728\u591a\u8fb9\u5f62\u4e2d')\n\n    for i in range(4):\n        point = points_2[i]\n        if in_polygon(lines_1, point):\n            print(f'{point} \u5728\u591a\u8fb9\u5f62\u4e2d')\n            insection_points.append(point)\n        else:\n            print(f'{point} \u4e0d\u5728\u591a\u8fb9\u5f62\u4e2d')\n\n\n    center_point = Point(0, 0)\n    for point in insection_points:\n        center_point += point\n    center_point /= len(insection_points)\n\n    vectors = [point - center_point for point in insection_points]\n    vectors_degree = [math.atan2(vector.y, vector.x) for vector in vectors]\n    vectors = list(zip(vectors, insection_points, vectors_degree))\n    vectors.sort(key=lambda x: x[-1])\n\n    for i, (_, point, _) in enumerate(vectors):\n        plt.scatter(point.x, point.y, color=\"red\")\n        plt.text(point.x, point.y, f'{i}')\n\n    # \u8bbe\u7f6e\u5750\u6807\u8f74\n    ax.set_xlim(-30, 30)\n    ax.set_ylim(-30, 30)\n    # \u5b9a\u4e49\u5750\u6807\n    x = np.arange(-30, 31, 5)\n    y = np.arange(-30, 31, 5)\n    ax.set_xticks(x)\n    ax.set_yticks(y)\n    ax.grid(True)\n    # \u663e\u793a\u56fe\u8c61\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u53ef\u89c6\u5316\u7ed3\u679c</p> <p></p> <p>\u4e0a\u9762\u57fa\u4e8e\u4e00\u4e2a\u5047\u8bbe\uff0c\u5373\u4ea4\u70b9\u96c6\u5408\u4e2d\u7684\u70b9\u90fd\u4e3a\u591a\u8fb9\u5f62\u7684\u70b9\uff0c\u5b9e\u9645\u4e24\u4e2a\u591a\u8fb9\u5f62\u76f8\u4ea4\u65f6\uff0c\u6709\u53ef\u80fd\u4e00\u4e9b\u70b9\u5b58\u5728\u4e8e\u591a\u8fb9\u5f62\u533a\u57df\u7684\u5185\u90e8\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u9700\u8981\u627e\u5230\u8fd9\u4e9b\u70b9\u4e2d\u7684\u5b50\u96c6\u53ef\u4ee5\u5305\u7edc\u8fd9\u4e9b\u70b9\u3002</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u9488\u5bf9\u51f8\u56db\u8fb9\u5f62\u76f8\u4ea4\u7684\u60c5\u51b5\uff0c\u91c7\u7528\u4e0a\u8ff0\u6392\u5e8f\u7b97\u6cd5\u505a\u597d\u6392\u5e8f\u5c31\u591f\u4e86\u3002</p> <p>\u5728\u51f8\u5305\u7b97\u6cd5\u4e2d\uff0c\u8fd9\u91c7\u7528Graham\uff08\u683c\u62c9\u7ff0\uff09\u626b\u63cf\u6cd5</p> <p>\u7b97\u6cd5\u6b65\u9aa4\uff1a</p> <ol> <li>\u5148\u627e\u51fay\u503c\u6700\u5c0f\u7684\u70b9\uff0c\u5982\u679c\u5b58\u5728y\u503c\u76f8\u7b49\uff0c\u5219\u4f18\u5148\u9009\u62e9x\u503c\u6700\u5c0f\u7684\u4f5c\u4e3a\u8d77\u59cb\u70b9 \\(P_0\\) \uff0c\u8be5\u70b9\u4e00\u5b9a\u5904\u4e8e\u51f8\u5305\u4e0a</li> <li>\u4ee5 \\(P_0\\) \u4f5c\u4e3a\u539f\u70b9\uff0c\u5176\u4ed6\u6240\u6709\u70b9\u51cf\u53bb \\(P_0\\) \u5f97\u5230\u5bf9\u5e94\u7684\u5411\u91cf</li> </ol> <p></p> <ol> <li>\u8ba1\u7b97\u6240\u6709\u5411\u91cf\u4e0e \\(X\\) \u8f74\u6b63\u5411\u7684\u5939\u89d2 \\(\\alpha\\) \uff0c\u6309\u4ece\u5c0f\u5230\u5927\u8fdb\u884c\u6392\u5217\uff0c\u9047\u5230 \\(\\alpha\\) \u76f8\u540c\u7684\u60c5\u51b5\uff0c\u5219\u5411\u91cf\u8f83\u77ed\uff08\u5373\u79bb \\(P_0\\) \u8f83\u8fd1\u7684\u70b9\uff09\u7684\u6392\u5728\u524d\u9762\uff0c\u5f97\u5230\u521d\u59cb\u70b9\u5e8f \\(P_1,P_2, ..., P_n\\) \uff0c\u7531\u51e0\u4f55\u5173\u7cfb\u53ef\u77e5\u70b9\u5e8f\u4e2d\u7b2c\u4e00\u4e2a\u70b9 \\(P_1\\) \u548c\u6700\u540e\u4e00\u4e2a\u70b9 \\(P_n\\) \u4e00\u5b9a\u5728\u51f8\u5305\u4e0a\uff1b</li> <li>\u5c06 \\(P_0\\) \u548c \\(P_1\\) \u538b\u5165\u6808\u4e2d\uff0c\u5c06\u540e\u7eed\u70b9 \\(P_2\\) \u4f5c\u4e3a\u5f53\u524d\u70b9\uff0c\u8df3\u8f6c\u7b2c8\u6b65\u3002</li> <li>\u6808\u4e2d\u6700\u4e0a\u9762\u4e24\u4e2a\u5143\u7d20\u5f62\u6210\u5411\u91cf \\(P_{ij}, i &lt; j\\) \uff0c \u5229\u7528\u53c9\u4e58\u5224\u65ad\u5f53\u524d\u70b9\u662f\u5426\u5728\u8be5\u5411\u91cf\u7684\u5de6\u8fb9\u8fd8\u662f\u53f3\u8fb9\u6216\u8005\u5411\u91cf\u4e0a</li> <li>\u5982\u679c\u5728\u5de6\u8fb9\u6216\u8005\u5411\u91cf\u4e0a\uff0c\u5219\u5c06\u5f53\u524d\u70b9\u538b\u5165\u6808\u4e2d\uff0c\u4e0b\u4e00\u4e2a\u70b9\u4f5c\u4e3a\u5f53\u524d\u70b9\uff0c\u8df3\u8f6c\u7b2c8\u6b65</li> <li>\u5982\u679c\u5f53\u524d\u70b9\u5728\u5411\u91cf\u53f3\u8fb9\uff0c\u5219\u8868\u660e\u6808\u9876\u5143\u7d20\u4e0d\u5728\u51f8\u5305\u4e0a\uff0c\u5c06\u6808\u9876\u5143\u7d20\u5f39\u51fa\uff0c\u8df3\u8f6c\u7b2c5\u6b65</li> <li>\u5224\u65ad\u5f53\u524d\u70b9\u662f\u5426\u662f\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u5982\u679c\u662f\u5219\u5c06\u5176\u538b\u7f29\u6808\u4e2d\uff0c\u6808\u4e2d\u6240\u6709\u5143\u7d20\u5373\u662f\u51f8\u5305\u4e0a\u6240\u6709\u70b9\uff0c\u7b97\u6cd5\u7ed3\u675f\uff0c\u5426\u5219\u8df3\u5230\u7b2c5\u6b65\u3002</li> </ol> <p>\u4ee3\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\nfrom typing import List\nimport math\nfrom copy import deepcopy\n\n\nclass RotatedBox:\n\n    def __init__(self, x, y, w, h, theta):\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        self.theta = theta\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n    def __sub__(self, other: 'Point'):\n        return Point(self.x - other.x, self.y - other.y)\n\n    def __mul__(self, other_scaler):\n        return Point(self.x * other_scaler, self.y * other_scaler)\n\n    def __truediv__(self, other_scaler):\n        return Point(self.x / other_scaler, self.y / other_scaler)\n\n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n    __repr__ = __str__\n\n\nclass Line:\n\n    def __init__(self, start_point, end_point):\n        self.start_point = start_point\n        self.end_point = end_point\n\n    def get_vector_point(self):\n        return Point(self.end_point.x - self.start_point.x, self.end_point.y - self.start_point.y)\n\n\ndef cross2d(A: Point, B: Point):\n    return A.x * B.y - B.x * A.y\n\ndef dot2d(A: Point, B: Point):\n    return A.x * B.x + A.y * B.y\n\n\ndef convex_hull_graham(points: List[Point]):\n\n    ret_points = []\n\n    copy_points = deepcopy(points)\n    # 1. \u5148\u627e\u51fay\u503c\u6700\u5c0f\u7684\u70b9\uff0c\u5982\u679c\u5b58\u5728y\u503c\u76f8\u7b49\uff0c\u5219\u4f18\u5148\u9009\u62e9x\u503c\u6700\u5c0f\u7684\u4f5c\u4e3a\u8d77\u59cb\u70b9$P_0$\uff0c\u8be5\u70b9\u4e00\u5b9a\u5904\u4e8e\u51f8\u5305\u4e0a\n    copy_points.sort(key=lambda point:(point.y, point.x))\n\n    start_point = copy_points[0]\n\n\n    # 2. \u4ee5$P_0$\u4f5c\u4e3a\u539f\u70b9\uff0c\u5176\u4ed6\u6240\u6709\u70b9\u51cf\u53bb$P_0$\u5f97\u5230\u5bf9\u5e94\u7684\u5411\u91cf\n    vectors = []\n    len_copy_point = len(copy_points)\n    for i in range(0, len_copy_point, 1):\n        vector = copy_points[i] - start_point\n        vectors.append(vector)\n\n    # 3. \u8ba1\u7b97\u6240\u6709\u5411\u91cf\u4e0e$X$\u8f74\u6b63\u5411\u7684\u5939\u89d2$\\alpha$\uff0c\u6309\u4ece\u5c0f\u5230\u5927\u8fdb\u884c\u6392\u5217\uff0c\n    # \u9047\u5230$\\alpha$\u76f8\u540c\u7684\u60c5\u51b5\uff0c\u5219\u5411\u91cf\u8f83\u77ed\uff08\u5373\u79bb$P_0$\u8f83\u8fd1\u7684\u70b9\uff09\u7684\u6392\u5728\u524d\u9762\uff0c\n    # \u5f97\u5230\u521d\u59cb\u70b9\u5e8f$P_1,P_2, ..., P_n$\uff0c\n    # \u7531\u51e0\u4f55\u5173\u7cfb\u53ef\u77e5\u70b9\u5e8f\u4e2d\u7b2c\u4e00\u4e2a\u70b9$P_1$\u548c\u6700\u540e\u4e00\u4e2a\u70b9$P_n$\u4e00\u5b9a\u5728\u51f8\u5305\u4e0a\uff1b\n    def cmp_function(point_a: Point):\n        # \u5148\u6839\u636e\u65b9\u4f4d\u89d2\uff0c\u65b9\u4f4d\u89d2\u76f8\u540c\u518d\u6839\u636e\u6a21\u957f\n        return math.atan2(point_a.y, point_a.x), dot2d(point_a, point_a)\n\n    vectors.sort(key=cmp_function)\n    dists = [dot2d(vector, vector) for vector in vectors]\n\n    # 4. \u5c06$P_0$\u548c$P_1$\u538b\u5165\u6808\u4e2d\uff0c\u5c06\u540e\u7eed\u70b9$P_2$\u4f5c\u4e3a\u5f53\u524d\u70b9\uff0c\u8df3\u8f6c\u7b2c8\u6b65\u3002\n    ret_points.append(vectors[0])\n    k = 1\n    while k &lt; len_copy_point:\n        if dists[k] &gt; 1e-8:\n            break\n        k += 1\n\n    if k &gt;= len_copy_point:\n        return ret_points\n\n    ret_points.append(vectors[k])\n\n    m = len(ret_points)\n\n    # 5.\u6808\u4e2d\u6700\u4e0a\u9762\u4e24\u4e2a\u5143\u7d20\u5f62\u6210\u5411\u91cf$P_{ij}, i &lt; j$\n    # \u5229\u7528\u53c9\u4e58\u5224\u65ad\u5f53\u524d\u70b9\u662f\u5426\u5728\u8be5\u5411\u91cf\u7684\u5de6\u8fb9\u8fd8\u662f\u53f3\u8fb9\u6216\u8005\u5411\u91cf\u4e0a\n    # 6. \u5982\u679c\u5728\u5de6\u8fb9\u6216\u8005\u5411\u91cf\u4e0a\uff0c\u5219\u5c06\u5f53\u524d\u70b9\u538b\u5165\u6808\u4e2d\uff0c\u4e0b\u4e00\u4e2a\u70b9\u4f5c\u4e3a\u5f53\u524d\u70b9\uff0c\u8df3\u8f6c\u7b2c8\u6b65\n    # 7. \u5982\u679c\u5f53\u524d\u70b9\u5728\u5411\u91cf\u53f3\u8fb9\uff0c\u5219\u8868\u660e\u6808\u9876\u5143\u7d20\u4e0d\u5728\u51f8\u5305\u4e0a\uff0c\u5c06\u6808\u9876\u5143\u7d20\u5f39\u51fa\uff0c\u8df3\u8f6c\u7b2c5\u6b65\n    # 8. \u5224\u65ad\u5f53\u524d\u70b9\u662f\u5426\u662f\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u5982\u679c\u662f\u5219\u5c06\u5176\u538b\u7f29\u6808\u4e2d\uff0c\u6808\u4e2d\u6240\u6709\u5143\u7d20\u5373\u662f\u51f8\u5305\u4e0a\u6240\u6709\u70b9\uff0c\u7b97\u6cd5\u7ed3\u675f\uff0c\u5426\u5219\u8df3\u5230\u7b2c5\u6b65\u3002\n    for i in range(k + 1, len_copy_point, 1):\n        while m &gt;= 2:\n            # \u67e5\u770b\u5f53\u524d\u70b9\u5728\u5411\u91cf\u5de6\u8fb9\u8fd8\u662f\u53f3\u8fb9\n            q1 = vectors[i] - ret_points[-2]\n            q2 = ret_points[-1] - ret_points[-2]\n            if q1.x * q2.y &gt;= q2.x * q1.y:\n                m -= 1\n                ret_points.pop()\n            else:\n                break\n\n        ret_points.append(vectors[i])\n        m = len(ret_points)\n\n    for point in ret_points:\n        point.x += start_point.x\n        point.y += start_point.y\n\n    return ret_points\n\n\n\ndef main():\n\n    fig, ax = plt.subplots()\n    fig.set_figheight(6)\n    fig.set_figwidth(6)\n\n    np.random.seed(10)\n\n    points = [Point(np.random.uniform(-30, 30), np.random.uniform(-30, 30)) for i in range(30)]\n\n    for i, point in enumerate(points):\n        plt.scatter(point.x, point.y, color=\"red\")\n        plt.text(point.x, point.y, f'{i}')\n\n    convex_hull_points = convex_hull_graham(points)\n\n    for i, point in enumerate(convex_hull_points):\n        plt.scatter(point.x, point.y, color=\"blue\")\n        # plt.text(point.x, point.y, f'{i}')\n\n    polygon = mptch.Polygon(xy=[(convex_hull_point.x, convex_hull_point.y) for convex_hull_point in convex_hull_points], closed=True, color=\"red\", fill=False)\n    ax.add_patch(polygon)\n\n    # \u8bbe\u7f6e\u5750\u6807\u8f74\n    ax.set_xlim(-30, 30)\n    ax.set_ylim(-30, 30)\n    # \u5b9a\u4e49\u5750\u6807\n    x = np.arange(-30, 31, 5)\n    y = np.arange(-30, 31, 5)\n    ax.set_xticks(x)\n    ax.set_yticks(y)\n    ax.grid(True)\n    # \u663e\u793a\u56fe\u8c61\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u53ef\u89c6\u5316\u7ed3\u679c</p> <p></p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#_5","title":"\u4e94\u3001\u8ba1\u7b97\u591a\u8fb9\u5f62\u9762\u79ef","text":"<p>\u5229\u7528\u5411\u91cf\u79ef\uff08\u53c9\u79ef\uff09\u8ba1\u7b97\u591a\u8fb9\u5f62\u7684\u9762\u79ef\uff0c\u8981\u6c42\u591a\u8fb9\u5f62\u6240\u6709\u70b9\u6309\u987a\u5e8f\u6392\u5217\u5373\u53ef\uff0c\u4e0d\u8981\u6c42\u975e\u5f97\u662f\u51f8\u591a\u8fb9\u5f62\u3002</p> <p>\u5177\u4f53\u8bc1\u660e\u8bf7\u770b\u53c2\u8003\u94fe\u63a5</p> <p>\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>def polygon_area(points):\n    copy_points = points + [points[0]]\n    lines = [Line(copy_points[i], copy_points[i + 1]) for i in range(len(copy_points))]\n\n    s_polygon = 0.0\n    for line in lines:\n        A, B = line.start_point, line.end_point\n        s_tri = cross2d(A, B)\n        s_polygon += s_tri\n    return abs(s_polygon / 2)\n</code></pre>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#iou_1","title":"\u516d\u3001IoU\u7684\u8ba1\u7b97","text":"<p>\u6211\u4eec\u524d\u9762\u94fa\u57ab\u4e86\u90a3\u4e48\u591a\uff0c\u7ec8\u4e8e\u5230\u4e86\u6574\u5408\u5168\u90e8\u65b9\u6848\u7684\u65f6\u523b\u4e86\u3002</p> <p>\u6c42iou\u53ef\u4ee5\u8f6c\u6362\u4e3a\u6c42\u53d6\u4e24\u4e2a\u56fe\u56db\u8fb9\u5f62\u7684\u9762\u79ef\uff0c\u548c\u76f8\u4ea4\u51f8\u591a\u8fb9\u5f62\u7684\u9762\u79ef\uff0c\u6211\u4eec\u9700\u8981\u505a\u7684\u5c31\u662f\u5c06\u4e0a\u9762\u7684\u65b9\u6848\u8fdb\u884c\u7ec4\u88c5\u3002\u6700\u7ec8\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mptch\nfrom typing import List\nimport math\nfrom copy import deepcopy\nimport cv2\n\n\nclass RotatedBox:\n\n    def __init__(self, x, y, w, h, theta):\n        self.x = x\n        self.y = y\n        self.w = w\n        self.h = h\n        self.theta = theta\n\n\nclass Point:\n\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: 'Point'):\n        return Point(other.x + self.x, other.y + self.y)\n\n    def __sub__(self, other: 'Point'):\n        return Point(self.x - other.x, self.y - other.y)\n\n    def __mul__(self, other_scaler):\n        return Point(self.x * other_scaler, self.y * other_scaler)\n\n    def __truediv__(self, other_scaler):\n        return Point(self.x / other_scaler, self.y / other_scaler)\n\n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n    __repr__ = __str__\n\n\nclass Line:\n\n    def __init__(self, start_point, end_point):\n        self.start_point = start_point\n        self.end_point = end_point\n\n    def get_vector_point(self):\n        return Point(self.end_point.x - self.start_point.x, self.end_point.y - self.start_point.y)\n\n    def __str__(self):\n        return f\"start_point: Point({self.start_point.x}, {self.start_point.y}), end_point:Point({self.end_point.x}, {self.end_point.y})\"\n\n\ndef cross2d(A: Point, B: Point):\n    return A.x * B.y - B.x * A.y\n\ndef dot2d(A: Point, B: Point):\n    return A.x * B.x + A.y * B.y\n\ndef get_intersection_points(line1: Line, line2: Line):\n\n    line1_vec = line1.get_vector_point()\n    line2_vec = line2.get_vector_point()\n\n    det_value = cross2d(line2_vec, line1_vec)\n\n    if abs(det_value) &lt; 1e-14:\n        return False, Point(0, 0)\n\n    ac_line_vec = line2.start_point - line1.start_point\n\n    t = cross2d(line2_vec, ac_line_vec) / det_value\n    u = cross2d(line1_vec, ac_line_vec) / det_value\n\n    eps = 1e-14\n\n    if -eps &lt;= t &lt;= 1.0 + eps and -eps &lt;= u &lt;= 1.0 + eps:\n        return True, line1.start_point + line1_vec * t\n\n    return False, Point(0, 0)\n\n\ndef in_polygon(lines: List[Line], point: Point):\n\n    odd_nodes = False\n\n    x = point.x\n    y = point.y\n\n    for line in lines:\n        y1 = line.start_point.y\n        y2 = line.end_point.y\n        x1 = line.start_point.x\n        x2 = line.end_point.x\n        if ((y1 &lt; y &lt;= y2) or (y2 &lt; y &lt;= y1)) and min(x1, x2) &lt;= x:\n            x_pred = (y - y1) / (y2 - y1) * (x2 - x1) + x1\n            if x_pred &lt; x:\n                odd_nodes = not odd_nodes\n\n    return odd_nodes\n\n\ndef polygon_area(points):\n    copy_points = points + [points[0]]\n    lines = [Line(copy_points[i], copy_points[i + 1]) for i in range(len(copy_points) - 1)]\n\n    s_polygon = 0.0\n    for line in lines:\n        A, B = line.start_point, line.end_point\n        s_tri = cross2d(A, B)\n        s_polygon += s_tri\n    return abs(s_polygon / 2)\n\n\ndef convex_hull_graham(points: List[Point]):\n\n    ret_points = []\n\n    copy_points = deepcopy(points)\n    # 1. \u5148\u627e\u51fay\u503c\u6700\u5c0f\u7684\u70b9\uff0c\u5982\u679c\u5b58\u5728y\u503c\u76f8\u7b49\uff0c\u5219\u4f18\u5148\u9009\u62e9x\u503c\u6700\u5c0f\u7684\u4f5c\u4e3a\u8d77\u59cb\u70b9$P_0$\uff0c\u8be5\u70b9\u4e00\u5b9a\u5904\u4e8e\u51f8\u5305\u4e0a\n    copy_points.sort(key=lambda point:(point.y, point.x))\n\n    start_point = copy_points[0]\n\n    # 2. \u4ee5$P_0$\u4f5c\u4e3a\u539f\u70b9\uff0c\u5176\u4ed6\u6240\u6709\u70b9\u51cf\u53bb$P_0$\u5f97\u5230\u5bf9\u5e94\u7684\u5411\u91cf\n    vectors = []\n    len_copy_point = len(copy_points)\n    for i in range(0, len_copy_point, 1):\n        vector = copy_points[i] - start_point\n        vectors.append(vector)\n\n    # 3. \u8ba1\u7b97\u6240\u6709\u5411\u91cf\u4e0e$X$\u8f74\u6b63\u5411\u7684\u5939\u89d2$\\alpha$\uff0c\u6309\u4ece\u5c0f\u5230\u5927\u8fdb\u884c\u6392\u5217\uff0c\n    # \u9047\u5230$\\alpha$\u76f8\u540c\u7684\u60c5\u51b5\uff0c\u5219\u5411\u91cf\u8f83\u77ed\uff08\u5373\u79bb$P_0$\u8f83\u8fd1\u7684\u70b9\uff09\u7684\u6392\u5728\u524d\u9762\uff0c\n    # \u5f97\u5230\u521d\u59cb\u70b9\u5e8f$P_1,P_2, ..., P_n$\uff0c\n    # \u7531\u51e0\u4f55\u5173\u7cfb\u53ef\u77e5\u70b9\u5e8f\u4e2d\u7b2c\u4e00\u4e2a\u70b9$P_1$\u548c\u6700\u540e\u4e00\u4e2a\u70b9$P_n$\u4e00\u5b9a\u5728\u51f8\u5305\u4e0a\uff1b\n    def cmp_function(point_a: Point):\n        # \u5148\u6839\u636e\u65b9\u4f4d\u89d2\uff0c\u65b9\u4f4d\u89d2\u76f8\u540c\u518d\u6839\u636e\u6a21\u957f\n        return math.atan2(point_a.y, point_a.x), dot2d(point_a, point_a)\n\n    vectors.sort(key=cmp_function)\n    dists = [dot2d(vector, vector) for vector in vectors]\n\n    # 4. \u5c06$P_0$\u548c$P_1$\u538b\u5165\u6808\u4e2d\uff0c\u5c06\u540e\u7eed\u70b9$P_2$\u4f5c\u4e3a\u5f53\u524d\u70b9\uff0c\u8df3\u8f6c\u7b2c8\u6b65\u3002\n    ret_points.append(vectors[0])\n    k = 1\n    while k &lt; len_copy_point:\n        if dists[k] &gt; 1e-8:\n            break\n        k += 1\n\n    if k &gt;= len_copy_point:\n        return ret_points\n\n    ret_points.append(vectors[k])\n\n    m = len(ret_points)\n\n    # 5.\u6808\u4e2d\u6700\u4e0a\u9762\u4e24\u4e2a\u5143\u7d20\u5f62\u6210\u5411\u91cf$P_{ij}, i &lt; j$\n    # \u5229\u7528\u53c9\u4e58\u5224\u65ad\u5f53\u524d\u70b9\u662f\u5426\u5728\u8be5\u5411\u91cf\u7684\u5de6\u8fb9\u8fd8\u662f\u53f3\u8fb9\u6216\u8005\u5411\u91cf\u4e0a\n    # 6. \u5982\u679c\u5728\u5de6\u8fb9\u6216\u8005\u5411\u91cf\u4e0a\uff0c\u5219\u5c06\u5f53\u524d\u70b9\u538b\u5165\u6808\u4e2d\uff0c\u4e0b\u4e00\u4e2a\u70b9\u4f5c\u4e3a\u5f53\u524d\u70b9\uff0c\u8df3\u8f6c\u7b2c8\u6b65\n    # 7. \u5982\u679c\u5f53\u524d\u70b9\u5728\u5411\u91cf\u53f3\u8fb9\uff0c\u5219\u8868\u660e\u6808\u9876\u5143\u7d20\u4e0d\u5728\u51f8\u5305\u4e0a\uff0c\u5c06\u6808\u9876\u5143\u7d20\u5f39\u51fa\uff0c\u8df3\u8f6c\u7b2c5\u6b65\n    # 8. \u5224\u65ad\u5f53\u524d\u70b9\u662f\u5426\u662f\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u5982\u679c\u662f\u5219\u5c06\u5176\u538b\u7f29\u6808\u4e2d\uff0c\u6808\u4e2d\u6240\u6709\u5143\u7d20\u5373\u662f\u51f8\u5305\u4e0a\u6240\u6709\u70b9\uff0c\u7b97\u6cd5\u7ed3\u675f\uff0c\u5426\u5219\u8df3\u5230\u7b2c5\u6b65\u3002\n    for i in range(k + 1, len_copy_point, 1):\n        while m &gt;= 2:\n            # \u67e5\u770b\u5f53\u524d\u70b9\u5728\u5411\u91cf\u5de6\u8fb9\u8fd8\u662f\u53f3\u8fb9\n            q1 = vectors[i] - ret_points[-2]\n            q2 = ret_points[-1] - ret_points[-2]\n            if q1.x * q2.y &gt;= q2.x * q1.y:\n                m -= 1\n                ret_points.pop()\n            else:\n                break\n\n        ret_points.append(vectors[i])\n        m = len(ret_points)\n\n    for point in ret_points:\n        point.x += start_point.x\n        point.y += start_point.y\n\n    return ret_points\n\n\ndef iou_polygon(points_1: List[Point], points_2: List[Point]):\n\n    points_1 = convex_hull_graham(points_1)\n    points_2 = convex_hull_graham(points_2)\n\n    insection_points = []\n\n    len_points_1 = len(points_1)\n    len_points_2 = len(points_2)\n\n    points_1 = points_1 + [points_1[0]]\n    points_2 = points_2 + [points_2[0]]\n\n    for i in range(len_points_1):\n        for j in range(len_points_2):\n            line1 = points_1[i:i+2]\n            line2 = points_2[j:j+2]\n\n            is_intersect, intersection_point = get_intersection_points(Line(line1[0], line1[1]), Line(line2[0], line2[1]))\n\n            if is_intersect:\n                insection_points.append(intersection_point)\n\n    lines_1 = [Line(points_1[i], points_1[i+1]) for i in range(len_points_1)]\n    lines_2 = [Line(points_2[i], points_2[i+1]) for i in range(len_points_2)]\n\n    for i in range(len_points_1):\n        point = points_1[i]\n        if in_polygon(lines_2, point):\n            insection_points.append(point)\n\n    for i in range(len_points_2):\n        point = points_2[i]\n        if in_polygon(lines_1, point):\n            insection_points.append(point)\n\n    insection_points = convex_hull_graham(insection_points)\n\n    if len(insection_points) &lt;= 2:\n        return 0\n\n    insection_area = polygon_area(insection_points)\n\n    points_1_area = polygon_area(points_1)\n    points_2_area = polygon_area(points_2)\n\n    return insection_area / (points_1_area + points_2_area - insection_area)\n\n\ndef iou_polygon_cv2(contour1, contour2):\n    # opencv \u7248\u672c\u4e3a 4.5\n\n    # \u8ba1\u7b97\u4ea4\u96c6\u9762\u79ef\n    contour1 = np.array([(point.x, point.y) for point in contour1]).astype(np.float32)\n    contour2 = np.array([(point.x, point.y) for point in contour2]).astype(np.float32)\n    _, intersection = cv2.intersectConvexConvex(contour1, contour2)\n    intersection_area = cv2.contourArea(intersection)\n\n    # \u8ba1\u7b97\u5e76\u96c6\u9762\u79ef\n    union_area = cv2.contourArea(contour1) + cv2.contourArea(contour2) - intersection_area\n\n    # \u8ba1\u7b97IOU\n    iou = intersection_area / union_area\n    return iou\n\ndef main():\n    # return \n    x = -5\n    y = -5\n    w = 15\n    h = 20\n    theta = 45\n    theta = theta / 180 * math.pi\n    det_box = RotatedBox(x, y, w, h, theta)\n\n    points = [Point(0, 0) for _ in range(4)]\n    cos_theta = math.cos(theta) * 0.5\n    sin_theta = math.sin(theta) * 0.5\n\n    points[0].x = det_box.x + sin_theta * det_box.h + cos_theta * det_box.w\n    points[0].y = det_box.y + cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[1].x = det_box.x - sin_theta * det_box.h + cos_theta * det_box.w\n    points[1].y = det_box.y - cos_theta * det_box.h - sin_theta * det_box.w\n\n    points[2].x = 2 * det_box.x - points[0].x\n    points[2].y = 2 * det_box.y - points[0].y\n\n    points[3].x = 2 * det_box.x - points[1].x\n    points[3].y = 2 * det_box.y - points[1].y\n\n    # # points \u6574\u4f53\u5411\u4e0b\u79fb\u52a85\n    for point in points:\n        point.y -= 5\n\n    x1 = x - w / 2\n    y1 = y - h / 2\n\n    x2 = x + w / 2\n    y2 = y - h / 2\n\n    x3 = x + w / 2\n    y3 = y + h / 2\n\n    x4 = x - w / 2\n    y4 = y + h / 2\n\n    # \u5224\u65ad \u5404\u4e2a\u76f4\u7ebf\u4e4b\u95f4\u662f\u5426\u6709\u4ea4\u70b9\n    A = Point(x1, y1)\n    B = Point(x2, y2)\n    C = Point(x3, y3)\n    D = Point(x4, y4)\n\n\n    fig, ax = plt.subplots()\n    fig.set_figheight(6)\n    fig.set_figwidth(6)\n\n    # \u7ed8\u5236\u77e9\u5f62\n    # \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5de6\u4e0b\u89d2\u5750\u6807 \u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3awidth \u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3aheight\n    x_center, y_center, width, height = det_box.x, det_box.y, det_box.w, det_box.h\n    x1 = x_center - det_box.w / 2\n    y1 = y_center - det_box.h / 2\n\n    rect = plt.Rectangle((x1, y1), det_box.w, det_box.h, angle=0, fill=False, color=\"blue\")\n    ax.add_patch(rect)\n\n    # \u7ed5 center (x,y) \u65cb\u8f6c45\u5ea6\n    polygon = mptch.Polygon(xy=[(points[i].x, points[i].y) for i in range(4)], closed=True, color=\"red\", fill=False)\n    ax.add_patch(polygon)\n\n    insection_points = []\n\n    points_1 = points\n    points_2 = [A, B, C, D]\n\n    # \u4e0eopencv\u7ed3\u679c\u5bf9\u6bd4\n    iou = iou_polygon(points_1, points_2)\n    iou_cv2 = iou_polygon_cv2(points_1, points_2)\n    print('iou', iou)\n    print('iou_cv2', iou_cv2)\n\n\n\n    # \u8bbe\u7f6e\u5750\u6807\u8f74\n    ax.set_xlim(-30, 30)\n    ax.set_ylim(-30, 30)\n    # \u5b9a\u4e49\u5750\u6807\n    x = np.arange(-30, 31, 5)\n    y = np.arange(-30, 31, 5)\n    ax.set_xticks(x)\n    ax.set_yticks(y)\n    ax.grid(True)\n    # \u663e\u793a\u56fe\u8c61\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u7ed3\u679c\u5982\u4e0b\uff1a</p> <pre><code>iou 0.49793304538337396\niou_cv2 0.4979330453833741\n</code></pre> <p>\u5982\u4e0a\uff0c\u6211\u4eec\u624b\u5199\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0eopencv\u7684\u8ba1\u7b97\u7ed3\u679c\u5b8c\u5168\u4e00\u81f4\u3002</p>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#cuda","title":"\u4e03\u3001cuda\u7248\u672c\u4ee3\u7801\u89e3\u8bfb","text":"<p>\u89e3\u8bfb\u4e00\u4e0bmmcv\u4e2d\u503e\u659c\u56db\u8fb9\u5f62iou\u8ba1\u7b97\u7684\u5b9e\u73b0\uff0c\u6211\u4eec\u9009\u62e9<code>1.7.1</code>\u8fd9\u4e2a\u7248\u672c\u89e3\u8bfb\u3002</p> <p>single_box_iou_rotated github\u53c2\u8003\u94fe\u63a5</p> <p>rotated \u5de5\u5177\u51fd\u6570github\u53c2\u8003\u94fe\u63a5</p> <p>\u4e0a\u8ff0\u4ee3\u7801\u6307\u5411\u6700\u5173\u952e\u7684<code>single_box_iou_rotated</code>\u51fd\u6570</p> <p><code>single_box_iou_rotated</code>\u5c55\u5f00\u5982\u4e0b</p> <pre><code>template &lt;typename T&gt;\nHOST_DEVICE_INLINE T single_box_iou_rotated(T const* const box1_raw,\n                                            T const* const box2_raw,\n                                            const int mode_flag) {\n  // shift center to the middle point to achieve higher precision in result\n  RotatedBox&lt;T&gt; box1, box2;\n  auto center_shift_x = (box1_raw[0] + box2_raw[0]) / 2.0;\n  auto center_shift_y = (box1_raw[1] + box2_raw[1]) / 2.0;\n  box1.x_ctr = box1_raw[0] - center_shift_x;\n  box1.y_ctr = box1_raw[1] - center_shift_y;\n  box1.w = box1_raw[2];\n  box1.h = box1_raw[3];\n  box1.a = box1_raw[4];\n  box2.x_ctr = box2_raw[0] - center_shift_x;\n  box2.y_ctr = box2_raw[1] - center_shift_y;\n  box2.w = box2_raw[2];\n  box2.h = box2_raw[3];\n  box2.a = box2_raw[4];\n\n  // \u6c42\u53d6\u4e24\u4e2a\u65cb\u8f6c\u6846\u7684\u9762\u79ef\uff0c\u5982\u679c\u6709\u4e00\u4e2a\u9762\u79ef\u5f88\u5c0f\u5219\u76f4\u63a5\u8fd4\u56deiou=0\n  const T area1 = box1.w * box1.h;\n  const T area2 = box2.w * box2.h;\n  if (area1 &lt; 1e-14 || area2 &lt; 1e-14) {\n    return 0.f;\n  }\n  // \u6c42\u53d6 insection \u9762\u79ef\n  const T intersection = rotated_boxes_intersection&lt;T&gt;(box1, box2);\n  T baseS = 1.0;\n  if (mode_flag == 0) {\n    baseS = (area1 + area2 - intersection);\n  } else if (mode_flag == 1) {\n    baseS = area1;\n  }\n  const T iou = intersection / baseS;\n  return iou;\n}\n</code></pre> <p>\u8ba1\u7b97iou\u51fd\u6570<code>rotated_boxes_intersection</code></p> <pre><code>template &lt;typename T&gt;\nHOST_DEVICE_INLINE T rotated_boxes_intersection(const RotatedBox&lt;T&gt;&amp; box1,\n                                                const RotatedBox&lt;T&gt;&amp; box2) {\n  // There are up to 4 x 4 + 4 + 4 = 24 intersections (including dups) returned\n  // from rotated_rect_intersection_pts\n  Point&lt;T&gt; intersectPts[24], orderedPts[24];\n\n  Point&lt;T&gt; pts1[4];\n  Point&lt;T&gt; pts2[4];\n  // \u83b7\u53d6\u65cb\u8f6c\u77e9\u5f62\u7684\u56db\u4e2a\u70b9\u7684\u5750\u6807\u653e\u5230points\u6570\u7ec4\u4e2d\n  get_rotated_vertices&lt;T&gt;(box1, pts1);\n  get_rotated_vertices&lt;T&gt;(box2, pts2);\n  // \u8ba1\u7b97\u7126\u70b9\n  int num = get_intersection_points&lt;T&gt;(pts1, pts2, intersectPts);\n\n  if (num &lt;= 2) {\n    return 0.0;\n  }\n\n  // Convex Hull to order the intersection points in clockwise order and find\n  // the contour area.\n  // \u51f8\u5305\u7b97\u6cd5\n  int num_convex = convex_hull_graham&lt;T&gt;(intersectPts, num, orderedPts, true);\n  return polygon_area&lt;T&gt;(orderedPts, num_convex);\n}\n</code></pre> <p><code>get_rotated_vertices</code>\u51fd\u6570</p> <pre><code>template &lt;typename T&gt;\nHOST_DEVICE_INLINE void get_rotated_vertices(const RotatedBox&lt;T&gt;&amp; box,\n                                             Point&lt;T&gt; (&amp;pts)[4]) {\n  // M_PI / 180. == 0.01745329251\n  // double theta = box.a * 0.01745329251;\n  // MODIFIED\n  double theta = box.a;\n  T cosTheta2 = (T)cos(theta) * 0.5f;\n  T sinTheta2 = (T)sin(theta) * 0.5f;\n\n  // y: top --&gt; down; x: left --&gt; right\n  pts[0].x = box.x_ctr - sinTheta2 * box.h - cosTheta2 * box.w;\n  pts[0].y = box.y_ctr + cosTheta2 * box.h - sinTheta2 * box.w;\n  pts[1].x = box.x_ctr + sinTheta2 * box.h - cosTheta2 * box.w;\n  pts[1].y = box.y_ctr - cosTheta2 * box.h - sinTheta2 * box.w;\n  pts[2].x = 2 * box.x_ctr - pts[0].x;\n  pts[2].y = 2 * box.y_ctr - pts[0].y;\n  pts[3].x = 2 * box.x_ctr - pts[1].x;\n  pts[3].y = 2 * box.y_ctr - pts[1].y;\n}\n</code></pre> <p><code>get_intersection_points</code>\u51fd\u6570\u7528\u4e8e\u83b7\u53d6\u76f8\u4ea4\u7684\u70b9</p> <pre><code>template &lt;typename T&gt;\nHOST_DEVICE_INLINE int get_intersection_points(const Point&lt;T&gt; (&amp;pts1)[4],\n                                               const Point&lt;T&gt; (&amp;pts2)[4],\n                                               Point&lt;T&gt; (&amp;intersections)[24]) {\n  // Line vector\n  // A line from p1 to p2 is: p1 + (p2-p1)*t, t=[0,1]\n  Point&lt;T&gt; vec1[4], vec2[4];\n  for (int i = 0; i &lt; 4; i++) {\n    vec1[i] = pts1[(i + 1) % 4] - pts1[i];\n    vec2[i] = pts2[(i + 1) % 4] - pts2[i];\n  }\n\n  // \u6c42\u53d6\u6240\u6709\u8fb9\u7684\u4ea4\u70b9\uff0c\u8ddf\u672c\u6587\u4ecb\u7ecd\u7684\u6cd5\u4e00\u76f8\u540c\n  // Line test - test all line combos for intersection\n  int num = 0;  // number of intersections\n  for (int i = 0; i &lt; 4; i++) {\n    for (int j = 0; j &lt; 4; j++) {\n      // Solve for 2x2 Ax=b\n      T det = cross_2d&lt;T&gt;(vec2[j], vec1[i]);\n\n      // This takes care of parallel lines\n      if (fabs(det) &lt;= 1e-14) {\n        continue;\n      }\n\n      auto vec12 = pts2[j] - pts1[i];\n\n      T t1 = cross_2d&lt;T&gt;(vec2[j], vec12) / det;\n      T t2 = cross_2d&lt;T&gt;(vec1[i], vec12) / det;\n\n      if (t1 &gt;= 0.0f &amp;&amp; t1 &lt;= 1.0f &amp;&amp; t2 &gt;= 0.0f &amp;&amp; t2 &lt;= 1.0f) {\n        intersections[num++] = pts1[i] + vec1[i] * t1;\n      }\n    }\n  }\n\n  // \u67e5\u770b\u77e9\u5f62\u89d2\u70b9\u662f\u5426\u5728\u77e9\u5f62\u4e2d\uff0c\u8fd9\u91cc\u7528\u5230\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u65b9\u6cd5\u5728\u4e0b\u9762\u6709\u89e3\u91ca\n\n  // Check for vertices of rect1 inside rect2\n  {\n    const auto&amp; AB = vec2[0];\n    const auto&amp; DA = vec2[3];\n    // \u6c42\u53d6AB\u6a21\u957f\u7684\u5e73\u65b9\n    auto ABdotAB = dot_2d&lt;T&gt;(AB, AB);\n    // \u6c42\u53d6AD\u6a21\u957f\u7684\u5e73\u65b9\n    auto ADdotAD = dot_2d&lt;T&gt;(DA, DA);\n    for (int i = 0; i &lt; 4; i++) {\n      // assume ABCD is the rectangle, and P is the point to be judged\n      // P is inside ABCD iff. P's projection on AB lies within AB\n      // and P's projection on AD lies within AD\n\n      // pts1[i]\u5373\u4e3aP\u70b9 pts2[0]\u4e3aA\u70b9\n      auto AP = pts1[i] - pts2[0];\n\n      // \u6c42\u53d6AP\u4e0eAB\u7684\u5185\u79ef AP\u5728AB\u4e0a\u7684\u6295\u5f71\u4e58\u4ee5AB\u7684\u6a21\u957f\n      auto APdotAB = dot_2d&lt;T&gt;(AP, AB);\n      // \u6c42\u53d6AP\u4e0eAD\u7684\u5185\u79ef AP\u5728AD\u4e0a\u7684\u6295\u5f71\u4e58\u4ee5AD\u7684\u6a21\u957f\n      auto APdotAD = -dot_2d&lt;T&gt;(AP, DA);\n\n      // \u6ee1\u8db3\u70b9\u5728\u77e9\u5f62\u7684\u5185\u90e8\u6761\u4ef6\n      if ((APdotAB &gt;= 0) &amp;&amp; (APdotAD &gt;= 0) &amp;&amp; (APdotAB &lt;= ABdotAB) &amp;&amp;\n          (APdotAD &lt;= ADdotAD)) {\n        intersections[num++] = pts1[i];\n      }\n    }\n  }\n\n  // Reverse the check - check for vertices of rect2 inside rect1\n  {\n    const auto&amp; AB = vec1[0];\n    const auto&amp; DA = vec1[3];\n    auto ABdotAB = dot_2d&lt;T&gt;(AB, AB);\n    auto ADdotAD = dot_2d&lt;T&gt;(DA, DA);\n    for (int i = 0; i &lt; 4; i++) {\n      auto AP = pts2[i] - pts1[0];\n\n      auto APdotAB = dot_2d&lt;T&gt;(AP, AB);\n      auto APdotAD = -dot_2d&lt;T&gt;(AP, DA);\n\n      if ((APdotAB &gt;= 0) &amp;&amp; (APdotAD &gt;= 0) &amp;&amp; (APdotAB &lt;= ABdotAB) &amp;&amp;\n          (APdotAD &lt;= ADdotAD)) {\n        intersections[num++] = pts2[i];\n      }\n    }\n  }\n\n  return num;\n}\n</code></pre> <p></p> <p>\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5982\u679c\u70b9P\u5728\u77e9\u5f62\u5185\u90e8\uff0c\u5219\uff1a  \\(\\vec{AP}\\)  \u5230  \\(\\vec{AB}\\)  \u7684\u6295\u5f71\u957f\u5ea6\u5c0f\u4e8e\u6216\u7b49\u4e8e  \\(\\vec{AB}\\)  \u7684\u957f\u5ea6\u4e14  \\(\\vec{AP}\\)  \u5230  \\(\\vec{AD}\\)  \u7684\u6295\u5f71\u957f\u5ea6\u5c0f\u4e8e\u6216\u7b49\u4e8e \\(\\vec{AD}\\) \uff0c \u5176\u4e2d\u6295\u5f71\u53ef\u4ee5\u91c7\u7528\u5411\u91cf\u70b9\u4e58\u8ba1\u7b97</p> <p>\u76f8\u53cd\u5982\u679c\u70b9P\u5728\u77e9\u5f62\u5916\u90e8\uff0c\u5219\uff1a  \\(\\vec{AP}\\)  \u5230  \\(\\vec{AB}\\)  \u7684\u6295\u5f71\u957f\u5ea6\u5927\u4e8e  \\(\\vec{AB}\\)  \u7684\u957f\u5ea6\u6216  \\(\\vec{AP}\\)  \u5230  \\(\\vec{AD}\\)  \u7684\u6295\u5f71\u957f\u5ea6\u5927\u4e8e \\(\\vec{AD}\\) \uff0c</p> <p>\u63a5\u4e0b\u6765\u5c31\u662f\u51f8\u5305\u7b97\u6cd5<code>convex_hull_graham</code>\uff0c\u8fd9\u91cc\u7528\u7684\u662fGraham\uff08\u683c\u62c9\u7ff0\uff09\u626b\u63cf\u6cd5\uff0c\u8ddfPython\u7248\u672c\u5b9e\u73b0\u4e00\u81f4\uff0c\u5c31\u4e0d\u8d58\u8ff0\u4e86\u3002</p> <pre><code>template &lt;typename T&gt;\nHOST_DEVICE_INLINE int convex_hull_graham(const Point&lt;T&gt; (&amp;p)[24],\n                                          const int&amp; num_in, Point&lt;T&gt; (&amp;q)[24],\n                                          bool shift_to_zero = false) {\n  assert(num_in &gt;= 2);\n\n  // Step 1:\n  // Find point with minimum y\n  // if more than 1 points have the same minimum y,\n  // pick the one with the minimum x.\n  int t = 0;\n  for (int i = 1; i &lt; num_in; i++) {\n    if (p[i].y &lt; p[t].y || (p[i].y == p[t].y &amp;&amp; p[i].x &lt; p[t].x)) {\n      t = i;\n    }\n  }\n  auto&amp; start = p[t];  // starting point\n\n  // Step 2:\n  // Subtract starting point from every points (for sorting in the next step)\n  for (int i = 0; i &lt; num_in; i++) {\n    q[i] = p[i] - start;\n  }\n\n  // Swap the starting point to position 0\n  auto tmp = q[0];\n  q[0] = q[t];\n  q[t] = tmp;\n\n  // Step 3:\n  // Sort point 1 ~ num_in according to their relative cross-product values\n  // (essentially sorting according to angles)\n  // If the angles are the same, sort according to their distance to origin\n  T dist[24];\n  for (int i = 0; i &lt; num_in; i++) {\n    dist[i] = dot_2d&lt;T&gt;(q[i], q[i]);\n  }\n\n#ifdef __CUDACC__\n  // CUDA version\n  // In the future, we can potentially use thrust\n  // for sorting here to improve speed (though not guaranteed)\n  for (int i = 1; i &lt; num_in - 1; i++) {\n    for (int j = i + 1; j &lt; num_in; j++) {\n      T crossProduct = cross_2d&lt;T&gt;(q[i], q[j]);\n      if ((crossProduct &lt; -1e-6) ||\n          (fabs(crossProduct) &lt; 1e-6 &amp;&amp; dist[i] &gt; dist[j])) {\n        auto q_tmp = q[i];\n        q[i] = q[j];\n        q[j] = q_tmp;\n        auto dist_tmp = dist[i];\n        dist[i] = dist[j];\n        dist[j] = dist_tmp;\n      }\n    }\n  }\n#else\n  // CPU version\n  std::sort(q + 1, q + num_in,\n            [](const Point&lt;T&gt;&amp; A, const Point&lt;T&gt;&amp; B) -&gt; bool {\n              T temp = cross_2d&lt;T&gt;(A, B);\n              if (fabs(temp) &lt; 1e-6) {\n                return dot_2d&lt;T&gt;(A, A) &lt; dot_2d&lt;T&gt;(B, B);\n              } else {\n                return temp &gt; 0;\n              }\n            });\n  // compute distance to origin after sort, since the points are now different.\n  for (int i = 0; i &lt; num_in; i++) {\n    dist[i] = dot_2d&lt;T&gt;(q[i], q[i]);\n  }\n#endif\n\n  // Step 4:\n  // Make sure there are at least 2 points (that don't overlap with each other)\n  // in the stack\n  int k;  // index of the non-overlapped second point\n  for (k = 1; k &lt; num_in; k++) {\n    if (dist[k] &gt; 1e-8) {\n      break;\n    }\n  }\n  if (k == num_in) {\n    // We reach the end, which means the convex hull is just one point\n    q[0] = p[t];\n    return 1;\n  }\n  q[1] = q[k];\n  int m = 2;  // 2 points in the stack\n  // Step 5:\n  // Finally we can start the scanning process.\n  // When a non-convex relationship between the 3 points is found\n  // (either concave shape or duplicated points),\n  // we pop the previous point from the stack\n  // until the 3-point relationship is convex again, or\n  // until the stack only contains two points\n  for (int i = k + 1; i &lt; num_in; i++) {\n    while (m &gt; 1 &amp;&amp; cross_2d&lt;T&gt;(q[i] - q[m - 2], q[m - 1] - q[m - 2]) &gt;= 0) {\n      m--;\n    }\n    q[m++] = q[i];\n  }\n\n  // Step 6 (Optional):\n  // In general sense we need the original coordinates, so we\n  // need to shift the points back (reverting Step 2)\n  // But if we're only interested in getting the area/perimeter of the shape\n  // We can simply return.\n  if (!shift_to_zero) {\n    for (int i = 0; i &lt; m; i++) {\n      q[i] += start;\n    }\n  }\n\n  return m;\n}\n</code></pre>"},{"location":"OCR%E7%9B%B8%E5%85%B3/%E4%BB%BB%E6%84%8F%E5%87%B8%E5%9B%9B%E8%BE%B9%E5%BD%A2iou%E7%9A%84%E8%AE%A1%E7%AE%97/#_6","title":"\u53c2\u8003\u94fe\u63a5","text":"<ul> <li>https://www.cnblogs.com/xiaxuexiaoab/p/16801580.html</li> <li>https://www.cnblogs.com/xiaxuexiaoab/p/16801579.html</li> <li>https://www.jianshu.com/p/64534f8eecc6</li> <li>https://blog.csdn.net/yzf279533105/article/details/131029773</li> <li>https://arxiv.org/pdf/1703.01086.pdf</li> <li>https://mdnice.com/writing/02c11b814ac7403cbb8587fa09d48e8e</li> <li>https://blog.csdn.net/lemonxiaoxiao/article/details/108619552</li> <li>https://www.cnblogs.com/xiexinxinlove/p/3708147.html</li> </ul>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/","title":"cublas\u4e2d\u77e9\u9635\u4e58\u53ca\u5176\u5e7f\u64ad\u673a\u5236\u7684\u5b9e\u73b0\u4e0e\u5355\u5143\u6d4b\u8bd5","text":"<p>\u672c\u6587\u5199\u4e8e2022\u5e746\u670812\u53f7\u665a22\u70b9</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/#_1","title":"\u4e00\u3001\u51c6\u5907\u5de5\u4f5c","text":"<p>\u8981\u60f3\u6d4b\u8bd5cuda\u51fd\u6570\uff0c\u5982\u679c\u91c7\u7528\u539f\u751f\u7684\u9a8c\u8bc1\u65b9\u5f0f\u5c31\u9700\u8981\u81ea\u5df1\u5728cpu\u4e0a\u5c06\u5728gpu\u4e0a\u7684<code>kernel</code>\u5168\u90fd\u5b9e\u73b0\u4e00\u904d\uff0c\u8fd9\u4e2a\u5de5\u4f5c\u91cf\u662f\u5f88\u5927\u7684\u3002\u6b64\u5916\u5bf9\u4e8e\u663e\u5b58\u7684\u7ba1\u7406\u548ccublas\u53c2\u6570\u7684\u914d\u7f6e\u4e5f\u8f83\u4e3a\u590d\u6742\uff0c\u5bf9\u8fd9\u4e9b\u8fc7\u7a0b\u7b80\u5316\u7684\u65b9\u5f0f\u5c31\u662f\u5c01\u88c5\uff0c\u5bf9\u663e\u5b58\u548c\u5185\u5b58\u7684\u7ba1\u7406\u8fdb\u884c\u5c01\u88c5\u3002\u4e3a\u4e86\u89e3\u51b3\u9a8c\u8bc1\u7684\u95ee\u9898\uff0c\u8fd8\u9700\u8981\u5c06\u8fd0\u884c\u5728kernel\u7684\u6570\u636e\u5bfc\u51fa\uff0c\u91c7\u7528python\u7684numpy\u5e93\u8fdb\u884c\u9a8c\u8bc1\u3002\u9762\u5bf9\u8fd9\u6837\u7684\u95ee\u9898\uff0c\u672c\u9879\u5de5\u4f5c\u5c06cnpy\u5c01\u88c5\u8fdb\u7528\u4e8e\u7ba1\u7406\u663e\u5b58\u548c\u5185\u5b58\u7684Tensor\u7c7b\u4e2d,Tensor\u7c7b\u7684\u539f\u7248\u53c2\u8003TensorRT-Pro\uff0c\u6211\u624b\u52a8\u589e\u52a0\u4e86\u4e00\u4e9b\u7c7b\u578b\u652f\u6301\u548ccnpy\u7684\u5bfc\u51fa\u529f\u80fd\u3002 \u9a8c\u8bc1\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <ol> <li>cpp/cu\u5b9e\u73b0cuda/cublas\u51fd\u6570\uff0c\u5e76\u5c06\u8f93\u5165\u8f93\u51fa\u7684tensor\u5bfc\u51fa\u4e3anpy/npz/bin</li> <li>\u91c7\u7528python\u4e2d\u7684numpy\u8bfb\u53d6\u4fdd\u5b58\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5e76\u5c06cuda\u51fd\u6570\u5b9e\u73b0\u7684\u529f\u80fd\u91c7\u7528\u5be5\u5be5\u51e0\u884cpython\u4ee3\u7801\u5b9e\u73b0\u4e00\u8fb9\uff0c\u5c06python\u8ba1\u7b97\u7684\u7ed3\u679c\u4e0ecuda\u7ed3\u679c\u6bd4\u5bf9\u3002</li> </ol> <p>\u672c\u9879\u76ee\u5168\u90e8\u4ee3\u7801\u5f00\u6e90\u5728: https://github.com/thb1314/cublas_matmul</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/#python","title":"\u4e8c\u3001python\u7aef\u9a8c\u8bc1\u4ee3\u7801","text":"<p>\u8fd9\u91cc\u4ee5\u9a8c\u8bc1\u77e9\u9635elementwise\u52a0\u6cd5\u4e3a\u4f8b\u3002</p> <pre><code>import numpy as np\ndef _load_tensor(file):\n    with open(file, \"rb\") as f:\n        binary_data = f.read()\n    magic_number, ndims, dtype = np.frombuffer(binary_data, np.uint32, count=3, offset=0)\n    assert magic_number == 0xFCCFE2E2, f\"{file} not a tensor file.\"\n    dims = np.frombuffer(binary_data, np.uint32, count=ndims, offset=3 * 4)\n    if dtype == 0:\n        np_dtype = np.float32\n    elif dtype == 1:\n        np_dtype = np.float16\n    else:\n        assert False, f\"Unsupport dtype = {dtype}, can not convert to numpy dtype\"\n    return np.frombuffer(binary_data, np_dtype, offset=(ndims + 3) * 4).reshape(*dims)\ndef load_tensor(file):\n    if file.endswith(\"npz\"):\n        return np.load(file)['data']\n    elif file.endswith(\"npy\"):\n        return np.load(file)\n    else:\n        return _load_tensor(file)\ndef test():\n    p_tensor = load_tensor('p_tensor.npz')\n    q_tensor = load_tensor('q_tensor.npz')\n    out_tensor = load_tensor('out_tensor.npz')\n    out = p_tensor + q_tensor\n    print(np.abs(out - out_tensor).max())\n\nif __name__ == \"__main__\":\n    test()\n</code></pre>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/#_2","title":"\u4e09\u3001\u77e9\u9635\u4e58\u6cd5\u7684\u5b9e\u73b0","text":""},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/#31","title":"3.1 \u666e\u901a\u77e9\u9635\u4e58","text":"<ol> <li>\u884c\u4e3b\u7ef4\u4e0e\u5217\u4e3b\u7ef4</li> </ol> <p>\u5728C/C++\u4e2d\u6570\u636e\u7684\u5b58\u50a8\u662f\u6309\u7167\u7ebf\u6027\u7684\uff0c\u662f\u6309\u7167\u884c\u4f18\u5148\u5b58\u50a8\u7684\u3002\u6bd4\u5982\u5bf9\u4e8e\u4e00\u4e2a\u4e24\u884c\u4e09\u5217\u7684\u4e8c\u7ef4\u77e9\u9635<code>[[1,2,3],[4,5,6]]</code>\uff0c\u90a3\u4e48\u6309\u7167\u884c\u4f18\u5148\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\u4e3a<code>[1,2,3,4,5,6]</code>\u3002\u4f46\u662f\u5728\u4e00\u4e9b\u8bed\u8a00\uff08\u6bd4\u5982Fortran\uff09\u548ccublas\u4e2d\u662f\u6309\u7167\u5217\u4f18\u5148\u5b58\u50a8\u6765\u8bfb\u53d6\u6570\u636e\u7684\u3002\u540c\u6837\u662f\u8868\u793a<code>[[1,2,3],[4,5,6]]</code>\uff0c\u6309\u7167\u5217\u4f18\u5148\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\u5e94\u8be5\u4e3a<code>[1,4,2,5,3,6]</code>\u3002\u5982\u679c\u662f<code>[1,2,3,4,5,6]</code>\u6309\u7167\u5217\u4f18\u5148\u8bfb\u53d6\u4e3a\u4e24\u884c\u4e09\u5217\u7684\u4e8c\u7ef4\u77e9\u9635\u7684\u8bdd\uff0c\u5e94\u8be5\u8868\u793a\u4e3a<code>[[1,3,5],[2,4,6]]</code>\uff0c\u8fd9\u663e\u7136\u4e0e\u539f\u6765\u7684\u77e9\u9635\u5bf9\u4e0d\u4e0a\u3002\u4f46\u662f\uff0c\u5982\u679c\u6309\u7167\u4e09\u884c\u4e24\u5217\u7684\u4e8c\u7ef4\u77e9\u9635\u6765\u8bfb\u53d6\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a<code>[[1,4],[2,5],[3,6]]</code>\uff0c\u4f1a\u53d1\u73b0\u6309\u7167\u884c\u4f18\u5148\u5b58\u50a8\u7684\u77e9\u9635\u6309\u7167\u5217\u4f18\u5148\u65b9\u5f0f\u8bfb\u53d6\u4e3a\u5176\u8f6c\u7f6e\u5f62\u72b6\u7684\u8bdd\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u5176\u5728\u884c\u4f18\u5148\u5b58\u50a8\u5f62\u5f0f\u7684\u77e9\u9635\u7684\u8f6c\u7f6e\u3002\u5373\u6211\u4eec\u5728\u7533\u8bf7\u4e00\u5757\u663e\u5b58\u6309\u7167\u884c\u4f18\u5148\u6765\u5b58\u50a8\u77e9\u9635\uff0c\u90a3\u4e48\u5728cublas\u4f7f\u7528\u65f6\u8981\u6309\u7167\u5176\u8f6c\u7f6e\u7684\u5f62\u72b6\u6765\u7406\u89e3\u3002</p> <ol> <li>\u77e9\u9635\u4e58\u7684\u8f6c\u6362</li> </ol> <p>\u7ed9\u5b9a<code>C = A @ B</code>\uff0c\u90a3\u4e48<code>C.T = B.T @ A.T</code>\u3002<code>C.T</code>\u662f\u76f8\u5bf9\u4e8ecublas\u6765\u8bf4\u7684\uff0c\u5176\u5185\u5b58\u5206\u5e03\u6309\u7167\u884c\u4f18\u5148\u5b58\u50a8\u5176\u5b9e\u4e3aC\uff0c\u6240\u4ee5\u6211\u4eec\u5728\u8c03\u7528cublas\u51fd\u6570\u65f6\uff0c\u9700\u8981\u5c06\u6240\u6709\u77e9\u9635\u6309\u7167\u8f6c\u7f6e\u7ef4\u5ea6\u6765\u7406\u89e3\uff0c\u5e76\u4e14\u9700\u8981\u6ce8\u610f\u7b2c\u4e00\u4e2a\u77e9\u9635\u7684\u53c2\u6570\u4e3a<code>B.T</code>\uff0c\u800c\u4e0d\u662f<code>A</code>\u4e86\u3002\u8fd9\u6837\u5c31\u5f15\u51fa\u4e86\u7b2c\u4e00\u4e2acublas\u7684\u77e9\u9635\u4e58\u6cd5\u51fd\u6570\u3002</p> <pre><code>cublasStatus_t cublasGemmEx(cublasHandle_t handle,\n                           cublasOperation_t transa,\n                           cublasOperation_t transb,\n                           int m,\n                           int n,\n                           int k,\n                           const void    *alpha,\n                           const void     *A,\n                           cudaDataType_t Atype,\n                           int lda,\n                           const void     *B,\n                           cudaDataType_t Btype,\n                           int ldb,\n                           const void    *beta,\n                           void           *C,\n                           cudaDataType_t Ctype,\n                           int ldc,\n                           cublasComputeType_t computeType,\n                           cublasGemmAlgo_t algo);\n</code></pre> <p>\u8fd9\u91cc\u6211\u4eec\u8ba1\u7b97<code>Q @ P</code>,\u5176\u4e2d<code>Q</code>\u7684\u5f62\u72b6\u4e3a<code>m x k</code>\uff0c<code>P</code>\u7684\u5f62\u72b6\u4e3a<code>k x n</code>\u3002\u4e0b\u9762\u7ed9\u51fa\u5173\u952e\u4ee3\u7801</p> <pre><code>float alpha = 1.0;\nfloat beta = 0.0;\n// the LDA is used to define the distance in memory between elements of two consecutive columns which have the same row index\n// B [k,n] B.T [n,k]\n// A [m,k] A.T [k,m]\n// C [m,n] C.T [n,m]\ncublasComputeType_t computeType = CUBLAS_COMPUTE_32F;\ncudaDataType_t qType = CUDA_R_32F;\ncudaDataType_t pType = CUDA_R_32F;\ncudaDataType_t oType = CUDA_R_32F;\ncublasGemmAlgo_t algo = CUBLAS_GEMM_DEFAULT;\ncublasGemmEx(mCublas, CUBLAS_OP_N, CUBLAS_OP_N, n, m, k, &amp;alpha,\n            pptr_gpu, pType, n,\n            qptr_gpu, qType, k,\n            &amp;beta,\n            outptr_gpu, oType, n,\n            computeType, algo\n);\n</code></pre> <p>\u8be6\u60c5\u53ef\u4ee5\u53c2\u8003git\u94fe\u63a5\u4e2d\u7684<code>02cublas_test_matmul</code>\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/#32-batched","title":"3.2 batched \u77e9\u9635\u4e58","text":"<p>batched\u77e9\u9635\u4e58\u6cd5git\u4e2d\u7ed9\u51fa\u4e24\u79cdapi\uff0c\u7b2c\u4e00\u4e2a\u662f<code>cublasGemmBatchedEx</code>\uff0c\u7b2c\u4e8c\u4e2a\u662f<code>cublasGemmStridedBatchedEx</code>\u3002 <code>cublasGemmBatchedEx</code>\u9700\u8981\u5c06\u4e00\u4e2a\u6279\u6b21\u4e2d\u7684\u5355\u4e2a\u6570\u636e\u7406\u89e3\u4e3a\u4e00\u4e2a\u6307\u9488\uff0c\u6574\u4e2abatch\u5b58\u50a8\u4e3a\u4e00\u4e2a\u6307\u9488\u6570\u636e\u3002 <code>cublasGemmStridedBatchedEx</code>\u662f\u5c06\u4e00\u4e2a\u6279\u6b21\u7684\u6570\u636e\u7406\u89e3\u4e3a\u4e00\u5757\u8fde\u7eed\u5185\u5b58\uff0c\u5355\u4e2a\u77e9\u9635\u6570\u636e\u4e4b\u95f4\u76f8\u9694stride\u7684\u8ddd\u79bb\u3002 \u7406\u89e3\u4e86\u4e0a\u9762\u7684\u8fd9\u4e9b\u77e5\u8bc6\u70b9\u548c\u5217\u4e3b\u7ef4\u5b58\u50a8\uff0c\u5bf9\u4e8e<code>A[b,m,k] @ B[b,k,n]</code>\u7684\u5b9e\u73b0\u5c31\u76f8\u5bf9\u7b80\u5355\u4e86\u3002 \u4e0b\u9762\u7ed9\u51fa\u5173\u952e\u4ee3\u7801</p> <pre><code>CUBLASASSERT(cublasGemmBatchedEx(mCublas, CUBLAS_OP_N, CUBLAS_OP_N, n, m, k,\n                                &amp;alpha,\n                                (void**)pptr_gpu_arr_tensor.to_gpu(true).gpu&lt;float*&gt;(), pType, n,\n                                (void**)qptr_gpu_arr_tensor.to_gpu(true).gpu&lt;float*&gt;(), qType, k,\n                                &amp;beta,\n                                (void**)outptr_gpu_arr_tensor.to_gpu().gpu&lt;float*&gt;(), oType, n,\n                                b, computeType, algo\n                                ));\n</code></pre> <pre><code>CUBLASASSERT(cublasGemmStridedBatchedEx(mCublas, CUBLAS_OP_N, CUBLAS_OP_N, n, m, k,\n                                        &amp;alpha,\n                                        pptr_gpu, pType, n, p_tensor.size(1) * p_tensor.size(2),\n                                        qptr_gpu, qType, k, q_tensor.size(1) * q_tensor.size(2),\n                                        &amp;beta,\n                                        outptr_gpu1, oType, n, out_tensor1.size(1) * out_tensor1.size(2),\n                                        b, computeType, algo\n                                        ));\n</code></pre>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/#33","title":"3.3 \u5e7f\u64ad\u7684\u77e9\u9635\u4e58","text":"<ol> <li>\u8f83\u4e3a\u7b80\u5355\u7684\u5f62\u5f0f</li> </ol> <p>\u5bf9\u4e8e <code>A[b,m,k] @ B[1,k,n]</code>\uff0c\u5728\u91c7\u7528<code>cublasGemmStridedBatchedEx</code> API\u65f6\u6211\u4eec\u53ea\u9700\u8981\u5c06B\u7684stride\u8bbe\u7f6e\u4e3a0\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u5b9e\u73b0b\u4e2abatch\u8bfb\u53d6\u7684\u90fd\u662f\u76f8\u540c\u7684B\u3002 \u5173\u952e\u4ee3\u7801\u5982\u4e0b</p> <pre><code>// Q[0:1] @ P    Q[0:1] \u4f1a\u5e7f\u64ad\u5230 P \u7684 batch\n    CUBLASASSERT(cublasGemmStridedBatchedEx(mCublas, CUBLAS_OP_N, CUBLAS_OP_N, n, m, k,\n                                            &amp;alpha,\n                                            pptr_gpu, pType, n, p_tensor.size(1) * p_tensor.size(2),\n                                            qptr_gpu, qType, k, 0,\n                                            &amp;beta,\n                                            outptr_gpu2, oType, n, out_tensor2.size(1) * out_tensor2.size(2),\n                                            b, computeType, algo\n                                            ));\n</code></pre> <ol> <li>\u8f83\u4e3a\u590d\u6742\u7684\u5f62\u5f0f</li> </ol> <p>\u5bf9\u4e8e<code>A[1,s,m,k] @ B[b,s,k,n]</code>\uff0cnumpy\u7684\u505a\u6cd5\u65f6\u5c06B\u5e7f\u64ad\u4e3a<code>B[b,s,k,n]</code>\uff0c\u90a3\u4e48\u8be5\u5982\u4f55\u6a21\u62df\u8fd9\u79cd\u884c\u4e3a\u5462\uff1f\u5b9e\u9645\u4e0a\u8fd8\u662f\u62c6\u89e3\u4e3a\u5df2\u77e5\u7684\u65b9\u6cd5\u3002 \u62c6\u89e3\u65b9\u6cd5\u5982\u4e0b</p> <pre><code>C[0, s, :m, :n] = A[0, s, :m, :k] @ B[0, s, :k, :n]\nC[1, s, :m, :n] = A[0, s, :m, :k] @ B[1, s, :k, :n]\nC[2, s, :m, :n] = A[0, s, :m, :k] @ B[2, s, :k, :n]\n...\n</code></pre> <p>\u8fd9\u6837\u6211\u4eec\u9700\u8981\u5faa\u73afb\u6b21\u6765\u5b8c\u6210\u4e0a\u9762\u7684\u5e7f\u64ad\uff0c\u5e76\u4e14batch\u53c2\u6570\u8bbe\u7f6e\u4e3as\uff0cA\u7684stride\u4e3amk\u3002B\u7684stride\u4e3akn\uff0cB\u7684\u5730\u5740\u9700\u8981\u52a8\u6001\u8ba1\u7b97\u3002C\u7684stride\u4e3am*n\uff0cC\u7684\u5730\u5740\u5728\u6bcf\u6b21\u5faa\u73af\u65f6\u4e5f\u9700\u8981\u52a8\u6001\u8ba1\u7b97\u3002 \u76f8\u5173\u4ee3\u7801\u5b9e\u73b0\u5982\u4e0b</p> <pre><code>// \u4ee3\u7801\u4e2dQ=A\uff0cP=B\nfor(int i = 0; i &lt; b; ++i) {\n        CUBLASASSERT(cublasGemmStridedBatchedEx(mCublas, CUBLAS_OP_N, CUBLAS_OP_N, n, m, k,\n        &amp;alpha,\n        pptr_gpu + i * p_tensor.size(1) * p_tensor.size(2) * p_tensor.size(3), pType, n, p_tensor.size(2) * p_tensor.size(3),\n        qptr_gpu, qType, k, q_tensor.size(2) * q_tensor.size(3),\n        &amp;beta,\n        outptr_gpu2 + i * out_tensor2.size(1) * out_tensor2.size(2) * out_tensor2.size(3), oType, n, out_tensor2.size(2) * out_tensor2.size(3),\n        s, computeType, algo\n        ));\n    }\n</code></pre> <p>\u4e0b\u9762\u770b\u53e6\u5916\u4e00\u79cd\u5e7f\u64ad\u5f62\u5f0f\u7684\u5b9e\u73b0\uff0c <code>A[b,1,m,k] @ B[b,s,k,n]</code>,\u7167\u65e7\u8fd8\u662f\u9700\u8981\u8f6c\u6362\u4e3a\u5df2\u6709\u5e26stride\u5f62\u5f0f\u3002</p> <pre><code>C[b, 0, :m, :n] = A[b, 0, :m, :k] @ B[b, 0, :k, :n]\nC[b, 1, :m, :n] = A[b, 0, :m, :k] @ B[b, 1, :k, :n]\nC[b, 2, :m, :n] = A[b, 0, :m, :k] @ B[b, 2, :k, :n]\n...\n</code></pre> <p>\u76f8\u5e94\u7684stride\u548c\u5730\u5740\u90fd\u9700\u8981\u505a\u66f4\u6539\uff0c\u8fd9\u91ccA\u7684stride\u4e3a<code>s x m x k</code>\u7684\u539f\u56e0\u662f\u60f3\u5077\u4e2a\u61d2\uff0c\u91c7\u7528\u539f\u6765\u7684\u6570\u636e\u505a\u4e00\u4e9b\u5207\u7247\u3002 B\u7684stride\u4e3a<code>s x k x n</code>\uff0cC\u7684stride\u4e3a<code>s x m x n</code>\u3002 \u5173\u952e\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>for(int i = 0; i &lt; s; ++i) {\n        CUBLASASSERT(cublasGemmStridedBatchedEx(mCublas, CUBLAS_OP_N, CUBLAS_OP_N, n, m, k,\n        &amp;alpha,\n        pptr_gpu + (0 * p_tensor.size(1) +  i) * p_tensor.size(2) * p_tensor.size(3), pType, n, p_tensor.size(1) * p_tensor.size(2) * p_tensor.size(3),\n        qptr_gpu, qType, k, q_tensor.size(1) * q_tensor.size(2) * q_tensor.size(3),\n        &amp;beta,\n        outptr_gpu3 + (0 * out_tensor3.size(1) +  i) * out_tensor3.size(2) * out_tensor3.size(3), oType, n, out_tensor3.size(1) * out_tensor3.size(2) * out_tensor3.size(3),\n        b, computeType, algo\n        ));\n}\n</code></pre>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B406%E6%9C%8812%E6%97%A5%2021%E6%97%B613%E5%88%8644%E7%A7%92/#_3","title":"\u56db\u3001\u603b\u7ed3","text":"<p>\u672c\u6587\u9010\u6b65\u7ed9\u51facublas\u4e2d\u77e9\u9635\u4e58\u6cd5\u53ca\u5176\u5e7f\u64ad\u5f62\u5f0f\u7684\u5b9e\u73b0\uff0c\u5e76\u7ed9\u51fa\u4e00\u79cd\u9a8c\u8bc1cuda\u51fd\u6570\u7684\u8f83\u4e3a\u901a\u7528\u7684\u6846\u67b6\uff0c\u5e0c\u671b\u80fd\u7ed9\u8bfb\u8005\u5e26\u6765\u4e00\u4e9b\u542f\u53d1\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B407%E6%9C%8823%E6%97%A5%2023%E6%97%B617%E5%88%8614%E7%A7%92/","title":"cuDNN API\u7684\u4f7f\u7528\u4e0e\u6d4b\u8bd5-\u4ee5\u4e8c\u7ef4\u5377\u79ef+Relu\u6fc0\u6d3b\u51fd\u6570\u4e3a\u4f8b","text":"<p>\u672c\u6587\u5199\u4e8e2022\u5e747\u670823\u65e5</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B407%E6%9C%8823%E6%97%A5%2023%E6%97%B617%E5%88%8614%E7%A7%92/#cudnn","title":"\u4e00\u3001cudnn\u4ecb\u7ecd","text":"<p>NVIDIA CUDA\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5e93\uff08cuDNN\uff09\u662f\u9002\u7528\u4e8e\u82f1\u4f1f\u8fbeGPU\u7684\u7528\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684cuda\u51fd\u6570\u5e93\u3002cuDNN\u4e3a\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u89c1\u7684\u7b97\u5b50\u63d0\u4f9b\u4e86\u9ad8\u5ea6\u4f18\u5316\u7684\u5b9e\u73b0\uff0c\u4f8b\u5982\u5377\u79ef\uff0c\u6c60\u5316\uff0c\u5f52\u4e00\u5316\u5c42\u548c\u6fc0\u6d3b\u5c42\u7684\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u7684\u5b9e\u73b0\u3002 \u5168\u7403\u7684\u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u4eba\u5458\u548c\u6846\u67b6\u5f00\u53d1\u4eba\u5458\u90fd\u4f9d\u8d56cuDNN\u6765\u5b9e\u73b0\u9ad8\u6027\u80fdGPU\u52a0\u901f\u3002\u5b83\u4f7f\u4ed6\u4eec\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u548c\u5f00\u53d1\u8f6f\u4ef6\u5e94\u7528\u7a0b\u5e8f\uff0c\u800c\u4e0d\u5fc5\u82b1\u65f6\u95f4\u5728\u5e95\u5c42GPU\u6027\u80fd\u8c03\u6574\u4e0a\u3002cuDNN\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e0a\uff0c\u5305\u62ecCaffe2\uff0cChainer\uff0cKeras\uff0cMATLAB\uff0cMxNet\uff0cPyTorch\u548cTensorFlow\u3002</p> <p>\u539f\u7248\u7684cuda\u5b89\u88c5\u5305\u662f\u4e0d\u5305\u542bcudnn\u7684\uff0c\u9700\u8981\u7528\u6237\u989d\u5916\u4e0b\u8f7d\u548c\u5b89\u88c5\u3002cudnn\u7684\u5b89\u88c5\u8fc7\u7a0b\u4e0d\u518d\u6587\u672c\u5185\u5bb9\u7684\u8303\u56f4\u4ee5\u5185\uff0c\u8fd8\u8bf7\u8bfb\u8005\u4ed4\u7ec6\u641c\u7d22\u4e0b\u8f7d\u5b89\u88c5\u3002\u672c\u6587\u7684\u4f8b\u5b50\u662f\u57fa\u4e8ecudnn8.0\u7248\u672c\uff0cdemo\u5730\u5740\u4e3a\uff1a https://github.com/thb1314/cudnn_conv_relu \u66f4\u591a\u5b66\u4e60\u8d44\u6599\u8bf7\u53c2\u8003: https://docs.nvidia.com/deeplearning/cudnn/ </p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B407%E6%9C%8823%E6%97%A5%2023%E6%97%B617%E5%88%8614%E7%A7%92/#cudnn-api","title":"\u4e8c\u3001cudnn API\u7684\u4f7f\u7528\u6b65\u9aa4","text":"<p>\u4f7f\u7528 cuDNN \u7684\u5e94\u7528\u7a0b\u5e8f\u5fc5\u987b\u901a\u8fc7\u8c03\u7528 <code>cudnnCreate()</code> \u6765\u521d\u59cb\u5316\u5e93\u4e0a\u4e0b\u6587\u7684\u53e5\u67c4\u3002\u8fd9\u4e2a\u53e5\u67c4\u88ab\u663e\u5f0f\u5730\u4f20\u9012\u7ed9\u5bf9 GPU \u6570\u636e\u8fdb\u884c\u64cd\u4f5c\u7684\u6bcf\u4e2a\u5e93\u51fd\u6570\u3002\u4e00\u65e6\u5e94\u7528\u7a0b\u5e8f\u5b8c\u6210\u4f7f\u7528 <code>cuDNN</code>\uff0c\u5b83\u53ef\u4ee5\u4f7f\u7528 <code>cudnnDestroy()</code> \u91ca\u653e\u4e0e\u5e93\u53e5\u67c4\u5173\u8054\u7684\u8d44\u6e90\u3002\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u7528\u6237\u5728\u4f7f\u7528\u591a\u4e2ahost\u4e3b\u673a\u7ebf\u7a0b\uff08\u6bd4\u5982cpu\u7ebf\u7a0b\uff09\u3001GPU \u6216\u8005 CUDA stream\u65f6\u663e\u5f0f\u63a7\u5236\u5e93\u7684\u529f\u80fd\u3002 cudnn API\u4f7f\u7528\u6b65\u9aa4\u4e00\u822c\u5982\u4e0b\uff1a</p> <ol> <li> <p>\u521b\u5efacuDNN\u53e5\u67c4 <code>cudnnStatus_t cudnnCreate(cudnnHandle_t *handle)</code></p> </li> <li> <p>\u4ee5Host\u65b9\u5f0f\u8c03\u7528\u5728Device\u4e0a\u8fd0\u884c\u7684\u51fd\u6570   \u6bd4\u5982\u5377\u79ef\u8fd0\u7b97\uff1a <code>cudnnConvolutionForward</code>\u7b49</p> </li> <li> <p>\u91ca\u653ecuDNN\u53e5\u67c4   <code>cudnnStatus_t cudnnDestroy(cudnnHandle_t handle)</code> \u5176\u4ed6\u51fd\u6570 \u6bd4\u5982\u5728\u521b\u5efacudnn\u7684\u65f6\u5019\u53ef\u4ee5\u8bbe\u7f6e\u6216\u8005\u4e92\u6bb4cudnn\u6240\u7528\u7684stream  </p> <ul> <li><code>cudnnStatus_t cudnnSetStream( cudnnHandle_t handle, cudaStream_t streamId)</code></li> <li><code>cudnnStatus_t cudnnGetStream( cudnnHandle_t handle, cudaStream_t *streamId)</code></li> </ul> </li> </ol>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B407%E6%9C%8823%E6%97%A5%2023%E6%97%B617%E5%88%8614%E7%A7%92/#_1","title":"\u4e09\u3001\u4e8c\u7ef4\u5377\u79ef\u7684\u5b9e\u73b0\u6848\u4f8b","text":"<p>\u672c\u5c0f\u8282\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528cuDNN\u7684\u5377\u79ef\u76f8\u5173api\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\u8fd0\u7b97\uff0c\u672c\u6587\u8fd8\u662f\u4f1a\u4f7f\u7528\u5728cublas\u7ae0\u8282\u91c7\u7528\u7684\u4e00\u4e2a\u5f20\u91cf\u7ba1\u7406\u7684\u5c01\u88c5\u7c7b\u3002\u5177\u4f53\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ol> <li>\u521b\u5efa\u5377\u79ef\u6240\u9700\u8981\u7684\u8f93\u5165Tensor\uff0c\u5377\u79ef\u6743\u91cd\u548c\u5377\u79ef\u504f\u6267\u9879\u3002</li> <li>\u521b\u5efacudnn handle\u5e76\u4e14\u8bbe\u7f6ehandle\u7684stream</li> <li>\u8bbe\u7f6e\u5377\u79ef\u8f93\u5165\u76f8\u5173Tensor\u7684\u5f62\u72b6\u63cf\u8ff0\u7b26\uff08\u4f7f\u7528TensorDescriptor\u7cfb\u5217API\uff09\u548c\u5377\u79ef\u914d\u7f6e\u76f8\u5173\u7684\u63cf\u8ff0\u7b26</li> <li>\u6839\u636e\u5f53\u524d\u914d\u5408\u641c\u7d22\u5377\u79ef\u8ba1\u7b97\u65b9\u6cd5\u5e76\u7533\u8bf7\u76f8\u5173workspace</li> <li>\u8c03\u7528<code>cudnnConvolutionBiasActivationForward</code>\u5b8c\u6210\u5377\u79ef\u8ba1\u7b97</li> <li>\u91ca\u653eworkspace\u663e\u5b58\u5360\u7528\uff0c\u9500\u6bc1cudnn \u53e5\u67c4</li> </ol> <p>\u6838\u5fc3\u4ee3\u7801\u5982\u4e0b:</p> <pre><code>// 123\nint test_conv_relu() {\n    ::srand(::time(0));\n    std::cout &lt;&lt; \"CUDNN_VERSION:\" &lt;&lt; CUDNN_VERSION &lt;&lt; std::endl;\n    // \u8bbe\u5b9a\u8f93\u5165\u8f93\u51fatensor\u7684\u7ef4\u5ea6\u53c2\u6570\n    constexpr int batch_size = 4;\n    constexpr int channel_in = 3;\n    constexpr int height_in = 112;\n    constexpr int width_in = 112;\n    constexpr int channel_out = 15;\n    constexpr int height_out = 112;\n    constexpr int width_out = 112;\n    constexpr int kernel_h = 1;\n    constexpr int kernel_w = 1;\n    // \u6784\u9020\u76f8\u5173Tensor\n    // input\n    TRT::Tensor q_tensor(std::vector&lt;int&gt;{batch_size, channel_in, height_in, width_in});\n    // kernel input\n    TRT::Tensor kernel_tensor(std::vector&lt;int&gt;{channel_out, channel_in, kernel_h, kernel_w});\n    // bias\n    TRT::Tensor bias_tensor(std::vector&lt;int&gt;{channel_out});\n    TRT::Tensor z_tensor(std::vector&lt;int&gt;{batch_size, channel_out, height_out, width_out});\n    // output\n    TRT::Tensor out_tensor(std::vector&lt;int&gt;{batch_size, channel_out, height_out, width_out});\n    auto qptr_cpu = q_tensor.cpu&lt;float&gt;();\n    for(int i = 0; i &lt; q_tensor.numel(); ++i)\n    {\n        qptr_cpu[i] = float(rand() % 100000) / 100000;\n    }\n    q_tensor.save_to_file(\"q_tensor.npz\");\n    auto biasptr_cpu = bias_tensor.cpu&lt;float&gt;();\n    for(int i = 0; i &lt; bias_tensor.numel(); ++i)\n    {\n        biasptr_cpu[i] = float(rand() % 100000) / 100000;\n    }\n    bias_tensor.save_to_file(\"bias_tensor.npz\");\n    auto kernelptr_cpu = kernel_tensor.cpu&lt;float&gt;();\n    for(int i = 0; i &lt; kernel_tensor.numel(); ++i)\n    {\n        kernelptr_cpu[i] = float(rand() % 100000) / 100000;\n    }\n    kernel_tensor.save_to_file(\"kernel_tensor.npz\");\n    auto qptr_gpu = q_tensor.to_gpu(true).gpu&lt;float&gt;();\n    auto bias_gpu = bias_tensor.to_gpu(true).gpu&lt;float&gt;();\n    auto kernel_gpu = kernel_tensor.to_gpu(true).gpu&lt;float&gt;();\n    auto outptr_gpu = out_tensor.to_gpu().gpu&lt;float&gt;();\n    cudaStream_t stream = out_tensor.get_stream();\n    // \u521b\u5efacudnn\u53e5\u67c4\u5e76\u8bbe\u7f6ehandle\u7684stream\n    cudnnHandle_t cudnn;\n    checkCUDNN(cudnnCreate(&amp;cudnn));\n    checkCUDNN(cudnnSetStream(cudnn, stream));\n    // y = act ( alpha1 * conv(x) + alpha2 * z + bias )\n    const float alpha1 = 1;\n    const float alpha2 = 0;\n    // \u8bbe\u7f6e\u8f93\u5165Tensor\u63cf\u8ff0\u7b26\n    cudnnTensorDescriptor_t input_descriptor;\n    checkCUDNN(cudnnCreateTensorDescriptor(&amp;input_descriptor));\n    checkCUDNN(cudnnSetTensor4dDescriptor(input_descriptor,\n                                          /*format=*/CUDNN_TENSOR_NCHW,\n                                          /*dataType=*/CUDNN_DATA_FLOAT,\n                                          /*batch_size=*/batch_size,\n                                          /*channels=*/channel_in,\n                                          /*image_height=*/height_in,\n                                          /*image_width=*/width_in));\n    // \u8bbe\u7f6e\u8f93\u51faTensor\u63cf\u8ff0\u7b26\n    cudnnTensorDescriptor_t output_descriptor;\n    checkCUDNN(cudnnCreateTensorDescriptor(&amp;output_descriptor));\n    checkCUDNN(cudnnSetTensor4dDescriptor(output_descriptor,\n                                      /*format=*/CUDNN_TENSOR_NCHW,\n                                      /*dataType=*/CUDNN_DATA_FLOAT,\n                                      /*batch_size=*/batch_size,\n                                      /*channels=*/channel_out,\n                                      /*image_height=*/height_out,\n                                      /*image_width=*/width_out));\n    // \u8bbe\u7f6ebias\u63cf\u8ff0\u7b26\n    cudnnTensorDescriptor_t bias_descriptor;\n    checkCUDNN(cudnnCreateTensorDescriptor(&amp;bias_descriptor));\n    checkCUDNN(cudnnSetTensor4dDescriptor(bias_descriptor,\n                                      /*format=*/CUDNN_TENSOR_NCHW,\n                                      /*dataType=*/CUDNN_DATA_FLOAT,\n                                      /*batch_size=*/1,\n                                      /*channels=*/channel_out,\n                                      /*image_height=*/1,\n                                      /*image_width=*/1));\n    // \u8bbe\u7f6ez\u63cf\u8ff0\u7b26\n    // // y = act ( alpha1 * conv(x) + alpha2 * z + bias ) \u8fd9\u91cc\u7528\u4e0d\u5230\n    cudnnTensorDescriptor_t z_descriptor;\n    checkCUDNN(cudnnCreateTensorDescriptor(&amp;z_descriptor));\n    checkCUDNN(cudnnSetTensor4dDescriptor(z_descriptor,\n                                      /*format=*/CUDNN_TENSOR_NCHW,\n                                      /*dataType=*/CUDNN_DATA_FLOAT,\n                                      /*batch_size=*/batch_size,\n                                      /*channels=*/channel_out,\n                                      /*image_height=*/height_out,\n                                      /*image_width=*/width_out));\n    // \u8bbe\u7f6econv weight\u7684\u63cf\u8ff0\n    cudnnFilterDescriptor_t kernel_descriptor;\n    checkCUDNN(cudnnCreateFilterDescriptor(&amp;kernel_descriptor));\n    checkCUDNN(cudnnSetFilter4dDescriptor(kernel_descriptor,\n                                          /*dataType=*/CUDNN_DATA_FLOAT,\n                                          /*format=*/CUDNN_TENSOR_NCHW,\n                                          /*out_channels=*/channel_out,\n                                          /*in_channels=*/channel_in,\n                                          /*kernel_height=*/kernel_h,\n                                          /*kernel_width=*/kernel_w));\n    // \u8bbe\u7f6e\u5377\u79ef\u76f8\u5173\u53c2\u6570\n    cudnnConvolutionDescriptor_t convolution_descriptor;\n    checkCUDNN(cudnnCreateConvolutionDescriptor(&amp;convolution_descriptor));\n    checkCUDNN(cudnnSetConvolution2dDescriptor(convolution_descriptor,\n                                              /*pad_height=*/0,\n                                              /*pad_width=*/0,\n                                              /*vertical_stride=*/1,\n                                              /*horizontal_stride=*/1,\n                                              /*dilation_height=*/1,\n                                              /*dilation_width=*/1,\n                                              /*mode=*/CUDNN_CROSS_CORRELATION,\n                                              /*computeType=*/CUDNN_DATA_FLOAT));\n    // \u8bbe\u7f6e\u6fc0\u6d3b\u5c42\u76f8\u5173\u53c2\u6570\n    cudnnActivationDescriptor_t activation_descriptor;\n    checkCUDNN(cudnnCreateActivationDescriptor(&amp;activation_descriptor));\n    checkCUDNN(cudnnSetActivationDescriptor(activation_descriptor,\n                                            /*mode=*/CUDNN_ACTIVATION_RELU,\n                                            /*reluNanOpt=*/CUDNN_PROPAGATE_NAN,\n                                            /*relu_coef=*/0));\n    // \u83b7\u53d6\u5377\u79ef\u8ba1\u7b97\u7b97\u6cd5\u76f8\u5173\u53c2\u6570\u548cworkspace\n    int cnt = 0;\n    cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn, &amp;cnt);\n    std::cout &lt;&lt; \"cnt: \" &lt;&lt; cnt &lt;&lt; std::endl;\n    cudnnConvolutionFwdAlgoPerf_t convolution_algorithm;\n    int ret_cnt = 0;\n    checkCUDNN(cudnnGetConvolutionForwardAlgorithm_v7(cudnn,\n                                            input_descriptor,\n                                            kernel_descriptor,\n                                            convolution_descriptor,\n                                            output_descriptor,\n                                            1,\n                                            &amp;ret_cnt,\n                                            &amp;convolution_algorithm));\n    size_t workspace_bytes = 0;\n    checkCUDNN(cudnnGetConvolutionForwardWorkspaceSize(cudnn,\n                                                      input_descriptor,\n                                                      kernel_descriptor,\n                                                      convolution_descriptor,\n                                                      output_descriptor,\n                                                      convolution_algorithm.algo,\n                                                      &amp;workspace_bytes));\n    void* d_workspace{nullptr};\n    cudaMalloc(&amp;d_workspace, workspace_bytes);\n    // \u6267\u884c\u5377\u79ef\u8fd0\u7b97\n    checkCUDNN(cudnnConvolutionBiasActivationForward(\n        cudnn, &amp;alpha1, input_descriptor, qptr_gpu, kernel_descriptor, kernel_gpu,\n        convolution_descriptor, convolution_algorithm.algo, d_workspace, workspace_bytes,\n        &amp;alpha2, z_descriptor, outptr_gpu,\n        bias_descriptor, bias_gpu, activation_descriptor, output_descriptor, outptr_gpu));\n    out_tensor.to_cpu(true);\n    out_tensor.save_to_file(\"out_tensor.npz\");\n    // \u9500\u6bc1\u63cf\u8ff0\u7b26\u548c\u53e5\u67c4\n    cudnnDestroyTensorDescriptor(input_descriptor);\n    cudnnDestroyTensorDescriptor(z_descriptor);\n    cudnnDestroyTensorDescriptor(output_descriptor);\n    cudnnDestroyTensorDescriptor(bias_descriptor);\n    cudnnDestroyFilterDescriptor(kernel_descriptor);\n    cudnnDestroyConvolutionDescriptor(convolution_descriptor);\n    cudnnDestroy(cudnn);\n    cudaFree(d_workspace);\n    return 0;\n}\n</code></pre>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B407%E6%9C%8823%E6%97%A5%2023%E6%97%B617%E5%88%8614%E7%A7%92/#_2","title":"\u56db\u3001\u9a8c\u8bc1\u73af\u8282","text":"<p>\u9a8c\u8bc1\u73af\u8282\u6211\u4eec\u53ef\u4ee5\u91c7\u7528pytorch api\u6765\u9a8c\u8bc1cudnn\u7684\u5b9e\u73b0\u662f\u5426\u80fd\u4e0ecpu\u4e0atorch\u7684\u8ba1\u7b97\u7ed3\u679c\u5bf9\u9f50\u3002\u4e3b\u8981\u8fd8\u662f\u7528\u5230npy\u6587\u4ef6\u6765\u4fdd\u5b58\uff0c\u76f8\u5173py\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>import numpy as np\nimport torch.nn.functional as F\nimport torch\ndef _load_tensor(file):\n    with open(file, \"rb\") as f:\n        binary_data = f.read()\n    magic_number, ndims, dtype = np.frombuffer(binary_data, np.uint32, count=3, offset=0)\n    assert magic_number == 0xFCCFE2E2, f\"{file} not a tensor file.\"\n    dims = np.frombuffer(binary_data, np.uint32, count=ndims, offset=3 * 4)\n    if dtype == 0:\n        np_dtype = np.float32\n    elif dtype == 1:\n        np_dtype = np.float16\n    else:\n        assert False, f\"Unsupport dtype = {dtype}, can not convert to numpy dtype\"\n    return np.frombuffer(binary_data, np_dtype, offset=(ndims + 3) * 4).reshape(*dims)\ndef load_tensor(file):\n    if file.endswith(\"npz\"):\n        return np.load(file)['data']\n    elif file.endswith(\"npy\"):\n        return np.load(file)\n    else:\n        return _load_tensor(file)\ndef test():\n    input_tensor = load_tensor('q_tensor.npz')\n    weight_tensor = load_tensor('kernel_tensor.npz')\n    bias_tensor = load_tensor('bias_tensor.npz')\n    out_tensor = load_tensor('out_tensor.npz')\n    input_tensor = torch.as_tensor(input_tensor).float()\n    weight_tensor = torch.as_tensor(weight_tensor).float()\n    bias_tensor = torch.as_tensor(bias_tensor).float()\n    out_tensor = torch.as_tensor(out_tensor).float()\n    print(input_tensor.shape)\n    print(weight_tensor.shape)\n    print(bias_tensor.shape)\n    print(out_tensor.shape)\n    # \u5173\u952e\u65b9\u6cd5 F.conv2d\n    out_tensor_torch = F.conv2d(input_tensor, weight_tensor, bias_tensor, stride=1)\n    out_tensor_torch = F.relu(out_tensor_torch)\n    print(torch.abs(out_tensor_torch - out_tensor).max())\n\nif __name__ == \"__main__\":\n    test()\n</code></pre>"},{"location":"cuda%E7%9B%B8%E5%85%B3/2022%E5%B9%B407%E6%9C%8823%E6%97%A5%2023%E6%97%B617%E5%88%8614%E7%A7%92/#_3","title":"\u4e94\u3001\u603b\u7ed3","text":"<p>\u672c\u6587\u4ee5\u4e8c\u7ef4\u5377\u79ef\u8fd0\u7b97\u4e3a\u4f8b\u7b80\u5355\u4ecb\u7ecd\u4e86cudnn API\u7684\u4f7f\u7528\u4e0e\u9a8c\u8bc1\u3002cuDNN\u4e3acuda\u5f00\u53d1\u8005\u63d0\u4f9b\u4fbf\u5229\uff0c\u4e00\u4e9b\u4e13\u4e1a\u7684cuda\u5f00\u53d1\u8005\u5728\u5199cuda\u7b97\u5b50\u7684\u65f6\u5019\u5e38\u5e38\u505a\u7684\u4e00\u4ef6\u4e8b\u5c31\u662f\u5148\u770b\u770bcudnn\u4e0a\u6709\u6ca1\u6709\u5b9e\u73b0\uff0c\u5e76\u4e14\u9a8c\u8bc1\u81ea\u5df1\u7684\u5b9e\u73b0\u4e0ecudnn\u7684\u5b9e\u73b0\u76f8\u6bd4\u54ea\u4e2a\u66f4\u4f18\u3002\u5728\u65e5\u5e38\u7684cuda\u5f00\u53d1\u4e2d\uff0c\u5bf9cudnn\u7684\u719f\u6089\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u73af\u8282\uff0c\u5b98\u7f51\u7684\u4f8b\u5b50\u8f83\u4e3a\u4e30\u5bcc\uff0c\u9047\u5230\u54ea\u4e2aapi\u4e0d\u4f1a\u7528\u7684\u65f6\u5019\u76f4\u63a5\u5728github\u4e0a\u641c\u7d22\u5c31\u53ef\u4ee5\u627e\u5230\u7528\u4f8b\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/","title":"RoiAlign\u7b97\u5b50\u7684\u524d\u5411\u4f20\u64ad\u4e0e\u53cd\u5411\u4f20\u64ad\u89e3\u8bfb","text":"<p>\u672c\u6587\u5199\u4e8e2024-01-20/21\u4e0b\u5348</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#_1","title":"\u4e00\u3001\u524d\u8a00","text":"<p>\u5fd9\u6d3b\u4e86\u4e00\u4e2a\u591a\u6708\uff0c\u7ec8\u4e8e\u817e\u51fa\u624b\u6765\u5c06\u8fd9\u7bc7\u6587\u7ae0\u5b89\u6392\u8fdb\u4e86TODO List\uff0c\u501f\u7740\u4e00\u4e2a\u5468\u672b\u4e24\u4e2a\u6175\u61d2\u7684\u4e0b\u5348\u68b3\u7406\u4e00\u4e0bRoiAlign\u7684\u5177\u4f53\u5b9e\u73b0\u6b65\u9aa4\u548c\u539f\u7406\u3002</p> <p>\u53ea\u8981\u662f\u5165\u95e8\u4e86\u76ee\u6807\u68c0\u6d4b\u7684\u670b\u53cb\u5c31\u4e00\u5b9a\u77e5\u9053RoiAlign\uff0c\u53ea\u662f\u4e86\u89e3\u7a0b\u5ea6\u4e0d\u4e00\u6837\uff0c\u66fe\u7ecf\u7684\u6211\u770b\u6e90\u7801\u90fd\u770b\u7684\u5934\u75bc\uff0c\u73b0\u5728\u603b\u7b97\u53ef\u4ee5\u6c89\u4e0b\u5fc3\u6765\u6df1\u5165\u7814\u7a76\u4e00\u4e0b\u3002</p> <p>\u4e3a\u4ec0\u4e48\u7814\u7a76\u5b83\u5462\uff1f\u5b9e\u9645\u4e0a\u662f\u6211\u5728\u770bGrounding DINO\u7684\u65f6\u5019\uff0c\u4e00\u76f4\u5411\u524d\u8ffd\u6eaf\u76f8\u5173\u6587\u732e\uff0c\u4eceDINO\u3001DETR\u3001DCN\u7cfb\u5217\u518d\u5230RoiAlign\uff0c\u6211\u4e0d\u7981\u95ee\u81ea\u5df1\uff1aRoiAlign\u524d\u5411\u8ba1\u7b97\u6bd4\u8f83\u597d\u7406\u89e3\uff0c\u90a3\u4e48RoiAlign\u7684\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u662f\u4ec0\u4e48\u6837\u5b50\u5462\uff1f</p> <p>\u4e8e\u662f\uff0c\u5c31\u6709\u4e86\u8fd9\u7bc7\u6587\u7ae0\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#roialign_1","title":"\u4e8c\u3001RoiAlign\u57fa\u672c\u539f\u7406","text":""},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#21-roi-pooling","title":"2.1 Roi Pooling","text":"<p>\u8bf4\u8d77<code>RoiAlign</code>\u5c31\u4e0d\u5f97\u4e0d\u63d0<code>RoiPooling</code>\uff0c\u539f\u59cb\u7248\u672cFasterRCNN\u6807\u51c6\u914d\u7f6e\u3002\u5728two-stage\u68c0\u6d4b\u5668\u4e2d\uff0c\u6709\u4e00\u4e2a\u9700\u8981\u4ece\u6839\u636e\u5019\u9009\u6846\u5750\u6807\u63d0\u53d6\u8f93\u5165\u56fe\u50cf\u7279\u5f81\u7684\u64cd\u4f5c\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u7684\u8f93\u5165\u9700\u8981\u6ee1\u8db3\u8f93\u5165\u4e00\u4e2a\u76ee\u6807\u6846\u548c\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u8f93\u51fa\u4e00\u4e2a\u4ece\u7279\u5f81\u56fe\u4e0a\u62a0\u51fa\u76ee\u6807\u6846\u4f4d\u7f6e\u7684\u5b50\u7279\u5f81\u56fe\u3002</p> <p>\u540c\u65f6\uff0c\u4e3a\u4e86\u4fbf\u4e8e\u540e\u7eed\u6279\u5904\u7406\uff0c\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u53ea\u6709batch\u7ef4\u5ea6\u53ef\u4ee5\u53d8\u5316\uff0cH\u548cW\u7ef4\u5ea6\u4e0d\u80fd\u53d8\u5316\uff0c\u6240\u4ee5\u5c31\u6709\u4e86RoiPooling\u7b97\u5b50\u7684\u8bbe\u8ba1\u3002</p> <p>RoiPooling \u5c31\u662f\u8f93\u5165Roi\u76ee\u6807\u533a\u57df\u7684\u5750\u6807\u6846\u63cf\u8ff0\uff0c\u8f93\u51fa\u76ee\u6807\u6846\u5bf9\u5e94\u7684<code>Roi feature</code>\uff0c\u4e14\u6240\u6709\u8f93\u51fa\u7684feature\u5728<code>C\u3001H\u3001W</code>\u4e09\u4e2a\u65b9\u5411\u4e0a\u4fdd\u6301\u4e00\u81f4\u3002</p> <p>\u5148\u8d34\u51fa\u4e00\u5f20\u56fe\uff0c\u901a\u8fc7\u4e0b\u9762\u8fd9\u5e45\u56fe\u50cf\u89e3\u91caRoiPooling\u7684\u5de5\u4f5c\u539f\u7406.</p> <p></p> <p>\u9488\u5bf9\u4e0a\u56fe</p> <ol> <li>Conv layers\u4f7f\u7528\u7684\u662fVGG16\uff0cfeat_stride=32(\u5373\u8868\u793a\uff0c\u7ecf\u8fc7\u7f51\u7edc\u5c42\u540e\u56fe\u7247\u7f29\u5c0f\u4e3a\u539f\u56fe\u76841/32),\u539f\u56fe800*800,\u6700\u540e\u4e00\u5c42\u7279\u5f81\u56fefeature map\u5927\u5c0f:25*25</li> <li>\u5047\u5b9a\u539f\u56fe\u4e2d\u6709\u4e00region proposal\uff0c\u5927\u5c0f\u4e3a \\(665\\times665\\) \uff0c\u8fd9\u6837\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\u7684\u5927\u5c0f\uff1a665/32=20.78\uff0c\u5373 \\(20.78\\times20.78\\) \uff0c\u5982\u679c\u4f60\u770b\u8fc7Caffe\u7684RoiPooling\u7684C++\u6e90\u7801\uff0c\u5728\u8ba1\u7b97\u7684\u65f6\u5019\u4f1a\u8fdb\u884c\u53d6\u6574\u64cd\u4f5c\uff0c\u4e8e\u662f\u8fdb\u884c\u6240\u8c13\u7684\u7b2c\u4e00\u6b21\u91cf\u5316\uff0c\u5373\u6620\u5c04\u7684\u7279\u5f81\u56fe\u5927\u5c0f\u4e3a20*20\u3002</li> <li>\u5047\u5b9a<code>pooled_w=7,pooled_h=7</code>,\u5373pooling\u540e\u56fa\u5b9a\u6210 \\(7 \\times7\\) \u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002\u5c06\u4e0a\u9762\u5728 feature map\u4e0a\u6620\u5c04\u7684 \\(20 \\times 20\\) \u7684<code>region proposal</code>\u5212\u5206\u621049\u4e2a\u540c\u7b49\u5927\u5c0f\u7684\u5c0f\u533a\u57df\uff0c\u6bcf\u4e2a\u5c0f\u533a\u57df\u7684\u5927\u5c0f20/7=2.86,\u5373 \\(2.86 \\times 2.86\\) \uff0c\u6240\u4ee5\u8fdb\u884c\u7b2c\u4e8c\u6b21\u91cf\u5316\uff0c\u6545\u5c0f\u533a\u57df\u5927\u5c0f\u53d8\u6210 \\(2 \\times 2\\) \u3002</li> <li>\u6bcf\u4e2a \\(2 \\times 2\\) \u7684\u5c0f\u533a\u57df\u91cc\uff0c\u53d6\u51fa\u5176\u4e2d\u6700\u5927\u7684\u50cf\u7d20\u503c\uff0c\u4f5c\u4e3a\u8fd9\u4e2a\u533a\u57df\u7684\"\u4ee3\u8868\"\u3002\u8fd9\u683749\u4e2a\u5c0f\u533a\u57df\u5c31\u8f93\u51fa49\u4e2a\u50cf\u7d20\u503c\uff0c\u7ec4\u6210 \\(7 \\times 7\\) \u5927\u5c0f\u7684feature map\u3002</li> </ol> <p>\u901a\u8fc7\u4e0a\u9762\u53ef\u4ee5\u770b\u51fa\uff0c\u7ecf\u8fc7\u4e24\u6b21\u91cf\u5316\uff0c\u5373\u5c06\u6d6e\u70b9\u6570\u53d6\u6574\uff0c\u539f\u672c\u5728\u7279\u5f81\u56fe\u4e0a\u6620\u5c04\u7684 \\(20\\times20\\) \u5927\u5c0f\u7684region proposal\uff0c\u7ecf\u8fc7\u81ea\u9002\u5e94Pooling\u64cd\u4f5c\u53d8\u4e3a \\(7 \\times 7\\) \uff0c\u8fd9\u6837\u7684\u50cf\u7d20\u504f\u5dee\u52bf\u5fc5\u4f1a\u5bf9\u540e\u5c42\u7684\u56de\u5f52\u5b9a\u4f4d\u4ea7\u751f\u5f71\u54cd\u3002</p> <p>\u4e3a\u4e86\u907f\u514d\u91cf\u5316\u5e26\u6765\u7684\u4f4d\u7f6e\u8868\u5f81\u504f\u5dee\uff0c\u4e8e\u662f\u5c31\u6709\u4e86RoiAlign\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#22-roialign","title":"2.2 RoiAlign","text":"<p>\u4e3a\u4e86\u89e3\u51b3Roi Pooling\u4e24\u6b21\u91cf\u5316\u95ee\u9898\uff0cRoi Align\u4e0d\u518d\u91c7\u7528\u53d6\u6574\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4fdd\u7559\u4e86\u6d6e\u70b9\u6570\u7684\u8fd0\u7b97\uff0c\u5e76\u4f7f\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u7684\u65b9\u5f0f\u6c42\u53d6\u50cf\u7d20\u503c\u3002</p> <p>\u5148\u8bf4\u4e00\u4e0b\u4ec0\u4e48\u662f\u53cc\u7ebf\u6027\u63d2\u503c\u3002</p> <p>\u53cc\u7ebf\u6027\u63d2\u503c\u662f\u6709\u4e24\u4e2a\u53d8\u91cf\u7684\u63d2\u503c\u51fd\u6570\u7684\u7ebf\u6027\u63d2\u503c\u6269\u5c55\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5728\u4e24\u4e2a\u65b9\u5411\u5206\u522b\u8fdb\u884c\u4e00\u6b21\u7ebf\u6027\u63d2\u503c\u3002</p> <p></p> <p>\u5047\u5982\u6211\u4eec\u60f3\u5f97\u5230\u672a\u77e5\u51fd\u6570  \\(f(z)\\) \u5728\u70b9 \\(P = (x, y)\\)  \u7684\u503c\uff0c\u5df2\u77e5\u51fd\u6570 \\(f(z)\\) \u5728 \\(Q_{11} = (x_1, y_1)\\) \u3001 \\(Q_{12}=(x_1, y_2)\\) \uff0c \\(Q_{21}=(x_2,y_1)\\)  \u4ee5\u53ca  \\(Q_{22}=(x_2,y_2)\\)  \u56db\u4e2a\u70b9\u7684\u503c\u3002\u6700\u5e38\u89c1\u7684\u60c5\u51b5\uff0c \\(f(z)\\) \u5c31\u662f\u4e00\u4e2a\u50cf\u7d20\u70b9\u7684\u50cf\u7d20\u503c\u3002\u9996\u5148\u5728 \\(X\\) \u65b9\u5411\u8fdb\u884c\u7ebf\u6027\u63d2\u503c\uff0c\u5f97\u5230</p> \\[ \\begin{align*} &amp; f(R_1) \\approx \\frac{x_2 - x}{x_2 - x_1} f(Q_{11}) + \\frac{x - x_1}{x_2 - x_1} f(Q_{21})\\ where\\ R_1 = (x, y_1) \\\\ &amp; f(R_2) \\approx \\frac{x_2 - x}{x_2 - x_1} f(Q_{12}) + \\frac{x - x_1}{x_2 - x_1} f(Q_{22})\\ where\\ R_2 = (x, y_2) \\end{align*} \\] <p>\u7136\u540e\u5728y\u65b9\u5411\u8fdb\u884c\u7ebf\u6027\u63d2\u503c\uff0c\u5f97\u5230</p> \\[ f(P) \\approx \\frac{y_2 - y}{y_2 - y_1} f(R_1) + \\frac{y - y_1}{y_2 - y_1} f(R_2) \\] <p>\u7efc\u5408\u8d77\u6765\u5c31\u662f\u53cc\u7ebf\u6027\u63d2\u503c\u7684\u7ed3\u679c\uff1a</p> \\[ \\begin{align*} f(x, y) &amp;\\approx \\frac{(x_2 - x)(y_2 - y)}{(x_2 - x_1)(y_2 - y_1)}f(Q_{11})  \\\\  &amp;+ \\frac{(x - x_1)(y_2 - y)}{(x_2 - x_1)(y_2 - y_1)}f(Q_{21}) \\\\ &amp;+ \\frac{(x_2 - x)(y - y_1)}{(x_2 - x_1)(y_2 - y_1)}f(Q_{12})  \\\\ &amp;+ \\frac{(x - x_1)(y - y_1)}{(x_2 - x_1)(y_2 - y_1)}f(Q_{22}) \\end{align*} \\] <p>\u56e0\u6b64\u53cc\u7ebf\u6027\u63d2\u503c\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0e\u516b\u4e2a\u503c\u6709\u5173\u7cfb\uff0c\u56db\u4e2a\u51fd\u6570\u503c\u548c\u56db\u4e2a\u4e0e\u4e4b\u5bf9\u5e94\u7684\u7cfb\u6570\u503c\u3002</p> <p>\u56de\u8fc7\u5934\u6211\u4eec\u770b\u4e00\u4e0bRoiAlign\u7b97\u5b50\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8fd9\u56fe\u89e3\u91caRoiAlign\u7684\u5de5\u4f5c\u539f\u7406</p> <p></p> <p>\u9488\u5bf9\u4e0a\u56fe</p> <ol> <li><code>Conv layers</code>\u4f7f\u7528\u7684\u662fVGG16\uff0cfeat_stride=32(\u5373\u8868\u793a\uff0c\u7ecf\u8fc7\u7f51\u7edc\u5c42\u540e\u56fe\u7247\u7f29\u5c0f\u4e3a\u539f\u56fe\u76841/32),\u539f\u56fe \\(800 \\times 800\\) ,\u6700\u540e\u4e00\u5c42\u7279\u5f81\u56fefeature map\u5927\u5c0f\uff1a \\(25 \\times 25\\)</li> <li>\u5047\u5b9a\u539f\u56fe\u4e2d\u6709\u4e00region proposal\uff0c\u5927\u5c0f\u4e3a \\(665 \\times 665\\) \uff0c\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\u7684\u5927\u5c0f\uff1a665/32=20.78,\u5373 \\(20.78 \\times 20.78\\) \uff0c\u6b64\u65f6\uff0c\u6ca1\u6709\u50cfRoiPooling\u90a3\u6837\u5c31\u884c\u53d6\u6574\u64cd\u4f5c\uff0c\u4fdd\u7559\u6d6e\u70b9\u6570</li> <li>\u5047\u5b9a<code>pooled_w=7,pooled_h=7</code>\uff0c\u5373pooling\u540e\u56fa\u5b9a\u6210 \\(7 \\times 7\\) \u5927\u5c0f\u7684\u7279\u5f81\u56fe\uff0c\u6240\u4ee5\u5c06\u5728feature map\u4e0a\u6620\u5c04\u7684 \\(20.78 \\times 20.78\\) \u7684region proposal\u5212\u5206\u621049\u4e2a\u540c\u7b49\u5927\u5c0f\u7684\u5c0f\u533a\u57df\uff0c\u6bcf\u4e2a\u5c0f\u533a\u57df\u7684\u5927\u5c0f20.78/7=2.97,\u5373\u533a\u57df\u5927\u5c0f\u4e3a \\(2.97 \\times 2.97\\)</li> <li>\u5047\u5b9a\u91c7\u6837\u70b9\u6570\u4e3a4\uff0c\u5373\u8868\u793a\u5bf9\u4e8e\u6bcf\u4e2a \\(2.97 \\times 2.97\\) \u7684\u5c0f\u533a\u57df\uff0c\u5e73\u5206\u56db\u4efd\uff0c\u6bcf\u4e00\u4efd\u53d6\u5176\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\uff0c\u800c\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\u7684\u50cf\u7d20\uff0c\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u6cd5\u8fdb\u884c\u8ba1\u7b97\uff0c\u8fd9\u6837\uff0c\u5c31\u4f1a\u5f97\u5230\u56db\u4e2a\u70b9\u7684\u50cf\u7d20\u503c\uff0c\u5982\u4e0b\u56fe</li> </ol> <p></p> <p>\u4e0a\u56fe\u4e2d\uff0c\u56db\u4e2a\u7ea2\u8272\u53c9\u53c9\u2018\u00d7\u2019\u7684\u50cf\u7d20\u503c\u662f\u901a\u8fc7\u53cc\u7ebf\u6027\u63d2\u503c\u7b97\u6cd5\u8ba1\u7b97\u5f97\u5230\u7684\u3002</p> <p>\u6700\u540e\uff0c\u53d6\u56db\u4e2a\u50cf\u7d20\u503c\u4e2d\u6700\u5927\u503c\u6216\u8005\u5e73\u5747\u503c(\u6709\u53c2\u6570\u53ef\u4ee5\u8bbe\u5b9a\u8be5\u64cd\u4f5c)\u4f5c\u4e3a\u8fd9\u4e2a\u5c0f\u533a\u57df(\u5373\uff1a \\(2.97 \\times 2.97\\) \u5927\u5c0f\u7684\u533a\u57df)\u7684\u50cf\u7d20\u503c\uff0c\u5982\u6b64\u7c7b\u63a8\u540c\u6837\u662f49\u4e2a\u5c0f\u533a\u57df\u5f97\u523049\u4e2a\u50cf\u7d20\u503c\uff0c\u7ec4\u6210 \\(7 \\times 7\\) \u5927\u5c0f\u7684feature map\u3002</p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u901a\u8fc7\u89e3\u8bfbmmcv\u4e2d<code>RoiAlign</code>\u7b97\u5b50\u7684\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u7684\u4ee3\u7801\u6765\u7406\u89e3\u5177\u4f53\u64cd\u4f5c\u7ec6\u8282\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#roialigncpu","title":"\u4e09\u3001RoiAlign\u7b97\u5b50CPU\u7248\u672c\u89e3\u8bfb","text":"<p>mmcv\u4e2d\u4ee3\u7801\u5730\u5740\uff1a</p> <p>https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/pytorch/cpu/roi_align.cpp</p> <p>\u9996\u5148<code>Line 11-21</code>\u5b9a\u4e49\u7528\u4e8e\u5b58\u50a8\u53cc\u7ebf\u6027\u63d2\u503c\u7684\u56db\u4e2a\u81ea\u53d8\u91cf\u548c\u56db\u4e2a\u6743\u91cd\u7cfb\u6570\u7684\u7ed3\u6784\u4f53<code>PreCalc</code></p> <pre><code>// implementation taken from Caffe2\ntemplate &lt;typename T&gt;\nstruct PreCalc {\n  // \u7528\u4e8e\u8bb0\u5f55\u5b58\u653e\u56db\u4e2a\u70b9\u7684\u50cf\u7d20\u503c\u7684\u7d22\u5f15\u503c\n  int pos1;\n  int pos2;\n  int pos3;\n  int pos4;\n  // \u5bf9\u5e94\u56db\u4e2a\u70b9\u7684\u6743\u91cd\u503c\n  T w1;\n  T w2;\n  T w3;\n  T w4;\n};\n</code></pre> <p>\u7136\u540e\u6211\u4eec\u5148\u770b\u770b\u8c03\u7528\u5173\u7cfb\uff0c\u5728<code>Line 384-403</code>\u884c\uff0c\u5b9a\u4e49\uff1a</p> <pre><code>void ROIAlignForwardCPULauncher(Tensor input, Tensor rois, Tensor output,\n                                Tensor argmax_y, Tensor argmax_x,\n                                int aligned_height, int aligned_width,\n                                float spatial_scale, int sampling_ratio,\n                                int pool_mode, bool aligned) {\n  /*\n  input\uff1a\u8f93\u5165\u7279\u5f81\u56fe\n  rois\uff1a\u8f93\u5165roi\u5750\u6807\uff0c\u7ef4\u5ea6 [N,5] \u7b2c\u4e00\u5217\u8868\u793aroi\u5750\u6807\u7684batch index\n  output\uff1a\u8f93\u51fatensor\u3002\u7ef4\u5ea6[B, C, aligned_height, aligned_width]\n  argmax_y\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684y\u5750\u6807\n  argmax_x\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684x\u5750\u6807\n  aligned_height\uff1a\u8f93\u51faFeatureMap\u7684H\n  aligned_width\uff1a\u8f93\u51faFeatureMap\u7684W\n  spatial_scale\uff1a\u5f53\u524d\u7279\u5f81\u56fe / \u539f\u56fe\u5927\u5c0f \u7684\u503c\n  sampling_ratio\uff1a\u5212\u5206\u597d aligned_height x aligned_width \u4e2a\u7f51\u683c\u540e\uff0c\u5355\u4e2a\u7f51\u683c\u7528sampling_ratio\u4e2a\u70b9\u8868\u793a\n  pool_mode\uff1a1 \u8868\u793a \u63cf\u8ff0\u5355\u4e2a\u7f51\u683c\u7684\u70b9\u662f\u5bf9\u6240\u6709\u91c7\u6837\u70b9\u53bb\u5e73\u5747 0 \u8868\u793a\u53d6\u6700\u5927\n  aligned\uff1a\u53cc\u7ebf\u6027\u63d2\u503c\u7684\u6a21\u5f0f\u63a7\u5236\u53c2\u6570 \u8868\u793a\u662f\u5426\u91c7\u7528\u5750\u6807\u5bf9\u9f50\u6a21\u5f0f\n  */\n  int output_size = output.numel();\n  int channels = input.size(1);\n  int height = input.size(2);\n  int width = input.size(3);\n\n  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n      input.scalar_type(), \"ROIAlign_forward\", [&amp;] {\n        ROIAlignForward&lt;scalar_t&gt;(\n            output_size, input.data_ptr&lt;scalar_t&gt;(), rois.data_ptr&lt;scalar_t&gt;(),\n            output.data_ptr&lt;scalar_t&gt;(), argmax_y.data_ptr&lt;scalar_t&gt;(),\n            argmax_x.data_ptr&lt;scalar_t&gt;(), aligned_height, aligned_width,\n            static_cast&lt;scalar_t&gt;(spatial_scale), sampling_ratio, pool_mode,\n            aligned, channels, height, width);\n      });\n}\n</code></pre> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u770b\u4e00\u4e0b<code>ROIAlignForward</code>\u51fd\u6570\uff0c<code>Line110-214</code></p> <pre><code>template &lt;typename T&gt;\nvoid ROIAlignForward(const int nthreads, const T* input, const T* rois,\n                     T* output, T* argmax_y, T* argmax_x,\n                     const int pooled_height, const int pooled_width,\n                     const T spatial_scale, const int sampling_ratio,\n                     const int pool_mode,  // 0 - max pool, 1 - avg pool\n                     const bool aligned, const int channels, const int height,\n                     const int width) {\n  /*\n  nthreads\uff1a\u8868\u9762\u610f\u601d\u662f\u7ebf\u7a0b\u4e2a\u6570\uff0c\u5b9e\u9645\u4e0a\u662f\u8f93\u51fa\u7684\u5143\u7d20\u603b\u4e2a\u6570\uff0c\u5373N x C x pooled_height x pooled_width\n  input\uff1a\u8f93\u5165feature map\u7684\u5185\u5b58\u6307\u9488\n  rois\uff1a\u8f93\u5165rois\u7684\u5185\u5b58\u6307\u9488\n  output\uff1a\u8f93\u51fafeature map\u7684\u5185\u5b58\u6307\u9488\n  argmax_y\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684y\u5750\u6807\n  argmax_x\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684x\u5750\u6807\n  pooled_height\uff1a\u8f93\u51faFeatureMap\u7684H\n  pooled_width\uff1a\u8f93\u51faFeatureMap\u7684W\n  spatial_scale\uff1a\u5f53\u524d\u8f93\u5165\u7684input feature map\u7684\u7a7a\u95f4\u5927\u5c0f / \u539f\u56fe\u5927\u5c0f \u6bd4\u59821/16\n  sampling_ratio\uff1a\u5212\u5206\u597d aligned_height x aligned_width \u4e2a\u7f51\u683c\u540e\uff0c\u5355\u4e2a\u7f51\u683c\u7528sampling_ratio\u4e2a\u70b9\u8868\u793a\n  pool_mode\uff1a1 \u8868\u793a \u63cf\u8ff0\u5355\u4e2a\u7f51\u683c\u7684\u70b9\u662f\u5bf9\u6240\u6709\u91c7\u6837\u70b9\u53bb\u5e73\u5747 0 \u8868\u793a\u53d6\u6700\u5927\n  aligned\uff1a\u53cc\u7ebf\u6027\u63d2\u503c\u53c2\u6570\uff0c\u662f\u89d2\u70b9\u5bf9\u9f50\u8fd8\u662f\u4e2d\u5fc3\u5bf9\u9f50\uff0c\u89d2\u70b9\u5bf9\u9f50\u8bbe\u7f6e\u4e3a0\uff0c\u4e2d\u5fc3\u5bf9\u9f50\u8bbe\u7f6e\u4e3a1\n  channels\uff1a\u8f93\u5165channels\n  height\uff1a\u8f93\u5165feature map\u7684\u9ad8\n  width\uff1a\u8f93\u5165feature map\u7684\u5bbd\n  */\n\n  // \u6839\u636e\u8f93\u51fa\u603b\u5143\u7d20\u4e2a\u6570\u8ba1\u7b97roi\u7684\u4e2a\u6570\n  int n_rois = nthreads / channels / pooled_width / pooled_height;\n\n  // (n, c, ph, pw) is an element in the pooled output\n  // can be parallelized using omp\n  // #pragma omp parallel for num_threads(32)\n  // \u904d\u5386\u6bcf\u4e00\u4e2aroi \u8ba1\u7b97\u5176\u5bf9\u5e94\u7684feature map\n  for (int n = 0; n &lt; n_rois; n++) {\n    // \u5f53\u524droi \u5bf9\u5e94\u8f93\u51fafeature \u7684\u5185\u5b58\u504f\u79fb\n    int index_n = n * channels * pooled_width * pooled_height;\n\n    // \u9996\u5730\u5740\u504f\u79fb\n    const T* offset_rois = rois + n * 5;\n    // \u53d6\u51faroi\u5bf9\u5e94\u7684batch index\n    int roi_batch_ind = offset_rois[0];\n\n    // Do not use rounding; this implementation detail is critical\n    // \u662f\u5426\u662f\u4e2d\u5fc3\u5bf9\u9f50 aligned \u7b49\u4e8e1\u8868\u793a\u4e2d\u5fc3\u5bf9\u9f50 \n    T offset = aligned ? (T)0.5 : (T)0.0;\n    // roi\u4e2d\u5b58\u50a8\u7684\u662f\u5b9e\u9645\u5750\u6807\uff0c\u8fd9\u91cc\u8f6c\u6362\u4e3a\u5728roi\u4e0a\u7684\u5750\u6807\n    T roi_start_w = offset_rois[1] * spatial_scale - offset;\n    T roi_start_h = offset_rois[2] * spatial_scale - offset;\n    T roi_end_w = offset_rois[3] * spatial_scale - offset;\n    T roi_end_h = offset_rois[4] * spatial_scale - offset;\n\n    // roi\u7684\u5bbd\u548c\u9ad8\n    T roi_width = roi_end_w - roi_start_w;\n    T roi_height = roi_end_h - roi_start_h;\n    if (aligned) {\n      AT_ASSERTM(roi_width &gt;= 0 &amp;&amp; roi_height &gt;= 0,\n                 \"ROIs in ROIAlign cannot have non-negative size!\");\n    } else {  // for backward-compatibility only\n      roi_width = std::max(roi_width, (T)1.);\n      roi_height = std::max(roi_height, (T)1.);\n    }\n\n    // \u5c06roi_height x roi_width \u5212\u5206\u6210 pooled_height x pooled_width\u4e2a\u7f51\u683c\n    // \u5355\u4e2a\u7f51\u683c\u7684\u5c3a\u5bf8\u5728\u8f93\u5165feature map\u957f\u5ea6\u548c\u5bbd\u5ea6\u65b9\u5411\u4e0a\u7684\u5927\u5c0f\n    T bin_size_h = static_cast&lt;T&gt;(roi_height) / static_cast&lt;T&gt;(pooled_height);\n    T bin_size_w = static_cast&lt;T&gt;(roi_width) / static_cast&lt;T&gt;(pooled_width);\n\n    // We use roi_bin_grid to sample the grid and mimic integral\n    // \u5355\u4e2a\u7f51\u683c\u91c7\u7528\u591a\u5c11\u4e2a\u5b50\u7f51\u683c\u70b9\u91c7\u96c6\u8868\u793a\n    // \u5982\u679csampling_ratio &gt; 0 \u5c31\u662f sampling_ratio x sampling_ratio \u4e2a\u70b9\n    // \u5728\u5c0f\u4e8e\u96f6\u7684\u60c5\u51b5\u4e0b \u9ad8\u5ea6\u65b9\u5411\u70b9\u7684\u5c3a\u5ea6\u4e3a ceil(roi_height / pooled_height) \u81ea\u52a8\u8ba1\u7b97\n    // \u5373 \u5355\u4e2a\u7f51\u683c\u7684\u5c3a\u5bf8\u5728\u8f93\u5165feature map\u957f\u5ea6\u548c\u5bbd\u5ea6\u65b9\u5411\u4e0a\u7684\u5927\u5c0f ceil\u4e4b\u540e\u4f5c\u4e3a\u957f\u548c\u5bbd\u7684\u5927\u5c0f\n    int roi_bin_grid_h = (sampling_ratio &gt; 0)\n                             ? sampling_ratio\n                             : ceilf(roi_height / pooled_height);  // e.g., = 2\n\n    int roi_bin_grid_w =\n        (sampling_ratio &gt; 0) ? sampling_ratio : ceilf(roi_width / pooled_width);\n\n    // \u5355\u4e2a\u7f51\u683c\u70b9\u88ab\u51e0\u4e2a\u70b9\u8868\u793a\n    // When the grid is empty, output zeros == 0/1, instead of NaN.\n    const T count = std::max(roi_bin_grid_h * roi_bin_grid_w, 1);  // e.g. = 4\n\n    // \u63a5\u4e0b\u6765\u662f\u53cc\u7ebf\u6027\u63d2\u503c\u73af\u8282\n    // \u8c03\u7528pre_calc_for_bilinear_interpolate\u6bcf\u4e00\u4e2a\u7f51\u683c\u9700\u8981\u7684\u70b9\u7684\u4e2a\u6570\n    // \u4e00\u4e2a\u7f51\u683c\u6709roi_bin_grid_h * roi_bin_grid_w\u4e2a\u70b9\n    // \u4e00\u5171 pooled_width * pooled_height \u4e2a\u7f51\u683c\n    // we want to precalculate indices and weights shared by all channels,\n    // this is the key point of optimization\n    std::vector&lt;PreCalc&lt;T&gt;&gt; pre_calc(roi_bin_grid_h * roi_bin_grid_w *\n                                     pooled_width * pooled_height);\n    pre_calc_for_bilinear_interpolate(\n        height, width, pooled_height, pooled_width, roi_bin_grid_h,\n        roi_bin_grid_w, roi_start_h, roi_start_w, bin_size_h, bin_size_w,\n        roi_bin_grid_h, roi_bin_grid_w, pre_calc);\n\n    // \u904d\u5386channel \u5728\u7a7a\u95f4\u65b9\u5411\u4e0a\u8ba1\u7b97feature map\n    for (int c = 0; c &lt; channels; c++) {\n      // \u8f93\u5165feature map B\uff0cC\uff0cH\uff0cW\n      // index_n \u662f \u5f53\u524d\u8f93\u51fafeature \u7684 batch \u7ef4\u5ea6\u4e0a\u7684\u504f\u79fb\n      // index_n = n * channels * pooled_width * pooled_height;\n\n      // index_n_c \u662f \u5f53\u524d\u8f93\u51fafeature \u5728 c\u901a\u9053\u4e0a\u7684\u504f\u79fb\n      int index_n_c = index_n + c * pooled_width * pooled_height;\n      // \u8ba1\u7b97 \u5f53\u524d roi_batch_ind batch\u4f4d\u7f6e c\u901a\u9053 \u8f93\u5165feature map\u6307\u5411 \u7684\u5185\u5bb9\u5730\u5740\n      // \u5373 &amp;input[roi_batch_ind][c]\u7684\u9996\u5730\u5740\n      const T* offset_input =\n          input + (roi_batch_ind * channels + c) * height * width;\n      int pre_calc_index = 0;\n\n      // \u904d\u5386\u6bcf\u4e00\u4e2a\u7f51\u683c\uff0c\u8fdb\u884c\u586b\u5145\n      for (int ph = 0; ph &lt; pooled_height; ph++) {\n        for (int pw = 0; pw &lt; pooled_width; pw++) {\n          // \u8ba1\u7b97\u8f93\u51fafeature \u5bf9\u5e94 \u7f51\u683c\u7d22\u5f15\n          int index = index_n_c + ph * pooled_width + pw;\n\n          // \u5b9a\u4e49\u8f93\u51fa\u503c\u3001\u6700\u5927\u503c\u3001\u6700\u5927\u503c\u7d22\u5f15\n          T output_val = 0.;\n          T maxval = -10000;\n          T maxidx_y = -1.f, maxidx_x = -1.f;\n          // \u904d\u5386\u7528\u4e8e\u8ba1\u7b97\u5f53\u524d\u7f51\u683c\u70b9\u7684\u6240\u6709\u70b9\n          for (int iy = 0; iy &lt; roi_bin_grid_h; iy++) {\n            // \u8ba1\u7b97 \u70b9\u96c6\u4e2d\u7684y\u5750\u6807\n            // roi_start_h \u662f roi \u8d77\u59cb\u5750\u6807\n            // ph * bin_size_h \u662f \u5f53\u524d\u7f51\u683cy\u65b9\u5411\u504f\u79fb\n            // (iy + .5f) * bin_size_h / static_cast&lt;T&gt;(roi_bin_grid_h)\n            // \u662f \u5728 bin\u4e2d\u7684y\u65b9\u5411\u504f\u79fb\n            // \u5373 \u5c06\u4e00\u4e2a bin_size_h \u5206\u6210\u4e86 roi_bin_grid_h \u4efd\n            const T y = roi_start_h + ph * bin_size_h +\n                        static_cast&lt;T&gt;(iy + .5f) * bin_size_h /\n                            static_cast&lt;T&gt;(roi_bin_grid_h);\n            for (int ix = 0; ix &lt; roi_bin_grid_w; ix++) {\n              const T x = roi_start_w + pw * bin_size_w +\n                          static_cast&lt;T&gt;(ix + .5f) * bin_size_w /\n                              static_cast&lt;T&gt;(roi_bin_grid_w);\n              // \u6839\u636e\u9884\u5148\u8ba1\u7b97\u7684\u503c\u8fdb\u884c\u52a0\u6743\n              PreCalc&lt;T&gt; pc = pre_calc[pre_calc_index];\n              T val = pc.w1 * offset_input[pc.pos1] +\n                      pc.w2 * offset_input[pc.pos2] +\n                      pc.w3 * offset_input[pc.pos3] +\n                      pc.w4 * offset_input[pc.pos4];\n              // \u6c42\u53d6\u6700\u5927\u503c \u5e76\u8bb0\u5f55\u5750\u6807\n              if (val &gt; maxval) {\n                maxval = val;\n                maxidx_y = y;\n                maxidx_x = x;\n              }\n              // \u6c42\u548c\n              output_val += val;\n              // \u79fb\u52a8\u7d22\u5f15\n              pre_calc_index += 1;\n            }\n          }\n          // \u5728\u6bcf\u4e2a\u7f51\u683c\u4e2d \u5982\u679cpool_mode\u4e3a0 \u5219\u6267\u884c\u5bf9\u91c7\u6837\u70b9\u96c6\u5408\u6267\u884cmax pooling\n          // \u5982\u679c pool_mode \u4e3a1 \u5c31\u53d6\u5e73\u5747\n          if (pool_mode == 0) {\n            // We do max pooling inside a bin\n            output[index] = maxval;\n            argmax_y[index] = maxidx_y;\n            argmax_x[index] = maxidx_x;\n          } else if (pool_mode == 1) {\n            // We do average (integral) pooling inside a bin\n            output[index] = output_val / count;\n          }  // if\n        }    // for pw\n      }      // for ph\n    }        // for c\n  }          // for n\n}\n</code></pre> <p>\u4e0b\u9762\u6211\u4eec\u770b\u4e00\u4e0b\u6bcf\u4e00\u4e2a\u7f51\u683c\u9700\u8981\u7684\u70b9\u662f\u600e\u4e48\u751f\u6210\u7684\uff0c\u529f\u80fd\u5b9e\u73b0\u5728<code>pre_calc_for_bilinear_interpolate</code>\u51fd\u6570<code>Line 23-108</code></p> <pre><code>template &lt;typename T&gt;\nvoid pre_calc_for_bilinear_interpolate(\n    const int height, const int width, const int pooled_height,\n    const int pooled_width, const int iy_upper, const int ix_upper,\n    T roi_start_h, T roi_start_w, T bin_size_h, T bin_size_w,\n    int roi_bin_grid_h, int roi_bin_grid_w, std::vector&lt;PreCalc&lt;T&gt;&gt;&amp; pre_calc) \n/*\nheight\uff1a\u8f93\u5165feature map\u7684height\nwidth\uff1a\u8f93\u5165feature map\u7684width\npooled_height\uff1a\u8f93\u51fafeature map\u7684pooled_height\npooled_width\uff1a\u8f93\u51fafeature map\u7684pooled_width\niy_upper\uff1a\u4e00\u4e2a\u7f51\u683c\u5212\u5206\u6210iy_upper * ix_upper\u4e2a\u70b9\u8868\u793a\nix_upper\uff1a\u4e00\u4e2a\u7f51\u683c\u5212\u5206\u6210iy_upper * ix_upper\u4e2a\u70b9\u8868\u793a\nroi_start_h\uff1aroi y\u65b9\u5411\u8d77\u59cb\u5750\u6807\nroi_start_w\uff1aroi x\u65b9\u5411\u8d77\u59cb\u5750\u6807\nbin_size_h\uff1a\u5355\u4e2a\u7f51\u683c\u7684\u9ad8\u5ea6\nbin_size_w\uff1a\u5355\u4e2a\u7f51\u683c\u7684\u5bbd\u5ea6\nroi_bin_grid_h\uff1a\u4e00\u4e2a\u7f51\u683c\u5212\u5206\u6210roi_bin_grid_h * roi_bin_grid_w\u4e2a\u70b9\u8868\u793a\nroi_bin_grid_w\uff1a\u4e00\u4e2a\u7f51\u683c\u5212\u5206\u6210roi_bin_grid_h * roi_bin_grid_w\u4e2a\u70b9\u8868\u793a\npre_calc\uff1a\u8f93\u51fa\u70b9\u7684vector\n*/\n\n{\n  int pre_calc_index = 0;\n  // \u904d\u5386\u7528\u4e8e\u8ba1\u7b97\u5f53\u524d\u7f51\u683c\u70b9\u7684\u6240\u6709\u70b9\n  for (int ph = 0; ph &lt; pooled_height; ph++) {\n    for (int pw = 0; pw &lt; pooled_width; pw++) {\n      for (int iy = 0; iy &lt; iy_upper; iy++) {\n        // \u8ba1\u7b97 \u70b9\u96c6 \u4e2d\u7684y\u5750\u6807\n        // roi_start_h \u662f roi \u8d77\u59cb\u5750\u6807\n        // ph * bin_size_h \u662f \u5f53\u524d\u7f51\u683cy\u65b9\u5411\u504f\u79fb\n        // (iy + .5f) * bin_size_h / static_cast&lt;T&gt;(roi_bin_grid_h)\n        // \u662f \u5728 bin\u4e2d\u7684y\u65b9\u5411\u504f\u79fb\n        // \u5373 \u5c06\u4e00\u4e2a bin_size_h \u5206\u6210\u4e86 roi_bin_grid_h \u4efd\n        const T yy = roi_start_h + ph * bin_size_h +\n                     static_cast&lt;T&gt;(iy + .5f) * bin_size_h /\n                         static_cast&lt;T&gt;(roi_bin_grid_h);  // e.g., 0.5, 1.5\n        for (int ix = 0; ix &lt; ix_upper; ix++) {\n          // \u540c\u7406\u6c42 \u70b9\u96c6 \u4e2d\u7684\u70b9\u7684x\u5750\u6807\n          const T xx = roi_start_w + pw * bin_size_w +\n                       static_cast&lt;T&gt;(ix + .5f) * bin_size_w /\n                           static_cast&lt;T&gt;(roi_bin_grid_w);\n\n          T x = xx;\n          T y = yy;\n          // \u5982\u679c\u5750\u6807\u4e0d\u5408\u6cd5\u5c31\u76f4\u63a5\u8fd4\u56de\n          // deal with: inverse elements are out of feature map boundary\n          if (y &lt; -1.0 || y &gt; height || x &lt; -1.0 || x &gt; width) {\n            // empty\n            PreCalc&lt;T&gt; pc;\n            pc.pos1 = 0;\n            pc.pos2 = 0;\n            pc.pos3 = 0;\n            pc.pos4 = 0;\n            pc.w1 = 0;\n            pc.w2 = 0;\n            pc.w3 = 0;\n            pc.w4 = 0;\n            pre_calc[pre_calc_index] = pc;\n            pre_calc_index += 1;\n            continue;\n          }\n\n          if (y &lt;= 0) {\n            y = 0;\n          }\n          if (x &lt;= 0) {\n            x = 0;\n          }\n          // \u53cc\u7ebf\u6027\u63d2\u503c\u90e8\u5206\n          // \u8ba1\u7b97\u79bbx\uff0cy\u6700\u8fd1\u7684\u56db\u4e2a\u70b9\u7684\u5750\u6807\n          int y_low = (int)y;\n          int x_low = (int)x;\n          int y_high;\n          int x_high;\n\n          if (y_low &gt;= height - 1) {\n            y_high = y_low = height - 1;\n            y = (T)y_low;\n          } else {\n            y_high = y_low + 1;\n          }\n\n          if (x_low &gt;= width - 1) {\n            x_high = x_low = width - 1;\n            x = (T)x_low;\n          } else {\n            x_high = x_low + 1;\n          }\n          // \u8ba1\u7b97\u7cfb\u6570\n          T ly = y - y_low;\n          T lx = x - x_low;\n          T hy = 1. - ly, hx = 1. - lx;\n          T w1 = hy * hx, w2 = hy * lx, w3 = ly * hx, w4 = ly * lx;\n\n          // \u770b\u516c\u5f0f \u5206\u6bcd\u90fd\u662f1\n          // \u56e0\u4e3ax_2 - x_1 = 1\n          // y_2 - y_1 = 1\n          // \u53cd\u6620\u5230\u4ee3\u7801\n          // \u5373 y_high - y_low = 1\n          //    x_high - x_low = 1\n          // \u8ba1\u7b97\u56db\u4e2a\u6743\u91cd\u503c\u5bf9\u5e94\u7684\u7cfb\u6570\u5bf9\u5e94\u7684\u7d22\u5f15\u503c\n          // save weights and indices\n          PreCalc&lt;T&gt; pc;\n          pc.pos1 = y_low * width + x_low;\n          pc.pos2 = y_low * width + x_high;\n          pc.pos3 = y_high * width + x_low;\n          pc.pos4 = y_high * width + x_high;\n          // \u5b58\u50a8 \u63d2\u503c \u7cfb\u6570\n          pc.w1 = w1;\n          pc.w2 = w2;\n          pc.w3 = w3;\n          pc.w4 = w4;\n          pre_calc[pre_calc_index] = pc;\n\n          pre_calc_index += 1;\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>\u4e0b\u9762\u6211\u4eec\u770b\u4e00\u4e0b\u53cd\u5411\u4f20\u64ad\u662f\u5982\u4f55\u6267\u884c\u7684\u3002</p> <p>\u6574\u4f53\u6d41\u7a0b\u53d1\u8d77\u51fd\u6570\u5728<code>ROIAlignBackwardCPULauncher</code>\u5f53\u4e2d</p> <pre><code>void ROIAlignBackwardCPULauncher(Tensor grad_output, Tensor rois,\n                                 Tensor argmax_y, Tensor argmax_x,\n                                 Tensor grad_input, int aligned_height,\n                                 int aligned_width, float spatial_scale,\n                                 int sampling_ratio, int pool_mode,\n                                 bool aligned)\n/*\ngrad_output\uff1a\u5bf9roi feature map\u7684\u68af\u5ea6\u7d2f\u8ba1\u4fe1\u606f \u7ef4\u5ea6\u4e3a [N, C, H, W] H\u548cW\u4e3a pooled_height \u548c pooled_width\nrois\uff1aroi\u8f93\u5165\u6570\u636e\nargmax_y\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684y\u5750\u6807\nargmax_x\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684x\u5750\u6807\ngrad_input\uff1a\u5bf9\u8f93\u5165\u7ed9Roi Align\u7684feature map\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u521d\u59cb\u5316\u4e3a\u51680\naligned_height\uff1apooled_height\naligned_width\uff1apooled_width\nspatial_scale\uff1a\u5f53\u524d\u8f93\u5165\u7684input feature map\u7684\u7a7a\u95f4\u5927\u5c0f / \u539f\u56fe\u5927\u5c0f \u6bd4\u59821/16\nsampling_ratio\uff1a\u5212\u5206\u597d aligned_height x aligned_width \u4e2a\u7f51\u683c\u540e\uff0c\u5355\u4e2a\u7f51\u683c\u7528sampling_ratio\u4e2a\u70b9\u8868\u793a\npool_mode\uff1a1 \u8868\u793a \u63cf\u8ff0\u5355\u4e2a\u7f51\u683c\u7684\u70b9\u662f\u5bf9\u6240\u6709\u91c7\u6837\u70b9\u53bb\u5e73\u5747 0 \u8868\u793a\u53d6\u6700\u5927\naligned\uff1a\u53cc\u7ebf\u6027\u63d2\u503c\u53c2\u6570\uff0c\u662f\u89d2\u70b9\u5bf9\u9f50\u8fd8\u662f\u4e2d\u5fc3\u5bf9\u9f50\uff0c\u89d2\u70b9\u5bf9\u9f50\u8bbe\u7f6e\u4e3a0\uff0c\u4e2d\u5fc3\u5bf9\u9f50\u8bbe\u7f6e\u4e3a1\n*/\n{\n  int output_size = grad_output.numel();\n  int channels = grad_input.size(1);\n  int height = grad_input.size(2);\n  int width = grad_input.size(3);\n\n  // get stride values to ensure indexing into gradients is correct.\n  int n_stride = grad_output.stride(0);\n  int c_stride = grad_output.stride(1);\n  int h_stride = grad_output.stride(2);\n  int w_stride = grad_output.stride(3);\n\n  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n      grad_output.scalar_type(), \"ROIAlign_backward\", [&amp;] {\n        ROIAlignBackward&lt;scalar_t&gt;(\n            output_size, grad_output.data_ptr&lt;scalar_t&gt;(),\n            rois.data_ptr&lt;scalar_t&gt;(), argmax_y.data_ptr&lt;scalar_t&gt;(),\n            argmax_x.data_ptr&lt;scalar_t&gt;(), grad_input.data_ptr&lt;scalar_t&gt;(),\n            aligned_height, aligned_width, static_cast&lt;scalar_t&gt;(spatial_scale),\n            sampling_ratio, pool_mode, aligned, channels, height, width,\n            n_stride, c_stride, h_stride, w_stride);\n      });\n}\n</code></pre> <p>\u63a5\u4e0b\u6765\u770b<code>ROIAlignBackward</code>\u51fd\u6570\uff0c\u5728<code>Line 270-382</code></p> <pre><code>template &lt;typename T&gt;\nvoid ROIAlignBackward(const int nthreads, const T* grad_output, const T* rois,\n                      const T* argmax_y, const T* argmax_x, T* grad_input,\n                      const int pooled_height, const int pooled_width,\n                      const T spatial_scale, const int sampling_ratio,\n                      const int pool_mode,  // 0 - max pool, 1 - avg pool\n                      const bool aligned, const int channels, const int height,\n                      const int width, const int n_stride, const int c_stride,\n                      const int h_stride, const int w_stride)\n/*\nnthreads\uff1a\u8868\u9762\u610f\u601d\u662f\u7ebf\u7a0b\u4e2a\u6570\uff0c\u5b9e\u9645\u4e0a\u662froi align\u7b97\u5b50\u8f93\u51fafeature map\u8f93\u51fa\u7684\u5143\u7d20\u603b\u4e2a\u6570\uff0c\u5373N x C x pooled_height x pooled_width\ngrad_output\uff1a\u5bf9roi feature map\u7684\u68af\u5ea6\u7d2f\u8ba1\u4fe1\u606f \u7ef4\u5ea6\u4e3a [N, C, H, W] H\u548cW\u4e3a pooled_height \u548c pooled_width\nrois\uff1a\u8f93\u5165rois\u7684\u5185\u5b58\u6307\u9488\nargmax_y\uff1a\u8f93\u5165tensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684y\u5750\u6807\nargmax_x\uff1a\u8f93\u5165tensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684x\u5750\u6807\ngrad_input\uff1a\u8f93\u51fa\u6307\u9488\uff0c\u5bf9\u8f93\u5165\u7ed9Roi Align\u7684feature map\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u521d\u59cb\u5316\u4e3a\u51680\npooled_height\uff1aRoiAlign\u8f93\u51faFeatureMap\u7684H\npooled_width\uff1aRoiAlign\u8f93\u51faFeatureMap\u7684W\nspatial_scale\uff1a\u5f53\u524d\u8f93\u5165\u7684input feature map\u7684\u7a7a\u95f4\u5927\u5c0f / \u539f\u56fe\u5927\u5c0f \u6bd4\u59821/16\nsampling_ratio\uff1a\u5212\u5206\u597d aligned_height x aligned_width \u4e2a\u7f51\u683c\u540e\uff0c\u5355\u4e2a\u7f51\u683c\u7528sampling_ratio\u4e2a\u70b9\u8868\u793a\npool_mode\uff1a1 \u8868\u793a \u63cf\u8ff0\u5355\u4e2a\u7f51\u683c\u7684\u70b9\u662f\u5bf9\u6240\u6709\u91c7\u6837\u70b9\u53bb\u5e73\u5747 0 \u8868\u793a\u53d6\u6700\u5927\naligned\uff1a\u53cc\u7ebf\u6027\u63d2\u503c\u53c2\u6570\uff0c\u662f\u89d2\u70b9\u5bf9\u9f50\u8fd8\u662f\u4e2d\u5fc3\u5bf9\u9f50\uff0c\u89d2\u70b9\u5bf9\u9f50\u8bbe\u7f6e\u4e3a0\uff0c\u4e2d\u5fc3\u5bf9\u9f50\u8bbe\u7f6e\u4e3a1\nchannels\uff1a\u8f93\u5165channels\nheight\uff1a\u8f93\u5165feature map\u7684\u9ad8\nwidth\uff1a\u8f93\u5165feature map\u7684\u5bbd\nn_stride\uff1a\u8bb0\u5f55grad_output\u6307\u9488 batch\u65b9\u5411\u7684stride\uff0c\u517c\u5bb9\u5185\u5b58\u4e0d\u8fde\u7eed\u7684\u60c5\u51b5\nc_stride\uff1a\u8bb0\u5f55grad_output\u6307\u9488 channel\u65b9\u5411\u7684stride\uff0c\u517c\u5bb9\u5185\u5b58\u4e0d\u8fde\u7eed\u7684\u60c5\u51b5\nh_stride\uff1a\u8bb0\u5f55grad_output\u6307\u9488 height\u65b9\u5411\u7684stride\uff0c\u517c\u5bb9\u5185\u5b58\u4e0d\u8fde\u7eed\u7684\u60c5\u51b5\nw_stride\uff1a\u8bb0\u5f55grad_output\u6307\u9488 width\u65b9\u5411\u7684stride\uff0c\u517c\u5bb9\u5185\u5b58\u4e0d\u8fde\u7eed\u7684\u60c5\u51b5\n*/\n{\n  // \u904d\u5386\u8f93\u51fa\u6240\u6709\u8f93\u5165\u5143\u7d20\u3002\u8ba1\u7b97\u5176\u5bf9\u8f93\u5165\u76f8\u5173\u8054\u8f93\u5165\u5143\u7d20\u7684\u68af\u5ea6\n  for (int index = 0; index &lt; nthreads; index++) {\n    // (n, c, ph, pw) is an element in the pooled output\n    // \u8ba1\u7b97\u51fapooled_width\u7ef4\u5ea6\u4e0a\u7684\u7d22\u5f15\n    int pw = index % pooled_width;\n    // \u8ba1\u7b97\u51fapooled_height\u7ef4\u5ea6\u4e0a\u7684\u7d22\u5f15\n    int ph = (index / pooled_width) % pooled_height;\n    // \u8ba1\u7b97\u51fachannel\u7ef4\u5ea6\u4e0a\u7684\u7d22\u5f15\n    int c = (index / pooled_width / pooled_height) % channels;\n    // \u8ba1\u7b97\u51faroi batch\u7ef4\u5ea6\u4e0a\u7684\u7d22\u5f15\n    int n = index / pooled_width / pooled_height / channels;\n\n    // \u53d6\u8f93\u5165roi\u7684\u5750\u6807\u503c\n    const T* offset_rois = rois + n * 5;\n    // \u53d6\u51fa\u5f53\u524droi\u5bf9\u5e94\u7684 batch index\n    int roi_batch_ind = offset_rois[0];\n\n    // \u4e0e\u524d\u5411\u4f20\u64ad\u8ba1\u7b97\u76f8\u540c\uff0c\u8ba1\u7b97\u51faroi\u5750\u6807\u6620\u5c04\u5230feature map\u540e\u7684\u5750\u6807\n    // Do not use rounding; this implementation detail is critical\n    T offset = aligned ? (T)0.5 : (T)0.0;\n    T roi_start_w = offset_rois[1] * spatial_scale - offset;\n    T roi_start_h = offset_rois[2] * spatial_scale - offset;\n    T roi_end_w = offset_rois[3] * spatial_scale - offset;\n    T roi_end_h = offset_rois[4] * spatial_scale - offset;\n\n    T roi_width = roi_end_w - roi_start_w;\n    T roi_height = roi_end_h - roi_start_h;\n    if (aligned) {\n      AT_ASSERTM(roi_width &gt;= 0 &amp;&amp; roi_height &gt;= 0,\n                 \"ROIs in ROIAlign do not have non-negative size!\");\n    } else {  // for backward-compatibility only\n      roi_width = std::max(roi_width, (T)1.);\n      roi_height = std::max(roi_height, (T)1.);\n    }\n    // \u5355\u4e2a\u7f51\u683c\u5927\u5c0f\n    T bin_size_h = static_cast&lt;T&gt;(roi_height) / static_cast&lt;T&gt;(pooled_height);\n    T bin_size_w = static_cast&lt;T&gt;(roi_width) / static_cast&lt;T&gt;(pooled_width);\n\n    // \u9488\u5bf9\u8f93\u5165 feature map \u7684\u504f\u79fb\u9996\u5730\u5740\uff0c\u7b49\u4ef7\u4e8e grad_input[roi_batch_ind][c]\n    T* offset_grad_input =\n        grad_input + ((roi_batch_ind * channels + c) * height * width);\n\n    // \u8ba1\u7b97\u8f93\u51fa feature map \u7684\u504f\u79fb\u9996\u5730\u5740\n    int output_offset = n * n_stride + c * c_stride;\n    // \u7b49\u4ef7\u4e8e &amp;grad_output[n][c]\n    const T* offset_grad_output = grad_output + output_offset;\n    // \u53d6\u51fa\u5f53\u524d\u5bf9roi feature map\u7684\u68af\u5ea6\u503c\uff0c\u7b49\u4ef7\u4e8e grad_output[n][c][ph][pw]\n    const T grad_output_this_bin =\n        offset_grad_output[ph * h_stride + pw * w_stride];\n\n    // \u5982\u679c\u662fmax pooling\u6a21\u5f0f \u90a3\u4e48\u68af\u5ea6\u4ec5\u4ec5\u56de\u4f20\u5230 argmax \u5bf9\u5e94\u7684\u5750\u6807\u7684\u70b9\n    // \u5176\u4f59\u4f4d\u7f6e\u4e3a\u68af\u5ea6\u4e3a0\uff0c\u6240\u4ee5grad_input\u5143\u7d20\u8c03\u7528\u524d\u8981\u524d\u90e8\u521d\u59cb\u5316\u4e3a0\n    if (pool_mode == 0) {\n      // We do max pooling inside a bin\n      // \u53d6\u51fa\u6700\u5927\u503c\u662f\u54ea\u4e2a\u70b9\n      T y = argmax_y[index], x = argmax_x[index];\n      if (y != -1.f) {\n        T w1, w2, w3, w4;\n        int x_low, x_high, y_low, y_high;\n        // \u8ba1\u7b97\u9488\u5bf9(x,y)\u5750\u6807\u5904 \u56db\u4e2a\u5750\u6807\u70b9\u5750\u6807\u548c\u5bf9\u5e94\u7684\u6743\u503c\n        // \u6743\u503c\u5c31\u662f\u5bf9\u5e94\u5750\u6807\u70b9\u7684\u68af\u5ea6\n        bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n                                      x_low, x_high, y_low, y_high, index);\n        // \u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\uff0c\u8ba1\u7b97\u51fa\u5bf9\u56db\u4e2a\u70b9\u7684\u68af\u5ea6\n        T g1 = grad_output_this_bin * w1;\n        T g2 = grad_output_this_bin * w2;\n        T g3 = grad_output_this_bin * w3;\n        T g4 = grad_output_this_bin * w4;\n\n        if (x_low &gt;= 0 &amp;&amp; x_high &gt;= 0 &amp;&amp; y_low &gt;= 0 &amp;&amp; y_high &gt;= 0) {\n          // \u6309\u7167\u591a\u5143\u51fd\u6570\u5fae\u5206\u5b66\uff0c\u5c06\u6b64\u5904\u68af\u5ea6\u8fdb\u884c\u7d2f\u52a0\u64cd\u4f5c\n          // \u56e0\u4e3a\u540c\u4e00\u5904\u4f4d\u7f6e\u53ef\u80fd\u6709\u591a\u4e2aroi\u505a\u524d\u5411\u8ba1\u7b97\n          // atomic add is not needed for now since it is single threaded\n          add(offset_grad_input + y_low * width + x_low, static_cast&lt;T&gt;(g1));\n          add(offset_grad_input + y_low * width + x_high, static_cast&lt;T&gt;(g2));\n          add(offset_grad_input + y_high * width + x_low, static_cast&lt;T&gt;(g3));\n          add(offset_grad_input + y_high * width + x_high, static_cast&lt;T&gt;(g4));\n        }  // if\n      }    // mode\n    } else if (pool_mode == 1) {\n      // avg pooling \u6a21\u5f0f\u8ba1\u7b97\u68af\u5ea6 \u5c31\u9700\u8981\u8ba1\u7b97\u51fa\u6240\u6709\u7684\u76f8\u5173\u70b9\n      // y = x / n\uff0c dy/dx = 1/n\n      // We do average (integral) pooling inside a bin\n      // We use roi_bin_grid to sample the grid and mimic integral\n      // \u8ba1\u7b97\u4e00\u4e2a\u7f51\u683c\u70b9\u7528\u4e86\u591a\u5c11\u4e2a\u91c7\u6837\u70b9\n      int roi_bin_grid_h =\n          (sampling_ratio &gt; 0)\n              ? sampling_ratio\n              : ceilf(roi_height / pooled_height);  // e.g., = 2\n      int roi_bin_grid_w = (sampling_ratio &gt; 0)\n                               ? sampling_ratio\n                               : ceilf(roi_width / pooled_width);\n\n      const T count = roi_bin_grid_h * roi_bin_grid_w;  // e.g. = 4\n      // \u4e24\u91cd\u5faa\u73af\u91cd\u65b0\u8ba1\u7b97\u91c7\u6837\u70b9\u5750\u6807\n      for (int iy = 0; iy &lt; roi_bin_grid_h; iy++) {\n        const T y = roi_start_h + ph * bin_size_h +\n                    static_cast&lt;T&gt;(iy + .5f) * bin_size_h /\n                        static_cast&lt;T&gt;(roi_bin_grid_h);  // e.g., 0.5, 1.5\n        for (int ix = 0; ix &lt; roi_bin_grid_w; ix++) {\n          const T x = roi_start_w + pw * bin_size_w +\n                      static_cast&lt;T&gt;(ix + .5f) * bin_size_w /\n                          static_cast&lt;T&gt;(roi_bin_grid_w);\n\n          T w1, w2, w3, w4;\n          int x_low, x_high, y_low, y_high;\n          // \u8ba1\u7b97\u5f53\u524d\u91c7\u6837\u70b9\u4e0b\u7684\u5bf9\u5e94\u7684\u56db\u4e2a\u70b9\u5750\u6807\u548c\u5bf9\u5e94\u6743\u503c\n          bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n                                        x_low, x_high, y_low, y_high, index);\n          // \u8ba1\u7b97\u68af\u5ea6\u5e76\u56de\u4f20\n          T g1 = grad_output_this_bin * w1 / count;\n          T g2 = grad_output_this_bin * w2 / count;\n          T g3 = grad_output_this_bin * w3 / count;\n          T g4 = grad_output_this_bin * w4 / count;\n\n          if (x_low &gt;= 0 &amp;&amp; x_high &gt;= 0 &amp;&amp; y_low &gt;= 0 &amp;&amp; y_high &gt;= 0) {\n            // atomic add is not needed for now since it is single threaded\n            add(offset_grad_input + y_low * width + x_low, static_cast&lt;T&gt;(g1));\n            add(offset_grad_input + y_low * width + x_high, static_cast&lt;T&gt;(g2));\n            add(offset_grad_input + y_high * width + x_low, static_cast&lt;T&gt;(g3));\n            add(offset_grad_input + y_high * width + x_high,\n                static_cast&lt;T&gt;(g4));\n          }  // if\n        }    // ix\n      }      // iy\n    }        // mode\n  }          // for\n}  // ROIAlignBackward\n</code></pre> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u518d\u770b\u4e0b<code>bilinear_interpolate_gradient</code>\u51fd\u6570\uff0c<code>Line 216-263</code></p> <pre><code>template &lt;typename T&gt;\nvoid bilinear_interpolate_gradient(const int height, const int width, T y, T x,\n                                   T&amp; w1, T&amp; w2, T&amp; w3, T&amp; w4, int&amp; x_low,\n                                   int&amp; x_high, int&amp; y_low, int&amp; y_high,\n                                   const int index /* index for debug only*/)\n/*\nheight\uff1a\u8f93\u5165feature map\u7684\u9ad8\u5ea6\nwidth\uff1a\u8f93\u5165feature map\u7684\u5bbd\u5ea6\ny\uff1a\u91c7\u6837\u70b9\u7684y\u5750\u6807\nx\uff1a\u91c7\u6837\u70b9\u7684x\u5750\u6807\nw1/w2/w3/w4\uff1a(x,y)\u9644\u8fd1\u56db\u4e2a\u70b9\u5bf9\u5e94\u7684\u6743\u91cd\u503c\nx_low/x_high/y_low/y_high\uff1a\u56db\u4e2a\u70b9\u5bf9\u5e94\u7684\u5750\u6807\u503c\nindex\uff1afor debug\n*/\n{\n  // \u5904\u7406\u4e0d\u5408\u6cd5\u7684case\n  // deal with cases that inverse elements are out of feature map boundary\n  if (y &lt; -1.0 || y &gt; height || x &lt; -1.0 || x &gt; width) {\n    // empty\n    w1 = w2 = w3 = w4 = 0.;\n    x_low = x_high = y_low = y_high = -1;\n    return;\n  }\n\n  if (y &lt;= 0) y = 0;\n  if (x &lt;= 0) x = 0;\n\n  // \u8ba1\u7b97\u56db\u4e2a\u70b9\u5750\u6807\n  y_low = (int)y;\n  x_low = (int)x;\n\n  if (y_low &gt;= height - 1) {\n    y_high = y_low = height - 1;\n    y = (T)y_low;\n  } else {\n    y_high = y_low + 1;\n  }\n\n  if (x_low &gt;= width - 1) {\n    x_high = x_low = width - 1;\n    x = (T)x_low;\n  } else {\n    x_high = x_low + 1;\n  }\n\n  // \u8ba1\u7b97\u56db\u4e2a\u70b9\u7684\u5bf9\u5e94\u7684\u6743\u91cd\n  T ly = y - y_low;\n  T lx = x - x_low;\n  T hy = 1. - ly, hx = 1. - lx;\n\n  // reference in forward\n  // T v1 = input[y_low * width + x_low];\n  // T v2 = input[y_low * width + x_high];\n  // T v3 = input[y_high * width + x_low];\n  // T v4 = input[y_high * width + x_high];\n  // T val = (w1 * v1 + w2 * v2 + w3 * v3 + w4 * v4);\n\n  w1 = hy * hx, w2 = hy * lx, w3 = ly * hx, w4 = ly * lx;\n\n  return;\n}\n</code></pre> <p>OK\uff0c\u547c~\uff0c\u957f\u8212\u4e00\u53e3\u6c14\uff0cCPU\u7248\u672c\u89e3\u8bfb\u5b8c\u6bd5\u3002</p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u770b\u4e0bgpu\u7248\u672c</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#roialigngpu","title":"\u56db\u3001RoiAlign\u7b97\u5b50GPU\u7248\u672c\u89e3\u8bfb","text":"<p>\u8001\u89c4\u77e9\uff0c\u5148\u770b\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b</p> <p>\u5728 https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/pytorch/cuda/roi_align_cuda.cu</p> <p><code>ROIAlignForwardCUDAKernelLauncher</code>\u51fd\u6570\uff0c<code>Line 5-30</code>\uff0c\u8fd9\u91cc\u5404\u4e2a\u53c2\u6570\u6211\u5c31\u4e0d\u89e3\u91ca\u4e86\uff0c\u5728cpu\u7248\u672c\u89e3\u91ca\u4e86\u3002</p> <pre><code>void ROIAlignForwardCUDAKernelLauncher(Tensor input, Tensor rois, Tensor output,\n                                       Tensor argmax_y, Tensor argmax_x,\n                                       int aligned_height, int aligned_width,\n                                       float spatial_scale, int sampling_ratio,\n                                       int pool_mode, bool aligned) {\n  int output_size = output.numel();\n  int channels = input.size(1);\n  int height = input.size(2);\n  int width = input.size(3);\n\n  at::cuda::CUDAGuard device_guard(input.device());\n  cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n      input.scalar_type(), \"roi_align_forward_cuda_kernel\", [&amp;] {\n        roi_align_forward_cuda_kernel&lt;scalar_t&gt;\n            &lt;&lt;&lt;GET_BLOCKS(output_size), THREADS_PER_BLOCK, 0, stream&gt;&gt;&gt;(\n                output_size, input.data_ptr&lt;scalar_t&gt;(),\n                rois.data_ptr&lt;scalar_t&gt;(), output.data_ptr&lt;scalar_t&gt;(),\n                argmax_y.data_ptr&lt;scalar_t&gt;(), argmax_x.data_ptr&lt;scalar_t&gt;(),\n                aligned_height, aligned_width,\n                static_cast&lt;scalar_t&gt;(spatial_scale), sampling_ratio, pool_mode,\n                aligned, channels, height, width);\n      });\n\n  AT_CUDA_CHECK(cudaGetLastError());\n}\n</code></pre> <p>\u6211\u4eec\u91cd\u70b9\u770b\u4e0bcuda\u6838\u51fd\u6570\u8c03\u7528</p> <p>\u53c2\u8003 https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/common/cuda/common_cuda_helper.hpp</p> <pre><code>// \u5728common.cuh \u5b9a\u4e49\u4e86\n// #define THREADS_PER_BLOCK 512\n\n// \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a grid \u7684\u7ef4\u5ea6\u548c\u5927\u5c0f (grid_size) \u5355\u4e2agrid\u5171\u6709 GET_BLOCKS(output_size) \u4e2a block\n// \u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3a \u6bcf\u4e2a\u7ebf\u7a0b\u5757\u7684\u7ef4\u5ea6\u548c\u5927\u5c0f (block_size) \u8bbe\u7f6e\u5171\u6709 THREADS_PER_BLOCK \u4e2a thread\n// \u7b2c\u4e09\u4e2a\u53c2\u6570\u4e3a \u6bcf\u4e2a\u7ebf\u7a0b\u5757\u9700\u52a8\u6001\u5206\u914d\u7684\u5171\u4eab\u5185\u5b58\u7684\u5b57\u8282\u6570\uff0c\u8bbe\u7f6e\u4e3a0\n// \u7b2c\u56db\u4e2a\u53c2\u6570\u4e3a \u6307\u5b9a\u7684\u76f8\u5173\u8054\u7684 CUDA \u6d41 \u8bbe\u7f6e\u4e3a\u8f93\u5165tensor\u7ed1\u5b9a\u7684stream\nroi_align_forward_cuda_kernel&lt;scalar_t&gt;\n            &lt;&lt;&lt;GET_BLOCKS(output_size), THREADS_PER_BLOCK, 0, stream&gt;&gt;&gt;\n</code></pre> <pre><code>// GET_BLOCKS\u5b9a\u4e49\uff1a\u7b49\u4ef7\u4e8e min(4096, ceil(N / num_threads))\ninline int GET_BLOCKS(const int N, const int num_threads = THREADS_PER_BLOCK) {\n  int optimal_block_num = (N + num_threads - 1) / num_threads;\n  int max_block_num = 4096;\n  return min(optimal_block_num, max_block_num);\n}\n</code></pre> <p>\u6240\u4ee5\u4e00\u5171\u542f\u52a8\u4e86<code>ceil(output_size / THREADS_PER_BLOCK) * THREADS_PER_BLOCK</code>\u4e2acuda thread\u3002</p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u770b\u4e0b<code>roi_align_forward_cuda_kernel</code>\u51fd\u6570\uff0c\u5728</p> <p>https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/common/cuda/roi_align_cuda_kernel.cuh</p> <p><code>Line 17-108</code></p> <pre><code>/*** Forward ***/\ntemplate &lt;typename T&gt;\n__global__ void roi_align_forward_cuda_kernel(\n    const int nthreads, const T* input, const T* rois, T* output, T* argmax_y,\n    T* argmax_x, const int pooled_height, const int pooled_width,\n    const T spatial_scale, const int sampling_ratio,\n    const int pool_mode,  // 0 - max pool, 1 - avg pool\n    const bool aligned, const int channels, const int height, const int width)\n/*\n  nthreads\uff1a\u7ebf\u7a0b\u4e2a\u6570\uff0c\u5b9e\u9645\u4e0a\u662f\u8f93\u51fa\u7684\u5143\u7d20\u603b\u4e2a\u6570\uff0c\u5373N x C x pooled_height x pooled_width\n  input\uff1a\u8f93\u5165feature map\u7684\u5185\u5b58\u6307\u9488\n  rois\uff1a\u8f93\u5165rois\u7684\u5185\u5b58\u6307\u9488\n  output\uff1a\u8f93\u51fafeature map\u7684\u5185\u5b58\u6307\u9488\n  argmax_y\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684y\u5750\u6807\n  argmax_x\uff1a\u8f93\u51fatensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684x\u5750\u6807\n  pooled_height\uff1a\u8f93\u51faFeatureMap\u7684H\n  pooled_width\uff1a\u8f93\u51faFeatureMap\u7684W\n  spatial_scale\uff1a\u5f53\u524d\u8f93\u5165\u7684input feature map\u7684\u7a7a\u95f4\u5927\u5c0f / \u539f\u56fe\u5927\u5c0f \u6bd4\u59821/16\n  sampling_ratio\uff1a\u5212\u5206\u597d aligned_height x aligned_width \u4e2a\u7f51\u683c\u540e\uff0c\u5355\u4e2a\u7f51\u683c\u7528sampling_ratio\u4e2a\u70b9\u8868\u793a\n  pool_mode\uff1a1 \u8868\u793a \u63cf\u8ff0\u5355\u4e2a\u7f51\u683c\u7684\u70b9\u662f\u5bf9\u6240\u6709\u91c7\u6837\u70b9\u53bb\u5e73\u5747 0 \u8868\u793a\u53d6\u6700\u5927\n  aligned\uff1a\u53cc\u7ebf\u6027\u63d2\u503c\u53c2\u6570\uff0c\u662f\u89d2\u70b9\u5bf9\u9f50\u8fd8\u662f\u4e2d\u5fc3\u5bf9\u9f50\uff0c\u89d2\u70b9\u5bf9\u9f50\u8bbe\u7f6e\u4e3a0\uff0c\u4e2d\u5fc3\u5bf9\u9f50\u8bbe\u7f6e\u4e3a1\n  channels\uff1a\u8f93\u5165channels\n  height\uff1a\u8f93\u5165feature map\u7684\u9ad8\n  width\uff1a\u8f93\u5165feature map\u7684\u5bbd\n  */\n{\n/*\n\u5728common.cuh\u4e2d\u6709\u5b9a\u4e49\n#define CUDA_1D_KERNEL_LOOP(i, n)                              \\\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; (n); \\\n       i += blockDim.x * gridDim.x)\n\n\u4e0a\u8ff0\u5faa\u73af\u8868\u793a\ni \u521d\u59cb\u5316\u4e3a blockIdx.x * blockDim.x + threadIdx.x\n\u6b65\u957f\u4e3a blockDim.x * gridDim.x\n\n\u56de\u987e\u8c03\u7528\u8fc7\u7a0b blockDim.x \u5373\u4e3a \u5355\u4e2ablock\u7ebf\u7a0b\u7684\u603b\u4e2a\u6570\nblockIdx.x \u5373\u4e3agrid\u7ef4\u5ea6\u4e0ablock\u7684\u7d22\u5f15\n\u4e00\u5171\u542f\u52a8\u4e86 blockDim.x * gridDim.x \u4e2a\u6838\u51fd\u6570\n\u6b65\u957f\u4e3a blockDim.x * gridDim.x \u662f\u4e3a\u4e86\u6ee1\u8db3\uff0c\u5f53nthreads &gt; blockDim.x * gridDim.x \u65f6\uff0c\u4f9d\u7136\u53ef\u4ee5\u5904\u7406\u5269\u4f59\u5143\u7d20\n*/\n  // \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0ccuda\u6838\u51fd\u6570\u7684\u8ba1\u7b97\u903b\u8f91\u4e0ecpu\u7248\u672c\u903b\u8f91\u4e0d\u592a\u4e00\u6837\uff0ccpu\u662f\u904d\u5386roi\n  // cuda\u6838\u662f\u904d\u5386\u8f93\u51fafeature map\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u627e\u5230\u5bf9\u5e94\u7684\u8ba1\u7b97\n  CUDA_1D_KERNEL_LOOP(index, nthreads) {\n    // \u8ba1\u7b97\u8f93\u51fa\u5c42\u7684\u7684\u7d22\u5f15\uff0c\u8f93\u5165[N,5] \u8f93\u51fa [N, C, H, W]\n    // (n, c, ph, pw) is an element in the pooled output\n    int pw = index % pooled_width;\n    int ph = (index / pooled_width) % pooled_height;\n    int c = (index / pooled_width / pooled_height) % channels;\n    int n = index / pooled_width / pooled_height / channels;\n\n    const T* offset_rois = rois + n * 5;\n    // \u62ff\u5230\u5f53\u524d\u8f93\u51fafeature map\u7684\u503c\u5bf9\u5e94\u7684roi\u4e2d\u8bb0\u5f55\u7684batch index\n    int roi_batch_ind = offset_rois[0];\n\n    // \u5c06roi\u4e2d\u7684\u5927\u56fe\u5750\u6807 \u8f6c\u6362\u4e3a feature map\u4e0a\u7684\u5750\u6807\n    // Do not using rounding; this implementation detail is critical\n    T offset = aligned ? (T)0.5 : (T)0.0;\n    T roi_start_w = offset_rois[1] * spatial_scale - offset;\n    T roi_start_h = offset_rois[2] * spatial_scale - offset;\n    T roi_end_w = offset_rois[3] * spatial_scale - offset;\n    T roi_end_h = offset_rois[4] * spatial_scale - offset;\n\n    T roi_width = roi_end_w - roi_start_w;\n    T roi_height = roi_end_h - roi_start_h;\n    if (!aligned) {  // for backward-compatibility only\n      roi_width = max(roi_width, (T)1.);\n      roi_height = max(roi_height, (T)1.);\n    }\n\n    // \u5212\u5206\u7f51\u683c\uff0c\u5e76\u8ba1\u7b97\u5355\u4e2a\u7f51\u683c\u70b9\u5360feature map\u4e0a\u7684\u70b9\u6570\n    T bin_size_h = static_cast&lt;T&gt;(roi_height) / static_cast&lt;T&gt;(pooled_height);\n    T bin_size_w = static_cast&lt;T&gt;(roi_width) / static_cast&lt;T&gt;(pooled_width);\n\n    // \u8ba1\u7b97\u8f93\u5165feature map\u504f\u79fb\u6307\u9488 \u7c7b\u4f3c\u4e8e &amp;input[roi_batch_ind][c]\n    const T* offset_input =\n        input + (roi_batch_ind * channels + c) * height * width;\n\n    // \u5b9a\u4e49\u5355\u4e2a\u7f51\u683c\u91c7\u6837\u70b9\u4e2a\u6570\n    // We use roi_bin_grid to sample the grid and mimic integral\n    int roi_bin_grid_h =\n        (sampling_ratio &gt; 0)\n            ? sampling_ratio\n            : static_cast&lt;int&gt;(ceilf(roi_height / pooled_height));\n    int roi_bin_grid_w =\n        (sampling_ratio &gt; 0)\n            ? sampling_ratio\n            : static_cast&lt;int&gt;(ceilf(roi_width / pooled_width));\n\n    // max pooling\u6a21\u5f0f\n    if (pool_mode == 0) {\n      // We do max pooling inside a bin\n      T maxval = -FLT_MAX;\n      T maxidx_y = -1.f, maxidx_x = -1.f;\n      // \u4e24\u91cd\u5faa\u73af\u8ba1\u7b97\u91c7\u6837\u70b9\u7684\u5750\u6807\uff0c\u6839\u636e\u5355\u4e2a\u7f51\u683c\u70b9\u7684\u8303\u56f4\u7ee7\u7eed\u5212\u5206\u5c0f\u7f51\u683c\n      // \u7136\u540e\u53bb\u5c0f\u7f51\u683c\u7684\u4e2d\u5fc3\u70b9\u4f5c\u4e3a\u91c7\u6837\u70b9\n      for (int iy = 0; iy &lt; roi_bin_grid_h; iy++) {\n        const T y = roi_start_h + ph * bin_size_h +\n                    static_cast&lt;T&gt;(iy + .5f) * bin_size_h /\n                        static_cast&lt;T&gt;(roi_bin_grid_h);\n        for (int ix = 0; ix &lt; roi_bin_grid_w; ix++) {\n          const T x = roi_start_w + pw * bin_size_w +\n                      static_cast&lt;T&gt;(ix + .5f) * bin_size_w /\n                          static_cast&lt;T&gt;(roi_bin_grid_w);\n          // \u91c7\u6837\u53cc\u7ebf\u6027\u63d2\u503c\u8ba1\u7b97\u91c7\u6837\u70b9\uff0c\u5e76\u4fdd\u5b58\u6700\u5927\u503c\n          T val =\n              bilinear_interpolate(offset_input, height, width, y, x, index);\n          if (val &gt; maxval) {\n            maxval = val;\n            maxidx_y = y;\n            maxidx_x = x;\n          }\n        }\n      }\n      output[index] = maxval;\n      argmax_y[index] = maxidx_y;\n      argmax_x[index] = maxidx_x;\n    } else if (pool_mode == 1) {\n      // \u540c\u7406 pool_mode == 1 \u8868\u793a avg pooling \u5bf9\u6240\u6709\u91c7\u6837\u70b9\u6c42\u548c\u540e\u53d6\u5e73\u5747\n      // We do average pooling inside a bin\n      const T count = max(roi_bin_grid_h * roi_bin_grid_w, 1);\n      T output_val = 0.;\n      for (int iy = 0; iy &lt; roi_bin_grid_h; iy++) {\n        const T y = roi_start_h + ph * bin_size_h +\n                    static_cast&lt;T&gt;(iy + .5f) * bin_size_h /\n                        static_cast&lt;T&gt;(roi_bin_grid_h);\n        for (int ix = 0; ix &lt; roi_bin_grid_w; ix++) {\n          const T x = roi_start_w + pw * bin_size_w +\n                      static_cast&lt;T&gt;(ix + .5f) * bin_size_w /\n                          static_cast&lt;T&gt;(roi_bin_grid_w);\n          T val =\n              bilinear_interpolate(offset_input, height, width, y, x, index);\n          output_val += val;\n        }\n      }\n      output[index] = output_val / count;\n    }\n  }\n}\n</code></pre> <p>\u4e0b\u9762\u6211\u4eec\u770b\u4e00\u4e0b\u53cd\u5411\u4f20\u64ad\uff0c\u8c03\u7528<code>ROIAlignBackwardCUDAKernelLauncher</code>\uff0c\u5728<code>roi_align_cuda.cu</code> <code>Line 32-58</code></p> <pre><code>void ROIAlignBackwardCUDAKernelLauncher(Tensor grad_output, Tensor rois,\n                                        Tensor argmax_y, Tensor argmax_x,\n                                        Tensor grad_input, int aligned_height,\n                                        int aligned_width, float spatial_scale,\n                                        int sampling_ratio, int pool_mode,\n                                        bool aligned) {\n  int output_size = grad_output.numel();\n  int channels = grad_input.size(1);\n  int height = grad_input.size(2);\n  int width = grad_input.size(3);\n\n  at::cuda::CUDAGuard device_guard(grad_output.device());\n  cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n      grad_output.scalar_type(), \"roi_align_backward_cuda_kernel\", [&amp;] {\n        roi_align_backward_cuda_kernel&lt;scalar_t&gt;\n            &lt;&lt;&lt;GET_BLOCKS(output_size), THREADS_PER_BLOCK, 0, stream&gt;&gt;&gt;(\n                output_size, grad_output.data_ptr&lt;scalar_t&gt;(),\n                rois.data_ptr&lt;scalar_t&gt;(), argmax_y.data_ptr&lt;scalar_t&gt;(),\n                argmax_x.data_ptr&lt;scalar_t&gt;(), grad_input.data_ptr&lt;scalar_t&gt;(),\n                aligned_height, aligned_width,\n                static_cast&lt;scalar_t&gt;(spatial_scale), sampling_ratio, pool_mode,\n                aligned, channels, height, width);\n      });\n\n  AT_CUDA_CHECK(cudaGetLastError());\n}\n</code></pre> <p>\u8c03\u7528<code>roi_align_backward_cuda_kernel</code>\u4e00\u5171\u542f\u52a8\u4e86 <code>ceil(output_size / THREADS_PER_BLOCK) * THREADS_PER_BLOCK</code>\u4e2acuda\u7ebf\u7a0b</p> <p><code>roi_align_backward_cuda_kernel</code>\u5728<code>roi_align_cuda_kernel.cuh</code> <code>Line110 - 210</code>\u5b9a\u4e49</p> <pre><code>/*** Backward ***/\ntemplate &lt;typename T&gt;\n__global__ void roi_align_backward_cuda_kernel(\n    const int nthreads, const T* grad_output, const T* rois, const T* argmax_y,\n    const T* argmax_x, T* grad_input, const int pooled_height,\n    const int pooled_width, const T spatial_scale, const int sampling_ratio,\n    const int pool_mode,  // 0 - max pool, 1 - avg pool\n    const bool aligned, const int channels, const int height, const int width) {\n/*\nnthreads\uff1a\u8868\u9762\u610f\u601d\u662f\u7ebf\u7a0b\u4e2a\u6570\uff0c\u5b9e\u9645\u4e0a\u662froi align\u7b97\u5b50\u8f93\u51fafeature map\u8f93\u51fa\u7684\u5143\u7d20\u603b\u4e2a\u6570\uff0c\u5373N x C x pooled_height x pooled_width\ngrad_output\uff1a\u5bf9roi feature map\u7684\u68af\u5ea6\u7d2f\u8ba1\u4fe1\u606f \u7ef4\u5ea6\u4e3a [N, C, H, W] H\u548cW\u4e3a pooled_height \u548c pooled_width\nrois\uff1a\u8f93\u5165rois\u7684\u5185\u5b58\u6307\u9488\nargmax_y\uff1a\u8f93\u5165tensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684y\u5750\u6807\nargmax_x\uff1a\u8f93\u5165tensor\uff0c\u7ef4\u5ea6\u4e0eoutput\u76f8\u540c\uff0c\u7528\u4e8e\u8bb0\u5f55\u8bb0\u5f55\u5f53\u4e3a\u5355\u4e2a\u7f51\u683c\u7684\u503c\u4e3amax pooling\u64cd\u4f5c\u53d6\u503c\u65f6\uff0c\u6bcf\u4e2a\u8f93\u51fa\u7684feature\u7684\u4f4d\u7f6e\u7528\u5230\u7684\u539f\u8f93\u5165tensor\u7684\u4f4d\u7f6e\u7684x\u5750\u6807\ngrad_input\uff1a\u8f93\u51fa\u6307\u9488\uff0c\u5bf9\u8f93\u5165\u7ed9Roi Align\u7684feature map\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u521d\u59cb\u5316\u4e3a\u51680\npooled_height\uff1aRoiAlign\u8f93\u51faFeatureMap\u7684H\npooled_width\uff1aRoiAlign\u8f93\u51faFeatureMap\u7684W\nspatial_scale\uff1a\u5f53\u524d\u8f93\u5165\u7684input feature map\u7684\u7a7a\u95f4\u5927\u5c0f / \u539f\u56fe\u5927\u5c0f \u6bd4\u59821/16\nsampling_ratio\uff1a\u5212\u5206\u597d aligned_height x aligned_width \u4e2a\u7f51\u683c\u540e\uff0c\u5355\u4e2a\u7f51\u683c\u7528sampling_ratio\u4e2a\u70b9\u8868\u793a\npool_mode\uff1a1 \u8868\u793a \u63cf\u8ff0\u5355\u4e2a\u7f51\u683c\u7684\u70b9\u662f\u5bf9\u6240\u6709\u91c7\u6837\u70b9\u53bb\u5e73\u5747 0 \u8868\u793a\u53d6\u6700\u5927\naligned\uff1a\u53cc\u7ebf\u6027\u63d2\u503c\u53c2\u6570\uff0c\u662f\u89d2\u70b9\u5bf9\u9f50\u8fd8\u662f\u4e2d\u5fc3\u5bf9\u9f50\uff0c\u89d2\u70b9\u5bf9\u9f50\u8bbe\u7f6e\u4e3a0\uff0c\u4e2d\u5fc3\u5bf9\u9f50\u8bbe\u7f6e\u4e3a1\nchannels\uff1a\u8f93\u5165channels\nheight\uff1a\u8f93\u5165feature map\u7684\u9ad8\nwidth\uff1a\u8f93\u5165feature map\u7684\u5bbd\n*/\n\n/*\n\u5728common.cuh\u4e2d\u6709\u5b9a\u4e49\n#define CUDA_1D_KERNEL_LOOP(i, n)                              \\\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; (n); \\\n       i += blockDim.x * gridDim.x)\n\n\u4e0a\u8ff0\u5faa\u73af\u8868\u793a\ni \u521d\u59cb\u5316\u4e3a blockIdx.x * blockDim.x + threadIdx.x\n\u6b65\u957f\u4e3a blockDim.x * gridDim.x\n\n\u56de\u987e\u8c03\u7528\u8fc7\u7a0b blockDim.x \u5373\u4e3a \u5355\u4e2ablock\u7ebf\u7a0b\u7684\u603b\u4e2a\u6570\nblockIdx.x \u5373\u4e3agrid\u7ef4\u5ea6\u4e0ablock\u7684\u7d22\u5f15\n\u4e00\u5171\u542f\u52a8\u4e86 blockDim.x * gridDim.x \u4e2a\u6838\u51fd\u6570\n\u6b65\u957f\u4e3a blockDim.x * gridDim.x \u662f\u4e3a\u4e86\u6ee1\u8db3\uff0c\u5f53nthreads &gt; blockDim.x * gridDim.x \u65f6\uff0c\u4f9d\u7136\u53ef\u4ee5\u5904\u7406\u5269\u4f59\u5143\u7d20\n*/\n  CUDA_1D_KERNEL_LOOP(index, nthreads) {\n    // (n, c, ph, pw) is an element in the pooled output\n    int pw = index % pooled_width;\n    int ph = (index / pooled_width) % pooled_height;\n    int c = (index / pooled_width / pooled_height) % channels;\n    int n = index / pooled_width / pooled_height / channels;\n\n    const T grad_output_this_bin = grad_output[index];\n\n    const T* offset_rois = rois + n * 5;\n    int roi_batch_ind = offset_rois[0];\n    T* offset_grad_input =\n        grad_input + ((roi_batch_ind * channels + c) * height * width);\n\n    if (pool_mode == 0) {\n      T y = argmax_y[index], x = argmax_x[index];\n      if (y != -1.f) {\n        T w1, w2, w3, w4;\n        int x_low, x_high, y_low, y_high;\n        bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n                                      x_low, x_high, y_low, y_high, index);\n\n        if (x_low &gt;= 0 &amp;&amp; x_high &gt;= 0 &amp;&amp; y_low &gt;= 0 &amp;&amp; y_high &gt;= 0) {\n          atomicAdd(offset_grad_input + y_low * width + x_low,\n                    grad_output_this_bin * w1);\n          atomicAdd(offset_grad_input + y_low * width + x_high,\n                    grad_output_this_bin * w2);\n          atomicAdd(offset_grad_input + y_high * width + x_low,\n                    grad_output_this_bin * w3);\n          atomicAdd(offset_grad_input + y_high * width + x_high,\n                    grad_output_this_bin * w4);\n        }\n      }\n    } else if (pool_mode == 1) {\n      // Do not using rounding; this implementation detail is critical\n      T offset = aligned ? (T)0.5 : (T)0.0;\n      T roi_start_w = offset_rois[1] * spatial_scale - offset;\n      T roi_start_h = offset_rois[2] * spatial_scale - offset;\n      T roi_end_w = offset_rois[3] * spatial_scale - offset;\n      T roi_end_h = offset_rois[4] * spatial_scale - offset;\n\n      T roi_width = roi_end_w - roi_start_w;\n      T roi_height = roi_end_h - roi_start_h;\n      if (!aligned) {  // for backward-compatibility only\n        roi_width = max(roi_width, (T)1.);\n        roi_height = max(roi_height, (T)1.);\n      }\n\n      T bin_size_h = static_cast&lt;T&gt;(roi_height) / static_cast&lt;T&gt;(pooled_height);\n      T bin_size_w = static_cast&lt;T&gt;(roi_width) / static_cast&lt;T&gt;(pooled_width);\n\n      // We use roi_bin_grid to sample the grid and mimic integral\n      int roi_bin_grid_h =\n          (sampling_ratio &gt; 0)\n              ? sampling_ratio\n              : static_cast&lt;int&gt;(ceilf(roi_height / pooled_height));\n      int roi_bin_grid_w =\n          (sampling_ratio &gt; 0)\n              ? sampling_ratio\n              : static_cast&lt;int&gt;(ceilf(roi_width / pooled_width));\n\n      // We do average (integral) pooling inside a bin\n      const T count = roi_bin_grid_h * roi_bin_grid_w;  // e.g. = 4\n\n      for (int iy = 0; iy &lt; roi_bin_grid_h; iy++) {\n        const T y = roi_start_h + ph * bin_size_h +\n                    static_cast&lt;T&gt;(iy + .5f) * bin_size_h /\n                        static_cast&lt;T&gt;(roi_bin_grid_h);\n        for (int ix = 0; ix &lt; roi_bin_grid_w; ix++) {\n          const T x = roi_start_w + pw * bin_size_w +\n                      static_cast&lt;T&gt;(ix + .5f) * bin_size_w /\n                          static_cast&lt;T&gt;(roi_bin_grid_w);\n\n          T w1, w2, w3, w4;\n          int x_low, x_high, y_low, y_high;\n          bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n                                        x_low, x_high, y_low, y_high, index);\n\n          if (x_low &gt;= 0 &amp;&amp; x_high &gt;= 0 &amp;&amp; y_low &gt;= 0 &amp;&amp; y_high &gt;= 0) {\n            atomicAdd(offset_grad_input + y_low * width + x_low,\n                      grad_output_this_bin * w1 / count);\n            atomicAdd(offset_grad_input + y_low * width + x_high,\n                      grad_output_this_bin * w2 / count);\n            atomicAdd(offset_grad_input + y_high * width + x_low,\n                      grad_output_this_bin * w3 / count);\n            atomicAdd(offset_grad_input + y_high * width + x_high,\n                      grad_output_this_bin * w4 / count);\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>\u4e0a\u8ff0backward\u8fc7\u7a0b\u4e0ecpu\u7248\u672c\u57fa\u672c\u76f8\u540c\uff0c\u552f\u4e00\u4e0d\u540c\u662f\u68af\u5ea6\u7d2f\u52a0\u662f\u91c7\u7528<code>atomicAdd</code>\u4fdd\u8bc1\u539f\u5b50\u5199\u5165\u3002</p> <p>OK\uff0cGPU\u7248\u672c\u7684\u89e3\u8bfb\u4e5f\u5b8c\u4e8b\u4e86\uff0c\u771f\u662f\u901a\u900f\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#_2","title":"\u4e94\u3001\u603b\u7ed3","text":"<p>\u672c\u6587\u8be6\u7ec6\u89e3\u91ca\u4e86RoiAlign\u7684\u539f\u7406\u3001\u6280\u672f\u7ec6\u8282\u548c\u5177\u4f53\u5b9e\u73b0\uff0c\u5e0c\u671b\u80fd\u4e3a\u4e00\u4e9b\u70ed\u7231\u5e95\u5c42\u5b9e\u73b0\u6216\u8005\u60f3\u201d\u77e5\u5176\u6240\u4ee5\u7136\u201c\u7684\u670b\u53cb\u4e00\u70b9\u70b9\u542f\u53d1\uff0c\u6709\u4ec0\u4e48\u95ee\u9898\u6b22\u8fce\u5728\u8bc4\u8bba\u533a\u5e95\u4e0b\u7559\u8a00\u3002</p>"},{"location":"cuda%E7%9B%B8%E5%85%B3/ROIAlign%E7%AE%97%E5%AD%90%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/#_3","title":"\u516d\u3001\u53c2\u8003\u94fe\u63a5","text":"<ol> <li>https://www.cnblogs.com/wangyong/p/8523814.html</li> <li>https://blog.csdn.net/weixin_45492636/article/details/120550968</li> <li>https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/pytorch/cpu/roi_align.cpp</li> <li>https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/common/cuda/roi_align_cuda_kernel.cuh</li> <li>https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/pytorch/cuda/roi_align_cuda.cu</li> <li>https://github.com/open-mmlab/mmcv/blob/v2.1.0/mmcv/ops/csrc/common/cuda/common_cuda_helper.hpp</li> </ol>"},{"location":"python%26C%2B%2B/2022%E5%B9%B406%E6%9C%8807%E6%97%A5%2015%E6%97%B650%E5%88%8636%E7%A7%92/","title":"python\u4e0eC/C++\u6570\u636e\u4ea4\u4e92\u7684\u9677\u9631\uff1anumpy/torch\u4e2d\u7684\u89c6\u56fe","text":"<p>\u672c\u6587\u5199\u4e8e2022\u5e746\u67087\u65e515\u65f650\u5206</p>"},{"location":"python%26C%2B%2B/2022%E5%B9%B406%E6%9C%8807%E6%97%A5%2015%E6%97%B650%E5%88%8636%E7%A7%92/#_1","title":"\u524d\u8a00","text":"<p>\u6700\u8fd1\u78b0\u5230\u4e86\u4e00\u4e2abug\uff0c\u8c03\u8bd5\u4e86\u4e24\u5929\u3002\u6700\u540e\u53d1\u73b0\u662f\u6570\u636e\u5b58\u50a8\u6392\u5217\u65b9\u5f0f\u7684\u95ee\u9898\uff0c\u7531\u6b64\u5ffd\u7136\u60f3\u5230pytorch\u6216\u8005numpy\u4e2dtensor(\u6216\u8005ndarray)\u91cc\u9762\u89c6\u56fe\u7684\u6982\u5ff5\u3002</p>"},{"location":"python%26C%2B%2B/2022%E5%B9%B406%E6%9C%8807%E6%97%A5%2015%E6%97%B650%E5%88%8636%E7%A7%92/#_2","title":"\u89c6\u56fe","text":"<ul> <li>\u89c6\u56fe\u662f\u6570\u636e\u7684\u4e00\u4e2a\u522b\u79f0\u6216\u5f15\u7528\uff0c\u901a\u8fc7\u8be5\u522b\u79f0\u6216\u5f15\u7528\u4ea6\u4fbf\u53ef\u8bbf\u95ee\u3001\u64cd\u4f5c\u539f\u6709\u6570\u636e\uff0c\u4f46\u539f\u6709\u6570\u636e\u4e0d\u4f1a\u4ea7\u751f\u62f7\u8d1d\u3002\u5982\u679c\u6211\u4eec\u5bf9\u89c6\u56fe\u8fdb\u884c\u4fee\u6539\uff0c\u5b83\u4f1a\u5f71\u54cd\u5230\u539f\u59cb\u6570\u636e\uff0c\u7269\u7406\u5185\u5b58\u5728\u540c\u4e00\u4f4d\u7f6e\u3002</li> <li>\u526f\u672c\u662f\u4e00\u4e2a\u6570\u636e\u7684\u5b8c\u6574\u7684\u62f7\u8d1d\uff0c\u5982\u679c\u6211\u4eec\u5bf9\u526f\u672c\u8fdb\u884c\u4fee\u6539\uff0c\u5b83\u4e0d\u4f1a\u5f71\u54cd\u5230\u539f\u59cb\u6570\u636e\uff0c\u7269\u7406\u5185\u5b58\u4e0d\u5728\u540c\u4e00\u4f4d\u7f6e\u3002</li> </ul> <p>\u89c6\u56fe\u4e00\u822c\u53d1\u751f\u5728\uff1a</p> <ol> <li>numpy\u7684\u5207\u7247\u64cd\u4f5c\u8fd4\u56de\u539f\u6570\u636e\u7684\u89c6\u56fe\u3002</li> <li>\u8c03\u7528 ndarray \u7684 <code>view()</code> \u51fd\u6570\u4ea7\u751f\u4e00\u4e2a\u89c6\u56fe\u3002</li> <li>\u8c03\u7528 <code>transpose</code>, <code>.T</code></li> <li>\u8c03\u7528 <code>np.split</code></li> <li>\u8c03\u7528\u5176\u4ed6\u4e0d\u4f1a\u53d1\u751f\u5185\u5b58copy\u7684\u51fd\u6570</li> </ol> <p>\u7279\u522b\u7684\uff0c\u5982\u679c\u5bf9\u4e8e contiguous = False \u7684\u6570\u636e\uff0c\u76f4\u63a5\u5bf9\u5176<code>.shape</code>\u8d4b\u503c\u4f1a\u62a5\u9519\uff0c\u8c03\u7528<code>reshape</code>\u64cd\u4f5c\u4f1a\u53d1\u751fcopy\u64cd\u4f5c\u3002 \u526f\u672c\u4e00\u822c\u53d1\u751f\u5728\uff1a</p> <ol> <li>Python \u5e8f\u5217\u7684\u5207\u7247\u64cd\u4f5c\uff0c\u8c03\u7528deepCopy()\u51fd\u6570\u3002</li> <li>\u8c03\u7528 ndarray \u7684 copy() \u51fd\u6570\u4ea7\u751f\u4e00\u4e2a\u526f\u672c\u3002</li> </ol>"},{"location":"python%26C%2B%2B/2022%E5%B9%B406%E6%9C%8807%E6%97%A5%2015%E6%97%B650%E5%88%8636%E7%A7%92/#bug","title":"bug\u590d\u73b0","text":"<p>\u65e2\u7136\u521b\u5efa\u89c6\u56fe\u4e0d\u4f1a\u53d1\u751f\u5185\u5b58\u590d\u5236\uff0c\u90a3\u5bf9\u4e8e\u6240\u6709\u62e5\u6709\u4e0d\u540c\u89c6\u56fe\u5374\u62e5\u6709\u76f8\u540c\u6570\u636e\u5b58\u50a8\u5730\u5740\u7684ndarray\u6216\u8005tensor\u6765\u8bf4\uff0c\u6307\u5411\u7684\u7a7a\u95f4\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u6837python\u4e2d\u6570\u636e\u4f20\u5165c/c++\u65f6\u8bfb\u53d6\u7684\u5b9e\u9645\u4e0a\u8fd8\u662f\u539f\u6570\u636e\u3002 \u6bd4\u5982\u9488\u5bf9\u4e8etensor A\uff0c\u73b0\u5728\u60f3\u628aA.T\u5229\u7528ctypes\u6216\u8005cython\u4f20\u7ed9c\u7a0b\u5e8f\uff0c\u76f4\u63a5\u4f20\u5165<code>A.T</code>\u5c31\u4f1a\u4ea7\u751fbug\uff0c\u800c\u4e14\u4e0d\u6613\u67e5\u627e\u3002</p> <pre><code>import numpy as np\nA = np.random.rand(1,9,2)\nB = A.T\nnp.savez('testB.npz', b = B)\nC = np.load('testB.npz')\nnewB = C['b']\nprint(newB)\nprint(A)\n# \u6309\u7167\u5185\u5b58\u6392\u5217\u65b9\u5f0f\u67e5\u770b\u6570\u636e\nprint(newB.ravel(order='K'))\nprint(A.ravel(order='K'))\n</code></pre> <p>\u6b63\u5982\u4e0a\u9762code\u6240\u793a\uff0c\u5982\u679c\u76f4\u63a5\u770bA\u6216\u8005newB\uff0c\u6070\u597d\u53ef\u4ee5\u770b\u5230newB\u6070\u597d\u662fA\u7684\u8f6c\u7f6e\uff0c\u5373\u4f7f\u53cd\u5e8f\u5217\u5316\u4ee5\u540e\u4e5f\u662f\u4e00\u6837\uff0c\u4f46\u662f\u6309\u7167\u5185\u5b58\u6392\u5217\u65b9\u5f0f\u6253\u5370A\u548cnewB\u5c31\u53ef\u4ee5\u770b\u5230\u4ed6\u4eec\u7684\u6570\u636e\u6392\u5217\u662f\u4e00\u6837\u7684\u3002</p> <p>\u8fd9\u91ccravel\u51fd\u6570\u7684order\u53c2\u6570\u89e3\u91ca\u5982\u4e0b order{\u2018C\u2019,\u2019F\u2019, \u2018A\u2019, \u2018K\u2019}, optional The elements of a are read using this index order. \u2018C\u2019 means to index the elements in row-major, C-style order, with the last axis index changing fastest, back to the first axis index changing slowest. \u2018F\u2019 means to index the elements in column-major, Fortran-style order, with the first index changing fastest, and the last index changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of the memory layout of the underlying array, and only refer to the order of axis indexing. \u2018A\u2019 means to read the elements in Fortran-like index order if a is Fortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the elements in the order they occur in memory, except for reversing the data when strides are negative. By default, \u2018C\u2019 index order is used. \u6240\u4ee5\u5c3d\u7ba1\u6211\u4eec\u7684\u76ee\u7684\u662f\u60f3\u7ed9C/C++\u51fd\u6570\u4f20\u5165A\u7684\u8f6c\u7f6e\uff0c\u4f46\u4f20\u5165\u7684\u4f9d\u7136\u662fA\u3002<code>A.T</code>\u4ec5\u4ec5\u662f\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u56fe\uff0c\u5e76\u4e14\u5176\u6570\u636e\u4e5f\u4e0d\u518d\u662f<code>contiguous</code>\uff0c\u53e6\u5916\u6253\u5370<code>A.T.flags</code>\u4f1a\u53d1\u73b0</p> <pre><code>C_CONTIGUOUS : False\n&gt; F_CONTIGUOUS : True\n&gt; OWNDATA : False\n&gt; WRITEABLE : True\n&gt; ALIGNED : True\n&gt; WRITEBACKIFCOPY : False\n&gt; UPDATEIFCOPY : False\n</code></pre> <p>\u65b0\u7684\u89c6\u56fe\u53d8\u6210\u4e86\u5217\u8fde\u7eed\u3002\uff08C\u4ee3\u8868C\u8bed\u8a00\u683c\u5f0f\u5b58\u50a8,\u884c\u4f18\u5148\uff0cF\u4ee3\u8868Fortran \u8868\u793a\u5217\u4f18\u5148\uff09 \u90a3\u4e48\u8be5\u5982\u4f55\u89e3\u51b3\u5462\uff1f \u5b9e\u9645\u4e0a\u89e3\u51b3\u601d\u8def\u5f88\u7b80\u5355\uff0c\u90a3\u5c31\u662f\u5c06\u6309\u7167\u6570\u636e\u7684\u89c6\u56fe\u91cd\u65b0\u590d\u5236\u4e00\u904d\u6570\u636e\uff0c\u5c06\u5176\u53d8\u4e3a<code>contiguous</code>\u7684\u3002\u5373\u4f20\u5165A\u7684\u8f6c\u7f6e\u65f6\u8c03\u7528<code>np.ascontiguous(A.T)</code>\u5373\u53ef\u5c06\u5176\u6570\u636ecopy\u4e00\u8fb9\u5e76\u8bbe\u7f6e\u4e3a\u884c\u4f18\u5148\u5b58\u50a8\u3002</p>"},{"location":"python%26C%2B%2B/2022%E5%B9%B406%E6%9C%8807%E6%97%A5%2015%E6%97%B650%E5%88%8636%E7%A7%92/#_3","title":"\u5c0f\u7ed3","text":"<p>\u8fd9\u4e2abug\u5b9e\u5728\u9690\u853d\uff0c\u6211\u5bf9\u8ba1\u7b97\u56fe\u7684\u67d0\u4e2a\u6a21\u5757\u4e00\u5c42\u4e00\u5c42\u7684\u6253\u5370\u548c\u6821\u5bf9\u624d\u627e\u5230\uff0c\u89e3\u51b3\u95ee\u9898\u540e\u5206\u6790\u539f\u56e0\u5199\u4e0b\u8fd9\u7bc7\u6587\u7ae0\u907f\u514d\u4ee5\u540e\u518d\u51fa\u9519\u3002</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/","title":"Numpy\u548cEigen\u2014Python\u4e0eC++\u4e2d\u7684\u77e9\u9635\u8fd0\u7b97\u5e93\u7684\u8054\u7cfb","text":"<p>\u672c\u6587\u5199\u4e8e2024\u5e749\u670817\u65e5\u665a\u5341\u70b9</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#_1","title":"\u4e00\u3001\u9700\u6c42\u80cc\u666f","text":"<p>\u5728\u4e00\u4e2a\u7eafC/C++\u7684\u9879\u76ee\u4e2d\u7684\u9879\u76ee\u4e2d\uff0c\u7b97\u6cd5\u5f00\u53d1\u4eba\u5458\u5728CPU\u4e0a\u4e60\u60ef\u91c7\u7528python\u4e2d\u7684numpy\u5e93\u7f16\u5199\u4e86\u76f8\u5173\u4f18\u5316\u7b97\u6cd5\uff0c\u4f46\u5de5\u7a0b\u8981\u6c42\u9700\u8981\u5c06python\u5b9e\u73b0\u7684\u7b97\u6cd5\u4ee5C/C++\u8bed\u8a00\u91cd\u65b0\u8868\u8fbe\u4ee5\u65b9\u4fbf\u5728\u5404\u4e2a\u786c\u4ef6\u5e73\u53f0\u4e0a\u7684\u7f16\u8bd1\u79fb\u690d\u3002</p> <p>\u7531\u6b64\uff0c\u5f15\u51fa\u4e86\u8be5\u9879\u6280\u672f\uff1aPython\u4e2d\u7684\u77e9\u9635\u8fd0\u7b97\u5e93numpy\u4e0eC++\u4e2d\u7684\u77e9\u9635\u5143\u7d20\u5e93-Eigen\u4e4b\u95f4\u7684\u8f6c\u6362\u3002</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#_2","title":"\u4e8c\u3001\u76f8\u5173\u5e93\u4ecb\u7ecd","text":"<p>NumPy\uff08Numerical Python\u7684\u7b80\u79f0\uff09\u662f\u4e00\u4e2a\u5f00\u6e90\u7684Python\u79d1\u5b66\u8ba1\u7b97\u5e93\uff0c\u7528\u4e8e\u5904\u7406\u5927\u578b\u591a\u7ef4\u6570\u7ec4\u548c\u77e9\u9635\uff0c\u63d0\u4f9b\u4e86\u5927\u91cf\u7684\u6570\u5b66\u51fd\u6570\u6765\u64cd\u4f5c\u8fd9\u4e9b\u6570\u7ec4\u3002\u4ee5\u4e0b\u662fNumPy\u7684\u4e00\u4e9b\u4e3b\u8981\u7279\u70b9\uff1a  </p> <ol> <li>\u5f3a\u5927\u7684\u6570\u7ec4\u5bf9\u8c61\uff1aNumPy\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684n\u7ef4\u6570\u7ec4\u5bf9\u8c61\uff08\u5373<code>ndarray</code>\uff09\uff0c\u5b83\u662f\u4e00\u4e2a\u7528\u4e8e\u5b58\u50a8\u540c\u7c7b\u578b\u6570\u636e\u7684\u591a\u7ef4\u5bb9\u5668\u3002\u8fd9\u79cd\u6570\u7ec4\u6bd4Python\u539f\u751f\u7684\u5217\u8868\u66f4\u52a0\u9ad8\u6548\u548c\u65b9\u4fbf\u3002  </li> <li>\u5e7f\u64ad\u529f\u80fd\uff1aNumPy\u7684\u5e7f\u64ad\u529f\u80fd\u5141\u8bb8\u4e0d\u540c\u5f62\u72b6\u7684\u6570\u7ec4\u5728\u8fd0\u7b97\u65f6\u8fdb\u884c\u81ea\u52a8\u6269\u5c55\uff0c\u4f7f\u5f97\u4ee3\u7801\u66f4\u52a0\u7b80\u6d01\u3002  </li> <li>\u6570\u5b66\u51fd\u6570\u5e93\uff1aNumPy\u63d0\u4f9b\u4e86\u5927\u91cf\u7684\u6570\u5b66\u51fd\u6570\uff0c\u53ef\u4ee5\u7528\u4e8e\u6267\u884c\u5404\u79cd\u6570\u5b66\u8fd0\u7b97\uff0c\u5982\u7ebf\u6027\u4ee3\u6570\u3001\u5085\u91cc\u53f6\u53d8\u6362\u3001\u6982\u7387\u5206\u5e03\u7b49\u3002  </li> <li>\u9ad8\u6548\u7684\u5185\u5b58\u4f7f\u7528\uff1aNumPy\u7684\u6570\u7ec4\u5728\u5185\u5b58\u4e2d\u662f\u8fde\u7eed\u5b58\u50a8\u7684\uff0c\u8fd9\u6709\u52a9\u4e8e\u63d0\u9ad8\u6570\u636e\u5904\u7406\u7684\u6548\u7387\u3002  </li> <li>\u6210\u719f\u7684\u751f\u6001\u7cfb\u7edf\uff1aNumPy\u662fPython\u79d1\u5b66\u8ba1\u7b97\u751f\u6001\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u8bb8\u591a\u5176\u4ed6\u79d1\u5b66\u8ba1\u7b97\u5e93\uff08\u5982Pandas\u3001SciPy\u3001Matplotlib\u7b49\uff09\u90fd\u4f9d\u8d56\u4e8eNumPy\u3002  </li> </ol> <p>NumPy\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6570\u636e\u5206\u6790\u3001\u673a\u5668\u5b66\u4e60\u3001\u56fe\u50cf\u5904\u7406\u3001\u7269\u7406\u5b66\u6a21\u62df\u7b49\u9886\u57df\uff0c\u662fPython\u79d1\u5b66\u8ba1\u7b97\u4e0d\u53ef\u6216\u7f3a\u7684\u5de5\u5177\u4e4b\u4e00\u3002</p> <p>Eigen\u662f\u4e00\u4e2a\u9ad8\u7ea7\u7684C++\u5e93\uff0c\u7528\u4e8e\u7ebf\u6027\u4ee3\u6570\u3001\u77e9\u9635\u548c\u5411\u91cf\u8fd0\u7b97\uff0c\u6570\u503c\u89e3\u7b97\u4ee5\u53ca\u76f8\u5173\u7684\u7b97\u6cd5\u3002\u5b83\u662f\u7531Benjamin Schindler\u3001Ga\u00ebl Guennebaud\u548c\u5176\u4ed6\u8d21\u732e\u8005\u5171\u540c\u5f00\u53d1\u7684\uff0c\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u3001\u9ad8\u6548\u4e14\u7075\u6d3b\u7684API\u6765\u5904\u7406\u6570\u503c\u8ba1\u7b97\u95ee\u9898\u3002\u4ee5\u4e0b\u662fEigen\u7684\u4e00\u4e9b\u4e3b\u8981\u7279\u70b9\uff1a  </p> <ol> <li>\u77e9\u9635\u548c\u5411\u91cf\u7684\u8868\u793a\uff1aEigen\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6570\u636e\u7ed3\u6784\u6765\u8868\u793a\u77e9\u9635\u548c\u5411\u91cf\uff0c\u652f\u6301\u52a8\u6001\u548c\u56fa\u5b9a\u5927\u5c0f\u7684\u7c7b\u578b\uff0c\u4ee5\u53ca\u7279\u6b8a\u7c7b\u578b\u7684\u77e9\u9635\uff0c\u5982\u5bf9\u89d2\u77e9\u9635\u3001\u4e09\u5bf9\u89d2\u77e9\u9635\u7b49\u3002</li> <li>\u76f4\u89c2\u7684\u63a5\u53e3\uff1aEigen\u7684\u63a5\u53e3\u8bbe\u8ba1\u5f97\u5f88\u76f4\u89c2\uff0c\u4f7f\u5f97\u7f16\u5199\u77e9\u9635\u8fd0\u7b97\u7684\u4ee3\u7801\u5c31\u50cf\u5728\u7eb8\u4e0a\u5199\u6570\u5b66\u516c\u5f0f\u4e00\u6837\u7b80\u5355\u3002</li> <li>\u9ad8\u6548\u7684\u6027\u80fd\uff1aEigen\u7ecf\u8fc7\u9ad8\u5ea6\u4f18\u5316\uff0c\u80fd\u591f\u5145\u5206\u5229\u7528\u73b0\u4ee3CPU\u7684\u6307\u4ee4\u96c6\uff0c\u5982SSE\u548cAVX\uff0c\u4ee5\u63d0\u4f9b\u5feb\u901f\u7684\u77e9\u9635\u8fd0\u7b97\u3002</li> <li>\u5b8c\u5168\u7684\u6a21\u677f\u5316\uff1aEigen\u662f\u4e00\u4e2a\u5b8c\u5168\u6a21\u677f\u5316\u7684\u5e93\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u53ef\u4ee5\u4e0e\u4efb\u4f55\u6570\u503c\u7c7b\u578b\u4e00\u8d77\u4f7f\u7528\uff0c\u5305\u62ec\u6807\u51c6\u7684\u5185\u7f6e\u7c7b\u578b\u3001\u7528\u6237\u5b9a\u4e49\u7684\u7c7b\u578b\u4ee5\u53ca\u7b2c\u4e09\u65b9\u5e93\u4e2d\u7684\u7c7b\u578b\u3002</li> <li>\u652f\u6301\u590d\u6742\u7684\u6570\u5b66\u8fd0\u7b97\uff1aEigen\u4e0d\u4ec5\u652f\u6301\u57fa\u672c\u7684\u7ebf\u6027\u4ee3\u6570\u8fd0\u7b97\uff0c\u8fd8\u652f\u6301\u66f4\u590d\u6742\u7684\u6570\u5b66\u8fd0\u7b97\uff0c\u5982\u7279\u5f81\u503c\u5206\u89e3\u3001\u5947\u5f02\u503c\u5206\u89e3\u3001\u77e9\u9635\u6c42\u9006\u3001\u6700\u5c0f\u4e8c\u4e58\u6c42\u89e3\u7b49\u3002</li> <li>\u6613\u4e8e\u96c6\u6210\uff1aEigen\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u96c6\u6210\u5230\u73b0\u6709\u7684C++\u9879\u76ee\u4e2d\uff0c\u53ea\u9700\u8981\u5305\u542b\u76f8\u5e94\u7684\u5934\u6587\u4ef6\u5373\u53ef\u3002</li> <li>\u8de8\u5e73\u53f0\uff1aEigen\u662f\u8de8\u5e73\u53f0\u7684\uff0c\u53ef\u4ee5\u5728\u591a\u79cd\u64cd\u4f5c\u7cfb\u7edf\u4e0a\u7f16\u8bd1\u548c\u4f7f\u7528\uff0c\u5305\u62ecLinux\u3001Windows\u548cmacOS\u3002</li> </ol> <p>Eigen\u5e7f\u6cdb\u5e94\u7528\u4e8e\u79d1\u5b66\u7814\u7a76\u3001\u5de5\u7a0b\u8ba1\u7b97\u3001\u673a\u5668\u5b66\u4e60\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49\u9886\u57df\uff0c\u662fC++\u5f00\u53d1\u8005\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\u7684\u4e00\u4e2a\u5f3a\u5927\u5de5\u5177\u3002\u7531\u4e8e\u5176\u9ad8\u6548\u7684\u6027\u80fd\u548c\u6613\u7528\u7684\u63a5\u53e3\uff0cEigen\u5728\u9700\u8981\u9ad8\u6027\u80fd\u6570\u503c\u8ba1\u7b97\u7684\u9879\u76ee\u4e2d\u975e\u5e38\u53d7\u6b22\u8fce\u3002</p> <p>\u5bf9\u4e0a\u8ff0\u4e24\u8005\u7684\u76f8\u4e92\u8f6c\u6362\u8981\u6c42\u5f00\u53d1\u8005\u719f\u6089\u77e9\u9635\u8fd0\u7b97\u7684\u8868\u8fbe\u548c\u5316\u7b80\uff0c\u4ee5\u53ca\u5bf9\u4e8enumpy\u548cEigen\uff0cpython\u3001C++\u7b49\u90fd\u6bd4\u8f83\u719f\u6089\u3002</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#_3","title":"\u4e09\u3001\u76f8\u5173\u8f6c\u6362","text":""},{"location":"python%26C%2B%2B/matrix_python_cpp/#31","title":"3.1 \u77e9\u9635\u6570\u636e\u8bfb\u53d6\u5185\u5b58\u7684\u8f6c\u6362","text":"<p>Eigen\u9ed8\u8ba4\u662f\u5217\u4f18\u5148\uff08column-major\uff09\u7684\u5b58\u50a8\u987a\u5e8f\u3002\u8fd9\u610f\u5473\u7740\u5728\u5185\u5b58\u4e2d\uff0c\u77e9\u9635\u7684\u5217\u662f\u8fde\u7eed\u5b58\u50a8\u7684\u3002\u8fd9\u4e0eMATLAB\u548cFortran\u4e2d\u7684\u5b58\u50a8\u987a\u5e8f\u76f8\u540c\uff0c\u4f46\u4e0eC/C++\u9ed8\u8ba4\u7684\u884c\u4f18\u5148\uff08row-major\uff09\u5b58\u50a8\u987a\u5e8f\u4e0d\u540c\u3002</p> <p>\u5728Eigen\u4e2d\uff0c\u5982\u679c\u4f60\u60f3\u8981\u4f7f\u7528\u884c\u4f18\u5148\u5b58\u50a8\u987a\u5e8f\uff0c\u53ef\u4ee5\u91c7\u7528\u5982\u4e0b\u4ee3\u7801\u5b9a\u4e49\u884c\u4f18\u5148\u7684\u7c7b\uff1a</p> <pre><code>#include &lt;Eigen/Dense&gt;\n\nnamespace Eigen {\n    using MatrixXiRowMajor = Eigen::Matrix&lt;int, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;;\n    using MatrixXdRowMajor = Eigen::Matrix&lt;double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;;\n    using MatrixXfRowMajor = Eigen::Matrix&lt;float, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;;\n};\n</code></pre> <p>NumPy\u9ed8\u8ba4\u4f7f\u7528\u884c\u4f18\u5148\uff08row-major\uff09\u7684\u5b58\u50a8\u987a\u5e8f\uff0c\u4fdd\u5b58npy\u6587\u4ef6\u65f6\u9ed8\u8ba4\u4e5f\u662f\u884c\u4f18\u5148\u5b58\u50a8\uff0c\u8fd9\u610f\u5473\u7740\u5728\u5185\u5b58\u4e2d\uff0c\u77e9\u9635\u7684\u884c\u662f\u8fde\u7eed\u5b58\u50a8\u7684\uff0c\u8fd9\u4e0eC\u8bed\u8a00\u4e2d\u7684\u6570\u7ec4\u5b58\u50a8\u987a\u5e8f\u662f\u4e00\u81f4\u7684\u3002</p> <p>\u5982\u679c\u60f3\u5b9e\u73b0numpy\u4e2d\u7684npy\u6587\u4ef6\u4ee5\u6b63\u5e38\u7684Eigen\u5f62\u5f0f\u8868\u8fbe\uff0c\u65b9\u5f0f\u4e4b\u4e00\u662f\u91c7\u7528\u5217\u4f18\u5148\u65b9\u5f0f\u8bfb\u53d6\uff0c\u7136\u540e\u8f6c\u7f6e\u3002</p> <p>\u5728\u5217\u4f18\u5148\u7684\u8bbe\u7f6e\u4e0b\uff0c\u5148\u5c06\u884c\u548c\u5217\u7684\u8bbe\u7f6e\u4e92\u6362\uff0c</p> <pre><code>Eigen::MatrixXfRowMajor load_conf_npy(const std::string&amp; npy_path) {\n    cnpy::NpyArray conf_1_npy = cnpy::npy_load(npy_path);\n    int col = conf_1_npy.shape.back();\n    int row = 1;\n    for(int i = 0; i &lt; (int)conf_1_npy.shape.size() - 1; ++i) {\n        row *= conf_1_npy.shape[i];\n    }\n    return Eigen::Map&lt;Eigen::MatrixXf, Eigen::ColMajor&gt;(conf_1_npy.data&lt;float&gt;(), col, row).transpose();\n}\n</code></pre> <p>\u4e3e\u4e2a\u6817\u5b50\uff1a</p> <p>\u539f\u77e9\u96352x3\u4e3a</p> <pre><code>1 2 3\n4 5 6\n</code></pre> <p>\u884c\u4f18\u5148\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\u4e3a</p> <pre><code>1 2 3 4 5 6\n</code></pre> <p>\u6309\u7167\u5217\u4f18\u5148\u8bfb\u53d6\u4e3a3x2\u7684\u77e9\u9635\uff0c\u8868\u793a\u5982\u4e0b</p> <pre><code>1 4\n2 5\n3 6\n</code></pre> <p>\u8f6c\u7f6e\u540e\u4e3a</p> <pre><code>1 2 3\n4 5 6\n</code></pre> <p>\u518d\u4e4b\u540e\u8f6c\u6362\u4e3a\u884c\u4f18\u5148\u5b58\u50a8\u5373\u53ef</p> <p>\u7a0d\u5fae\u6709\u70b9\u7ed5\uff0c\u8bfb\u8005\u8fd8\u8bf7\u81ea\u884c\u7406\u89e3\u4e00\u4e0b</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#32","title":"3.2 \u57fa\u672c\u8fd0\u7b97\u64cd\u4f5c","text":"<p>\u5728Eigen\u5e93\u4e2d\uff0c\u77e9\u9635\u7684\u52a0\u51cf\u4e58\u9664\u64cd\u4f5c\u975e\u5e38\u76f4\u89c2\u3002\u4ee5\u4e0b\u662f\u5982\u4f55\u5728Eigen\u4e2d\u6267\u884c\u8fd9\u4e9b\u57fa\u672c\u77e9\u9635\u8fd0\u7b97\u7684\u793a\u4f8b\uff1a</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#321-addition","title":"3.2.1 \u52a0\u6cd5\uff08Addition\uff09","text":"<p>\u8981\u6dfb\u52a0\u4e24\u4e2a\u77e9\u9635\uff0c\u5b83\u4eec\u5fc5\u987b\u5177\u6709\u76f8\u540c\u7684\u7ef4\u5ea6\u3002</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::Matrix2d mat1;\n    Eigen::Matrix2d mat2;\n\n    mat1 &lt;&lt; 1, 2,\n            3, 4;\n    mat2 &lt;&lt; 5, 6,\n            7, 8;\n\n    // \u77e9\u9635\u52a0\u6cd5\n    Eigen::Matrix2d resultAdd = mat1 + mat2;\n\n    std::cout &lt;&lt; \"Addition:\n\" &lt;&lt; resultAdd &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#322-subtraction","title":"3.2.2 \u51cf\u6cd5\uff08Subtraction\uff09","text":"<p>\u4e0e\u52a0\u6cd5\u7c7b\u4f3c\uff0c\u4e24\u4e2a\u77e9\u9635\u5fc5\u987b\u5177\u6709\u76f8\u540c\u7684\u7ef4\u5ea6\u624d\u80fd\u8fdb\u884c\u51cf\u6cd5\u3002</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::Matrix2d mat1;\n    Eigen::Matrix2d mat2;\n\n    mat1 &lt;&lt; 1, 2,\n            3, 4;\n    mat2 &lt;&lt; 5, 6,\n            7, 8;\n\n    // \u77e9\u9635\u51cf\u6cd5\n    Eigen::Matrix2d resultSub = mat1 - mat2;\n\n    std::cout &lt;&lt; \"Subtraction:\n\" &lt;&lt; resultSub &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#323","title":"3.2.3 \u5143\u7d20\u7ea7\u522b\u4e58\u9664\u6cd5","text":"<p>\u5728Eigen\u4e2d\uff0c\u5982\u679c\u4f60\u60f3\u6267\u884c\u77e9\u9635\u7684\u5143\u7d20\u7ea7\u522b\u7684\u4e58\u9664\uff08\u5373\u9010\u5143\u7d20\u4e58\u6cd5\u6216\u9010\u5143\u7d20\u9664\u6cd5\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528<code>array</code>\u7c7b\u578b\u7684\u5bf9\u8c61\uff0c\u6216\u8005\u4f7f\u7528\u7279\u6b8a\u7684\u6210\u5458\u51fd\u6570<code>cwiseProduct()</code>\u548c<code>cwiseQuotient()</code>\u3002\u4ee5\u4e0b\u662f\u9010\u5143\u7d20\u4e58\u6cd5\u548c\u9664\u6cd5\u7684\u793a\u4f8b\uff1a</p> <p>\u9010\u5143\u7d20\u4e58\u6cd5\uff08Element-wise Multiplication\uff09</p> <p>\u4f7f\u7528<code>array</code>\u7c7b\u578b\uff1a</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::Matrix2d mat1;\n    Eigen::Matrix2d mat2;\n\n    mat1 &lt;&lt; 1, 2,\n            3, 4;\n    mat2 &lt;&lt; 5, 6,\n            7, 8;\n\n    // \u9010\u5143\u7d20\u4e58\u6cd5\uff08\u4f7f\u7528array\uff09\n    Eigen::ArrayXXd resultMul = mat1.array() * mat2.array();\n\n    std::cout &lt;&lt; \"Element-wise Multiplication:\n\" &lt;&lt; resultMul &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u4f7f\u7528<code>cwiseProduct()</code>\u51fd\u6570\uff1a</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::Matrix2d mat1;\n    Eigen::Matrix2d mat2;\n\n    mat1 &lt;&lt; 1, 2,\n            3, 4;\n    mat2 &lt;&lt; 5, 6,\n            7, 8;\n\n    // \u9010\u5143\u7d20\u4e58\u6cd5\uff08\u4f7f\u7528cwiseProduct\uff09\n    Eigen::Matrix2d resultMul = mat1.cwiseProduct(mat2);\n\n    std::cout &lt;&lt; \"Element-wise Multiplication:\n\" &lt;&lt; resultMul &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u9010\u5143\u7d20\u9664\u6cd5\uff08Element-wise Division\uff09\uff0c\u4f7f\u7528<code>array</code>\u7c7b\u578b\uff1a</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::Matrix2d mat1;\n    Eigen::Matrix2d mat2;\n\n    mat1 &lt;&lt; 1, 2,\n            3, 4;\n    mat2 &lt;&lt; 5, 6,\n            7, 8;\n\n    // \u9010\u5143\u7d20\u9664\u6cd5\uff08\u4f7f\u7528array\uff09\n    Eigen::ArrayXXd resultDiv = mat1.array() / mat2.array();\n\n    std::cout &lt;&lt; \"Element-wise Division:\n\" &lt;&lt; resultDiv &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u4f7f\u7528<code>cwiseQuotient()</code>\u51fd\u6570\uff1a</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::Matrix2d mat1;\n    Eigen::Matrix2d mat2;\n\n    mat1 &lt;&lt; 1, 2,\n            3, 4;\n    mat2 &lt;&lt; 5, 6,\n            7, 8;\n\n    // \u9010\u5143\u7d20\u9664\u6cd5\uff08\u4f7f\u7528cwiseQuotient\uff09\n    Eigen::Matrix2d resultDiv = mat1.cwiseQuotient(mat2);\n\n    std::cout &lt;&lt; \"Element-wise Division:\n\" &lt;&lt; resultDiv &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u5728\u8fd9\u4e9b\u4f8b\u5b50\u4e2d\uff0c<code>array()</code>\u6210\u5458\u51fd\u6570\u5c06\u77e9\u9635\u8f6c\u6362\u4e3a\u6570\u7ec4\u7c7b\u578b\uff0c\u5141\u8bb8\u8fdb\u884c\u9010\u5143\u7d20\u7684\u7b97\u672f\u8fd0\u7b97\u3002\u4f7f\u7528<code>cwiseProduct()</code>\u548c<code>cwiseQuotient()</code>\u51fd\u6570\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u539f\u59cb\u77e9\u9635\u7c7b\u578b\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u9010\u5143\u7d20\u8fd0\u7b97\u3002</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#324-matrix-multiplication","title":"3.2.4 \u77e9\u9635\u4e58\u6cd5\uff08Matrix Multiplication\uff09","text":"<p>\u4e24\u4e2a\u77e9\u9635\u8fdb\u884c\u4e58\u6cd5\u65f6\uff0c\u7b2c\u4e00\u4e2a\u77e9\u9635\u7684\u5217\u6570\u5fc5\u987b\u7b49\u4e8e\u7b2c\u4e8c\u4e2a\u77e9\u9635\u7684\u884c\u6570\u3002</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::Matrix2d mat1;\n    Eigen::Matrix2d mat2;\n\n    mat1 &lt;&lt; 1, 2,\n            3, 4;\n    mat2 &lt;&lt; 5, 6,\n            7, 8;\n\n    // \u77e9\u9635\u4e58\u6cd5\n    Eigen::Matrix2d resultMul = mat1 * mat2;\n\n    std::cout &lt;&lt; \"Multiplication:\n\" &lt;&lt; resultMul &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#33","title":"3.3 \u884c\u5217\u5f52\u7ea6\u64cd\u4f5c","text":"<p>\u5728NumPy\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528<code>numpy.sum</code>\u548c<code>numpy.mean</code>\u51fd\u6570\u6765\u6309\u7167\u884c\u6216\u5217\u5bf9\u6570\u7ec4\u8fdb\u884c\u6c42\u548c\u548c\u6c42\u5e73\u5747\u64cd\u4f5c\u3002\u8fd9\u4e24\u4e2a\u51fd\u6570\u90fd\u63a5\u53d7\u4e00\u4e2a<code>axis</code>\u53c2\u6570\uff0c\u8be5\u53c2\u6570\u6307\u5b9a\u4e86\u6cbf\u54ea\u4e2a\u8f74\u8fdb\u884c\u64cd\u4f5c\u3002</p> <p>\u4ee5\u4e0b\u662f\u5982\u4f55\u6309\u7167\u884c\u6216\u5217\u8fdb\u884c\u6c42\u548c\u548c\u6c42\u5e73\u5747\u7684\u793a\u4f8b\uff1a</p> <p>\u6309\u5217\u6c42\u548c</p> <pre><code>import numpy as np\n\n# \u521b\u5efa\u4e00\u4e2a2x3\u7684\u6570\u7ec4\narr = np.array([[1, 2, 3],\n                [4, 5, 6]])\n\n# \u6309\u5217\u6c42\u548c\nsums_cols = np.sum(arr, axis=0)\nprint(sums_cols)  # \u8f93\u51fa: [5 7 9]\n</code></pre> <p>\u6309\u884c\u6c42\u548c</p> <pre><code># \u6309\u884c\u6c42\u548c\nsums_rows = np.sum(arr, axis=1)\nprint(sums_rows)  # \u8f93\u51fa: [ 6 15]\n</code></pre> <p>\u6309\u5217\u6c42\u5e73\u5747</p> <pre><code># \u6309\u5217\u6c42\u5e73\u5747\nmeans_cols = np.mean(arr, axis=0)\nprint(means_cols)  # \u8f93\u51fa: [2.5 3.5 4.5]\n</code></pre> <p>\u6309\u884c\u6c42\u5e73\u5747</p> <pre><code># \u6309\u884c\u6c42\u5e73\u5747\nmeans_rows = np.mean(arr, axis=1)\nprint(means_rows)  # \u8f93\u51fa: [2. 5.]\n</code></pre> <p>\u5728\u8fd9\u4e9b\u4f8b\u5b50\u4e2d\uff0c<code>axis=0</code>\u8868\u793a\u6cbf\u7740\u7b2c\u4e00\u4e2a\u8f74\u64cd\u4f5c\uff0c\u5373\u6309\u5217\u8fdb\u884c\u64cd\u4f5c\uff1b<code>axis=1</code>\u8868\u793a\u6cbf\u7740\u7b2c\u4e8c\u4e2a\u8f74\u64cd\u4f5c\uff0c\u5373\u6309\u884c\u8fdb\u884c\u64cd\u4f5c\u3002\u5982\u679c\u4e0d\u6307\u5b9a<code>axis</code>\u53c2\u6570\uff0c<code>numpy.sum</code>\u548c<code>numpy.mean</code>\u4f1a\u8ba1\u7b97\u6574\u4e2a\u6570\u7ec4\u7684\u603b\u548c\u548c\u5e73\u5747\u503c\u3002</p> <p>\u5728Eigen\u5e93\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528\u6210\u5458\u51fd\u6570<code>sum()</code>\u548c<code>mean()</code>\u6765\u5206\u522b\u8ba1\u7b97\u77e9\u9635\u7684\u884c\u6216\u5217\u7684\u548c\u4e0e\u5e73\u5747\u503c\u3002\u8fd9\u4e9b\u64cd\u4f5c\u53ef\u4ee5\u901a\u8fc7\u6307\u5b9a\u64cd\u4f5c\u7684\u8f74\uff08\u884c\u6216\u5217\uff09\u6765\u5b8c\u6210\u3002</p> <p>\u4ee5\u4e0b\u662f\u5982\u4f55\u5728Eigen\u4e2d\u4f7f\u7528\u8fd9\u4e9b\u64cd\u4f5c\u7684\u793a\u4f8b\uff1a</p> <p>\u6309\u5217\u6c42\u548c</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXi mat(2, 3);\n    mat &lt;&lt; 1, 2, 3,\n           4, 5, 6;\n\n    // \u6309\u5217\u6c42\u548c\n    Eigen::VectorXi colSums = mat.colwise().sum();\n    std::cout &lt;&lt; \"Column sums: \" &lt;&lt; colSums.transpose() &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u6309\u884c\u6c42\u548c</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXi mat(2, 3);\n    mat &lt;&lt; 1, 2, 3,\n           4, 5, 6;\n\n    // \u6309\u884c\u6c42\u548c\n    Eigen::VectorXi rowSums = mat.rowwise().sum();\n    std::cout &lt;&lt; \"Row sums: \" &lt;&lt; rowSums.transpose() &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u6309\u5217\u6c42\u5e73\u5747</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXi mat(2, 3);\n    mat &lt;&lt; 1, 2, 3,\n           4, 5, 6;\n\n    // \u6309\u5217\u6c42\u5e73\u5747\n    Eigen::VectorXd colMeans = mat.colwise().mean();\n    std::cout &lt;&lt; \"Column means: \" &lt;&lt; colMeans.transpose() &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u6309\u884c\u6c42\u5e73\u5747</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXi mat(2, 3);\n    mat &lt;&lt; 1, 2, 3,\n           4, 5, 6;\n\n    // \u6309\u884c\u6c42\u5e73\u5747\n    Eigen::VectorXd rowMeans = mat.rowwise().mean();\n    std::cout &lt;&lt; \"Row means: \" &lt;&lt; rowMeans.transpose() &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u5728\u8fd9\u4e9b\u793a\u4f8b\u4e2d\uff0c<code>colwise()</code>\u548c<code>rowwise()</code>\u662fEigen\u4e2d\u7684\u64cd\u4f5c\u7b26\uff0c\u5b83\u4eec\u5141\u8bb8\u4f60\u5728\u77e9\u9635\u7684\u5217\u6216\u884c\u4e0a\u5e94\u7528\u51fd\u6570\u3002<code>sum()</code>\u548c<code>mean()</code>\u51fd\u6570\u5206\u522b\u8ba1\u7b97\u548c\u4e0e\u5e73\u5747\u503c\u3002\u6ce8\u610f\uff0c<code>mean()</code>\u51fd\u6570\u8fd4\u56de\u7684\u662f<code>VectorXd</code>\u7c7b\u578b\uff0c\u56e0\u4e3a\u5e73\u5747\u503c\u53ef\u80fd\u662f\u975e\u6574\u6570\u3002\u5982\u679c\u4f60\u6b63\u5728\u5904\u7406\u6574\u6570\u7c7b\u578b\u7684\u77e9\u9635\uff0c\u4f60\u53ef\u80fd\u9700\u8981\u5c06\u7ed3\u679c\u8f6c\u6362\u4e3a\u9002\u5f53\u7684\u7c7b\u578b\u3002</p> <p>Note\uff1a \u9700\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u91cc\u5f97\u5230\u7684\u8fd8\u662f\u4e00\u4e2a\u77e9\u9635\uff0ccolwise\u540e\u5f97\u5230\u7684shape\u4e3a(1, M)\uff0crowwise\u540e\u5f97\u5230\u7684shape\u4e3a(N, 1)\u3002</p> <p>\u5728Eigen\u4e2d\uff0c\u5982\u679c\u4f60\u60f3\u8981\u8ba1\u7b97\u6574\u4e2a\u77e9\u9635\u6240\u6709\u5143\u7d20\u7684\u5747\u503c\uff08mean\uff09\u6216\u603b\u548c\uff08sum\uff09\uff0c\u800c\u4e0d\u662f\u5355\u72ec\u9488\u5bf9\u884c\u6216\u5217\uff0c\u4f60\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528<code>mean()</code>\u548c<code>sum()</code>\u6210\u5458\u51fd\u6570\uff0c\u800c\u4e0d\u9700\u8981\u4f7f\u7528<code>colwise()</code>\u6216<code>rowwise()</code>\u3002</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#34","title":"3.4 \u5e7f\u64ad\u64cd\u4f5c\u7684\u8f6c\u6362","text":"<p>Eigen\u5e93\u652f\u6301\u7c7b\u4f3c\u4e8eNumPy\u4e2d\u7684\u5e7f\u64ad\uff08broadcasting\uff09\u64cd\u4f5c\uff0c\u5c3d\u7ba1Eigen\u4e2d\u7684\u5e7f\u64ad\u6982\u5ff5\u4e0eNumPy\u7684\u7565\u6709\u4e0d\u540c\u3002\u5728Eigen\u4e2d\uff0c\u5e7f\u64ad\u901a\u5e38\u6307\u7684\u662f\u5c06\u4e00\u4e2a\u8f83\u5c0f\u7684\u6570\u7ec4\u6216\u6807\u91cf\u6269\u5c55\u5230\u4e00\u4e2a\u8f83\u5927\u7684\u6570\u7ec4\u4e0a\uff0c\u4ee5\u8fdb\u884c\u9010\u5143\u7d20\u64cd\u4f5c\u3002</p> <p>\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5728Eigen\u4e2d\u6267\u884c\u5e7f\u64ad\u64cd\u4f5c\u7684\u793a\u4f8b\uff1a</p> <ol> <li>\u5c06\u6807\u91cf\u5e7f\u64ad\u5230\u77e9\u9635</li> </ol> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXd mat(2, 3);\n    mat &lt;&lt; 1, 2, 3,\n           4, 5, 6;\n\n    // \u5c06\u6807\u91cf\u5e7f\u64ad\u5230\u77e9\u9635\n    double scalar = 10.0;\n    Eigen::MatrixXd result = mat.array() + scalar;\n\n    std::cout &lt;&lt; \"Broadcast scalar to matrix:\n\" &lt;&lt; result &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u6807\u91cf10.0\u88ab\u5e7f\u64ad\u5230\u77e9\u9635\u7684\u6bcf\u4e2a\u5143\u7d20\u4e0a\uff0c\u5e76\u4e0e\u77e9\u9635\u7684\u6bcf\u4e2a\u5143\u7d20\u76f8\u52a0\u3002</p> <ol> <li>\u5c06\u5c0f\u77e9\u9635\u5e7f\u64ad\u5230\u5927\u77e9\u9635</li> </ol> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXd mat(2, 3);\n    mat &lt;&lt; 1, 2, 3,\n           4, 5, 6;\n\n    // \u5c06\u5c0f\u77e9\u9635\u5e7f\u64ad\u5230\u5927\u77e9\u9635\n    Eigen::VectorXd vec(3);\n    vec &lt;&lt; 10, 20, 30;\n    Eigen::MatrixXd result = mat.array().colwise() + vec.array();\n\n    std::cout &lt;&lt; \"Broadcast vector to matrix (column-wise):\n\" &lt;&lt; result &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u5411\u91cfvec\u88ab\u5e7f\u64ad\u5230\u77e9\u9635mat\u7684\u6bcf\u4e00\u5217\u4e0a\uff0c\u5e76\u4e0e\u5bf9\u5e94\u5217\u7684\u6bcf\u4e2a\u5143\u7d20\u76f8\u52a0\u3002</p> <ol> <li>\u5c06\u884c\u5411\u91cf\u5e7f\u64ad\u5230\u77e9\u9635</li> </ol> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXd mat(2, 3);\n    mat &lt;&lt; 1, 2, 3,\n           4, 5, 6;\n\n    // \u5c06\u884c\u5411\u91cf\u5e7f\u64ad\u5230\u77e9\u9635\n    Eigen::RowVectorXd rowVec(3);\n    rowVec &lt;&lt; 10, 20, 30;\n    Eigen::MatrixXd result = mat.array().rowwise() + rowVec.array();\n\n    std::cout &lt;&lt; \"Broadcast row vector to matrix (row-wise):\" &lt;&lt; result &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u884c\u5411\u91cfrowVec\u88ab\u5e7f\u64ad\u5230\u77e9\u9635mat\u7684\u6bcf\u4e00\u884c\u4e0a\uff0c\u5e76\u4e0e\u5bf9\u5e94\u884c\u7684\u6bcf\u4e2a\u5143\u7d20\u76f8\u52a0\u3002</p> <p>\u5728Eigen\u4e2d\uff0c\u5e7f\u64ad\u901a\u5e38\u901a\u8fc7.array()\u65b9\u6cd5\u5c06\u77e9\u9635\u6216\u5411\u91cf\u8f6c\u6362\u4e3a\u6570\u7ec4\u7c7b\u578b\uff0c\u7136\u540e\u4f7f\u7528.colwise()\u6216.rowwise()\u65b9\u6cd5\u8fdb\u884c\u9010\u5217\u6216\u9010\u884c\u7684\u64cd\u4f5c\u3002\u8fd9\u5141\u8bb8\u6570\u7ec4\u6216\u6807\u91cf\u4e0e\u77e9\u9635\u7684\u76f8\u5e94\u90e8\u5206\u8fdb\u884c\u9010\u5143\u7d20\u64cd\u4f5c\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5e7f\u64ad\u64cd\u4f5c\u8981\u6c42\u88ab\u5e7f\u64ad\u7684\u5bf9\u8c61\u7684\u7ef4\u5ea6\u5fc5\u987b\u4e0e\u76ee\u6807\u77e9\u9635\u7684\u76f8\u5e94\u7ef4\u5ea6\u517c\u5bb9\u3002</p> <ol> <li>\u9488\u5bf9\u4e0d\u517c\u5bb9\u7684\u60c5\u51b5\u9700\u8981\u81ea\u884c\u590d\u5236\u6269\u5145\u7ef4\u5ea6</li> </ol> <p>\u6bd4\u5982\u5728numpy\u4e2d\u5b9e\u73b0\u5217\u5f52\u4e00\u5316\u8bed\u53e5\u4e3a</p> <pre><code>a = a / a.sum(axis=0)\n</code></pre> <p>\u91c7\u7528Eigen\u5b9e\u73b0\u5219\u4e3a\uff1a</p> <pre><code>auto conf_res = a.array() / a.colwise().sum().replicate(a.rows(), 1);\n</code></pre>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#35","title":"3.5 \u5b50\u77e9\u9635\u7d22\u5f15","text":"<p>\u5728Eigen\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528\u51e0\u79cd\u4e0d\u540c\u7684\u65b9\u6cd5\u6765\u8bbf\u95ee\u548c\u64cd\u4f5c\u5b50\u77e9\u9635\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5e38\u7528\u7684\u65b9\u6cd5\u6765\u7d22\u5f15\u5b50\u77e9\u9635\uff1a</p> <p>\u4f7f\u7528<code>.row()</code>\u548c<code>.col()</code>\u65b9\u6cd5<code>.row(i)</code>\u548c<code>.col(j)</code>\u65b9\u6cd5\u5206\u522b\u5141\u8bb8\u4f60\u83b7\u53d6\u7b2c<code>i</code>\u884c\u548c\u7b2c<code>j</code>\u5217\u3002</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;Eigen/Dense&gt;\n\nint main() {\n    Eigen::MatrixXi mat(4, 4);\n    mat &lt;&lt; 1, 2, 3, 4,\n           5, 6, 7, 8,\n           9, 10, 11, 12,\n           13, 14, 15, 16;\n\n    // \u83b7\u53d6\u7b2c2\u884c\n    Eigen::VectorXi row = mat.row(1);\n\n    // \u83b7\u53d6\u7b2c3\u5217\n    Eigen::VectorXi col = mat.col(2);\n\n    std::cout &lt;&lt; \"Second row:\n\" &lt;&lt; row &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Third column:\n\" &lt;&lt; col &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>\u590d\u6742index\u5217\u8868\u7d22\u5f15</p> <p><code>\u200cEigen::placeholders::all\u200c</code>\u5728Eigen\u5e93\u4e2d\u7528\u4e8e\u6307\u5b9a\u77e9\u9635\u7684\u6240\u6709\u884c\uff0c\u5f53\u4e0e\u77e9\u9635\u7684\u5217\u7d22\u5f15\u4e00\u8d77\u4f7f\u7528\u65f6\uff0c\u53ef\u4ee5\u7528\u4e8e\u4ece\u77e9\u9635\u4e2d\u63d0\u53d6\u7279\u5b9a\u7684\u5217\u3002\u5728Eigen\u5e93\u4e2d\uff0c\u77e9\u9635\u7684\u7d22\u5f15\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b\u5217\u7d22\u5f15\u548c\u884c\u7d22\u5f15\u6765\u5b9e\u73b0\uff0c\u5176\u4e2d<code>Eigen::placeholders::all</code>\u4f5c\u4e3a\u4e00\u4e2a\u5360\u4f4d\u7b26\uff0c\u8868\u793a\u9009\u62e9\u6240\u6709\u884c\u3002</p> <pre><code>#include&lt;iostream&gt;\n#include&lt;vector&gt;\n#include&lt;Eigen/Dense&gt;\nusing namespace std;\nusing namespace Eigen;\n\nint main() {\n    MatrixXd test_matrix = MatrixXd::Random(4, 6);\n    cout &lt;&lt; test_matrix &lt;&lt; endl &lt;&lt; endl;\n    // \u6bd4\u5982\u6211\u8981\u4f9d\u6b21\u53d6\u51fa\u7b2c2\u5217\u3001\u7b2c5\u5217\u3001\u7b2c1\u5217\n    vector&lt;int&gt; indexs {1, 4, 0}; // \u5217\u7d22\u5f15\n    MatrixXd index_metrix = test_matrix(Eigen::placeholders::all, indexs); // \u4f7f\u7528Eigen::placeholders::all\u9009\u62e9\u6240\u6709\u884c\uff0c\u6839\u636eindexs\u9009\u62e9\u7279\u5b9a\u7684\u5217\n    cout &lt;&lt; index_metrix &lt;&lt; endl;\n    return 0;\n}\n</code></pre>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#_4","title":"\u56db\u3001\u603b\u7ed3","text":"<p>\u672c\u6587\u8be6\u7ec6\u603b\u7ed3\u4e86\u5728\u5b9e\u9645\u5de5\u7a0b\u4e2d\uff0cCPU\u4e0a\u77e9\u9635\u8fd0\u7b97\u5e93\u5728python\u548cC++\u4e4b\u95f4\u7684\u8f6c\u6362\u3002</p> <p>\u5b9e\u9645\u4e0a\uff0c\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\uff0c\u8fd8\u4f1a\u6709\u4e00\u4e9b\u6bd4\u5982\u77e9\u9635\u5143\u7d20\u6392\u5e8f\u3001\u67e5\u627e\u3001\u6c42\u9006\u3001\u6c42\u884c\u5217\u5f0f\u7b49\u8fd0\u7b97\uff0c\u4e00\u822c\u800c\u8a00numpy\u7684\u529f\u80fd\u76f8\u6bd4\u4e8e\u5176\u4ed6\u5e93\u8981\u4e30\u5bcc\u4e00\u4e9b\uff0c\u6211\u4eec\u9700\u8981\u77e5\u9053\u5176\u5185\u90e8\u5b9e\u73b0\u539f\u7406\uff0c\u5982\u679c\u5176\u4ed6\u5e93\u6ca1\u6709\u76f4\u63a5\u5b9e\u73b0\uff0c\u91c7\u7528\u6700\u539f\u59cb\u7684\u64cd\u4f5c\u5185\u5b58\u7684\u65b9\u5f0f\u5b9e\u73b0\u662f\u4fdd\u5e95\u65b9\u6848\u3002</p>"},{"location":"python%26C%2B%2B/matrix_python_cpp/#_5","title":"\u53c2\u8003\u6587\u732e","text":"<ul> <li>https://blog.csdn.net/wanzew/article/details/125703765</li> <li>ChatGLM</li> <li>https://blog.csdn.net/sdhdsf132452/article/details/127260531</li> </ul>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/","title":"\u4e00\u6587\u603b\u7ed3Python\u548cC/C++\u7684\u4ea4\u4e92\u65b9\u5f0f","text":""},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#_1","title":"\u4e00. \u524d\u8a00","text":"<p>\u672c\u6587\u65e8\u5728\u603b\u7ed3Python\u5982\u4f55\u8c03\u7528C/C++\uff0c\u4ee5\u53ca\u5728C/C++\u4ee3\u7801\u4e2d\u5982\u4f55\u8c03\u7528Python\uff0c\u6240\u7ed9\u6848\u4f8b\u8f83\u4e3a\u7b80\u5355\uff0c\u629b\u7816\u5f15\u7389\uff0c\u6b22\u8fce\u8bfb\u8005\u81ea\u884c\u62d3\u5c55\u3002</p> <p>\u5b9e\u9a8c\u73af\u5883 System: Ubuntu 22.04.1 LTS GCC version: 11.2.0 Python version: miniconda\u5b89\u88c5\u7684python3.7.13 \u672c\u6587\u7684\u6240\u6709\u9700\u8981\u5b89\u88c5\u7684\u5305\u4e3a\u4e86\u53ef\u590d\u73b0\u6027\uff0c\u90fd\u6307\u5b9a\u4e86\u7248\u672c\uff0c\u5982\u679c\u8bfb\u8005\u9700\u8981\u4f7f\u7528\u6700\u65b0\u7248\u672c\u8fd8\u8bf7\u53bb\u6389\u7248\u672c\u9650\u5236\u3002</p> <p>\u672c\u6587\u4ee3\u7801\u5f00\u6e90\u5730\u5740\uff1a</p> <p>https://github.com/thb1314/python_interact_c</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#pythonc","title":"\u4e8c. Python\u8c03\u7528C","text":""},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#21-ctypesc","title":"2.1 \u91c7\u7528ctypes\u5e93\u8c03\u7528C\u7f16\u8bd1\u4ea7\u751f\u7684\u52a8\u6001\u63a5\u5e93","text":""},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#211-so","title":"2.1.1 \u9884\u5907\u77e5\u8bc6 so\u6587\u4ef6\u7684\u751f\u6210\u4e0e\u4f7f\u7528","text":"<p>\u8fd9\u91cc\u4ee5\u5bf9\u6570\u7ec4\u8fdb\u884c\u6c42\u548c\u7684\u51fd\u6570\u4e3a\u4f8b\uff0c\u91c7\u7528gcc\u4f5c\u4e3a\u7f16\u8bd1\u5668\uff0c\u6837\u4f8b\u4ee3\u7801\u5728ctypes\u6587\u4ef6\u5939</p> <p><code>sum.c</code>\u6587\u4ef6</p> <pre><code>int sum(int* buffer, int len) {\n    int ret = 0;\n    for(int i = 0; i &lt; len; ++i)\n        ret += buffer[i];\n    return ret;\n}\n</code></pre> <p>shell\u6307\u4ee4</p> <pre><code>gcc sum.c -fPIC -shared -std=c99 -o libsum.so\n</code></pre> <p>\u4f7f\u7528<code>sum.so</code>\u6587\u4ef6\uff0c\u7f16\u5199<code>test.c</code>\u5185\u5bb9\u5982\u4e0b</p> <pre><code>#include &lt;stdio.h&gt;\n\nint sum(int* buffer, int len);\n\nint main(void) {\n    const int length = 10;\n    int buffer[length];\n    int buffer_sum = 0;\n    for(int i = 0; i &lt; length; ++i) {\n        buffer[i] = i;\n    }\n    buffer_sum = sum(buffer, length);\n    printf(\"buffer_sum = %d\n\", buffer_sum); \n    return 0;\n}\n</code></pre> <p>shell\u6307\u4ee4</p> <pre><code># \u65b9\u5f0f\u4e00\ngcc -o test test.c libsum.so\n# \u65b9\u5f0f\u4e8c\ngcc -o test test.c -L. -lsum\n\n# \u8fd0\u884ctest\n./test\n</code></pre> <p>\u5bf9\u4e8e\u4ee5\u4e0a\u6307\u4ee4\u8fd8\u8bf7\u8bfb\u8005\u81ea\u884c\u67e5\u9605\u76f8\u5173\u8d44\u6599\u4e86\u89e3\u5176\u4e2d\u542b\u4e49</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#212-python-ctypesso","title":"2.1.2 Python Ctypes\u5e93\u8c03\u7528\u52a8\u6001\u94fe\u63a5\u5e93so\u4e2d\u7684\u51fd\u6570","text":"<p>ctypes \u662fPython\u7684\u5916\u90e8\u51fd\u6570\u5e93\u3002\u5b83\u63d0\u4f9b\u4e86\u4e0e C\u8bed\u8a00\u517c\u5bb9\u7684\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u5141\u8bb8\u8c03\u7528 DLL \u6216\u5171\u4eab\u5e93\u4e2d\u7684\u51fd\u6570\u3002\u53ef\u4f7f\u7528\u8be5\u6a21\u5757\u4ee5\u7eaf Python \u5f62\u5f0f\u5bf9\u8fd9\u4e9b\u5e93\u8fdb\u884c\u5c01\u88c5\u3002</p> <p>\u8fd8\u662f\u4ee5\u8c03\u7528libsum.so\u4e2d\u7684sum\u51fd\u6570\u4e3a\u4f8b\uff0c\u7f16\u5199<code>ctypes_sum.py</code>\u5bf9libsum.so\u4e2d\u7684sum\u51fd\u6570\u8fdb\u884c\u5c01\u88c5\uff0c\u5185\u5bb9\u5982\u4e0b</p> <pre><code>import ctypes\n\n\n# windows\u5e73\u53f0\u7528  ctypes.WinDLL\nlibsum_so = ctypes.CDLL(\"./libsum.so\") \n\n\ndef sum(int_list):\n    for item in int_list:\n        assert isinstance(item, int)\n    func = libsum_so.sum\n    length = len(int_list)\n    first_arg_type = ctypes.c_int * length\n    first_arg = first_arg_type()\n    for i in range(length):\n        first_arg[i] = int_list[i]\n    return int(func(first_arg, length))\n\n\nif __name__ == \"__main__\":\n    print(sum([5, 6, 7, 8]))\n</code></pre>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#22-pybind11cpython","title":"2.2 \u91c7\u7528pybind11\u521b\u5efaC++\u4ee3\u7801\u7684Python\u63a5\u53e3","text":"<p>Pybind11 \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684 C++ \u5e93\uff0c\u7528\u4e8e\u5c06\u4f60\u7684 C++ \u4ee3\u7801\u66b4\u9732\u7ed9 Python \u8c03\u7528\uff08\u53cd\u4e4b\u4e5f\u53ef\uff0c\u4f46\u4e3b\u8981\u8fd8\u662f\u524d\u8005\uff09\u3002Pybind11 \u501f\u9274\u4e86 <code>Boost::Python</code> \u5e93\u7684\u8bbe\u8ba1\uff0c\u4f46\u4f7f\u7528\u4e86\u66f4\u4e3a\u7b80\u6d01\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u4f7f\u7528\u4e86\u5927\u91cf C++11 \u7684\u65b0\u7279\u6027\uff0c\u66f4\u6613\u4e8e\u4f7f\u7528\u3002</p> <p>\u5b98\u65b9\u6587\u6863\uff1ahttps://pybind11.readthedocs.io/en/stable/index.html</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#221-pybind11","title":"2.2.1 Pybind11\u7279\u70b9","text":"<p>Pybind11 \u5141\u8bb8\u4f60\u5728 C++ \u4ee3\u7801\u4e2d\u4f7f\u7528\u5982\u4e0b\u7279\u6027\uff0c\u5e76\u5728 Python \u4e2d\u65b9\u4fbf\u5730\u8c03\u7528\u3002</p> <ul> <li>\u5141\u8bb8\u51fd\u6570\u53c2\u6570\u4f7f\u7528\u81ea\u5b9a\u4e49\u7c7b\u578b\uff08\u5305\u62ec\u503c\u3001\u6307\u9488\u548c\u5f15\u7528\uff09\uff1b</li> <li>\u7c7b\u6210\u5458\u51fd\u6570\u4e0e\u9759\u6001\u51fd\u6570\uff1b</li> <li>\u51fd\u6570\u91cd\u8f7d\uff1b</li> <li>\u7c7b\u6210\u5458\u4e0e\u9759\u6001\u6210\u5458\uff1b</li> <li>\u5f02\u5e38\uff1b</li> <li>\u679a\u4e3e\uff1b</li> <li>\u56de\u8c03\u51fd\u6570\uff1b</li> <li>\u8fed\u4ee3\u5668\u548c\u8303\u56f4(<code>range</code>);</li> <li>\u81ea\u5b9a\u4e49 <code>operator</code>\uff1b</li> <li>\u7ee7\u627f\uff08\u5305\u62ec\u591a\u91cd\u7ee7\u627f\uff09\uff1b</li> <li>STL \u4e2d\u7684\u6570\u636e\u7ed3\u6784\uff1b</li> <li>\u667a\u80fd\u6307\u9488\uff1b</li> <li>\u5e26\u6709\u5f15\u7528\u8ba1\u6570\u7684\u5185\u90e8\u5f15\u7528\uff1b</li> <li>\u5728 C++ \u4e2d\u5b9a\u4e49\u865a\u65b9\u6cd5\uff0c\u5e76\u5728 Python \u4e2d\u8fdb\u884c\u6269\u5c55\uff1b</li> </ul> <p>Pybind11 \u7684\u4f18\u70b9\u6709\uff1a</p> <ul> <li>\u517c\u5bb9\u6027\u5f3a\uff0c\u652f\u6301 Python2.7\u3001Python3.x\u3001PyPy (PyPy2.7 &gt;= 5.7)\uff1b</li> <li>\u53ef\u4ee5\u5728 C++ \u4e2d\u4f7f\u7528 lambda \u8868\u8fbe\u5f0f\uff0c\u5e76\u5728 Python \u4e2d\u4f7f\u7528\u6355\u83b7\u7684\u53d8\u91cf\uff1b</li> <li>\u5927\u91cf\u4f7f\u7528\u79fb\u52a8\u7279\u6027\uff0c\u4fdd\u8bc1\u6570\u636e\u8f6c\u79fb\u65f6\u7684\u6027\u80fd\uff1b</li> <li>\u53ef\u4ee5\u5f88\u65b9\u4fbf\u5730\u901a\u8fc7 Python buffer protocol \u8fdb\u884c\u6570\u636e\u7c7b\u578b\u7684\u8f6c\u79fb\uff1b</li> <li>\u53ef\u4ee5\u5f88\u65b9\u4fbf\u5730\u5bf9\u51fd\u6570\u8fdb\u884c\u5411\u91cf\u5316\u52a0\u901f\uff1b</li> <li>\u652f\u6301\u4f7f\u7528 Python \u7684\u5207\u7247\u8bed\u6cd5\uff1b</li> <li>Pybind11 \u662f header-only \u7684\uff0c\u53ea\u9700\u8981\u5305\u542b\u5934\u6587\u4ef6\u5373\u53ef\uff1b</li> <li>\u76f8\u6bd4\u4e8e <code>Boost::Python</code>\uff0c\u751f\u6210\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u4f53\u79ef\u66f4\u5c0f\uff1b</li> <li>\u51fd\u6570\u7b7e\u540d\u901a\u8fc7 <code>constexper</code> \u63d0\u524d\u8ba1\u7b97\uff0c\u8fdb\u4e00\u6b65\u51cf\u5c0f\u4e8c\u8fdb\u5236\u6587\u4ef6\u4f53\u79ef\uff1b</li> <li>C++ \u4e2d\u7684\u7c7b\u578b\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u8fdb\u884c\u5e8f\u5217\u5316/\u53cd\u5e8f\u5217\u5316\uff1b</li> </ul> <p>pybind11\u7684\u5b89\u88c5\uff1a</p> <pre><code>pip install pybind11==2.10.1\n</code></pre>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#222","title":"2.2.2 \u4ee3\u7801\u793a\u4f8b","text":"<p>\u6837\u4f8b\u4ee3\u7801\u5728pybind11_sum\u6587\u4ef6\u5939</p> <p>\u9996\u5148\u521b\u5efac++\u6587\u4ef6<code>pybind11_sum.cpp</code></p> <pre><code>#include &lt;pybind11/pybind11.h&gt;\n#include &lt;pybind11/stl.h&gt;\n\n\nnamespace py = pybind11;\n\n// \u5f15\u5165 pybind11/stl.h \u540e std::vector\u4f1a\u81ea\u52a8\u4e0epython\u4e2dlist\u7c7b\u578b\u7ed1\u5b9a\nint sum(const std::vector&lt;int&gt;&amp; buffer) {\n    int ret = 0;\n    for(auto item: buffer)\n        ret += item;\n    return ret;\n}\n\n// pybind11_sum \u8fd9\u91cc\u7ea6\u5b9a\u8981\u4e0e\u6587\u4ef6\u540d\u76f8\u540c\nPYBIND11_MODULE(pybind11_sum, m) {\n    m.doc() = \"pybind11 sum plugin\"; // optional module docstring\n    m.def(\"sum\", &amp;sum, \"A function which calulate sum in buffer\",\n          py::arg(\"buffer\"));\n}\n</code></pre> <p>\u7136\u540e\u8fd0\u884cshell\u547d\u4ee4</p> <pre><code>g++ -O3 -Wall -shared -std=c++11 -fPIC $(python3 -m pybind11 --includes) pybind11_sum.cpp -o pybind11_sum$(python3-config --extension-suffix)\n</code></pre> <p>\u6d4b\u8bd5\u6587\u4ef6<code>test_pybind.py</code></p> <pre><code>import pybind11_sum\n\nprint(pybind11_sum)\nprint(dir(pybind11_sum))\nprint(pybind11_sum.sum([5, 6, 7]))\n</code></pre>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#223","title":"2.2.3 \u5e94\u7528\u6848\u4f8b","text":"<p>\u76ee\u524d\u5e02\u9762\u4e0a\u5927\u90e8\u5206 AI \u8ba1\u7b97\u6846\u67b6,\u5982 TensorFlow\u3001Pytorch\u3001\u963f\u91cc X-Deep Learning\u3001\u767e\u5ea6 PaddlePaddle \u7b49,\u5747\u4f7f\u7528 pybind11\u6765\u63d0\u4f9b C++\u5230 Python \u7aef\u63a5\u53e3\u5c01\u88c5\u3002</p> <p>Pytorch pybind extension\u6587\u6863\u5730\u5740</p> <p>https://pytorch.org/tutorials/advanced/cpp_extension.html</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#23-pythonc-apipython","title":"2.3 \u4f7f\u7528Python\u7684C-API\u521b\u5efaPython\u6269\u5c55","text":""},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#231","title":"2.3.1 \u4ee3\u7801\u6f14\u793a","text":"<p>\u6837\u4f8b\u4ee3\u7801\u5728python_api_sum\u6587\u4ef6\u5939</p> <p>\u76f4\u63a5\u4f7f\u7528Python\u5f00\u653e\u7684api\u4e5f\u53ef\u4ee5\u521b\u5efa\u76f4\u63a5import\u7684\u52a8\u6001\u5e93</p> <p>\u521b\u5efapython_api_sum.c</p> <pre><code>#include &lt;Python.h&gt;\n\n#if PY_MAJOR_VERSION &gt;= 3\n#define PyInt_Check PyLong_Check\n#define PyInt_AsLong PyLong_AsLong\n#endif\n\nstatic PyObject* list_sum(PyObject *self, PyObject *args)\n{\n    PyObject *pList;\n    PyObject *pItem;\n    Py_ssize_t n = 0;\n    int result = 0;\n    if(!PyArg_ParseTuple(args, \"O!\", &amp;PyList_Type, &amp;pList))\n    {\n        return NULL;\n    }\n    n = PyList_Size(pList);\n    for (int i=0; i&lt;n; i++) {\n        pItem = PyList_GetItem(pList, i);\n        if(!PyInt_Check(pItem)) {\n            PyErr_SetString(PyExc_TypeError, \"list items must be integers.\");\n            return NULL;\n        }\n        result += PyInt_AsLong(pItem);\n    }\n\n    return Py_BuildValue(\"i\", result);\n}\n\nstatic PyMethodDef methods[] = {\n   { \"sum\", (PyCFunction)list_sum, METH_VARARGS, \"sum method\" },\n   { NULL, NULL, 0, NULL }\n};\n\nstatic struct PyModuleDef python_api_sum_module = {\n    PyModuleDef_HEAD_INIT,\n    \"python_api_sum\",\n    \"Python interface for the array sum\",\n    -1,\n    methods\n};\n\nPyMODINIT_FUNC PyInit_python_api_sum(void)\n{\n   return PyModule_Create(&amp;python_api_sum_module);\n}\n</code></pre> <p>\u5728shell\u7a97\u53e3\u6267\u884c\u5982\u4e0b\u6307\u4ee4\uff1a</p> <pre><code>gcc -Wall -shared  -std=c99 -fPIC $(python3-config --includes) $(python3-config --ldflags) python_api_sum.c -o python_api_sum$(python3-config --extension-suffix)\n</code></pre> <p>\u6d4b\u8bd5\u4ee3\u7801\u6587\u4ef6<code>test_python_api.py</code></p> <pre><code>import python_api_sum\n\nprint(python_api_sum)\nprint(dir(python_api_sum))\nprint(python_api_sum.sum([5, 6, 7, 8]))\n</code></pre>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#232","title":"2.3.2 \u5e94\u7528\u4e3e\u4f8b","text":"<p>\u4ece\u4e0a\u9762\u53ef\u4ee5\u770b\u51fa\uff0c\u8be5\u65b9\u6cd5\u6bd4\u8f83\u590d\u6742\uff0c\u4e14\u8f83\u4e3a\u5e95\u5c42\u3002\u8d8a\u5e95\u5c42\u7684\u4e1c\u897f\u5728\u7528\u7684\u597d\u7684\u60c5\u51b5\u4e0b\u81ea\u7136\u6548\u7387\u8d8a\u9ad8\uff0c\u6240\u4ee5\u6bd4\u5982\u5728pytorch\u5b98\u65b9\u6e90\u7801\u4e2d\u5c31\u5bf9\u4e00\u4e9b\u7b97\u5b50\u8fd0\u7b97\u7684\u5e95\u5c42\u8bbe\u8ba1\u91c7\u7528\u8be5\u65b9\u5f0f\u505a\u5c01\u88c5\uff0c\u6bd4\u5982 https://github.com/pytorch/pytorch/blob/master/tools/autograd/templates/python_sparse_functions.cpp</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#24-swig","title":"2.4 \u4f7f\u7528SWIG\u7f16\u8bd1","text":"<p>SWIG\u662f\u7b80\u5355\u5305\u88c5\u5668\u548c\u63a5\u53e3\u751f\u6210\u5668\uff0c\u662f\u4e00\u4e2a\u9002\u7528\u4e8e\u591a\u79cd\u8bed\u8a00\u7684\u5de5\u5177\u3002\u4e00\u65b9\u9762\uff0c\u5b83\u8ba9\u4f60\u53ef\u4ee5\u4f7f\u7528C/C++\u7f16\u5199\u6269\u5c55\u4ee3\u7801\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u5b83\u81ea\u52a8\u5305\u88c5\u8fd9\u4e9b\u4ee3\u7801\uff0c\u5e76\u4e14\u8ba9\u8fd9\u4e9b\u4ee3\u7801\u5728Java\u3001Python\u3001Tcl\u3001Perl\u548cRuby\u7b49\u9ad8\u7ea7\u8bed\u8a00\u4e2d\u8fd0\u884c\u3002</p> <p>\u5b98\u65b9\u7f51\u5740\uff1ahttp://www.swig.org</p> <p>\u6587\u6863\u5730\u5740\uff1ahttps://www.swig.org/doc.html</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#241","title":"2.4.1 \u4ee3\u7801\u793a\u4f8b","text":"<p>\u5b89\u88c5\u65b9\u5f0f</p> <pre><code># \u5982\u679c\u4e0b\u8f7d\u4e0d\u4e0b\u6765\u8fd8\u8bf7\u6302\u4e2a\u68af\u5b50\nwget https://github.com/swig/swig/archive/refs/tags/v4.1.1.zip\n\nunzip v4.1.1.zip\ncd swig-4.1.1\nsudo apt install automake\nsudo apt install bison\n./autogen.sh\nmkdir -p ../swig\n./configure --prefix=\"`pwd`/../swig\" --without-pcre --without-perl5\nmake\nmake install\nexport PATH=\"`pwd`/../swig/bin:$PATH\"\n</code></pre> <p>\u7f16\u5199<code>example1.c</code></p> <pre><code>/* File : example1.c */\ndouble My_variable = 3.0;\n\n/* Compute factorial of n */\nint fact(int n)\n{\n    if (n &lt;= 1)\n        return 1;\n    else\n        return n * fact(n - 1);\n}\n\n/* Compute n mod m */\nint my_mod(int n, int m)\n{\n    return (n % m);\n}\n</code></pre> <p>\u7f16\u5199<code>example1.i</code></p> <pre><code>/* File : example1.i */\n%module example\n%{\n/* Put headers and other declarations here */\nextern double My_variable;\nextern int fact(int);\nextern int my_mod(int n, int m);\n%}\nextern double My_variable;\nextern int fact(int);\nextern int my_mod(int n, int m);\n</code></pre> <p>\u6267\u884cswig\u547d\u4ee4\u751f\u6210<code>example1_wrap.c</code></p> <pre><code>swig -python -interface example example1.i\n</code></pre> <p>\u751f\u6210python\u6269\u5c55\uff0c\u8fd9\u91cc\u5b9e\u9645\u4e0a\u4e0ePython API\u65b9\u5f0f\u76f8\u540c\uff0cswig\u5c31\u662f\u505a\u4e86\u8fd9\u6837\u7684\u4e8b\u60c5\uff0c\u81ea\u52a8\u751f\u6210\u4e86\u8fd9\u90e8\u5206\u4ee3\u7801\u3002</p> <pre><code>gcc -Wall -shared  -std=c99 -fPIC $(python3-config --includes) $(python3-config --ldflags) example1.c example1_wrap.c -o example$(python3-config --extension-suffix)\n</code></pre> <p>\u4e0a\u9762\u662fSwig\u5b98\u65b9\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u518d\u770b\u4e00\u4e2a\u5bf9list\u6c42\u548c\u7684\u4f8b\u5b50</p> <p>\u9996\u5148\u5b9a\u4e49.h\u6587\u4ef6<code>example2_sum.h</code></p> <pre><code>#include &lt;vector&gt;\n\n// swig std::vector\u4f1a\u81ea\u52a8\u4e0epython\u4e2dlist\u7c7b\u578b\u7ed1\u5b9a\nint list_sum(const std::vector&lt;int&gt;&amp; buffer) {\n    int ret = 0;\n    for(auto item: buffer)\n        ret += item;\n    return ret;\n}\n</code></pre> <p>\u7136\u540e\u7ed9\u51fa<code>.i</code>\u6587\u4ef6\u8bf4\u660e\u9700\u8981\u5bfc\u51fa\u7684\u4e1c\u897f(<code>example2_sum.i</code>)</p> <pre><code>%module py_swig_sum\n%{\n#include \"example2_sum.h\"\n%}\n\n%include \"std_vector.i\"\n// Instantiate templates \nnamespace std {\n    %template(IntVector) vector&lt;int&gt;;\n}\n// Include the header file with above prototypes\n%include \"example2_sum.h\"\n</code></pre> <p>\u7136\u540e\u8f93\u5165swig\u8f6c\u6362\u6307\u4ee4</p> <pre><code>swig -c++ -python -interface swig_sum -o example2_sum_wrap.cpp example2_sum.i\n</code></pre> <p>\u6700\u540e\u7f16\u8bd1python\u5e93</p> <pre><code>g++ -Wall -shared  -std=c++11 -fPIC $(python3-config --includes) $(python3-config --ldflags) example2_sum_wrap.cpp -o swig_sum$(python3-config --extension-suffix)\n</code></pre> <p>\u6d4b\u8bd5\u4ee3\u7801\u5982\u4e0b</p> <pre><code>import py_swig_sum\n\nprint(py_swig_sum)\nprint(dir(py_swig_sum))\nprint(py_swig_sum.list_sum([5,6,7]))\n\niv = py_swig_sum.IntVector(4)\nfor i in range(4):\n    iv[i] = i + 1\n\nprint(py_swig_sum.list_sum(iv))\n</code></pre> <p>\u66f4\u591a\u4fe1\u606f\u8fd8\u8bf7\u8bfb\u8005\u9605\u8bfb\u6587\u6863\uff0c\u4e2a\u4eba\u611f\u89c9swig\u8fd8\u662f\u505a\u5f97\u4e0d\u9519\u7684\u3002</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#25-cython","title":"2.5 \u4f7f\u7528Cython","text":"<p>\u5173\u4e8e Cython\uff0c\u6211\u4eec\u5fc5\u987b\u8981\u6e05\u695a\u4e24\u4ef6\u4e8b\uff1a</p> <p>1\uff09Cython \u662f\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\uff0c\u5b83\u5c06 C \u548c C++ \u7684\u9759\u6001\u7c7b\u578b\u7cfb\u7edf\u878d\u5408\u5728\u4e86 Python \u8eab\u4e0a\u3002Cython \u6e90\u6587\u4ef6\u7684\u540e\u7f00\u662f .pyx\uff0c\u5b83\u662f Python \u7684\u4e00\u4e2a\u8d85\u96c6\uff0c\u8bed\u6cd5\u662f Python \u8bed\u6cd5\u548c C \u8bed\u6cd5\u7684\u6df7\u8840\u3002\u5f53\u7136\u6211\u4eec\u8bf4\u5b83\u662f Python \u7684\u4e00\u4e2a\u8d85\u96c6\uff0c\u56e0\u6b64\u4f60\u5199\u7eaf Python \u4ee3\u7801\u4e5f\u662f\u53ef\u4ee5\u7684\u3002</p> <p>2\uff09\u5f53\u6211\u4eec\u7f16\u5199\u5b8c Cython \u4ee3\u7801\u65f6\uff0c\u9700\u8981\u5148\u5c06 Cython \u4ee3\u7801\u7ffb\u8bd1\u6210\u9ad8\u6548\u7684 C \u4ee3\u7801\uff0c\u7136\u540e\u518d\u5c06 C \u4ee3\u7801\u7f16\u8bd1\u6210 Python \u7684\u6269\u5c55\u6a21\u5757\u3002</p> <p>\u5982\u4e0a\uff0c\u6b63\u56e0\u4e3aCython\u662f\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\uff0c\u56e0\u6b64\u4e0d\u662f\u5f88\u63a8\u8350\u5b66\u4e60\uff08\u7b11\u54ed\uff09\u3002</p> <p>\u5728\u65e9\u671f\uff0c\u7f16\u5199 Python \u6269\u5c55\u90fd\u662f\u62ff C \u53bb\u5199\uff0c\u4f46\u662f\u8fd9\u5bf9\u5f00\u53d1\u8005\u6709\u4e24\u4e2a\u786c\u6027\u8981\u6c42\uff1a\u4e00\u4e2a\u662f\u719f\u6089 C\uff0c\u53e6\u4e00\u4e2a\u662f\u8981\u719f\u6089\u89e3\u91ca\u5668\u63d0\u4f9b\u7684 C API\uff0c\u8fd9\u5bf9\u5f00\u53d1\u8005\u662f\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u6311\u6218\u3002\u6b64\u5916\uff0c\u62ff C \u7f16\u5199\u4ee3\u7801\uff0c\u5f00\u53d1\u6548\u7387\u4e5f\u975e\u5e38\u4f4e\u3002</p> <p>\u800c Cython \u7684\u51fa\u73b0\u5219\u89e3\u51b3\u4e86\u8fd9\u4e00\u70b9\uff0cCython \u548c Python \u7684\u8bed\u6cd5\u975e\u5e38\u76f8\u4f3c\uff0c\u6211\u4eec\u53ea\u9700\u8981\u7f16\u5199 Cython \u4ee3\u7801\uff0c\u7136\u540e\u518d\u7531 Cython \u7f16\u8bd1\u5668\u5c06 Cython \u4ee3\u7801\u7ffb\u8bd1\u6210 C \u4ee3\u7801\u5373\u53ef\u3002\u6240\u4ee5\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u4e0a\u8bf4\uff0c\u62ff C \u5199\u6269\u5c55\u548c\u62ff Cython \u5199\u6269\u5c55\u662f\u7b49\u4ef7\u7684\u3002</p> <p>\u81f3\u4e8e\u5982\u4f55\u5c06 Cython \u4ee3\u7801\u7ffb\u8bd1\u6210 C \u4ee3\u7801\uff0c\u5219\u4f9d\u8d56\u4e8e\u76f8\u5e94\u7684\u7f16\u8bd1\u5668\uff0c\u8fd9\u4e2a\u7f16\u8bd1\u5668\u672c\u8d28\u4e0a\u5c31\u662f Python \u7684\u4e00\u4e2a\u7b2c\u4e09\u65b9\u6a21\u5757\u3002\u5b83\u5c31\u76f8\u5f53\u4e8e\u662f\u4e00\u4e2a\u7ffb\u8bd1\u5b98\uff0c\u65e2\u7136\u7528 C \u5199\u6269\u5c55\u662f\u4e00\u4ef6\u75db\u82e6\u7684\u4e8b\u60c5\uff0c\u90a3\u5c31\u62ff Cython \u53bb\u5199\uff0c\u5199\u5b8c\u4e86\u518d\u5e2e\u4f60\u7ffb\u8bd1\u6210 C\u3002</p> <p>\u56e0\u6b64 Cython \u7684\u5f3a\u5927\u4e4b\u5904\u5c31\u5728\u4e8e\u5b83\u5c06 Python \u548c C \u7ed3\u5408\u4e86\u8d77\u6765\uff0c\u53ef\u4ee5\u8ba9\u4f60\u50cf\u5199 Python \u4ee3\u7801\u4e00\u6837\u7684\u540c\u65f6\u8fd8\u53ef\u4ee5\u83b7\u5f97 C \u7684\u9ad8\u6548\u7387\u3002\u6240\u4ee5\u6211\u4eec\u770b\u5230 Cython \u76f8\u5f53\u4e8e\u662f\u9ad8\u7ea7\u8bed\u8a00 Python \u548c\u4f4e\u7ea7\u8bed\u8a00 C \u4e4b\u95f4\u7684\u4e00\u4e2a\u878d\u5408\uff0c\u56e0\u6b64\u6709\u4eba\u4e5f\u79f0 Cython \u662f \"\u514b\u91cc\u5965\u5c14\u7f16\u7a0b\u8bed\u8a00\"\uff08creole programming language\uff09\u3002</p> <p>Cython\u5b89\u88c5</p> <pre><code>pip install cython==0.29.32\n</code></pre>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#251","title":"2.5.1 \u4ee3\u7801\u793a\u4f8b","text":"<p>\u6211\u4eec\u4f9d\u7136\u7ed9\u51fa\u7684\u662f\u5bf9list\u5143\u7d20\u8fdb\u884csum\u7684\u6848\u4f8b\uff0c\u6837\u4f8b\u4ee3\u7801\u89c1<code>cython_demo'</code></p> <p>python\u4ee3\u7801\u793a\u4f8b</p> <p><code>sum.pyx</code></p> <pre><code>def py_list_sum(buffer):\n    return sum(buffer)\n</code></pre> <p>\u521b\u5efa\u5305\u5b89\u88c5\u6587\u4ef6<code>setup.py</code></p> <pre><code>from distutils.core import setup\nfrom distutils.extension import Extension\nfrom Cython.Distutils import build_ext\nimport glob\nimport os\n\npyx_filelist = glob.glob(os.path.join(os.path.realpath(\"./\"), \"**\", \"*.pyx\"), recursive=True)\n\nextension_name = \"sum_py\"\next_modules = [\n    Extension(extension_name,pyx_filelist)\n]\n\nsetup(\n    name = \"Hello pyx\",\n    version=\"1.0\",\n    cmdclass = {'install': build_ext},\n    ext_modules = ext_modules\n)\n</code></pre> <p>\u6784\u5efa\u547d\u4ee4</p> <pre><code> python setup.py install --inplace\n</code></pre> <p>\u672c\u6587\u4f5c\u8005\u5bf9cython\u7684\u8bed\u6cd5\u5b9e\u5728\u4e0d\u611f\u5174\u8da3\uff0c\u4f30\u7565\u53bb\u540e\u7eed\u63a2\u7d22\u3002</p>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#ccpython","title":"\u4e09. C/C++\u8c03\u7528Python","text":""},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#31-pythonapi","title":"3.1 \u91c7\u7528Python\u539f\u751fAPI","text":"<p>c++\u8c03\u7528 python \uff0c\u672c\u8d28\u4e0a\u662f\u5728 c++ \u4e2d\u542f\u52a8\u4e86\u4e00\u4e2a python \u89e3\u91ca\u5668\uff0c\u7531\u89e3\u91ca\u5668\u5bf9 python \u76f8\u5173\u7684\u4ee3\u7801\u8fdb\u884c\u6267\u884c\uff0c\u6267\u884c\u5b8c\u6bd5\u540e\u91ca\u653e\u8d44\u6e90\uff0c\u8fbe\u5230\u8c03\u7528\u76ee\u7684\u3002</p> <p>\u4ee3\u7801\u793a\u4f8b\u5982\u4e0b\uff08\u5728<code>c_call_python_by_pyapi</code>\u6587\u4ef6\u5939\uff09\uff1a</p> <p>\u9996\u5148\u521b\u5efa<code>main.cpp</code></p> <pre><code>#include &lt;Python.h&gt;\n\nint main(int argc, char *argv[]) {\n  // \u521d\u59cb\u5316python\u89e3\u91ca\u5668.C/C++\u4e2d\u8c03\u7528Python\u4e4b\u524d\u5fc5\u987b\u5148\u521d\u59cb\u5316\u89e3\u91ca\u5668\n  Py_Initialize();\n  // \u6267\u884c\u4e00\u4e2a\u7b80\u5355\u7684\u6267\u884cpython\u811a\u672c\u547d\u4ee4\n  PyRun_SimpleString(\"print('hello world')\n\");\n  PyRun_SimpleString(\"import sys\");\n  PyRun_SimpleString(\"sys.path.append('.')\");\n\n  PyObject* pModule = PyImport_ImportModule(\"sum\");\n  if( pModule == NULL ){\n        cout &lt;&lt;\"module not found\" &lt;&lt; endl;\n        return 1;\n  }\n    // 4\u3001\u8c03\u7528\u51fd\u6570\n    PyObject* pFunc = PyObject_GetAttrString(pModule, \"say\");\n    if( !pFunc || !PyCallable_Check(pFunc)){\n        cout &lt;&lt;\"not found function add_num\" &lt;&lt; endl;\n        return 0;\n    }\n    // \n    PyObject_CallObject(pFunc, NULL);\n  // \u64a4\u9500Py_Initialize()\u548c\u968f\u540e\u4f7f\u7528Python/C API\u51fd\u6570\u8fdb\u884c\u7684\u6240\u6709\u521d\u59cb\u5316\n  Py_Finalize();\n  return 0;\n}\n</code></pre> <p>\u8fd9\u91cc\u7ed9\u51fa<code>sum.py</code>\u5185\u5bb9</p> <pre><code>def py_list_sum(buffer):\n    return sum(buffer)\n</code></pre> <p>shell\u7f16\u8bd1\u547d\u4ee4\u5982\u4e0b</p> <pre><code>gcc main.c -std=c99 $(python3-config --includes) $(python3-config --ldflags) -fno-lto -o main\n# python3.8\u7248\u672c\u53ca\u4ee5\u4e0a\u8bf7\u5728python3-config --ldflags\u540e\u9762\u518d\u52a0\u5165--embed\u9009\u9879\n\n./main\n</code></pre>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#32-pybind11python","title":"3.2 \u91c7\u7528Pybind11\u6269\u5c55\u8c03\u7528python","text":"<p>pybind11\u901a\u8fc7\u7b80\u5355\u7684C++\u5305\u88c5\u516c\u5f00\u4e86Python\u7c7b\u578b\u548c\u51fd\u6570\uff0c\u8fd9\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u65b9\u4fbf\u7684\u5728C++\u4e2d\u8c03\u7528Python\u4ee3\u7801\uff0c\u800c\u65e0\u9700\u501f\u52a9Python C API\u3002</p> <p><code>demo1.cpp</code>(\u8c03\u7528\u81ea\u5df1\u5199\u7684sum\u6a21\u5757)</p> <pre><code>#include &lt;pybind11/pybind11.h&gt;\n#include &lt;pybind11/stl.h&gt;\n#include &lt;pybind11/embed.h&gt;\n#include &lt;vector&gt;\n#include &lt;iostream&gt;\n\n\nnamespace py = pybind11;\n\nint main(int argc, char *argv[]) {\n  py::scoped_interpreter guard{}; \n  py::object sum = py::module_::import(\"sum\");\n  py::object py_list_sum = sum.attr(\"py_list_sum\");\n  int result = py_list_sum(std::vector&lt;int&gt;{1,2,3,4,5}).cast&lt;int&gt;();\n  std::cout &lt;&lt; \"py_list_sum([1,2,3,4,5]) result:\" &lt;&lt; result &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <p><code>demo2.cpp</code>(\u8fd0\u884cpython\u8bed\u53e5)</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;pybind11/embed.h&gt;\n\nnamespace py = pybind11;\n\nint main()\n{\n    std::cout &lt;&lt; \"Hello PyBind World\" &lt;&lt; std::endl;\n\n    // start the interpreter and keep it alive\n    py::scoped_interpreter guard{}; \n    py::module math = py::module::import(\"math\");\n    py::object result = math.attr(\"sqrt\")(25);\n    std::cout &lt;&lt; \"Sqrt of 25 is: \" &lt;&lt; result.cast&lt;float&gt;() &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <pre><code># -c\u8868\u793a \u53ea\u7f16\u8bd1\u4e0d\u8fde\u63a5 \u53ea\u751f\u6210\u76ee\u6807\u6587\u4ef6 .o\u6587\u4ef6\n# -o \u6307\u5b9a\u751f\u6210\u7684\u53ef\u6267\u884c\u6587\u4ef6\u7684\u540d\u79f0\u3002\u5982\u679c\u4e0d\u4f7f\u7528-o\u9009\u9879\u5219\u4f1a\u751f\u6210\u9ed8\u8ba4\u53ef\u6267\u884c\u6587\u4ef6a.out\n# -g \u6dfb\u52a0gdb\u8c03\u8bd5\u9009\u9879\ng++ -std=c++11 $(python3 -m pybind11 --includes) demo1.cpp -Wl,-rpath,$(python3-config --prefix)/lib $(python3-config --prefix)/lib/libpython3.7m.so -o demo1 &amp;&amp; ./demo1\n\ng++ -std=c++11 $(python3 -m pybind11 --includes) demo2.cpp -Wl,-rpath,$(python3-config --prefix)/lib $(python3-config --prefix)/lib/libpython3.7m.so -o demo2 &amp;&amp; ./demo2\n</code></pre>"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#_2","title":"\u56db. \u6548\u7387\u5bf9\u6bd4","text":"<p>\u7531\u4e8e\u6211\u4eec\u7684\u529f\u80fd\u5b9e\u73b0\u7684\u8f83\u4e3a\u7b80\u5355\uff0c\u8fd9\u91cc\u7ed9\u51fab\u7ad9\u4e0a\u4e00\u4f4dup\u4e3b\u7ed9\u7684\u5173\u4e8e\u6548\u7387\u95ee\u9898\u505a\u7684\u603b\u7ed3</p> <p>https://www.bilibili.com/video/BV1Ng41167t6/</p> Solution Brief Description Scenarios Python C API \u9700\u8981\u5199C\uff0c\u590d\u6742\u4f46\u6027\u80fd\u6700\u4f18 \u8ffd\u6c42\u6781\u81f4\u6027\u80fd ctypes \u9700\u8981\u5728Python\u91cc\u9762\u5199/\u751f\u6210boilerplate code \u8c03\u7528\u5df2\u6709\u7684\u52a8\u6001\u5e93\uff0c\u4e14\u4e0d\u6d89\u53ca\u590d\u6742\u6570\u636e\u7ed3\u6784\uff0c\u5c31\u8c03\u7528\u51e0\u4e2afunction SWIG \u81ea\u52a8\u751f\u6210ext module\u7684binding code\uff0c\u8981\u5199inferface file \u9700\u8981\u652f\u6301\u5404\u79cd\u8bed\u8a00\u7684binding\uff0c\u53ea\u9700\u8981\u5199\u4e00\u4efdinferface\u6587\u4ef6 pybind11 \u597d\u5199\uff0c\u652f\u6301C++feature\uff0c\u6027\u80fd\u6709\u727a\u7272 \u6709\u590d\u6742\u7684\u6570\u636e\u7ed3\u6784\uff0cPython\u548cC/C++\u4ea4\u4e92\u8f83\u591a"},{"location":"python%26C%2B%2B/python%E5%92%8CC%E7%9A%84%E4%BA%A4%E4%BA%92/#_3","title":"\u4e94. \u603b\u7ed3","text":"<p>\u672c\u6587\u7ed9\u51faPython\u8c03\u7528C/C++\u7f16\u5199\u7684\u6269\u5c55\u4ee5\u53caC/C++\u5982\u4f55\u8c03\u7528Python\u811a\u672c\u548c\u5e93\u7684\u82e5\u5e72\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e00\u4e9b\u5177\u4f53\u7684\u5e94\u7528\u6848\u4f8b\u3002</p> <p>\u4ece\u4e2a\u4eba\u89d2\u5ea6\u6765\u8bb2\uff0c\u6211\u66f4\u559c\u6b22Pybind11\u548cPython C API\u8fd9\u4e24\u79cd\u65b9\u5f0f\u3002</p> <p>Python API\u7279\u70b9</p> <ul> <li>\u901f\u5ea6\u5feb</li> <li>\u5bf9CPython\u7684\u6e90\u7801\u5c24\u5176\u662f\u5f15\u7528\u8ba1\u6570\u90e8\u5206\u9700\u8981\u6709\u6df1\u5c42\u6b21\u4e86\u89e3</li> </ul> <p>Pybind11\u7279\u70b9</p> <ul> <li>\u5b8c\u7f8e\u878d\u5408c++11\u7279\u6027\uff0c\u65e0\u9700\u638c\u63e1\u989d\u5916\u8bed\u6cd5</li> <li>\u901f\u5ea6\u76f8\u6bd4\u4e8ePython API\u6b20\u4f73\uff0c\u4f46\u662f\u9488\u5bf9\u6bd4\u5982\u4e00\u4e9b\u7b97\u5b50\u5f00\u53d1\uff0c\u5f53\u8c03\u7528\u8017\u65f6\u4e0d\u662f\u4e3b\u8981\u5360\u6bd4\u7684\u65f6\u5019\uff0c\u8be5\u65b9\u5f0f\u8fd8\u662f\u503c\u5f97\u63a8\u8350\u3002</li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/","title":"\u5d4c\u5165\u5f0f\u5f00\u53d1\u91c7\u7528so\u52a8\u6001\u52a0\u8f7d\u6446\u8131buildroot\u4f9d\u8d56","text":"<p>\u672c\u6587\u5199\u4e8e2025\u5e746\u67089\u53f7\u817e\u51b2\u5e02\uff0c\u6574\u7406\u4e8e2025\u5e746\u670828\u53f7\u5317\u4eac\u5e02</p>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#_1","title":"\u4e00\u3001\u95ee\u9898\u80cc\u666f","text":"<p>\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\uff08\u5982\u57fa\u4e8e Rockchip SoC \u7684\u5f00\u53d1\u677f\uff09\u4e0a\u96c6\u6210\u6444\u50cf\u5934\u529f\u80fd\u65f6\uff0c\u5f80\u5f80\u9700\u8981\u4f9d\u8d56\u5382\u5546\u63d0\u4f9b\u7684\u786c\u4ef6\u52a0\u901f\u5e93\uff0c\u5982 RGA\uff08\u786c\u4ef6\u52a0\u901f\u7684\u56fe\u50cf\u683c\u5f0f\u8f6c\u6362\uff09\u3001RK AIQ\uff08\u56fe\u50cf\u4fe1\u53f7\u5904\u7406 ISP \u76f8\u5173\uff09\u3001MPP\uff08\u5a92\u4f53\u5904\u7406\u5e73\u53f0\u56fe\u50cf\u89c6\u9891\u786c\u4ef6\u7f16\u89e3\u7801\u7b49\uff09\u3002  </p> <p>\u7531\u4e8e\u8fd9\u4e9b\u5e93\u901a\u5e38\u53ea\u80fd\u5728\u76ee\u6807\u8bbe\u5907\u7cfb\u7edf\u4e0a\u4ee5\u4e8c\u8fdb\u5236\u5f62\u5f0f\u5b58\u5728\uff0c\u4e14\u53ef\u80fd\u6ca1\u6709\u9488\u5bf9\u4ea4\u53c9\u7f16\u8bd1\u73af\u5883\u7684\u5f00\u53d1\u5305\uff08\u5934\u6587\u4ef6\u53ef\u80fd\u53ef\u5f97\uff0c\u4f46\u4ea4\u53c9\u7f16\u8bd1\u65f6\u65e0\u6cd5\u94fe\u63a5\u5230\u5bf9\u5e94\u7684\u4ea4\u53c9\u7f16\u8bd1\u7248\u672c\u5e93\uff09\uff0c\u4f20\u7edf\u505a\u6cd5\u5f80\u5f80\u662f\u5728 Buildroot \u6216 OpenEmbedded \u7b49\u7cfb\u7edf\u4e2d\uff1a\u5c06\u6240\u6709\u9a71\u52a8\u3001\u7b2c\u4e09\u65b9\u95ed\u6e90\u5e93\u3001ISP \u76f8\u5173 SDK \u7b49\u6574\u5408\u8fdb\u4e00\u4e2a\u5b8c\u6574\u7684\u6839\u6587\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u5e76\u7edf\u4e00\u4ea4\u53c9\u7f16\u8bd1\u3001\u94fe\u63a5\uff0c\u751f\u6210\u6700\u7ec8\u53ef\u6267\u884c\u6587\u4ef6\u6216\u5e93\u3002  </p> <p>\u7136\u800c\uff0c\u8fd9\u79cd\u65b9\u5f0f\u7684\u5f0a\u7aef\u5305\u62ec\uff1a</p> <ul> <li>\u5e9e\u5927\u4e14\u590d\u6742\u7684 Buildroot \u914d\u7f6e\uff1a\u9700\u8981\u5c06\u5382\u5546\u63d0\u4f9b\u7684\u52a0\u901f\u5e93\u7684\u4ea4\u53c9\u7f16\u8bd1\u7248\u672c\u7eb3\u5165\u6784\u5efa\uff0c\u82e5\u5382\u5546\u4e0d\u63d0\u4f9b\u6216\u7248\u672c\u9891\u7e41\u66f4\u65b0\uff0c\u7ef4\u62a4\u6210\u672c\u9ad8\uff1b</li> <li>\u53ef\u79fb\u690d\u6027\u5dee\uff1a\u4e00\u65e6\u79fb\u690d\u5230\u5176\u4ed6\u786c\u4ef6\u5e73\u53f0\u6216\u66f4\u65b0 SDK\uff0c\u6574\u4e2a Buildroot \u73af\u5883\u9700\u91cd\u65b0\u8c03\u8bd5\u548c\u7f16\u8bd1\uff1b</li> <li>\u7f16\u8bd1\u65f6\u95f4\u957f\u3001\u5931\u8d25\u8c03\u8bd5\u6210\u672c\u9ad8\uff1a\u4efb\u4f55\u5e95\u5c42\u7ec4\u4ef6\u66f4\u65b0\u6216\u6539\u52a8\u90fd\u53ef\u80fd\u5bfc\u81f4\u5168\u94fe\u8def\u91cd\u65b0\u7f16\u8bd1\uff0c\u6bcf\u6b21\u6d4b\u8bd5\u7a0b\u5e8f\u70e7\u5199\u6574\u4e2a\u7cfb\u7edf\u6210\u672c\u5b9e\u5728\u592a\u9ad8\u3002</li> <li>\u4e8c\u8fdb\u5236\u517c\u5bb9\u5c40\u9650\uff1a\u5728\u4e0d\u540c\u7cfb\u7edf\u7248\u672c\u6216\u4e0d\u540c\u8bbe\u5907\u4e0a\uff0c\u52a8\u6001\u5e93\u8def\u5f84\u3001\u7248\u672c\u53ef\u80fd\u4e0d\u4e00\u81f4\uff0c\u9759\u6001\u94fe\u63a5\u6216\u4ea4\u53c9\u7f16\u8bd1\u94fe\u63a5\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u6240\u6709\u8fd0\u884c\u65f6\u73af\u5883\u3002</li> </ul> <p>\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u673a\u5236\uff0c\u5728\u5d4c\u5165\u5f0f\u5e94\u7528\u672c\u8eab\u4ec5\u7f16\u8bd1\u6838\u5fc3\u903b\u8f91\uff0c\u800c\u5c06\u4f9d\u8d56\u7684\u786c\u4ef6\u52a0\u901f\u5e93\uff08\u5982 librkaiq.so\u3001librga.so\u3001librockchip_mpp.so \u7b49\uff09\u7559\u5230\u76ee\u6807\u8bbe\u5907\u4e0a\u8fd0\u884c\u65f6\u518d\u52a0\u8f7d\uff0c\u51cf\u5c11\u4ea4\u53c9\u7f16\u8bd1\u65f6\u5bf9\u95ed\u6e90\u5e93\u7684\u76f4\u63a5\u94fe\u63a5\u4f9d\u8d56\uff0c\u4ece\u800c\u7b80\u5316 Buildroot \u914d\u7f6e\u3001\u52a0\u5feb\u8fed\u4ee3\u3002</p>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#_2","title":"\u4e8c\u3001\u52a8\u6001\u5e93\u52a8\u6001\u52a0\u8f7d\u7684\u539f\u7406\u4e0e\u4f18\u52bf","text":"<p>\u52a8\u6001\u52a0\u8f7d\uff08runtime dynamic loading\uff09\u901a\u5e38\u57fa\u4e8e<code>POSIX</code> \u7684 <code>dlopen</code>\u3001<code>dlsym</code>\u3001<code>dlclose</code> \u7b49\u63a5\u53e3\u3002\u5728\u7f16\u8bd1\u671f\u4e0d\u76f4\u63a5\u94fe\u63a5\u76ee\u6807\u5e93\uff0c\u800c\u662f\u5728\u8fd0\u884c\u65f6\u52a0\u8f7d\u5e76\u52a8\u6001\u89e3\u6790\uff0c\u5176\u4e00\u822c\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ol> <li>\u5c1d\u8bd5 <code>dlopen(\"\u5e93\u540d.so\", RTLD_LAZY)</code>\uff1a\u82e5\u6210\u529f\uff0c\u5373\u8868\u660e\u5f53\u524d\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8be5\u5e93\uff0c\u53ef\u4f7f\u7528\u786c\u4ef6\u52a0\u901f\u529f\u80fd</li> <li>\u4f7f\u7528 <code>dlsym(handle, \"\u51fd\u6570\u540d\")</code> \u83b7\u53d6\u51fd\u6570\u6307\u9488\uff1a\u5c06\u7b26\u53f7\u6620\u5c04\u5230\u672c\u5730\u51fd\u6570\u6307\u9488\uff0c\u8fdb\u800c\u8c03\u7528\uff1b</li> <li>\u82e5\u52a0\u8f7d\u6216\u83b7\u53d6\u7b26\u53f7\u5931\u8d25\uff1a\u53ef\u8bb0\u5f55\u65e5\u5fd7\u5e76\u8fdb\u884c\u56de\u9000</li> <li>\u65e0\u9700\u5728\u4ea4\u53c9\u7f16\u8bd1\u65f6\u63d0\u4f9b\u8be5\u5e93\u7684\u94fe\u63a5\u7248\u672c\uff1a\u53ea\u9700\u5728\u76ee\u6807\u7cfb\u7edf\u8fd0\u884c\u65f6\u63d0\u4f9b\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u5e93\u6587\u4ef6\u5730\u5740\uff08\u901a\u5e38\u7531\u5382\u5546\u7cfb\u7edf\u6216\u5347\u7ea7\u5305\u63d0\u4f9b\uff09\uff0c\u5e94\u7528\u53ef\u52a8\u6001\u52a0\u8f7d\u3002</li> </ol> <p>\u8fd9\u79cd\u65b9\u5f0f\u7684\u4e3b\u8981\u4f18\u52bf\uff1a</p> <ul> <li>\u51cf\u5c11\u4ea4\u53c9\u7f16\u8bd1\u4f9d\u8d56\uff1a\u65e0\u9700\u5728 Buildroot \u4e2d\u96c6\u6210\u5e93\u7684\u4ea4\u53c9\u7f16\u8bd1\u7248\u672c\uff0c\u4ec5\u9700\u8981\u5bf9\u5e94\u5934\u6587\u4ef6\uff08\u82e5\u63a5\u53e3\u5b9a\u4e49\u9700\u7f16\u8bd1\u671f\u53ef\u89c1\uff09\u6216\u5728\u8fd0\u884c\u65f6\u901a\u8fc7 dlsym \u67e5\u627e\u7b26\u53f7\u540d\uff1b</li> <li>\u63d0\u5347\u53ef\u79fb\u690d\u6027\uff1a\u540c\u4e00\u5e94\u7528\u4e8c\u8fdb\u5236\u53ef\u4ee5\u5728\u4e0d\u540c\u7cfb\u7edf\u6216\u8bbe\u5907\u4e0a\u8fd0\u884c\uff0c\u8fd0\u884c\u65f6\u6839\u636e\u7cfb\u7edf\u4e0a\u662f\u5426\u5b58\u5728\u786c\u4ef6\u52a0\u901f\u5e93\u51b3\u5b9a\u542f\u7528\uff1b</li> <li>\u4f18\u96c5\u964d\u7ea7\uff1a\u82e5\u786c\u4ef6\u5e93\u7248\u672c\u4e0d\u5339\u914d\u6216\u4e0d\u5b58\u5728\uff0c\u7a0b\u5e8f\u81ea\u52a8\u5207\u56de\u8f6f\u4ef6\u5b9e\u73b0\u8def\u5f84\uff0c\u65e0\u9700\u91cd\u65b0\u7f16\u8bd1\uff1b</li> <li>\u7f29\u77ed\u7f16\u8bd1\u65f6\u95f4\u3001\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\uff1a\u6838\u5fc3\u5e94\u7528\u6539\u52a8\u65f6\u53ea\u9700\u7f16\u8bd1\u81ea\u8eab\u4ee3\u7801\uff0c\u4e0d\u5fc5\u91cd\u65b0\u7f16\u8bd1\u786c\u4ef6 SDK\uff1b</li> <li>\u7075\u6d3b\u5347\u7ea7\uff1a\u8bbe\u5907\u4fa7\u53ef\u5355\u72ec\u5347\u7ea7\u786c\u4ef6\u52a0\u901f\u5e93\uff0c\u5e94\u7528\u65e0\u9700\u66f4\u65b0\uff1b\u53cd\u4e4b\u4ea6\u7136\u3002</li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#_3","title":"\u4e09\u3001\u52a8\u6001\u5e93\u52a8\u6001\u52a0\u8f7d\u63a5\u53e3","text":"<p>\u52a8\u6001\u52a0\u8f7d\u5e38\u7528\u63a5\u53e3\u5b9a\u4e49\u4e8e <code>&lt;dlfcn.h&gt;</code>\uff0c\u4e3b\u8981\u5305\u62ec\u4ee5\u4e0b\u51fd\u6570\uff1a</p> <pre><code>#include &lt;dlfcn.h&gt;\n\n// \u6253\u5f00\uff08\u52a0\u8f7d\uff09\u52a8\u6001\u5e93\nvoid *dlopen(const char *filename, int flag);\n\n// \u83b7\u53d6\u7b26\u53f7\u5730\u5740\nvoid *dlsym(void *handle, const char *symbol);\n\n// \u5173\u95ed\uff08\u5378\u8f7d\uff09\u52a8\u6001\u5e93\nint dlclose(void *handle);\n\n// \u83b7\u53d6\u6700\u8fd1\u4e00\u6b21\u52a8\u6001\u52a0\u8f7d\u9519\u8bef\u4fe1\u606f\nchar* dlerror(void);\n</code></pre>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#31","title":"3.1 \u63a5\u53e3\u8bf4\u660e","text":""},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#311-dlopen","title":"3.1.1 dlopen","text":"<ul> <li>\u539f\u578b\uff1a<code>void* dlopen(const char *filename, int flag);</code></li> <li>\u529f\u80fd\uff1a\u52a0\u8f7d\u52a8\u6001\u5e93\u6587\u4ef6\uff0c\u8fd4\u56de\u4e00\u4e2a\u53e5\u67c4 (handle)\uff0c\u540e\u7eed\u53ef\u901a\u8fc7\u8be5\u53e5\u67c4\u83b7\u53d6\u7b26\u53f7\u6216\u5173\u95ed\u5e93\u3002</li> <li>\u53c2\u6570\uff1a<ul> <li><code>filename</code>\uff1a\u8981\u52a0\u8f7d\u7684\u5e93\u8def\u5f84\u6216\u540d\u79f0\u3002\u82e5\u53ea\u7ed9\u5e93\u540d\uff08\u5982 <code>\"libfoo.so\"</code>\uff09\uff0c\u7cfb\u7edf\u4f1a\u5728\u8fd0\u884c\u65f6\u94fe\u63a5\u5668\u9ed8\u8ba4\u7684\u641c\u7d22\u8def\u5f84\u4e2d\u67e5\u627e\uff08\u5982 <code>/lib</code>, <code>/usr/lib</code> \u7b49\uff09\uff0c\u4e5f\u53ef\u80fd\u53d7\u73af\u5883\u53d8\u91cf <code>LD_LIBRARY_PATH</code> \u5f71\u54cd\u3002\u5728\u5d4c\u5165\u5f0f\u573a\u666f\u4e2d\uff0c\u5e38\u7528\u5b8c\u6574\u8def\u5f84\uff08\u5982 <code>/usr/lib/librga.so</code>\uff09\u6216\u4e8b\u5148\u8bbe\u7f6e\u597d\u641c\u7d22\u8def\u5f84\u3002\u82e5\u4f20\u5165 <code>NULL</code>\uff0c\u5219\u8fd4\u56de\u4e3b\u7a0b\u5e8f\uff08\u53ef\u6267\u884c\u6587\u4ef6\u672c\u8eab\uff09\u7684\u53e5\u67c4\uff0c\u5141\u8bb8\u8bbf\u95ee\u4e3b\u7a0b\u5e8f\u4e2d\u7684\u7b26\u53f7</li> <li><code>flag</code>\uff1a\u63a7\u5236\u7b26\u53f7\u89e3\u6790\u65b9\u5f0f\u548c\u53ef\u89c1\u6027\uff0c\u5e38\u89c1\u53d6\u503c\u6709\uff1a<ul> <li><code>RTLD_LAZY</code>\uff1a\u5ef6\u8fdf\u89e3\u6790\uff08lazy binding\uff09\u3002\u53ea\u6709\u5728\u5b9e\u9645\u8c03\u7528\u7b26\u53f7\u5730\u5740\u65f6\uff0c\u624d\u4f1a\u89e3\u6790\u5bf9\u5e94\u7b26\u53f7\u3002\u4f18\u70b9\u662f\u542f\u52a8\u65f6\u5f00\u9500\u5c0f\uff1b\u7f3a\u70b9\u662f\u5982\u679c\u7b26\u53f7\u7f3a\u5931\uff0c\u53ef\u80fd\u5728\u8fd0\u884c\u65f6\u624d\u51fa\u9519\u3002</li> <li><code>RTLD_NOW</code>\uff1a\u7acb\u5373\u89e3\u6790\u6240\u6709\u672a\u51b3\u7b26\u53f7\uff08eager binding\uff09\u3002\u82e5\u6709\u7b26\u53f7\u627e\u4e0d\u5230\uff0c\u5219 <code>dlopen</code> \u8fd4\u56de\u5931\u8d25\u3002\u9002\u5408\u5e0c\u671b\u5c3d\u65e9\u53d1\u73b0\u95ee\u9898\u7684\u573a\u666f\u3002</li> <li><code>RTLD_LOCAL</code>\uff1a\u672c\u5730\u7b26\u53f7\uff0c\u53ef\u4e0e\u540e\u7eed\u5176\u4ed6\u52a8\u6001\u52a0\u8f7d\u5e93\u9694\u79bb\uff0c\u5e93\u5185\u90e8\u89e3\u6790\u4e0d\u4f1a\u5f71\u54cd\u5168\u5c40\u7b26\u53f7\u8868\u3002\u901a\u5e38\u4e0e <code>RTLD_LAZY</code> \u6216 <code>RTLD_NOW</code> \u914d\u5408\u4f7f\u7528\uff1a\u4f8b\u5982 <code>RTLD_LAZY | RTLD_LOCAL</code>\u3002</li> <li><code>RTLD_GLOBAL</code>\uff1a\u5c06\u52a0\u8f7d\u5e93\u7684\u7b26\u53f7\u52a0\u5165\u5168\u5c40\u7b26\u53f7\u8868\uff0c\u540e\u7eed <code>dlopen</code> \u7684\u5176\u4ed6\u5e93\u53ef\u5f15\u7528\u8fd9\u4e9b\u7b26\u53f7\u3002\u82e5\u5e0c\u671b\u63d2\u4ef6\u5e93\u4e92\u76f8\u4f9d\u8d56\uff0c\u6216\u63d2\u4ef6\u8bbf\u95ee\u4e3b\u7a0b\u5e8f\u5bfc\u51fa\u7684\u7b26\u53f7\uff0c\u53ef\u4f7f\u7528\u6b64\u6807\u5fd7\u3002</li> <li>\uff08Linux \u7279\u6709\uff09<code>RTLD_NODELETE</code>\uff1a\u5378\u8f7d\u65f6\u4e0d\u771f\u6b63\u91ca\u653e\u5185\u5b58\uff0c\u4ee5\u4fbf\u5e93\u4e2d\u9759\u6001\u6570\u636e\u6301\u7eed\u5b58\u5728\uff0c\u4f46\u4e00\u822c\u4e0d\u5e38\u7528\u3002</li> </ul> </li> </ul> </li> <li>\u8fd4\u56de\u503c\uff1a\u6210\u529f\u8fd4\u56de\u4e00\u4e2a\u975e NULL \u7684 <code>void*</code> \u53e5\u67c4\uff1b\u5931\u8d25\u8fd4\u56de NULL\uff0c\u53ef\u901a\u8fc7 <code>dlerror()</code> \u53d6\u5f97\u9519\u8bef\u4fe1\u606f\u3002</li> <li>\u6ce8\u610f\uff1a  <ul> <li>\u5982\u679c\u591a\u6b21\u5bf9\u540c\u4e00 <code>filename</code> \u8c03\u7528 <code>dlopen</code>\uff0cglibc \u9ed8\u8ba4\u4f1a\u8fd4\u56de\u540c\u4e00 handle\uff0c\u5e76\u589e\u52a0\u5f15\u7528\u8ba1\u6570\u3002\u591a\u6b21 <code>dlclose</code> \u540e\uff0c\u5f15\u7528\u8ba1\u6570\u4e3a 0 \u65f6\u624d\u771f\u6b63\u5378\u8f7d\u3002</li> <li>\u82e5 <code>filename</code> \u4e3a NULL\uff0c\u5219\u8fd4\u56de\u4e3b\u7a0b\u5e8f\u672c\u8eab\u7684\u53e5\u67c4\uff0c\u5141\u8bb8\u4f7f\u7528 <code>dlsym(NULL, \"\u7b26\u53f7\u540d\")</code> \u83b7\u53d6\u4e3b\u7a0b\u5e8f\u6216\u5df2\u94fe\u63a5\u5e93\u4e2d\u7684\u7b26\u53f7\u3002</li> </ul> </li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#312-dlsym","title":"3.1.2 dlsym","text":"<ul> <li>\u539f\u578b\uff1a<code>void *dlsym(void *handle, const char *symbol);</code></li> <li>\u529f\u80fd\uff1a\u5728\u5df2\u52a0\u8f7d\u7684\u52a8\u6001\u5e93\uff08\u6216\u4e3b\u7a0b\u5e8f\uff0c\u82e5 handle \u4e3a NULL\uff09\u4e2d\u67e5\u627e\u7b26\u53f7 <code>symbol</code>\uff0c\u8fd4\u56de\u8be5\u7b26\u53f7\u7684\u5730\u5740\uff08\u51fd\u6570\u6216\u5168\u5c40\u53d8\u91cf\u5730\u5740\uff09\u3002</li> <li>\u53c2\u6570\uff1a<ul> <li><code>handle</code>\uff1a\u7531 <code>dlopen</code> \u8fd4\u56de\u7684\u53e5\u67c4\uff0c\u6216 NULL \u8868\u793a\u641c\u7d22\u4e3b\u7a0b\u5e8f\u53ca\u5176\u5df2\u94fe\u63a5\u5e93\u3002</li> <li><code>symbol</code>\uff1a\u7b26\u53f7\u540d\u5b57\u7b26\u4e32\uff0c\u4f8b\u5982 <code>\"rk_aiq_uapi2_sysctl_init\"</code>\u3002C++ \u51fd\u6570\u5f80\u5f80\u6709 name-mangling\uff0c\u9700\u8981 extern \"C\" \u6216\u4f7f\u7528\u5df2\u77e5\u7684 Mangled name(\u4e0d\u63a8\u8350\u8fd9\u79cd\u505a\u6cd5\uff0c\u4e0d\u5177\u6709\u901a\u7528\u6027)\uff1b\u901a\u5e38\u786c\u4ef6 SDK \u63d0\u4f9b\u7684\u662f C \u63a5\u53e3\uff0c\u4fbf\u4e8e\u76f4\u63a5\u7528 dlsym\u3002</li> </ul> </li> <li>\u8fd4\u56de\u503c\uff1a\u6210\u529f\u8fd4\u56de\u975e NULL \u5730\u5740\uff1b\u82e5\u627e\u4e0d\u5230\u8be5\u7b26\u53f7\uff0c\u5219\u8fd4\u56de NULL\u3002\u82e5\u8fd4\u56de NULL\uff0c\u8981\u7ed3\u5408 <code>dlerror()</code> \u5224\u65ad\u662f\u771f\u627e\u4e0d\u5230\u8fd8\u662f\u5176\u4ed6\u539f\u56e0\u3002</li> <li>\u6ce8\u610f\uff1a<ul> <li>\u5728\u8c03\u7528\u524d\u6700\u597d\u5148\u6e05\u7a7a\u9519\u8bef\uff1a<code>dlerror()</code>\uff1b\u7136\u540e\u8c03\u7528 <code>dlsym</code>\uff1b\u518d\u8c03\u7528 <code>char *err = dlerror()</code>\uff0c\u5982\u679c <code>err != NULL</code> \u5219\u8868\u793a\u6709\u9519\u8bef\uff1b\u5426\u5219\u5373\u4f7f <code>dlsym</code> \u8fd4\u56de NULL\uff0c\u4e5f\u53ef\u80fd\u610f\u5473\u7740\u7b26\u53f7\u5730\u5740\u5b9e\u9645\u4e3a NULL\uff08\u8f83\u5c11\u89c1\uff09\uff0c\u6545\u9700\u6309\u8fd9\u79cd\u987a\u5e8f\u68c0\u6d4b\u9519\u8bef\u3002</li> <li>\u9700\u8981\u5c06\u8fd4\u56de\u7684 <code>void*</code> \u5f3a\u5236\u8f6c\u6362\u4e3a\u6b63\u786e\u7684\u51fd\u6570\u6307\u9488\u7c7b\u578b\uff1a\u4f8b\u5982 <code>using FnInit = int (*)(int, int); FnInit init = (FnInit)dlsym(handle, \"init_func_name\");</code>\u3002\u4e0d\u540c\u5e73\u53f0\u5bf9\u51fd\u6570\u6307\u9488\u8f6c\u6362\u6709\u8981\u6c42\uff0c\u4f46\u901a\u5e38 <code>POSIX</code> \u5141\u8bb8\u8fd9\u79cd\u8f6c\u6362\u3002</li> </ul> </li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#313-dlclose","title":"3.1.3 dlclose","text":"<ul> <li>\u539f\u578b\uff1a<code>int dlclose(void *handle);</code></li> <li>\u529f\u80fd\uff1a\u51cf\u5c11\u52a0\u8f7d\u5e93\u7684\u5f15\u7528\u8ba1\u6570\uff1b\u5f53\u5f15\u7528\u8ba1\u6570\u964d\u4e3a 0 \u65f6\uff0c\u5378\u8f7d\u5e93\uff0c\u91ca\u653e\u76f8\u5173\u8d44\u6e90\uff08\u82e5\u65e0 <code>RTLD_NODELETE</code>\uff09\u3002</li> <li>\u53c2\u6570\uff1a<code>handle</code>\uff1a<code>dlopen</code> \u8fd4\u56de\u7684\u53e5\u67c4\u3002</li> <li>\u8fd4\u56de\u503c\uff1a\u6210\u529f\u8fd4\u56de 0\uff1b\u5931\u8d25\u8fd4\u56de\u975e 0\uff0c\u53ef\u901a\u8fc7 <code>dlerror()</code> \u83b7\u53d6\u9519\u8bef\u4fe1\u606f\u3002</li> <li>\u6ce8\u610f\uff1a<ul> <li>\u4e0d\u8981\u5728\u4ecd\u6709\u51fd\u6570\u5728\u6267\u884c\u6216\u7ebf\u7a0b\u6b63\u4f7f\u7528\u5e93\u529f\u80fd\u65f6\u8c03\u7528 <code>dlclose</code>\u3002\u5e94\u5728\u786e\u5b9a\u4e0d\u518d\u4f7f\u7528\u5e93\u4e2d\u4efb\u4f55\u7b26\u53f7\u540e\u518d\u5378\u8f7d\u3002</li> <li>\u5982\u679c\u591a\u6b21 <code>dlopen</code> \u5f97\u5230\u540c\u4e00 handle\uff0c\u5219\u9700\u5bf9\u5e94\u591a\u6b21 <code>dlclose</code> \u624d\u771f\u6b63\u5378\u8f7d\u3002</li> </ul> </li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#314-dlerror","title":"3.1.4 dlerror","text":"<ul> <li>\u539f\u578b\uff1a<code>char *dlerror(void);</code></li> <li>\u529f\u80fd\uff1a\u83b7\u53d6\u6700\u8fd1\u4e00\u6b21\u52a8\u6001\u52a0\u8f7d\u63a5\u53e3\u8c03\u7528\u7684\u9519\u8bef\u4fe1\u606f\u5b57\u7b26\u4e32\u3002\u6bcf\u6b21\u8c03\u7528\u6b64\u51fd\u6570\u540e\uff0c\u9519\u8bef\u72b6\u6001\u4f1a\u88ab\u6e05\u9664\uff1b\u5728\u4e0b\u4e00\u6b21\u51fa\u9519\u524d\uff0c\u540e\u7eed\u8c03\u7528\u8fd4\u56de NULL\u3002</li> <li>\u4f7f\u7528\u65b9\u5f0f\uff1a<ol> <li>\u8c03\u7528\u524d\u5148 <code>dlerror()</code> \u4e00\u6b21\u4ee5\u6e05\u9664\u65e7\u9519\u8bef\u3002</li> <li>\u8c03\u7528 <code>dlopen</code>/<code>dlsym</code> \u7b49\u540e\uff0c\u7acb\u5373\u8c03\u7528 <code>char *err = dlerror()</code>\u3002</li> <li>\u82e5 <code>err != NULL</code>\uff0c\u5219\u6253\u5370\u6216\u8bb0\u5f55 <code>err</code>\uff0c\u8868\u793a\u6709\u9519\u8bef\uff1b\u5426\u5219\u52a0\u8f7d\u6216\u67e5\u7b26\u53f7\u6210\u529f\u3002</li> </ol> </li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#315-flag","title":"3.1.5 \u5e38\u89c1 Flag \u7ec4\u5408\u793a\u4f8b","text":"<ul> <li><code>dlopen(\"librkaiq.so\", RTLD_LAZY | RTLD_LOCAL);</code></li> <li><code>dlopen(\"/usr/lib/librga.so\", RTLD_NOW | RTLD_LOCAL);</code></li> <li>\u82e5\u9700\u8981\u5168\u5c40\u53ef\u89c1\uff1a<code>dlopen(\"libplugin.so\", RTLD_LAZY | RTLD_GLOBAL);</code></li> </ul> <p>\u901a\u8fc7\u7075\u6d3b\u7ec4\u5408\u8fd9\u4e9b\u6807\u5fd7\uff0c\u53ef\u4ee5\u63a7\u5236\u7b26\u53f7\u89e3\u6790\u65f6\u673a\u53ca\u53ef\u89c1\u6027\uff0c\u4ece\u800c\u6ee1\u8db3\u4e0d\u540c\u573a\u666f\u9700\u6c42\u3002</p>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#32-demo","title":"3.2 \u4f7f\u7528 Demo","text":"<p>\u4e0b\u9762\u4ee5\u4e00\u4e2a\u7b80\u5316\u7684\u793a\u4f8b\u6f14\u793a\u52a8\u6001\u52a0\u8f7d\u7684\u5b8c\u6574\u6d41\u7a0b\u3002\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u63d2\u4ef6\u5e93 <code>libplugin.so</code>\uff0c\u63d0\u4f9b\u4e24\u4e2a\u63a5\u53e3\uff1a</p> <ul> <li><code>const char* plugin_name()</code>\uff1a\u8fd4\u56de\u63d2\u4ef6\u540d\u79f0\u5b57\u7b26\u4e32\u3002</li> <li><code>int plugin_add(int a, int b)</code>\uff1a\u8fd4\u56de a + b\u3002</li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#321","title":"3.2.1 \u51c6\u5907\u63d2\u4ef6\u5e93","text":"<ol> <li> <p>\u63d2\u4ef6\u6e90\u6587\u4ef6 plugin.c\uff1a</p> <pre><code>#include &lt;stdio.h&gt;\n\n// \u786e\u4fdd C \u7b26\u53f7\u5bfc\u51fa\uff0c\u65e0 name-mangling\nconst char* plugin_name() {\n    return \"\u793a\u4f8b\u63d2\u4ef6\";\n}\n\nint plugin_add(int a, int b) {\n    return a + b;\n}\n</code></pre> </li> <li> <p>\u7f16\u8bd1\u4e3a\u5171\u4eab\u5e93\uff08\u5728\u4ea4\u53c9\u7f16\u8bd1\u73af\u5883\u4e0b\uff0c\u6b64\u5904\u793a\u4f8b\u5728\u4e3b\u673a\u4e0a\u7f16\u8bd1\uff0c\u4ec5\u6f14\u793a\u6d41\u7a0b\uff1b\u5d4c\u5165\u5f0f\u9879\u76ee\u4e2d\u53ef\u6309\u76f8\u540c\u65b9\u6cd5\u4ea4\u53c9\u7f16\u8bd1\u751f\u6210 .so\uff09\uff1a</p> <pre><code>gcc -fPIC -shared -o libplugin.so plugin.c\n</code></pre> <ul> <li><code>-fPIC</code>\uff1a\u751f\u6210\u4f4d\u7f6e\u65e0\u5173\u4ee3\u7801\uff08Position Independent Code\uff09\uff0c\u5fc5\u9700\u7528\u4e8e\u5171\u4eab\u5e93\u3002</li> <li><code>-shared -o libplugin.so</code>\uff1a\u751f\u6210\u52a8\u6001\u5e93\u6587\u4ef6 libplugin.so\u3002</li> </ul> </li> <li> <p>\u5c06 <code>libplugin.so</code> \u653e\u5230\u7cfb\u7edf\u53ef\u641c\u7d22\u8def\u5f84\uff08\u6216\u6307\u5b9a\u8def\u5f84\uff09\uff1a</p> <ul> <li>\u53ef\u62f7\u8d1d\u5230 <code>/usr/lib/</code>\uff0c\u6216\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u67d0\u4e2a\u653e\u7f6e\u7b2c\u4e09\u65b9\u5e93\u7684\u76ee\u5f55\u3002</li> <li>\u4e5f\u53ef\u540c\u5e94\u7528\u653e\u5728\u540c\u4e00\u76ee\u5f55\uff0c\u8fd0\u884c\u65f6\u7528\u76f8\u5bf9\u8def\u5f84 <code>./libplugin.so</code> \u52a0\u8f7d\u3002</li> </ul> </li> </ol>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#322-mainc","title":"3.2.2 \u4e3b\u7a0b\u5e8f main.c","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;dlfcn.h&gt;\n\nint main() {\n    const char *libpath = \"./libplugin.so\";  // \u6839\u636e\u5b9e\u9645\u8def\u5f84\u8c03\u6574\n    // \u6e05\u9664\u65e7\u9519\u8bef\n    dlerror();\n\n    // 1. \u5c1d\u8bd5\u52a0\u8f7d\u52a8\u6001\u5e93\n    void *handle = dlopen(libpath, RTLD_LAZY | RTLD_LOCAL);\n    if (!handle) {\n        const char *err = dlerror();\n        fprintf(stderr, \"\u65e0\u6cd5\u52a0\u8f7d\u5e93 %s: %s\\n\", libpath, err ? err : \"\u672a\u77e5\u9519\u8bef\");\n        return EXIT_FAILURE;\n    }\n    printf(\"\u6210\u529f\u52a0\u8f7d\u5e93\uff1a%s\\n\", libpath);\n\n    // 2. \u67e5\u627e\u7b26\u53f7 plugin_name\n    dlerror();  // \u6e05\u9664\u9519\u8bef\n    typedef const char* (*FnPluginName)();\n    FnPluginName plugin_name = (FnPluginName)dlsym(handle, \"plugin_name\");\n    const char *err = dlerror();\n    if (err != NULL || plugin_name == NULL) {\n        fprintf(stderr, \"\u65e0\u6cd5\u627e\u5230\u7b26\u53f7 plugin_name: %s\\n\", err ? err : \"\u7b26\u53f7\u5730\u5740\u4e3a\u7a7a\");\n        dlclose(handle);\n        return EXIT_FAILURE;\n    }\n    // \u8c03\u7528\n    const char *name = plugin_name();\n    printf(\"\u63d2\u4ef6\u540d\u79f0: %s\\n\", name);\n\n    // 3. \u67e5\u627e\u7b26\u53f7 plugin_add\n    dlerror();\n    typedef int (*FnPluginAdd)(int, int);\n    FnPluginAdd plugin_add = (FnPluginAdd)dlsym(handle, \"plugin_add\");\n    err = dlerror();\n    if (err != NULL || plugin_add == NULL) {\n        fprintf(stderr, \"\u65e0\u6cd5\u627e\u5230\u7b26\u53f7 plugin_add: %s\\n\", err ? err : \"\u7b26\u53f7\u5730\u5740\u4e3a\u7a7a\");\n        dlclose(handle);\n        return EXIT_FAILURE;\n    }\n    // \u8c03\u7528\n    int a = 3, b = 5;\n    int sum = plugin_add(a, b);\n    printf(\"plugin_add(%d, %d) = %d\\n\", a, b, sum);\n\n    // 4. \u5173\u95ed\u5e93\n    if (dlclose(handle) != 0) {\n        fprintf(stderr, \"dlclose \u5931\u8d25: %s\\n\", dlerror());\n    } else {\n        printf(\"\u5e93\u5df2\u5378\u8f7d\\n\");\n    }\n\n    return EXIT_SUCCESS;\n}\n</code></pre>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#323","title":"3.2.3 \u8bf4\u660e","text":"<ol> <li>\u6e05\u9664\u65e7\u9519\u8bef<ul> <li>\u5728\u6bcf\u6b21 <code>dlopen</code> \u6216 <code>dlsym</code> \u524d\uff0c\u8c03\u7528\u4e00\u6b21 <code>dlerror()</code>\uff0c\u786e\u4fdd\u4e4b\u524d\u7684\u9519\u8bef\u4e0d\u4f1a\u5e72\u6270\u5f53\u524d\u5224\u65ad\u3002</li> </ul> </li> <li>\u52a0\u8f7d\u5e93<ul> <li><code>dlopen(libpath, RTLD_LAZY | RTLD_LOCAL)</code>\uff1a\u5ef6\u8fdf\u89e3\u6790\u3001\u7b26\u53f7\u672c\u5730\u53ef\u89c1\u3002\u82e5\u52a0\u8f7d\u5931\u8d25\uff0c\u7acb\u5373\u901a\u8fc7 <code>dlerror()</code> \u83b7\u53d6\u539f\u56e0\u5e76\u9000\u51fa\u6216\u56de\u9000\u3002</li> </ul> </li> <li>\u83b7\u53d6\u7b26\u53f7<ul> <li><code>dlsym(handle, \"symbol_name\")</code>\uff1a\u8fd4\u56de <code>void*</code>\uff0c\u9700\u8981\u5f3a\u5236\u8f6c\u6362\u4e3a\u6b63\u786e\u7684\u51fd\u6570\u6307\u9488\u7c7b\u578b\u3002\u4e3a\u5b89\u5168\u8d77\u89c1\uff0c\u8c03\u7528\u540e\u7acb\u5373\u68c0\u67e5 <code>dlerror()</code> \u662f\u5426\u8fd4\u56de\u9519\u8bef\u3002</li> </ul> </li> <li>\u8c03\u7528\u51fd\u6570<ul> <li>\u5c06\u51fd\u6570\u6307\u9488\u5f53\u666e\u901a\u51fd\u6570\u8c03\u7528\u3002\u6ce8\u610f\uff0c\u5982\u679c\u7b26\u53f7\u7ea6\u5b9a\u53d1\u751f\u53d8\u5316\uff08\u5982\u63a5\u53e3\u7b7e\u540d\u66f4\u65b0\uff09\uff0c\u8c03\u7528\u65f6\u53ef\u80fd\u5d29\u6e83\u6216\u4ea7\u751f\u672a\u5b9a\u4e49\u884c\u4e3a\uff0c\u56e0\u6b64\u5728\u7f16\u8bd1\u65f6\u8981\u4fdd\u8bc1\u5934\u6587\u4ef6\u4e0e\u8fd0\u884c\u65f6\u5e93\u63a5\u53e3\u4e00\u81f4\u3002</li> </ul> </li> <li>\u5378\u8f7d\u5e93<ul> <li><code>dlclose(handle)</code>\uff1a\u51cf\u5c11\u5f15\u7528\u8ba1\u6570\u5e76\u5728\u65e0\u66f4\u591a\u5f15\u7528\u65f6\u5378\u8f7d\u3002\u5378\u8f7d\u540e\uff0c\u82e5\u518d\u6b21\u4f7f\u7528\u8be5\u53e5\u67c4\u6216\u7b26\u53f7\u6307\u9488\u5c06\u51fa\u73b0\u672a\u5b9a\u4e49\u884c\u4e3a\u3002</li> </ul> </li> <li>\u8def\u5f84\u548c\u6743\u9650<ul> <li>\u793a\u4f8b\u4e2d\u4f7f\u7528\u76f8\u5bf9\u8def\u5f84 <code>./libplugin.so</code>\uff0c\u5b9e\u9645\u5d4c\u5165\u5f0f\u9879\u76ee\u4e2d\u53ef\u7528\u7edd\u5bf9\u8def\u5f84\u6216\u7531\u914d\u7f6e\u6307\u5b9a\uff1b\u786e\u4fdd\u8fd0\u884c\u65f6\u8fdb\u7a0b\u5bf9\u8be5\u8def\u5f84\u6709\u8bfb\u53d6\u6743\u9650\u3002</li> </ul> </li> </ol>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#33","title":"3.3 \u8fdb\u4e00\u6b65\u6269\u5c55\uff1a\u57fa\u4e8e\u914d\u7f6e\u7684\u52a8\u6001\u52a0\u8f7d","text":"<p>\u5728\u66f4\u590d\u6742\u9879\u76ee\u4e2d\uff0c\u53ef\u80fd\u9700\u8981\uff1a</p> <ul> <li>\u914d\u7f6e\u6587\u4ef6\u6216\u73af\u5883\u53d8\u91cf \u6307\u5b9a\u5e93\u8def\u5f84\u6216\u662f\u5426\u5f3a\u5236\u7981\u7528\u52a0\u8f7d\u3002\u4f8b\u5982\uff1a<code>export HW_ACCEL_LIB_PATH=/vendor/lib</code>\uff0c\u5728\u4ee3\u7801\u4e2d <code>dlopen(path_from_config + \"/librga.so\", ...)</code>\u3002</li> <li>\u7248\u672c\u68c0\u67e5\uff1a\u82e5\u5e93\u63d0\u4f9b\u7248\u672c\u67e5\u8be2\u63a5\u53e3\uff08\u5982 <code>int get_lib_version()</code>\uff09\uff0c\u53ef\u5148 <code>dlsym</code> \u7248\u672c\u67e5\u8be2\u7b26\u53f7\uff0c\u68c0\u67e5\u7248\u672c\u6ee1\u8db3\u9700\u6c42\u540e\u518d\u52a0\u8f7d\u5173\u952e\u63a5\u53e3\uff1b\u5426\u5219\u56de\u9000\u6216\u63d0\u793a\u5347\u7ea7\u3002</li> <li>\u591a\u5e93\u4f9d\u8d56\uff1a\u82e5\u67d0\u5e93\u4f9d\u8d56\u53e6\u4e00\u5e93\uff0c\u53ef\u5148\u540e\u6309\u987a\u5e8f\u52a0\u8f7d\u5e76\u68c0\u67e5\u3002\u4f8b\u5982\uff1a\u5148 <code>dlopen(\"libA.so\")</code>\uff1b\u82e5\u9700\u8981\u5728 libA \u4e2d\u67e5\u67d0\u7b26\u53f7\u65f6\uff0c\u53ef\u80fd\u9700\u8981\u4fdd\u8bc1 libB \u5df2\u52a0\u8f7d\uff0c\u53ef\u5148 <code>dlopen(\"libB.so\", RTLD_LAZY|RTLD_GLOBAL)</code>\uff0c\u7136\u540e\u518d\u52a0\u8f7d libA\u3002</li> <li>\u7b26\u53f7\u51b2\u7a81\u7ba1\u7406\uff1a\u82e5\u4e0d\u540c\u7248\u672c\u5e93\u53ef\u80fd\u5bfc\u51fa\u540c\u540d\u7b26\u53f7\uff0c\u901a\u8fc7 <code>RTLD_LOCAL</code> \u5c06\u5176\u9694\u79bb\uff0c\u6216\u901a\u8fc7 <code>dlmopen</code>\uff08Linux \u7279\u6709\uff09\u52a0\u8f7d\u5230\u4e0d\u540c\u547d\u540d\u7a7a\u95f4\u3002</li> <li>\u7ebf\u7a0b\u5b89\u5168\uff1a\u5728\u591a\u7ebf\u7a0b\u573a\u666f\uff0c\u82e5\u4e0d\u540c\u7ebf\u7a0b\u53ef\u80fd\u5e76\u53d1\u89e6\u53d1\u52a0\u8f7d\u903b\u8f91\uff0c\u9700\u52a0\u9501\u907f\u514d\u91cd\u590d\u52a0\u8f7d\u6216\u7ade\u6001\u3002</li> </ul>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#capture_v4l2_rk_aiqcpp","title":"\u56db\u3001\u4e1a\u754c\u5b9e\u73b0\u2014capture_v4l2_rk_aiq.cpp","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1ahttps://github.com/nihui/opencv-mobile/blob/v33/highgui/src/capture_v4l2_rk_aiq.cpp</p> <p>\u4ee5\u4e0b\u7ed3\u5408 OpenCV Mobile \u4e2d\u7684 capture_v4l2_rk_aiq.cpp\uff0c\u6982\u8ff0\u5176\u6838\u5fc3\u6d41\u7a0b\u548c\u52a8\u6001\u52a0\u8f7d\u5b9e\u73b0\u8981\u70b9\u3002</p> <ol> <li> <p>\u521d\u59cb\u5316\u9636\u6bb5</p> <ul> <li> <p>\u68c0\u6d4b\u5e73\u53f0\uff08\u5982\u8bfb\u53d6 <code>/proc/device-tree/model</code> \u5224\u65ad\u662f\u5426\u4e3a Rockchip\uff09\uff1b</p> </li> <li> <p>\u52a8\u6001\u52a0\u8f7d RK AIQ \u5e93\uff1a<code>dlopen(\"librkaiq.so\", RTLD_LAZY)</code>\uff1b</p> </li> <li> <p>dlsym \u83b7\u53d6\u5173\u952e API\uff1a\u5982 <code>rk_aiq_uapi2_sysctl_preInit_devBufCnt</code>\u3001<code>rk_aiq_uapi2_sysctl_init</code>\u3001<code>rk_aiq_uapi2_sysctl_prepare</code>\u3001<code>rk_aiq_uapi2_sysctl_start</code> \u7b49\uff1b</p> </li> <li> <p>\u82e5\u4efb\u4e00\u5173\u952e\u7b26\u53f7\u7f3a\u5931\uff0c\u5219\u7acb\u5373\u5378\u8f7d\u5e76\u6807\u8bb0\u201c\u65e0\u786c\u4ef6\u52a0\u901f\u201d\uff1b</p> </li> <li> <p>\u82e5\u6210\u529f\uff0c\u5219\u8c03\u7528\u9884\u521d\u59cb\u5316\u3001\u521d\u59cb\u5316\u63a5\u53e3\uff0c\u521b\u5efa AIQ \u4e0a\u4e0b\u6587\uff0c\u8bbe\u7f6e\u5206\u8fa8\u7387\u3001\u5e27\u7387\u3001\u7f13\u51b2\u7b49\u3002</p> <p>\u53c2\u8003 https://github.com/nihui/opencv-mobile/blob/v33/highgui/src/capture_v4l2_rk_aiq.cpp#L390</p> </li> </ul> </li> <li> <p>\u6355\u83b7\u5faa\u73af</p> <ul> <li> <p>\u4f7f\u7528 V4L2 \u63a5\u53e3\u6253\u5f00\u6444\u50cf\u5934\u8bbe\u5907\u8282\u70b9\uff0c\u8bbe\u7f6e pixel format\uff08NV12/NV21\uff09\u3001\u5206\u8fa8\u7387\u3001\u5e27\u7387\uff1b</p> </li> <li> <p>\u5728\u6bcf\u5e27\u5230\u6765\u540e\uff0c\u82e5\u542f\u7528 RK AIQ\uff1a\u53ef\u80fd\u5148\u8c03\u7528 AIQ \u201c\u51c6\u5907\u201d/\u201c\u6267\u884c\u201d\u63a5\u53e3\uff0c\u8ba9 ISP \u5bf9\u56fe\u50cf\u505a\u81ea\u52a8\u767d\u5e73\u8861\u3001\u66dd\u5149\u7b49\u5904\u7406\uff1b\u82e5\u4e0d\u542f\u7528\uff0c\u5219\u76f4\u63a5\u83b7\u53d6\u539f\u59cb\u5e27\uff1b</p> </li> <li> <p>\u5c06\u83b7\u53d6\u5230\u7684\u683c\u5f0f\u5316\u6570\u636e\u653e\u5165\u7f13\u51b2\uff1b</p> <p>\u53c2\u8003\uff1a</p> <ol> <li>https://github.com/nihui/opencv-mobile/blob/v33/highgui/src/capture_v4l2_rk_aiq.cpp#L940</li> <li>https://github.com/nihui/opencv-mobile/blob/v33/highgui/src/capture_v4l2_rk_aiq.cpp#L1197-L1431</li> </ol> </li> </ul> </li> <li> <p>\u540e\u5904\u7406</p> <ul> <li> <p>\u82e5\u542f\u7528\u4e86 RGA\uff1a\u52a8\u6001\u52a0\u8f7d librga.so\uff0cdlsym \u83b7\u53d6\u8f6c\u6362\u51fd\u6570\uff0c\u5982\u5c06 NV12 \u8f6c BGR\uff0c\u5e76\u53ef\u5728\u6b64\u9636\u6bb5\u6267\u884c\u7f29\u653e\uff1b</p> </li> <li> <p>\u82e5\u672a\u542f\u7528\u6216\u52a0\u8f7d\u5931\u8d25\uff1a\u76f4\u63a5\u9000\u51fa\u7cfb\u7edf\uff1b</p> </li> <li> <p>\u6700\u7ec8\u586b\u5145\u5230 cv::Mat \u6216 native buffer \u4e2d\uff1b   \u53c2\u8003\uff1a</p> <ol> <li>https://github.com/nihui/opencv-mobile/blob/v33/highgui/src/capture_v4l2_rk_aiq.cpp#L1446-L1465</li> <li>https://github.com/nihui/opencv-mobile/blob/v33/highgui/src/capture_v4l2_rk_aiq.cpp#L1584-L1614</li> </ol> </li> </ul> </li> <li> <p>\u9000\u51fa\u4e0e\u53cd\u521d\u59cb\u5316</p> <ul> <li>\u91ca\u653e V4L2 \u7f13\u51b2\u548c\u8bbe\u5907\uff1b</li> <li>\u82e5\u542f\u7528\u4e86 RK AIQ\uff1a\u8c03\u7528 stop/deinit \u63a5\u53e3\uff0cdlclose(handle_rkaiq)\uff1b</li> <li>\u82e5\u52a0\u8f7d\u4e86 RGA/MPP\uff1a\u5bf9\u5e94\u91ca\u653e\u548c dlclose\uff1b</li> <li>\u6e05\u7406\u5185\u90e8\u72b6\u6001\uff0c\u51c6\u5907\u4e0b\u6b21\u91cd\u542f\u6216\u8fdb\u7a0b\u9000\u51fa\uff1b</li> </ul> </li> <li> <p>\u9519\u8bef\u5904\u7406\u4e0e\u56de\u9000</p> <ul> <li>\u5728\u4efb\u610f\u9636\u6bb5\u82e5\u68c0\u6d4b\u5230\u5173\u952e\u8c03\u7528\u5931\u8d25\uff08\u5982 AIQ \u51c6\u5907\u5931\u8d25\u6216 RGA \u8f6c\u6362\u5931\u8d25\uff09\uff0c\u7cfb\u7edf\u9000\u51fa\uff1b</li> <li>\u8bb0\u5f55\u65e5\u5fd7\uff0c\u4fbf\u4e8e\u5206\u6790\u786c\u4ef6\u8def\u5f84\u4e3a\u4f55\u4e0d\u53ef\u7528\uff1b</li> </ul> </li> </ol> <p>\u4e0b\u9762\u8fd9\u5f20\u56fe\u7247\u662f\u6574\u4e2a\u539f\u4f5c\u8005nihui\u8bbe\u8ba1\u7684\u7a0b\u5e8f\u6846\u56fe</p> <p></p>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#_4","title":"\u4e94\u3001\u5b9e\u8df5\u8981\u70b9\u4e0e\u6ce8\u610f\u4e8b\u9879","text":"<p>\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u91c7\u7528\u52a8\u6001\u52a0\u8f7d\u65b9\u5f0f\u65f6\uff0c\u9700\u8981\u6ce8\u610f\u4ee5\u4e0b\u51e0\u70b9\uff1a</p> <ol> <li> <p>\u63a5\u53e3\u58f0\u660e\u4e0e\u5934\u6587\u4ef6\u7ba1\u7406</p> <ul> <li>\u5e94\u63d0\u524d\u83b7\u53d6\u786c\u4ef6 SDK \u63d0\u4f9b\u7684\u5934\u6587\u4ef6\uff08\u58f0\u660e\u51fd\u6570\u540d\u3001\u6570\u636e\u7ed3\u6784\u3001\u679a\u4e3e\u7b49\uff09\uff0c\u4fbf\u4e8e\u5728\u5e94\u7528\u4e2d\u6b63\u786e\u8c03\u7528\u548c\u7f16\u8bd1\uff1b</li> <li>\u53ef\u5c06\u5934\u6587\u4ef6\u7eb3\u5165\u5e94\u7528\u6e90\u7801\u6216\u4ee5\u5355\u72ec\u5305\u5f62\u5f0f\u7ba1\u7406\uff0c\u4f46\u4e0d\u9700\u8981\u94fe\u63a5\u5e93\uff1b</li> <li>\u5fc5\u987b\u786e\u4fdd\u7b26\u53f7\u540d\u79f0\u4e0e\u8fd0\u884c\u65f6\u5e93\u4e00\u81f4\uff08C++ \u4e0b\u6ce8\u610f extern \"C\" \u6216\u547d\u540d\u7a7a\u95f4\u95ee\u9898\uff09\uff1b</li> </ul> </li> <li> <p>\u8def\u5f84\u7ba1\u7406</p> <ul> <li>\u5728 dlopen \u65f6\u8981\u8003\u8651\u5e93\u6587\u4ef6\u5728\u76ee\u6807\u7cfb\u7edf\u7684\u5b9e\u9645\u8def\u5f84\uff0c\u6bd4\u5982 <code>/usr/lib/</code>\u3001<code>/vendor/lib/</code>\u3001\u6216\u81ea\u5b9a\u4e49\u8def\u5f84\uff1b</li> <li>\u53ef\u901a\u8fc7\u73af\u5883\u53d8\u91cf\u6216\u914d\u7f6e\u6587\u4ef6\u5728\u8fd0\u884c\u65f6\u6307\u5b9a\u5e93\u8def\u5f84\uff0c\u6216\u4f7f\u7528 <code>dlopen</code> \u65f6\u5b8c\u6574\u8def\u5f84\uff1b</li> <li>\u5982\u679c\u53ef\u80fd\u5b58\u5728\u591a\u7248\u672c\u5e93\uff0c\u53ef\u5728\u52a0\u8f7d\u524d\u68c0\u6d4b\u7248\u672c\u53f7\u6216\u4f7f\u7528\u7248\u672c\u5316\u7b26\u53f7\u540d\uff1b</li> </ul> </li> <li> <p>\u7b26\u53f7\u83b7\u53d6\u4e0e\u517c\u5bb9\u6027</p> <ul> <li>\u5bf9\u4e8e\u65b0\u589e\u63a5\u53e3\u6216\u7248\u672c\u53d8\u66f4\uff0c\u8981\u5224\u65ad\u5173\u952e\u7b26\u53f7\u662f\u5426\u5b58\u5728\uff0c\u82e5\u4e0d\u5b58\u5728\u5219\u56de\u9000\uff1b</li> <li>\u5728 dlsym \u83b7\u53d6\u51fd\u6570\u6307\u9488\u540e\uff0c\u5efa\u8bae\u68c0\u67e5\u6307\u9488\u6709\u6548\u6027\uff1b</li> <li>\u82e5\u67d0\u4e9b\u65b0\u529f\u80fd\u63a5\u53e3\u975e\u5f3a\u4f9d\u8d56\uff0c\u53ef\u5728\u8fd0\u884c\u65f6\u5224\u65ad\u662f\u5426\u53ef\u7528\uff0c\u5e76\u52a8\u6001\u9009\u62e9\u662f\u5426\u542f\u7528\u7279\u6027\uff1b</li> </ul> </li> <li> <p>\u9519\u8bef\u5904\u7406\u4e0e\u65e5\u5fd7\u8bb0\u5f55</p> <ul> <li>dlopen/dlsym \u53ef\u80fd\u5931\u8d25\uff0c\u9700\u901a\u8fc7 <code>dlerror()</code> \u83b7\u53d6\u8be6\u7ec6\u9519\u8bef\u4fe1\u606f\uff0c\u4fbf\u4e8e\u8bca\u65ad\uff1b</li> <li>\u5728\u56de\u9000\u5230\u8f6f\u4ef6\u8def\u5f84\u65f6\uff0c\u8bb0\u5f55\u65e5\u5fd7\u4ee5\u4fbf\u5206\u6790\u4e3a\u4f55\u786c\u4ef6\u52a0\u901f\u4e0d\u53ef\u7528\uff1b</li> <li>\u53ef\u5728\u542f\u52a8\u65f6\u6253\u5370\u786c\u4ef6\u68c0\u6d4b\u3001\u52a0\u8f7d\u8fc7\u7a0b\u6458\u8981\uff0c\u4fbf\u4e8e\u8fdc\u7a0b\u8c03\u8bd5\uff1b</li> </ul> </li> <li> <p>\u6027\u80fd\u4e0e\u8d44\u6e90\u7ba1\u7406</p> <ul> <li>\u867d\u7136\u52a8\u6001\u52a0\u8f7d\u672c\u8eab\u5f00\u9500\u8f83\u5c0f\uff08\u901a\u5e38\u53ea\u5728\u542f\u52a8\u6216\u9996\u6b21\u4f7f\u7528\u65f6\u52a0\u8f7d\uff09\uff0c\u4f46\u8981\u907f\u514d\u9891\u7e41 dlopen/dlclose\uff1b</li> <li>\u5bf9\u4e8e\u957f\u65f6\u95f4\u8fd0\u884c\u7684\u5e94\u7528\uff0c\u5e94\u4fdd\u6301\u5e93\u53e5\u67c4\u6253\u5f00\u76f4\u5230\u4e0d\u518d\u9700\u8981\uff1b</li> <li>\u91ca\u653e\u8d44\u6e90\u65f6\u987b\u6309\u6b63\u786e\u987a\u5e8f\u8c03\u7528\u53cd\u521d\u59cb\u5316\u63a5\u53e3\u5e76 dlclose\uff0c\u4ee5\u907f\u514d\u5185\u5b58\u6cc4\u6f0f\u6216\u8d44\u6e90\u672a\u91ca\u653e\uff1b</li> </ul> </li> <li> <p>\u5b89\u5168\u4e0e\u6743\u9650</p> <ul> <li>\u786e\u4fdd\u76ee\u6807\u7cfb\u7edf\u4e0a\u786c\u4ef6\u5e93\u53ef\u9760\u3001\u53ef\u4fe1\uff1b\u907f\u514d\u52a0\u8f7d\u4e0d\u53d7\u4fe1\u4efb\u7684\u5e93\uff1b</li> <li>\u5728\u67d0\u4e9b\u7cfb\u7edf\u4e0a\uff0c\u53ef\u80fd\u9700\u8981\u8c03\u6574 SELinux \u6216\u6743\u9650\u8bbe\u7f6e\uff0c\u5141\u8bb8\u5e94\u7528\u8bbf\u95ee\u5e93\u6587\u4ef6\u53ca\u5e95\u5c42\u8bbe\u5907\u8282\u70b9\uff1b</li> <li>\u82e5\u5e94\u7528\u4ee5\u975e root \u8eab\u4efd\u8fd0\u884c\uff0c\u9700\u4fdd\u8bc1\u5177\u5907\u8bbf\u95ee\u6444\u50cf\u5934\u8bbe\u5907\u8282\u70b9\u548c\u786c\u4ef6\u5e93\u6240\u9700\u6743\u9650\uff1b</li> </ul> </li> <li> <p>\u6d4b\u8bd5\u4e0e\u56de\u5f52</p> <ul> <li>\u5728\u591a\u79cd\u76ee\u6807\u7cfb\u7edf\u7248\u672c\u3001\u591a\u79cd\u786c\u4ef6\u578b\u53f7\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u786e\u4fdd\u52a8\u6001\u52a0\u8f7d\u903b\u8f91\u5065\u58ee\uff1b</li> <li>\u5728\u786c\u4ef6\u5e93\u5347\u7ea7\u540e\uff0c\u8981\u9a8c\u8bc1\u7b26\u53f7\u517c\u5bb9\u6027\uff1b\u5982\u679c\u91cd\u5927\u7248\u672c\u5347\u7ea7\u5bfc\u81f4\u4e0d\u517c\u5bb9\uff0c\u5e94\u66f4\u65b0\u5e94\u7528\u4e2d\u5bf9\u5e94\u7684\u5934\u6587\u4ef6\u6216\u52a0\u8f7d\u903b\u8f91\uff1b</li> <li>\u63d0\u4f9b\u914d\u7f6e\u9009\u9879\u4ee5\u5f3a\u5236\u7981\u7528\u786c\u4ef6\u52a0\u901f\uff0c\u4fbf\u4e8e\u5728\u95ee\u9898\u6392\u67e5\u65f6\u5feb\u901f\u5b9a\u4f4d\uff1b</li> </ul> </li> <li> <p>\u4ea4\u53c9\u7f16\u8bd1\u914d\u7f6e\u7b80\u5316</p> <ul> <li>\u5728 Buildroot \u6216 CMake \u4e2d\uff0c\u4ec5\u7f16\u8bd1\u5e94\u7528\u81ea\u8eab\u4ee3\u7801\u548c\u901a\u7528\u5e93\uff0c\u65e0\u9700\u5c06\u786c\u4ef6 SDK \u7eb3\u5165\u4ea4\u53c9\u7f16\u8bd1\uff1b</li> <li> <p>\u5728 CMake \u811a\u672c\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0b\u9762\u8fd9\u53e5\u8bdd\u6765\u5b9e\u73b0\u591a\u7cfb\u7edf\u517c\u5bb9</p> <p><pre><code># \u94fe\u63a5 dlopen \u6240\u5728\u7684\u5e93\uff08\u5728 Linux \u4e0a\u4f1a\u81ea\u52a8\u53d8\u6210 -ldl\uff1b\u5728 macOS/Windows \u4e0a\u4ec0\u4e48\u4e5f\u4e0d\u52a0\uff09\ntarget_link_libraries(my_app PRIVATE ${CMAKE_DL_LIBS})\n</code></pre>     - \u53ef\u5728\u751f\u6210\u7684 Makefile \u6216\u811a\u672c\u4e2d\u9884\u7559\u8fd0\u884c\u65f6\u73af\u5883\u53d8\u91cf\uff0c\u4ee5\u6307\u5411\u52a8\u6001\u5e93\u8def\u5f84\uff1b</p> </li> </ul> </li> </ol>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#_5","title":"\u516d\u3001\u53c2\u8003\u5c01\u88c5\u5b9e\u8df5","text":"<p>\u82e5\u9700\u5728\u81ea\u8eab\u5d4c\u5165\u5f0f\u9879\u76ee\u4e2d\u501f\u9274\u8be5\u8bbe\u8ba1\uff0c\u53ef\u6309\u4ee5\u4e0b\u6b65\u9aa4\u8fdb\u884c\uff1a</p> <ol> <li>\u83b7\u53d6\u786c\u4ef6 SDK \u5934\u6587\u4ef6\uff1a\u4ece Rockchip \u7b49\u5382\u5546\u83b7\u5f97\u5bf9\u5e94\u5934\u6587\u4ef6\uff0c\u4e86\u89e3\u5173\u952e API\uff0c\u6216\u8bfb\u53d6\u7cfb\u7edf\u5df2\u5b89\u88c5\u5e93\u7684\u5934\u6587\u4ef6\uff1b</li> <li>\u5728\u9879\u76ee\u4e2d\u7f16\u5199\u52a8\u6001\u52a0\u8f7d\u6a21\u5757\uff1a\u53c2\u8003 capture_v4l2_rk_aiq.cpp \u7684\u52a0\u8f7d\u903b\u8f91\uff0c\u5efa\u7acb\u4e00\u5c42 wrapper\uff0c\u5c01\u88c5 dlopen/dlsym \u53ca\u51fd\u6570\u6307\u9488\u7ba1\u7406\uff1b\u53ef\u5c06\u52a0\u8f7d\u903b\u8f91\u5c01\u88c5\u4e3a\u5355\u72ec\u7ec4\u4ef6\uff0c\u4f8b\u5982 <code>HardwareAccelLoader</code>\uff1b</li> <li>\u7f16\u8bd1\u671f\u4ec5\u4f9d\u8d56\u5934\u6587\u4ef6\uff1a\u5728 CMakeLists.txt \u6216 Makefile \u4e2d\uff0c\u4e0d\u94fe\u63a5\u786c\u4ef6\u5e93\uff0c\u4ec5\u5305\u542b\u5934\u6587\u4ef6\u8def\u5f84\uff1b</li> <li>\u8fd0\u884c\u671f\u90e8\u7f72\uff1a\u786e\u4fdd\u76ee\u6807\u7cfb\u7edf\u5b89\u88c5\u4e86\u5bf9\u5e94\u52a8\u6001\u5e93\u6587\u4ef6\uff08librkaiq.so\u3001librga.so\u3001librockchip_mpp.so \u7b49\uff09\uff0c\u6216\u8005\u901a\u8fc7\u7cfb\u7edf\u5347\u7ea7\u5305\u3001SDK \u5b89\u88c5\u811a\u672c\u7b49\u65b9\u5f0f\u653e\u7f6e\u5230\u5408\u9002\u7684\u8def\u5f84\uff1b</li> <li>\u65e5\u5fd7\u4e0e\u914d\u7f6e\uff1a\u63d0\u4f9b\u8fd0\u884c\u65f6\u914d\u7f6e\u9009\u9879\uff0c\u53ef\u624b\u52a8\u6307\u5b9a\u5e93\u8def\u5f84\u6216\u5f3a\u5236\u7981\u7528\u786c\u4ef6\u52a0\u901f\uff1b\u5728\u65e5\u5fd7\u4e2d\u6253\u5370\u52a0\u8f7d\u7ed3\u679c\uff1b</li> <li>\u6d4b\u8bd5\u591a\u573a\u666f\uff1a\u5728\u6709\u786c\u4ef6\u52a0\u901f\u4e14\u7248\u672c\u6b63\u786e\u7684\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\uff0c\u4f7f\u5176\u8fdb\u5165\u786c\u4ef6\u8def\u5f84\uff1b\u5728\u7f3a\u5c11\u786c\u4ef6\u5e93\u6216\u7248\u672c\u4e0d\u5339\u914d\u7684\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u56de\u9000\u5230\u8f6f\u4ef6\u8def\u5f84\u6b63\u5e38\uff1b</li> <li>\u66f4\u65b0\u7ef4\u62a4\uff1a\u82e5\u786c\u4ef6 SDK \u5347\u7ea7\uff0c\u9700\u6bd4\u5bf9\u7b26\u53f7\u53d8\u5316\uff0c\u66f4\u65b0\u51fd\u6570\u6307\u9488\u5217\u8868\uff1b\u5982\u679c\u65b0\u589e\u7279\u6027\uff0c\u52a8\u6001\u52a0\u8f7d\u65f6\u5148\u68c0\u6d4b\u65b0\u7b26\u53f7\u518d\u51b3\u5b9a\u662f\u5426\u542f\u7528\uff1b</li> </ol> <p>\u4e0b\u9762\u4e3e\u4e2a\u4f8b\u5b50\uff0c\u6bd4\u5982\u9700\u8981rv1126\u4e2d\u4e00\u4e9brkmidia\u76f8\u5173\u51fd\u6570</p> <ol> <li> <p>\u9996\u5148\u6211\u4eec\u9700\u8981\u5f15\u5165\u5934\u6587\u4ef6</p> <pre><code>#include \"rkmedia_common.h\"\n#include \"rkmedia_vi.h\"\n#include \"rkmedia_api.h\"\n</code></pre> </li> <li> <p>\u5b9a\u4e49handle\u6307\u9488</p> <pre><code>static void *librk_mpi = nullptr;\n</code></pre> </li> <li> <p>\u4f7f\u7528C++11\u7279\u6027\u5b9a\u4e49\u51fd\u6570\u6307\u9488</p> <pre><code>#define FUNC_PTR(func_name) decltype(&amp;func_name)\n\n\n// \u4ee5\u4e0b\u51fd\u6570\u6307\u9488\u5747\u4ece libeasymedia.so \u4e2d dlsym \u83b7\u53d6\nstatic FUNC_PTR(RK_MPI_SYS_Init)               PF_RK_MPI_SYS_Init            = nullptr;\nstatic FUNC_PTR(RK_MPI_VI_SetChnAttr)          PFN_RK_MPI_VI_SetChnAttr      = nullptr;\nstatic FUNC_PTR(RK_MPI_VI_EnableChn)           PFN_RK_MPI_VI_EnableChn       = nullptr;\nstatic FUNC_PTR(RK_MPI_SYS_GetMediaBuffer)     PF_RK_MPI_SYS_GetMediaBuffer  = nullptr;  // \u8fd4\u56de MEDIA_BUFFER\nstatic FUNC_PTR(RK_MPI_MB_Handle2VirAddr)      PF_RK_MPI_MB_Handle2VirAddr   = nullptr;  // \u4ece MEDIA_BUFFER \u83b7\u5f97\u865a\u62df\u5730\u5740\nstatic FUNC_PTR(RK_MPI_SYS_SendMediaBuffer)    PF_RK_MPI_SYS_SendMediaBuffer = nullptr;  // \u628a MEDIA_BUFFER \u9001\u7ed9 VO\nstatic FUNC_PTR(RK_MPI_VI_DisableChn)          PFN_RK_MPI_VI_DisableChn      = nullptr;\nstatic FUNC_PTR(RK_MPI_SYS_UnBind)             PFN_RK_MPI_SYS_UnBind         = nullptr;\nstatic FUNC_PTR(RK_MPI_RGA_DestroyChn)         PFN_RK_MPI_RGA_DestroyChn     = nullptr;\nstatic FUNC_PTR(RK_MPI_RGA_CreateChn)          PFN_RK_MPI_RGA_CreateChn      = nullptr;\nstatic FUNC_PTR(RK_MPI_VO_CreateChn)           PFN_RK_MPI_VO_CreateChn       = nullptr;\nstatic FUNC_PTR(RK_MPI_VO_DestroyChn)          PF_RK_MPI_VO_DestroyChn       = nullptr;\nstatic FUNC_PTR(RK_MPI_VI_RGN_SetCover)        PFN_RK_MPI_VI_RGN_SetCover    = nullptr;\nstatic FUNC_PTR(RK_MPI_SYS_Bind)               PFN_RK_MPI_SYS_Bind           = nullptr;\nstatic FUNC_PTR(RK_MPI_MB_ReleaseBuffer)       PFN_RK_MPI_MB_ReleaseBuffer   = nullptr;\nstatic FUNC_PTR(RK_MPI_MB_GetPtr)              PFN_RK_MPI_MB_GetPtr          = nullptr;\nstatic FUNC_PTR(RK_MPI_MB_GetSize)             PFN_RK_MPI_MB_GetSize         = nullptr;\nstatic FUNC_PTR(RK_MPI_MB_CreateBuffer)        PFN_RK_MPI_MB_CreateBuffer    = nullptr;\nstatic FUNC_PTR(RK_MPI_MB_SetSize)             PFN_RK_MPI_MB_SetSize         = nullptr;\nstatic FUNC_PTR(RK_MPI_MB_CreateImageBuffer)   PFN_RK_MPI_MB_CreateImageBuffer = nullptr;\n</code></pre> </li> <li> <p>\u52a8\u6001\u52a0\u8f7d\u5e93\u51fd\u6570</p> <pre><code>static int load_rk_mpi_library()\n{\n    if (librk_mpi) return 0;\n    librk_mpi = dlopen(\"libeasymedia.so\", RTLD_GLOBAL | RTLD_LAZY);\n    if (!librk_mpi) {\n        librk_mpi = dlopen(\"/oem/usr/lib/libeasymedia.so\", RTLD_GLOBAL | RTLD_LAZY);\n    }\n    if (!librk_mpi) {\n        fprintf(stderr, \"Error: cannot load libeasymedia.so\\n\");\n        return -1;\n    }\n\n    PF_RK_MPI_SYS_Init            = (decltype(PF_RK_MPI_SYS_Init))          dlsym(librk_mpi, \"RK_MPI_SYS_Init\");\n    PFN_RK_MPI_VI_SetChnAttr      = (decltype(PFN_RK_MPI_VI_SetChnAttr))    dlsym(librk_mpi, \"RK_MPI_VI_SetChnAttr\");\n    PFN_RK_MPI_VI_EnableChn       = (decltype(PFN_RK_MPI_VI_EnableChn))     dlsym(librk_mpi, \"RK_MPI_VI_EnableChn\");\n    PF_RK_MPI_SYS_GetMediaBuffer  = (decltype(PF_RK_MPI_SYS_GetMediaBuffer))dlsym(librk_mpi, \"RK_MPI_SYS_GetMediaBuffer\");\n    PF_RK_MPI_MB_Handle2VirAddr   = (decltype(PF_RK_MPI_MB_Handle2VirAddr)) dlsym(librk_mpi, \"RK_MPI_MB_Handle2VirAddr\");\n    PF_RK_MPI_SYS_SendMediaBuffer = (decltype(PF_RK_MPI_SYS_SendMediaBuffer))dlsym(librk_mpi, \"RK_MPI_SYS_SendMediaBuffer\");\n    PFN_RK_MPI_VI_DisableChn      = (decltype(PFN_RK_MPI_VI_DisableChn))    dlsym(librk_mpi, \"RK_MPI_VI_DisableChn\");\n    PFN_RK_MPI_SYS_UnBind         = (decltype(PFN_RK_MPI_SYS_UnBind))       dlsym(librk_mpi, \"RK_MPI_SYS_UnBind\");\n    PFN_RK_MPI_RGA_DestroyChn      = (decltype(PFN_RK_MPI_RGA_DestroyChn))    dlsym(librk_mpi, \"RK_MPI_RGA_DestroyChn\");\n    PFN_RK_MPI_RGA_CreateChn      = (decltype(PFN_RK_MPI_RGA_CreateChn))    dlsym(librk_mpi, \"RK_MPI_RGA_CreateChn\");\n    PFN_RK_MPI_VO_CreateChn       = (decltype(PFN_RK_MPI_VO_CreateChn))     dlsym(librk_mpi, \"RK_MPI_VO_CreateChn\");\n    PF_RK_MPI_VO_DestroyChn       = (decltype(PF_RK_MPI_VO_DestroyChn))     dlsym(librk_mpi, \"RK_MPI_VO_DestroyChn\");\n    PFN_RK_MPI_VI_RGN_SetCover    = (decltype(PFN_RK_MPI_VI_RGN_SetCover))     dlsym(librk_mpi, \"RK_MPI_VI_RGN_SetCover\");\n    PFN_RK_MPI_SYS_Bind           = (decltype(PFN_RK_MPI_SYS_Bind))     dlsym(librk_mpi, \"RK_MPI_SYS_Bind\");\n    PFN_RK_MPI_MB_ReleaseBuffer   = (decltype(PFN_RK_MPI_MB_ReleaseBuffer))     dlsym(librk_mpi, \"RK_MPI_MB_ReleaseBuffer\");\n    PFN_RK_MPI_MB_GetPtr          = (decltype(PFN_RK_MPI_MB_GetPtr))dlsym(librk_mpi, \"RK_MPI_MB_GetPtr\");\n    PFN_RK_MPI_MB_GetSize         = (decltype(PFN_RK_MPI_MB_GetSize))dlsym(librk_mpi, \"RK_MPI_MB_GetSize\");\n    PFN_RK_MPI_MB_CreateBuffer    = (decltype(PFN_RK_MPI_MB_CreateBuffer))dlsym(librk_mpi, \"RK_MPI_MB_CreateBuffer\");\n    PFN_RK_MPI_MB_SetSize         = (decltype(PFN_RK_MPI_MB_SetSize))dlsym(librk_mpi, \"RK_MPI_MB_SetSize\");\n    PFN_RK_MPI_MB_CreateImageBuffer = (decltype(PFN_RK_MPI_MB_CreateImageBuffer))dlsym(librk_mpi, \"RK_MPI_MB_CreateImageBuffer\");\n\n    // \u68c0\u67e5\u6240\u6709\u5fc5\u9700\u7b26\u53f7\u662f\u5426\u52a0\u8f7d\u6210\u529f\n    if (!PF_RK_MPI_SYS_Init ||\n        !PFN_RK_MPI_VI_SetChnAttr ||\n        !PFN_RK_MPI_VI_EnableChn ||\n        !PF_RK_MPI_SYS_GetMediaBuffer ||\n        !PF_RK_MPI_MB_Handle2VirAddr ||\n        !PF_RK_MPI_SYS_SendMediaBuffer ||\n        !PFN_RK_MPI_VI_DisableChn ||\n        !PFN_RK_MPI_SYS_UnBind ||\n        !PFN_RK_MPI_RGA_DestroyChn ||\n        !PFN_RK_MPI_RGA_CreateChn ||\n        !PFN_RK_MPI_VO_CreateChn ||\n        !PFN_RK_MPI_VI_RGN_SetCover ||\n        !PFN_RK_MPI_SYS_Bind ||\n        !PFN_RK_MPI_MB_ReleaseBuffer ||\n        !PF_RK_MPI_VO_DestroyChn) {\n        fprintf(stderr, \"Error: failed to load one or more RK_MPI symbols\\n\");\n        return -1;\n    }\n\n    return 0;\n}\n\nstatic int unload_rk_mpi_library()\n{\n    if (!librk_mpi) return 0;\n    dlclose(librk_mpi);\n    librk_mpi = nullptr;\n    PF_RK_MPI_SYS_Init            = nullptr;\n    PFN_RK_MPI_VI_SetChnAttr      = nullptr;\n    PFN_RK_MPI_VI_EnableChn       = nullptr;\n    PF_RK_MPI_SYS_GetMediaBuffer  = nullptr;\n    PF_RK_MPI_MB_Handle2VirAddr   = nullptr;\n    PF_RK_MPI_SYS_SendMediaBuffer = nullptr;\n    PFN_RK_MPI_VI_DisableChn      = nullptr;\n    PFN_RK_MPI_SYS_UnBind         = nullptr;\n    PFN_RK_MPI_RGA_DestroyChn     = nullptr;\n    PFN_RK_MPI_RGA_CreateChn      = nullptr;\n    PFN_RK_MPI_VO_CreateChn       = nullptr;\n    PF_RK_MPI_VO_DestroyChn       = nullptr;\n    return 0;\n}\n</code></pre> </li> <li> <p>\u5b9a\u4e49RAAI\u7c7b\u5e76\u521d\u59cb\u5316</p> <pre><code>class rk_mpi_library_loader {\npublic:\n    bool ready;\n    rk_mpi_library_loader()  { ready = (load_rk_mpi_library() == 0); }\n    ~rk_mpi_library_loader() { if (ready) unload_rk_mpi_library(); }\n} mpi;\n</code></pre> </li> </ol> <p>\u901a\u8fc7RAII\uff08Resource Acquisition Is Initialization\uff09\u65b9\u5f0f\uff0c\u5373rk_mpi_library_loader\u5b9e\u4f8b\u5316\u7684\u5bf9\u8c61\u6765\u7ba1\u7406\u5e93\u7684\u52a0\u8f7d\u4e0e\u91ca\u653e\u3002</p>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#_6","title":"\u4e03\u3001\u603b\u7ed3","text":"<p>\u901a\u8fc7\u52a8\u6001\u5e93\u52a8\u6001\u52a0\u8f7d\u65b9\u5f0f\uff0c\u53ef\u5927\u5927\u51cf\u5c11\u5d4c\u5165\u5f0f\u9879\u76ee\u5bf9 Buildroot \u5168\u5c40\u4ea4\u53c9\u7f16\u8bd1\u5e93\u7684\u4f9d\u8d56\uff0c\u5c06\u786c\u4ef6\u52a0\u901f\u5e93\u7684\u7ba1\u7406\u4ece\u7f16\u8bd1\u671f\u8f6c\u79fb\u5230\u8fd0\u884c\u671f\uff1a</p> <ul> <li>\u7f16\u8bd1\u66f4\u8f7b\u91cf\uff1a\u53ea\u9700\u7f16\u8bd1\u81ea\u8eab\u4ee3\u7801\uff0cBuildroot \u914d\u7f6e\u66f4\u7b80\u6d01\uff1b</li> <li>\u90e8\u7f72\u66f4\u7075\u6d3b\uff1a\u53ef\u5728\u4e0d\u540c\u7cfb\u7edf\u4e0a\u90e8\u7f72\u540c\u4e00\u4e8c\u8fdb\u5236\uff0c\u53ea\u8981\u8fd0\u884c\u65f6\u63d0\u4f9b\u6216\u4e0d\u63d0\u4f9b\u786c\u4ef6\u5e93\uff0c\u5373\u53ef\u81ea\u52a8\u542f\u7528\u6216\u7981\u7528\u786c\u4ef6\u52a0\u901f\uff1b</li> <li>\u7ef4\u62a4\u6210\u672c\u964d\u4f4e\uff1a\u786c\u4ef6 SDK \u66f4\u65b0\u65f6\u65e0\u9700\u91cd\u65b0\u7f16\u8bd1\u5e94\u7528\uff0c\u4ec5\u9700\u66f4\u65b0\u76ee\u6807\u7cfb\u7edf\u7684\u5e93\uff1b</li> <li>\u66f4\u597d\u5730\u9002\u5e94\u5d4c\u5165\u5f0f\u573a\u666f\u591a\u53d8\u7684\u7cfb\u7edf\u73af\u5883\uff1a\u4e0d\u540c\u8bbe\u5907\u3001\u4e0d\u540c\u7cfb\u7edf\u7248\u672c\u53ef\u80fd\u5b58\u5728\u4e0d\u540c\u5e93\u7248\u672c\u3001\u4e0d\u540c\u8def\u5f84\uff0c\u52a8\u6001\u52a0\u8f7d\u8bbe\u8ba1\u5177\u5907\u66f4\u5f3a\u517c\u5bb9\u6027\u548c\u53ef\u79fb\u690d\u6027\uff1b</li> <li>\u4f18\u96c5\u56de\u9000\uff1a\u5728\u786c\u4ef6\u52a0\u901f\u4e0d\u53ef\u7528\u65f6\u81ea\u52a8\u56de\u843d\u5230\u8f6f\u4ef6\u5b9e\u73b0\uff0c\u4fdd\u8bc1\u529f\u80fd\u53ef\u7528\u6027\u3002</li> </ul> <p>\u5728\u5177\u4f53\u9879\u76ee\u4e2d\uff0c\u53ef\u53c2\u8003\u4e0a\u8ff0\u8bbe\u8ba1\u601d\u8def\u548c\u5b9e\u8df5\u8981\u70b9\uff0c\u81ea\u884c\u7f16\u5199\u52a8\u6001\u52a0\u8f7d wrapper \u5c42\uff0c\u914d\u5408\u901a\u7528\u7684\u8f6f\u4ef6\u5b9e\u73b0\u8def\u5f84\uff0c\u4ece\u800c\u6446\u8131 Buildroot \u5bf9\u95ed\u6e90\u786c\u4ef6\u5e93\u7684\u9759\u6001\u4f9d\u8d56\uff0c\u63d0\u5347\u5f00\u53d1\u6548\u7387\u4e0e\u7cfb\u7edf\u517c\u5bb9\u80fd\u529b\u3002</p>"},{"location":"python%26C%2B%2B/%E5%B5%8C%E5%85%A5%E5%BC%8Fso%E5%BC%80%E5%8F%91/#_7","title":"\u53c2\u8003\u94fe\u63a5","text":"<ul> <li>https://github.com/nihui/opencv-mobile/blob/v33/highgui/src/capture_v4l2_rk_aiq.cpp</li> <li>https://deepwiki.com/nihui/opencv-mobile/4.3-rockchip-hardware-acceleration</li> </ul>"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/","title":"\u56fe\u6587\u591a\u6a21\u6001\u6570\u636e\u96c6\u5f52\u7eb3\uff08\u4e00\uff09","text":"<p>\u672c\u6587\u5199\u4e8e2025\u5e747\u670824\u53f7 \u665a11\u70b9</p>"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#_2","title":"\u524d\u8a00","text":"<p>\u5728\u5f53\u4eca\u4eba\u5de5\u667a\u80fd\u5feb\u901f\u53d1\u5c55\u7684\u65f6\u4ee3\uff0c\u56fe\u6587\u591a\u6a21\u6001\u6280\u672f\u6b63\u65e5\u76ca\u6210\u4e3a\u8fde\u63a5\u89c6\u89c9\u4e0e\u8bed\u8a00\u7684\u91cd\u8981\u6865\u6881\u3002</p> <p>\u4e3a\u4e86\u5e2e\u52a9\u7814\u7a76\u8005\u7cfb\u7edf\u68b3\u7406\u73b0\u6709\u6570\u636e\u8d44\u6e90\uff0c\u672c\u5f52\u7eb3\u4ece\u5341\u4e8c\u5927\u5e94\u7528\u573a\u666f\u5165\u624b\uff1a\u4ece\u57fa\u7840\u7684\u56fe\u50cf\u63cf\u8ff0\uff08Caption\uff09\u3001\u901a\u7528\u95ee\u7b54\uff08General\u202fQA\uff09\u3001\u6570\u5b66\u9898\u63a8\u7406\uff08Mathematics\uff09\uff0c\u5230\u4e13\u6ce8\u6587\u5b57\u8bc6\u522b\u7684 OCR\uff0c\u4ee5\u53ca\u6db5\u76d6\u77e5\u8bc6\u63a8\u7406\u3001\u89c6\u89c9\u5b9a\u4f4d\uff08Grounding\uff09\u3001\u6587\u6863\u89e3\u6790\u3001\u79d1\u5b66\u95ee\u7b54\u3001\u5bf9\u8bdd\u7cfb\u7edf\u3001\u533b\u7597\u5f71\u50cf\u3001\u754c\u9762\u4ea4\u4e92\uff08GUI\uff09\u4e0e\u8bc4\u4f30\u65b9\u6cd5\u7b49\u65b9\u5411\u3002\u6bcf\u4e00\u7ae0\u8282\u5747\u6c47\u96c6\u4ee3\u8868\u6027\u6570\u636e\u96c6\uff0c\u6df1\u5165\u5256\u6790\u5176\u7279\u70b9\u4e0e\u9002\u7528\u573a\u666f\uff0c\u52a9\u529b\u5927\u5bb6\u5feb\u901f\u5b9a\u4f4d\u6240\u9700\u8d44\u6e90\u3001\u5bf9\u6bd4\u65b9\u6cd5\u4f18\u52a3\uff0c\u5e76\u4e3a\u540e\u7eed\u7684\u6a21\u578b\u8bbe\u8ba1\u4e0e\u521b\u65b0\u63d0\u4f9b\u575a\u5b9e\u7684\u57fa\u77f3\u3002</p> <p>\u4e4b\u6240\u4ee5\u5199\u4e00\u662f\u56e0\u4e3a\u540e\u9762\u8fd8\u4f1a\u6709\uff0c\u672c\u6587\u4e2d\u7684\u6570\u636e\u96c6\u4ec5\u5173\u6ce8\u4e8e\u5355\u56feQA\uff0c\u540e\u7eed\u4f1a\u589e\u52a0\u591a\u56fe\u548c\u89c6\u9891\u7684\u603b\u7ed3\u653e\u5230\u4e8c\u4e09\u3002</p> <p>\u672c\u6587\u8d44\u6599\u4f1a\u4e00\u76f4\u66f4\u65b0\uff0c\u6b22\u8fce\u6279\u8bc4\u6307\u6b63</p>"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#1-caption","title":"1. Caption","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u662f\u5426\u5305\u542b Caption \u6570\u636e \u662f\u5426\u5305\u542b\u591a\u6a21\u6001 QA Instructtion \u6570\u636e \u8bad\u7ec3\u8fd8\u662f\u8bc4\u4f30 TextCaps \u4f7f\u7528\u5305\u542b\u6587\u5b57\u5185\u5bb9\u7684\u56fe\u50cf\u8fdb\u884c\u56fe\u50cf\u63cf\u8ff0\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u5f20\u56fe\u50cf\u6709 5 \u4e2a\u63cf\u8ff0\uff0c\u65e8\u5728\u63d0\u9ad8\u6a21\u578b\u5bf9\u56fe\u50cf\u4e2d\u6587\u5b57\u7684\u7406\u89e3\u548c\u63cf\u8ff0\u80fd\u529b \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2020 \u82f1\u6587 28408 \u5f20\u56fe\u50cf\uff0c142040 \u6761\u63cf\u8ff0 Facebook AI Research \u56e2\u961f \u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u56fe\u50cf\u63cf\u8ff0\u548c\u9605\u8bfb\u7406\u89e3\u80fd\u529b Hugging Face \u662f \u5426 \u8bad\u7ec3/\u8bc4\u4f30 ShareGPT4o \u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b20\u4e07\u5f20\u56fe\u50cf\u30011\u4e07\u6bb5\u89c6\u9891\u548c1\u4e07\u4efd\u97f3\u9891\u7684\u8be6\u7ec6\u63cf\u8ff0\uff0c\u5229\u7528GPT-4o\u7684\u591a\u6a21\u6001\u80fd\u529b\u751f\u6210\u6ce8\u91ca\u3002 \u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u591a\u6a21\u6001 2025 \u4e2d\u6587\u3001\u82f1\u6587 \u56fe\u50cf\uff1a20\u4e07\u5f20\uff1b\u89c6\u9891\uff1a1\u4e07\u6bb5\uff1b\u97f3\u9891\uff1a1\u4e07\u4efd\uff08\u5373\u5c06\u63a8\u51fa\uff09 OpenGVLab\u3001\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u7b49\u673a\u6784 \u7528\u4e8e\u589e\u5f3a\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u6a21\u6001\u5bf9\u9f50\u548c\u6574\u4f53\u6027\u80fd\uff0c\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\u3001\u89c6\u9891\u548c\u97f3\u9891\u63cf\u8ff0\u3002 Hugging Face \u662f \u662f \u8bad\u7ec3 ShareGPT4V \u57fa\u4e8eShareGPT\u548cGPT-4V\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u50cf\u4e0e\u6587\u672c\u4ea4\u4e92\u6307\u4ee4\u53ca\u56de\u590d\u3002 \u591a\u6a21\u6001\u3001\u89c6\u89c9\u8bed\u8a00 2023 \u4e2d\u6587/\u82f1\u6587 \u6570\u767e\u4e07\u5bf9\u8bdd\u6837\u672c \u534e\u79d1 \u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3 https://github.com/InternLM/InternLM-XComposer/blob/main/projects/ShareGPT4V/docs/Data.md \u662f \u662f \u8bad\u7ec3 OpenImages-Caption \u57fa\u4e8e OpenImages \u6570\u636e\u96c6\u7684\u56fe\u50cf\u63cf\u8ff0\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u56fe\u50cf\u548c\u5bf9\u5e94\u7684\u63cf\u8ff0\uff0c\u6db5\u76d6\u591a\u79cd\u7269\u4f53\u7c7b\u522b\u548c\u573a\u666f \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2018 \u82f1\u6587 \u8bad\u7ec3\u96c6 500 \u4e07\u5f20\u56fe\u50cf\uff0c\u9a8c\u8bc1\u96c6 25000 \u5f20\u56fe\u50cf\uff0c\u6d4b\u8bd5\u96c6 100000 \u5f20\u56fe\u50cf\uff0c\u6bcf\u5f20\u56fe\u50cf\u6709\u591a\u4e2a\u63cf\u8ff0 Google \u7528\u4e8e\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u4efb\u52a1\uff0c\u5e2e\u52a9\u6a21\u578b\u7406\u89e3\u590d\u6742\u573a\u666f\u4e2d\u7684\u7269\u4f53\u548c\u5173\u7cfb OpenImages \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 NewYorkerCaptionContest \u4ee5\u300a\u7ebd\u7ea6\u5ba2\u300b\u6742\u5fd7\u7684\u5361\u901a\u56fe\u7247\u4e3a\u7d20\u6750\uff0c\u6536\u96c6\u7528\u6237\u751f\u6210\u7684\u5e7d\u9ed8\u6807\u9898\uff0c\u7528\u4e8e\u7814\u7a76\u5e7d\u9ed8\u548c\u521b\u9020\u529b\u5728\u56fe\u50cf\u63cf\u8ff0\u4e2d\u7684\u5e94\u7528 \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u5e7d\u9ed8\u8ba1\u7b97 - \u82f1\u6587 \u7ea6 2400 \u5f20\u56fe\u50cf\uff0c\u6bcf\u5f20\u56fe\u50cf\u6709\u591a\u4e2a\u7528\u6237\u751f\u6210\u7684\u6807\u9898 \u300a\u7ebd\u7ea6\u5ba2\u300b\u6742\u5fd7\u53ca\u7814\u7a76\u673a\u6784 \u7528\u4e8e\u63a2\u7d22\u56fe\u50cf\u63cf\u8ff0\u4e2d\u7684\u5e7d\u9ed8\u5143\u7d20\u548c\u521b\u9020\u529b\uff0c\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u5e7d\u9ed8\u63cf\u8ff0\u7684\u80fd\u529b https://huggingface.co/datasets/jmhessel/newyorker_caption_contest \u662f \u5426 \u8bc4\u4f30 LAION-400-M \u5927\u89c4\u6a21\u56fe\u50cf-\u6587\u672c\u5bf9\u6570\u636e\u96c6\uff0c\u5305\u542b4\u4ebf\u4e2a\u56fe\u6587\u5bf9\uff0c\u7528\u4e8e\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002 \u56fe\u50cf\u4e0e\u6587\u672c 2021 \u591a\u8bed\u8a00 4\u4ebf\u56fe\u6587\u5bf9 LAION\u7ec4\u7ec7 \u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3 HuggingFace \u662f \u5426 \u8bad\u7ec3 LAION-COCO LAION-COCO \u662f\u57fa\u4e8e COCO \u6570\u636e\u96c6\u6269\u5c55\u7684\u4e00\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u50cf\u4e0e\u6587\u672c\u63cf\u8ff0\u7684\u914d\u5bf9\uff0c\u4e13\u6ce8\u4e8e\u5927\u89c4\u6a21\u7684\u56fe\u50cf-\u6587\u672c\u5bf9\u751f\u6210\u4efb\u52a1\u3002\u8be5\u6570\u636e\u96c6\u5c06 COCO \u56fe\u50cf\u96c6\u4e0e\u66f4\u591a\u56fe\u50cf-\u6587\u672c\u5bf9\u8fdb\u884c\u7ec4\u5408\u3002 \u591a\u6a21\u6001\u5b66\u4e60\uff0c\u56fe\u50cf\u63cf\u8ff0\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9 2022 \u82f1\u6587 \u5305\u542b\u8d85\u8fc7600\u4e07\u5f20\u56fe\u50cf\u4e0e\u5176\u6587\u672c\u63cf\u8ff0 LAION\uff08\u5fb7\u56fd\uff09 \u56fe\u50cf\u63cf\u8ff0\u751f\u6210\uff0c\u56fe\u50cf-\u6587\u672c\u5bf9\u5339\u914d Hugging Face LAION-COCO \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 LAION-5B LAION-5B \u662f\u4e00\u4e2a\u8d85\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b 58.5 \u4ebf\u4e2a\u56fe\u50cf-\u6587\u672c\u5bf9\uff0c\u6db5\u76d6\u591a\u79cd\u8bed\u8a00\uff0c\u5e7f\u6cdb\u7528\u4e8e\u591a\u6a21\u6001\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u3002 \u4e00\u822c 2022 \u591a\u8bed\u8a00 58.5\u4ebf\u4e2a\u56fe\u50cf-\u6587\u672c\u5bf9 LAION \u9884\u8bad\u7ec3 https://arxiv.org/abs/2210.08402 \u662f \u5426 \u8bad\u7ec3 LLaVAR \u57fa\u4e8e LAION \u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u63d0\u5347\u6a21\u578b\u5bf9\u542b\u6587\u672c\u7684\u56fe\u50cf\uff08\u5982\u7535\u5f71\u6d77\u62a5\u3001\u4e66\u7c4d\u5c01\u9762\u7b49\uff09\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4f7f\u7528 OCR \u5de5\u5177\u6536\u96c6 422K \u6587\u672c\u4e30\u5bcc\u56fe\u50cf\u7684\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u4e0e\u4ec5\u6587\u672c\u7684 GPT-4 \u4ea4\u4e92\u751f\u6210 16K \u9ad8\u8d28\u91cf\u6307\u4ee4\u9075\u5faa\u6570\u636e\u7528\u4e8e\u5fae\u8c03 \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2023 \u4e2d\u6587\u3001\u82f1\u6587 \u5305\u62ec 422K \u9884\u8bad\u7ec3\u6570\u636e\u548c 16K\uff08\u6216 20K \u66f4\u591a\u6837\u672c\u7684\u6269\u5c55\u96c6\uff09\u5fae\u8c03\u6570\u636e\u70b9 Georgia Tech\u3001Adobe Research\u3001Stanford University \u7528\u4e8e\u589e\u5f3a\u89c6\u89c9\u6307\u4ee4\u8c03\u6574\u6a21\u578b\u5bf9\u56fe\u50cf\u4e2d\u6587\u672c\u7ec6\u8282\u7684\u7406\u89e3\uff0c\u5728\u6587\u672c\u57fa\u7840\u7684\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff08\u5982 ST-VQA\u3001OCR-VQA\u3001TextVQA \u548c DocVQA\uff09\u548c ScienceQA \u4e0a\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd https://llavar.github.io/#data \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 MMInstruct MMInstruct\u5305\u542b 973K \u6761\u6765\u81ea 24 \u4e2a\u9886\u57df\u7684\u6307\u4ee4\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u89c6\u89c9\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u5728\u6307\u4ee4\u6ce8\u91ca\u8d28\u91cf\u3001\u56fe\u50cf\u548c\u6307\u4ee4\u591a\u6837\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4ee5\u63d0\u5347\u89c6\u89c9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08VLLMs\uff09\u7684\u6027\u80fd\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2024 \u82f1\u8bed \u6307\u4ee4\u6570\u91cf\u4e3a 973K \u6761 \u4e0a\u6d77AILab \u6307\u4ee4\u5fae\u8c03 https://huggingface.co/datasets/yuecao0119/MMInstruct-GPT4V \u662f \u662f \u8bad\u7ec3 CC12M CC12M \u662f\u4e00\u4e2a\u5305\u542b 1200 \u4e07\u56fe\u50cf\u6587\u672c\u5bf9\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u4e0eCC3M \u76f8\u6bd4\uff0c\u5b83\u66f4\u5927\uff0c\u6db5\u76d6\u4e86\u66f4\u591a\u7684\u89c6\u89c9\u6982\u5ff5\u96c6\uff0c\u8be5\u6982\u5ff5\u96c6\u5e7f\u6cdb\u7528\u4e8e\u56fe\u50cf\u5b57\u5e55\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u548c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002 Caption 2021 \u82f1\u8bed 1200\u4e07\u56fe\u50cf\u6587\u672c\u5bf9 Google \u9884\u8bad\u7ec3 https://github.com/google-research-datasets/conceptual-12m \u662f \u5426 \u8bad\u7ec3 CC3M CC3M \u63d0\u4f9b\u4e86 300 \u4e07\u56fe\u50cf\u6587\u672c\u5bf9\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u9884\u8bad\u7ec3\uff0c\u5e2e\u52a9\u6a21\u578b\u5b66\u4e60\u56fe\u50cf\u548c\u6587\u672c\u4e4b\u95f4\u7684\u5173\u8054\u3002 \u4e00\u822c 2021 \u82f1\u8bed 300\u4e07\u56fe\u50cf\u6587\u672c\u5bf9 Google \u9884\u8bad\u7ec3 https://huggingface.co/datasets/pixparse/cc3m-wds \u662f \u5426 \u8bad\u7ec3 SBU SBU \u6570\u636e\u96c6\u5305\u542b 80 \u4e07\u5f20\u56fe\u50cf\u548c 100 \u4e07\u6761\u6587\u672c\u63cf\u8ff0\uff0c\u5e7f\u6cdb\u7528\u4e8e\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u4efb\u52a1\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002 Caption 2011 \u82f1\u8bed 80\u4e07\u5f20\u56fe\u50cf\uff0c100\u4e07\u6761\u63cf\u8ff0 \u7ebd\u7ea6\u5dde\u7acb\u5927\u5b66\u77f3\u6eaa\u5206\u6821 \u56fe\u50cf\u63cf\u8ff0 https://opendatalab.com/OpenDataLab/SBU_Captions_Dataset/tree/main \u662f \u5426 \u8bad\u7ec3/\u8bc4\u4f30 WuKong WuKong\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u4e2d\u6587\u8de8\u6a21\u6001\u9884\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5305\u542b 100 \u4e07\u5bf9 &lt; \u56fe\u50cf\uff0c\u6587\u672c &gt;\uff0c\u56fe\u50cf\u548c\u6587\u672c\u5747\u7ecf\u8fc7\u8fc7\u6ee4\u5904\u7406\uff0c\u8003\u8651\u4e86\u9690\u79c1\u548c\u654f\u611f\u8bcd\u7b49\u56e0\u7d20\u3002 Caption 2022 \u4e2d\u6587 100 \u4e07\u5bf9 &lt; \u56fe\u50cf\uff0c\u6587\u672c \u534e\u4e3a\u8bfa\u4e9a\u65b9\u821f\u5b9e\u9a8c\u5ba4\u4e0e\u6607\u601d MindSpore \u793e\u533a \u9884\u8bad\u7ec3 https://wukong-dataset.github.io/wukong-dataset/ \u662f \u5426 \u8bad\u7ec3 InternVL-SA-1B-Caption InternVL-SA-1B-Caption \u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u591a\u6a21\u6001\u4ea4\u9519\u6570\u636e\u96c6\uff0c\u5305\u542b 10 \u4ebf\u6587\u672c\u4ee4\u724c\u548c 30 \u4ebf\u56fe\u50cf\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u3002 \u4e00\u822c 2024 \u82f1\u8bed 10\u4ebf\u6587\u672c\u4ee4\u724c\u548c30\u4ebf\u56fe\u50cf OpenGVLab \u9884\u8bad\u7ec3 https://huggingface.co/datasets/OpenGVLab/InternVL-SA-1B-Caption \u662f \u5426 \u8bad\u7ec3 Multimodal C4 Multimodal C4 \u662f\u4e00\u4e2a\u57fa\u4e8e C4 \u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u4ece Common Crawl \u6570\u636e\u4e2d\u63d0\u53d6\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u6587\u5bf9\u7b49\u591a\u79cd\u591a\u6a21\u6001\u5185\u5bb9\u3002 \u591a\u9886\u57df\uff0c\u6db5\u76d6\u4e92\u8054\u7f51\u4e0a\u7684\u5404\u79cd\u4e3b\u9898\u548c\u5185\u5bb9 2023 \u4e3b\u8981\u4e3a\u82f1\u8bed\uff0c\u4e5f\u6709\u5176\u4ed6\u8bed\u8a00\u7684\u6570\u636e - Google \u9884\u8bad\u7ec3 https://github.com/allenai/mmc4 \u662f \u5426 \u8bad\u7ec3 MINT-1T MINT-1T \u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u4ea4\u9519\u6570\u636e\u96c6\uff0c\u5305\u542b 1 \u4e07\u4ebf\u4e2a\u6587\u672ctoken\u548c34\u56fe\u7247\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u6a21\u578b\u7684\u9884\u8bad\u7ec3\uff0c\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u4e00\u822c 2024 \u82f1\u8bed 1\u4e07\u4ebf\u4e2a\u56fe\u50cf\u548c\u6587\u672c\u5bf9 \u65b0\u52a0\u5761\u7ba1\u7406\u5b66\u9662 Green AI \u5b9e\u9a8c\u5ba4\u548c\u97e9\u56fd\u79d1\u5b66\u6280\u672f\u9662\uff08KAIST\uff09\u7b49 \u9884\u8bad\u7ec3 https://github.com/mlfoundations/MINT-1T \u662f \u5426 \u8bad\u7ec3 Flickr30k Flickr30k \u63d0\u4f9b\u4e86 31,783 \u5f20\u56fe\u50cf\uff0c\u6bcf\u5f20\u56fe\u50cf\u914d\u6709 5 \u4e2a\u6587\u672c\u63cf\u8ff0\uff0c\u5e7f\u6cdb\u7528\u4e8e\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u4efb\u52a1\u7684\u8bc4\u4f30\u3002 \u770b\u56fe\u8bf4\u8bdd 2014 \u82f1\u8bed 31,783\u5f20\u56fe\u50cf\uff0c158,915\u6761\u63cf\u8ff0 - \u56fe\u50cf\u63cf\u8ff0\u8bc4\u4f30 https://huggingface.co/datasets/nlphuji/flickr30k \u662f \u5426 \u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#2-general-qa","title":"2. General QA","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u662f\u5426\u5305\u542b Caption \u6570\u636e \u662f\u5426\u5305\u542b\u591a\u6a21\u6001 QA Instructtion \u6570\u636e \u8bad\u7ec3\u8fd8\u662f\u8bc4\u4f30 VQAv2 VQAv2 \u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc7 20 \u4e07\u5f20\u56fe\u50cf\u548c 110 \u4e07\u4e2a\u95ee\u9898\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u7684\u89c6\u89c9\u95ee\u7b54\u80fd\u529b\u3002 \u4e00\u822c QA 2017 \u82f1\u8bed \u8d85\u8fc720\u4e07\u5f20\u56fe\u50cf\uff0c110\u4e07\u4e2a\u95ee\u9898\uff0c1100\u4e07\u4e2a\u7b54\u6848\uff08\u5355\u4e2a\u95ee\u9898\u5341\u4e2a\u7b54\u6848\uff09 \u5f17\u5409\u5c3c\u4e9a\u7406\u5de5\u5927\u5b66 \u89c6\u89c9\u95ee\u7b54 VQAv2 \u94fe\u63a5 \u5426 \u662f \u8bad\u7ec3/\u8bc4\u4f30 OK-VQA/A-OKVQA OK-VQA/A-OKVQA \u662f\u4e00\u4e2a\u5f00\u653e\u5f0f\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b\u590d\u6742\u7684\u95ee\u7b54\u5bf9\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002 \u4e00\u822c QA 2019 \u82f1\u8bed - CMU \u89c6\u89c9\u95ee\u7b54\u8bc4\u4f30 https://okvqa.allenai.org/download.html https://github.com/allenai/aokvqa?tab=readme-ov-file#downloading-the-dataset \u5426 \u662f \u8bc4\u4f30 GQA GQA \u7740\u91cd\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u7684\u63a8\u7406\u548c\u7ec4\u5408\u5f0f\u95ee\u9898\u56de\u7b54\uff0c\u5305\u542b\u590d\u6742\u7684\u95ee\u9898\u548c\u7b54\u6848\uff0c\u7528\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002 \u63a8\u7406 2019 \u82f1\u8bed 113K images and 22M questions \u65af\u5766\u798f\u5927\u5b66 \u89c6\u89c9\u95ee\u7b54 GQA \u94fe\u63a5 \u5426 \u662f \u8bad\u7ec3 IconQA IconQA \u662f\u4e00\u4e2a\u62bd\u8c61\u56fe\u8868\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\uff0c\u5305\u542b\u56fe\u8868\u548c\u76f8\u5173\u95ee\u9898\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u56fe\u8868\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\u3002 \u56fe\u8868\u7406\u89e3 2021 \u82f1\u8bed 10\u4e07\u4e2a\u56fe\u8868\u53ca\u76f8\u5173\u95ee\u9898 \u65b0\u52a0\u5761\u79d1\u6280\u8bbe\u8ba1\u5927\u5b66 \u56fe\u6807\u7406\u89e3\u8bc4\u4f30 https://opendatalab.com/OpenDataLab/IconQA \u5426 \u662f \u8bc4\u4f30 Visual7W \u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u89c6\u89c9\u95ee\u7b54\uff08QA\uff09\u6570\u636e\u96c6\uff0c\u5177\u6709\u5bf9\u8c61\u7ea7\u57fa\u7840\u548c\u591a\u6a21\u6001\u7b54\u6848\u3002\u6bcf\u4e2a\u95ee\u9898\u90fd\u4ee5\u4e03\u4e2a W \u4e4b\u4e00\u5f00\u59cb\u3002 \u8ba1\u7b97\u673a\u89c6\u89c9 2015 \u82f1\u8bed 327,929 \u4e2a QA \u5bf9\uff0c1,311,756 \u4e2a\u4eba\u5de5\u751f\u6210\u7684\u591a\u9879\u9009\u62e9\uff0c561,459 \u4e2a\u5bf9\u8c61\u57fa\u7840 \u65af\u5766\u798f\u5927\u5b66 \u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u7684\u7814\u7a76\u4e0e\u8bc4\u4f30 OpenDataLab \u5426 \u662f \u8bc4\u4f30 VisText VisText\u662f\u4e00\u4e2a\u5305\u542b12,441\u4e2a\u56fe\u8868\u53ca\u5176\u63cf\u8ff0\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u56fe\u8868\u6807\u9898\u3002 \u6570\u636e\u53ef\u89c6\u5316 2023 \u82f1\u8bed 12,441\u5bf9\u56fe\u8868\u548c\u6807\u9898 MIT CSAIL \u56fe\u8868\u63cf\u8ff0\u751f\u6210\u3001\u8bed\u4e49\u5206\u6790 Hugging Face \u662f \u5426 \u8bc4\u4f30 VSR VSR\uff08Visual Spatial Reasoning\uff09\u662f\u4e00\u4e2a\u5305\u542b\u8d85\u8fc7 10k \u81ea\u7136\u6587\u672c - \u56fe\u50cf\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6 66 \u79cd\u7a7a\u95f4\u5173\u7cfb\uff0c\u7528\u4e8e\u6d4b\u8bd5\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u7406\u89e3\u56fe\u50cf\u4e2d\u7684\u7a7a\u95f4\u5173\u7cfb\u65b9\u9762\u7684\u80fd\u529b\u3002 \u673a\u5668\u5b66\u4e60\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2022 \u5e74 \u82f1\u8bed \u5305\u542b\u8d85\u8fc7 10k \u6570\u636e\u70b9\uff0c\u4f7f\u7528 6,940 \u5f20\u6765\u81ea MS COCO \u7684\u56fe\u7247\uff0c\u6db5\u76d6 66 \u79cd\u7a7a\u95f4\u5173\u7cfb \u5251\u6865\u5927\u5b66 \u5728\u7406\u89e3\u56fe\u50cf\u4e2d\u4e24\u4e2a\u5bf9\u8c61\u4e4b\u95f4\u7a7a\u95f4\u5173\u7cfb\u65b9\u9762\u7684\u80fd\u529b https://huggingface.co/datasets/juletxara/visual-spatial-reasoning \u662f \u5426 \u8bc4\u4f30 TallyQA \u4e16\u754c\u4e0a\u6700\u5927\u7684\u5f00\u653e\u6027\u8ba1\u6570\u95ee\u9898\u6570\u636e\u96c6\uff0c\u5305\u542b\u7b80\u5355\u548c\u590d\u6742\u8ba1\u6570\u95ee\u9898\uff0c\u7528\u4e8e\u7814\u7a76\u89c6\u89c9\u95ee\u7b54\u4e2d\u7684\u8ba1\u6570\u95ee\u9898 \u8ba1\u7b97\u673a\u89c6\u89c9 2019 \u82f1\u8bed 287K\u95ee\u9898/165K\u56fe\u50cf Rochester Institute of Technology \u8bad\u7ec3\u548c\u8bc4\u4f30\u590d\u6742\u8ba1\u6570\u95ee\u9898\u7684\u89c6\u89c9\u95ee\u7b54\u6a21\u578b GitHub \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 VisDial VisDial \u6570\u636e\u96c6\u57fa\u4e8e MS\u202fCOCO \u56fe\u50cf\u6570\u636e\u96c6\uff0c\u7cbe\u5fc3\u7b5b\u9009\u4e86\u202f120\u202f000\u202f\u5f20\u591a\u6837\u5316\u7684\u65e5\u5e38\u573a\u666f\u56fe\u7247\uff0c\u5e76\u901a\u8fc7 Amazon Mechanical Turk \u5e73\u53f0\u6536\u96c6\u4e86\u5bf9\u5e94\u7684\u5bf9\u8bdd\u6570\u636e\u3002\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u4e00\u6761\u5bf9\u8bdd\uff0c\u5bf9\u8bdd\u957f\u5ea6\u56fa\u5b9a\u4e3a\u202f10\u202f\u8f6e\uff0c\u5305\u542b\u63d0\u95ee\u4e0e\u56de\u7b54\u4e24\u90e8\u5206\uff0c\u603b\u8ba1\u7ea6\u202f1.2\u202f\u767e\u4e07\u202f(1,200,000)\u202f\u4e2a\u95ee\u7b54\u5bf9\uff0c\u65e2\u6db5\u76d6\u4e86\u5bf9\u663e\u800c\u6613\u89c1\u89c6\u89c9\u5c5e\u6027\uff08\u5982\u989c\u8272\u3001\u4f4d\u7f6e\u3001\u7269\u4f53\u7c7b\u522b\uff09\u7684\u63d0\u95ee\uff0c\u4e5f\u6d89\u53ca\u5bf9\u573a\u666f\u8bed\u4e49\u3001\u7269\u4f53\u5173\u7cfb\u751a\u81f3\u4e3b\u4f53\u610f\u56fe\u7684\u6df1\u5165\u8ffd\u95ee \u8ba1\u7b97\u673a\u89c6\u89c9 2017 \u82f1\u8bed 1.2\u202f\u767e\u4e07\u202f(1,200,000)\u202f\u4e2a\u95ee\u7b54\u5bf9 Georgia Institute of Technology \u8bad\u7ec3\u548c\u8bc4\u4f30\u89c6\u89c9\u5bf9\u8bdd\u6a21\u578b GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 Hateful-Memes \u7528\u4e8e\u68c0\u6d4b\u591a\u6a21\u6001\u4ec7\u6068\u8a00\u8bba\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u5e26\u6709\u6587\u672c\u7684\u56fe\u50cf\uff08\u7f51\u7edc\u8ff7\u56e0\uff09 \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2020 \u82f1\u8bed \u7ea610,000\u4e2a\u6837\u672c Facebook AI\u3001DrivenData \u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b GitHub \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 FSC147 \u7528\u4e8e\u5c11\u6837\u672c\u76ee\u6807\u8ba1\u6570\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b147\u4e2a\u7c7b\u522b\u30016,135\u5f20\u56fe\u50cf\uff0c\u63d0\u4f9b\u70b9\u6ce8\u91ca\u548c\u793a\u4f8b\u6846 \u8ba1\u7b97\u673a\u89c6\u89c9 2021 \u82f1\u8bed 6,135\u56fe\u50cf/147\u7c7b\u522b VinAI Research\u3001\u77f3\u6eaa\u5927\u5b66 \u8bad\u7ec3\u548c\u8bc4\u4f30\u5c11\u6837\u672c\u76ee\u6807\u8ba1\u6570\u6a21\u578b GitHub \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 MMInstruct MMInstruct\u5305\u542b 973K \u6761\u6765\u81ea 24 \u4e2a\u9886\u57df\u7684\u6307\u4ee4\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u89c6\u89c9\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u5728\u6307\u4ee4\u6ce8\u91ca\u8d28\u91cf\u3001\u56fe\u50cf\u548c\u6307\u4ee4\u591a\u6837\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4ee5\u63d0\u5347\u89c6\u89c9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08VLLMs\uff09\u7684\u6027\u80fd\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2024 \u82f1\u8bed \u6307\u4ee4\u6570\u91cf\u4e3a 973K \u6761 \u4e0a\u6d77AILab \u6307\u4ee4\u5fae\u8c03 https://huggingface.co/datasets/yuecao0119/MMInstruct-GPT4V \u662f \u662f \u8bad\u7ec3 VisualGenome VisualGenome \u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u89c6\u89c9\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e86\u56fe\u50cf\u3001\u5bf9\u8c61\u3001\u5c5e\u6027\u548c\u5173\u7cfb\u7b49\u4fe1\u606f\uff0c\u76ee\u7684\u662f\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u652f\u6301\u3002 \u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u56fe\u50cf\u7406\u89e3\uff0c\u8bed\u8a00\u7406\u89e3 2016 \u82f1\u6587 \u5305\u542b\u8d85\u8fc710\u4e07\u5f20\u56fe\u50cf\uff0c\u8d85\u8fc7500\u4e07\u4e2a\u6807\u6ce8 VisualGenome\u56e2\u961f \u89c6\u89c9\u63a8\u7406\u3001\u89c6\u89c9\u95ee\u7b54\u3001\u56fe\u50cf\u63cf\u8ff0\u751f\u6210 https://huggingface.co/datasets/ranjaykrishna/visual_genome \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 ShareGPT4V \u57fa\u4e8eShareGPT\u548cGPT-4V\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u50cf\u4e0e\u6587\u672c\u4ea4\u4e92\u6307\u4ee4\u53ca\u56de\u590d\u3002 \u591a\u6a21\u6001\u3001\u89c6\u89c9\u8bed\u8a00 2023 \u4e2d\u6587/\u82f1\u6587 \u6570\u767e\u4e07\u5bf9\u8bdd\u6837\u672c \u534e\u79d1 \u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3 https://github.com/InternLM/InternLM-XComposer/blob/main/projects/ShareGPT4V/docs/Data.md \u5426 \u662f \u8bad\u7ec3 LLaVa LLaVa \u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u89c6\u89c9\u95ee\u7b54\u548c\u63a8\u7406\u7684\u5927\u578b\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u4e86\u8bed\u8a00\u548c\u89c6\u89c9\u4fe1\u606f\uff0c\u652f\u6301\u5927\u89c4\u6a21\u7684\u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u3002 \u591a\u6a21\u6001\u5b66\u4e60\uff0c\u89c6\u89c9\u95ee\u7b54\uff0c\u8bed\u8a00\u7406\u89e3 2023 \u82f1\u6587 \u5305\u542b\u7ea6150,000\u4e2a\u95ee\u7b54\u5bf9\u548c\u56fe\u50cf\u6570\u636e LLaVa\u56e2\u961f \u89c6\u89c9\u95ee\u7b54\uff0c\u89c6\u89c9\u63a8\u7406\uff0c\u8bed\u8a00\u7406\u89e3 https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 CogVLM-SFT-311K CogVLM\u2011SFT\u2011311K \u662f\u7528\u4e8e CogVLM v1.0 \u521d\u59cb\u8bad\u7ec3\u7684\u4e3b\u5bf9\u9f50\u8bed\u6599\uff0c\u5305\u542b\u4e2d\u82f1\u6587\u53cc\u8bed\u7684\u89c6\u89c9\u6307\u4ee4\u2013\u54cd\u5e94\u5bf9\u3002\u5b83\u65e8\u5728\u63d0\u5347\u6a21\u578b\u7684\u89c6\u89c9\u7406\u89e3\u4e0e\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\uff0c\u5c24\u5176\u9488\u5bf9\u56fe\u50cf\u63cf\u8ff0\u548c\u56fe\u50cf\u95ee\u7b54\u573a\u666f\u3002 \u591a\u6a21\u6001\u9884\u8bad\u7ec3\u6a21\u578b 2023 \u4e2d\u82f1\u53cc\u8bed \u603b\u8ba1\u7ea6 31 \u4e07\u6837\u672c\uff0c\u5305\u62ec\u56fe\u7247\u548c\u63cf\u8ff0\u3001\u591a\u8f6e\u5bf9\u8bdd\u3001\u5355\u8f6e\u5bf9\u8bdd\u7b49\u6570\u636e \u6e05\u534e\u5927\u5b66 \u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u76d1\u7763\u5fae\u8c03\u3001\u591a\u6a21\u6001\u5bf9\u8bdd\u7cfb\u7edf\u5f00\u53d1\u7b49 huggingface \u662f \u662f \u4e3b\u8981\u7528\u4e8e\u8bad\u7ec3 LVIS-Instruct4V \u5305\u542b\u901a\u8fc7\u4f7f\u7528 LVIS \u4e2d\u7684\u56fe\u50cf\u63d0\u793a\u5f3a\u5927\u7684 GPT-4V \u751f\u6210\u7684 22 \u4e07\u4e2a\u89c6\u89c9\u5bf9\u9f50\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6307\u4ee4 \u8ba1\u7b97\u673a\u89c6\u89c9\u7b49 2023 \u672a\u660e\u786e \u5305\u542b 22 \u4e07\u4e2a\u89c6\u89c9\u5bf9\u9f50\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6307\u4ee4 \u590d\u65e6\u5927\u5b66\u3001\u9a6c\u91cc\u5170\u5927\u5b66\u7b49 \u7528\u4e8e\u591a\u6a21\u6001\u6a21\u578b\u7684\u6307\u4ee4\u5fae\u8c03\uff0c\u63d0\u5347\u6a21\u578b\u5728\u89c6\u89c9\u95ee\u7b54\u7b49\u4efb\u52a1\u4e2d\u7684\u6027\u80fd github \u5426 \u662f \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30 MMIF-23k \u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u6307\u4ee4\u8ddf\u968f\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5305\u542b\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf-\u6307\u4ee4\u5bf9\uff0c\u7528\u4e8e\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002 \u591a\u6a21\u6001\uff08\u56fe\u50cf\u3001\u6587\u672c\uff09 2025 \u4e2d\u6587\u3001\u82f1\u6587 23,000 \u6761\u6570\u636e \u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u7b49\u673a\u6784 \u7528\u4e8e\u591a\u6a21\u6001\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u7684\u76d1\u7763\u5f0f\u5fae\u8c03\uff08SFT\uff09\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09 GitHub \u662f \u662f \u8bad\u7ec3 M3IT \u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u591a\u8bed\u8a00\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u5305\u542b 240 \u4e07\u6761\u6570\u636e\u548c 400 \u6761\u624b\u52a8\u7f16\u5199\u7684\u4efb\u52a1\u6307\u4ee4\uff0c\u8986\u76d6 40 \u79cd\u4efb\u52a1\u7c7b\u578b\u3002 \u591a\u6a21\u6001\uff08\u56fe\u50cf\u3001\u6587\u672c\u3001\u89c6\u9891\uff09 2023 \u82f1\u8bed\u3001\u4e2d\u6587\u300180 \u79cd\u8bed\u8a00 240 \u4e07\u6761\u6570\u636e \u5317\u4eac\u5927\u5b66\u3001\u9999\u6e2f\u5927\u5b66\u3001\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4 \u7528\u4e8e\u591a\u6a21\u6001\u6307\u4ee4\u5fae\u8c03\uff0c\u63d0\u5347\u6a21\u578b\u5728\u591a\u8bed\u8a00\u548c\u591a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0 Hugging Face \u662f \u662f \u8bad\u7ec3 Infinity-MM \u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc7 4000 \u4e07\u6761\u6570\u636e\uff0c\u6db5\u76d6\u56fe\u50cf\u63cf\u8ff0\u3001\u89c6\u89c9\u95ee\u7b54\u3001\u63a8\u7406\u7b49\u591a\u79cd\u4efb\u52a1\uff0c\u652f\u6301\u591a\u8bed\u8a00\u548c\u6570\u636e\u5408\u6210\u3002 \u591a\u6a21\u6001\uff08\u56fe\u50cf\u3001\u6587\u672c\uff09 2024 \u82f1\u8bed\u3001\u4e2d\u6587 4000 \u4e07\u6761\u6570\u636e \u5317\u4eac\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u9662 \u7528\u4e8e\u8bad\u7ec3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u5347\u5176\u5728\u591a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0 Hugging Face \u662f \u662f \u8bad\u7ec3"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#3-mathematics","title":"3. Mathematics","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 Super-CLEVR Super\u2011CLEVR \u662f\u4e00\u4e2a\u5408\u6210\u89c6\u89c9\u95ee\u7b54\u8bca\u65ad\u57fa\u51c6\uff0c\u901a\u8fc7\u53ef\u63a7\u7684\u89c6\u89c9\u590d\u6742\u5ea6\u3001\u95ee\u9898\u5197\u4f59\u3001\u6982\u5ff5\u5206\u5e03\u548c\u6982\u5ff5\u7ec4\u5408\u6027\u56db\u4e2a\u57df\u504f\u79fb\u56e0\u7d20\uff0c\u8bc4\u4f30\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u89c6\u89c9\u63a8\u7406 2022 \u82f1\u6587 30k \u56fe\u50cf\uff0c10k \u95ee\u9898 Johns Hopkins University \u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u7814\u7a76 Hugging Face \u5426 \u662f \u8bc4\u4f30 CMM-Math \u7528\u4e8e\u8bc4\u4f30\u548c\u589e\u5f3a\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u4e2d\u6587\u591a\u6a21\u6001\u6570\u5b66\u6570\u636e\u96c6 \u6570\u5b66\u63a8\u7406 2024 \u4e2d\u6587 28k+ \u8bad\u7ec3\u6837\u672c\uff0c5k+ \u8bc4\u4f30\u6837\u672c \u534e\u4e1c\u5e08\u8303\u5927\u5b66 \u7528\u4e8e\u6570\u5b66\u95ee\u9898\u7684\u591a\u6a21\u6001\u63a8\u7406\u7814\u7a76 Hugging Face \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 MAVIS \u7528\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u89c6\u89c9\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u5305\u542b\u6570\u5b66\u89c6\u89c9\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848 \u6570\u5b66\u89c6\u89c9\u95ee\u9898\u89e3\u51b3 2024 \u4e2d\u6587 MAVIS-Caption 558k \u56fe\u50cf-\u6807\u9898\u5bf9\uff0cMAVIS-Instruct 834k \u95ee\u9898 \u4e2d\u56fd\u79d1\u5b66\u6280\u672f\u5927\u5b66\u7b49 \u7528\u4e8e\u6570\u5b66\u89c6\u89c9\u95ee\u9898\u7684\u591a\u6a21\u6001\u63a8\u7406\u7814\u7a76 GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 GeomVerse \u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u51e0\u4f55\u95ee\u9898\u548c\u56fe\u8868 \u6570\u5b66 2023 \u82f1\u8bed 2612\u4e2a\u9ad8\u8d28\u91cf\u6570\u5b66\u95ee\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u67096\u79cd\u4e0d\u540c\u7248\u672c\uff0c\u603b\u8ba1\u7ea615000\u4e2a\u6d4b\u8bd5\u6837\u672c AI4Math \u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b Hugging Face \u5426 \u662f \u8bc4\u4f30 MetaMath-Rendered MetaMathQA \u6570\u636e\u96c6\u901a\u8fc7\u7b54\u6848\u589e\u5f3a\u3001\u95ee\u9898\u91cd\u8ff0\u3001\u81ea\u6211\u9a8c\u8bc1\u4e0e\u6b63\u53cd\u5411\u63a8\u7406\u7b49\u591a\u89c6\u89d2\u81ea\u4e3e\u7b56\u7565\uff0c\u751f\u6210\u8fd1 39.5 \u4e07\u6761\u683c\u5f0f\u5316 JSON \u6570\u5b66\u95ee\u7b54\u5bf9 \u6570\u5b66 2023 \u82f1\u8bed 39.5 \u4e07 MetaMath \u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b Hugging Face \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 MapQA \u4e00\u4e2a\u7528\u4e8e\u95ee\u7b54\u7684\u5730\u7406\u4fe1\u606f\u56fe\u8868\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u5730\u56fe\u98ce\u683c\u548c\u95ee\u9898\u7c7b\u578b \u5730\u7406\u4fe1\u606f 2022 \u82f1\u8bed \u7ea6800K\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u8986\u76d6\u7ea660K\u5730\u56fe\u56fe\u50cf\uff0c\u5206\u4e3a3\u4e2a\u5b50\u96c6\uff08MapQA-U\u3001MapQA-R\u3001MapQA-S\uff09 The Ohio State University \u8bc4\u4f30\u6a21\u578b\u5bf9\u5730\u7406\u4fe1\u606f\u56fe\u8868\u7684\u7406\u89e3\u80fd\u529b GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 GeoQA+ \u57fa\u4e8e GeoQA \u7684\u589e\u5f3a\u578b\u51e0\u4f55\u95ee\u9898\u89e3\u7b54\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u66f4\u4e30\u5bcc\u7c7b\u578b\u548c\u66f4\u9ad8\u96be\u5ea6\u7684\u95ee\u9898 \u51e0\u4f55\u95ee\u9898\u89e3\u7b54 2022 \u82f1\u6587 \u8bad\u7ec3\u96c6 6,027 \u4e2a\u95ee\u9898\uff0c\u6d4b\u8bd5\u96c6 7,528 \u4e2a\u95ee\u9898\uff0c\u6570\u636e\u589e\u5f3a\u540e\u8bad\u7ec3\u96c6\u6269\u5c55\u5230 12,054 SCNU203 \u56e2\u961f \u7528\u4e8e\u51e0\u4f55\u95ee\u9898\u7684\u81ea\u52a8\u89e3\u7b54\u7814\u7a76\uff0c\u652f\u6301\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30 GitHub \u5426 \u5426 \u8bad\u7ec3 + \u8bc4\u4f30 Geometry3K \u5927\u89c4\u6a21\u51e0\u4f55\u95ee\u9898\u89e3\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u9009\u51e0\u4f55\u95ee\u9898\u53ca\u56fe\u8868\u548c\u6587\u672c\u7684\u5f62\u5f0f\u8bed\u8a00\u6ce8\u91ca \u51e0\u4f55\u95ee\u9898\u89e3\u7b54 2021 \u82f1\u6587 3,002 \u4e2a\u591a\u9009\u51e0\u4f55\u95ee\u9898\uff0c27,213 \u4e2a\u56fe\u8868\u903b\u8f91\u5f62\u5f0f\uff0c6,293 \u4e2a\u6587\u672c\u903b\u8f91\u5f62\u5f0f InterGPS \u56e2\u961f \u7528\u4e8e\u51e0\u4f55\u95ee\u9898\u7684\u81ea\u52a8\u89e3\u7b54\u7814\u7a76\uff0c\u652f\u6301\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30 Hugging Face \u662f \u662f \u8bad\u7ec3 + \u8bc4\u4f30 UniGeo \u7edf\u4e00\u51e0\u4f55\u95ee\u9898\u57fa\u51c6\uff0c\u5305\u542b\u8ba1\u7b97\u548c\u8bc1\u660e\u95ee\u9898\uff0c\u652f\u6301\u591a\u4efb\u52a1\u51e0\u4f55\u95ee\u9898\u89e3\u7b54 \u51e0\u4f55\u95ee\u9898\u89e3\u7b54 2022 \u82f1\u6587 4,998 \u4e2a\u8ba1\u7b97\u95ee\u9898\u548c 9,543 \u4e2a\u8bc1\u660e\u95ee\u9898 \u4e2d\u5c71\u5927\u5b66 \u7528\u4e8e\u51e0\u4f55\u95ee\u9898\u7684\u7edf\u4e00\u903b\u8f91\u63a8\u7406\u7814\u7a76\uff0c\u652f\u6301\u591a\u4efb\u52a1\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30 GitHub \u5426 \u662f \u8bad\u7ec3 + \u8bc4\u4f30 GeoS \u7528\u4e8e\u81ea\u52a8\u89e3\u51b3\u6570\u5b66\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b SAT \u5e73\u9762\u51e0\u4f55\u95ee\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u6709\u82f1\u6587\u6587\u672c\u63cf\u8ff0\u3001\u56fe\u8868\u548c\u591a\u9879\u9009\u62e9 \u6570\u5b66 2015 \u82f1\u8bed \u672a\u660e\u786e\u5177\u4f53\u89c4\u6a21\uff0c\u5305\u542b\u4e00\u5b9a\u6570\u91cf\u7684 SAT \u51e0\u4f55\u95ee\u9898 University of Washington \u8bad\u7ec3\u548c\u8bc4\u4f30\u81ea\u52a8\u89e3\u9898\u6a21\u578b OpenDataLab \u5426 \u662f \u8bad\u7ec3 + \u8bc4\u4f30 CLEVR-Math \u7528\u4e8e\u7ec4\u5408\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u6570\u5b66\u63a8\u7406\u7684\u591a\u6a21\u6001\u6570\u5b66\u95ee\u9898\u6570\u636e\u96c6\uff0c\u5305\u542b\u7b80\u5355\u7684\u52a0\u51cf\u6cd5\u95ee\u9898\uff0c\u90e8\u5206\u7531\u6587\u672c\u63cf\u8ff0\uff0c\u90e8\u5206\u7531\u56fe\u50cf\u5c55\u793a \u6570\u5b66 2022 \u82f1\u8bed \u5305\u542b\u7ea6 5000 \u4e2a\u6d4b\u8bd5\u573a\u666f\uff08\u591a\u6a21\u6001\u95ee\u9898\uff09 Ume\u00e5 University \u548c \u00d6rebro University \u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b Hugging Face \u662f \u662f\uff08\u5305\u542b\u6587\u672c\u548c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u95ee\u9898\uff09 \u8bad\u7ec3 + \u8bc4\u4f30 TallyQA \u4e16\u754c\u4e0a\u6700\u5927\u7684\u5f00\u653e\u6027\u8ba1\u6570\u95ee\u9898\u6570\u636e\u96c6\uff0c\u5305\u542b\u7b80\u5355\u548c\u590d\u6742\u8ba1\u6570\u95ee\u9898\uff0c\u7528\u4e8e\u7814\u7a76\u89c6\u89c9\u95ee\u7b54\u4e2d\u7684\u8ba1\u6570\u95ee\u9898 \u8ba1\u7b97\u673a\u89c6\u89c9 2019 \u82f1\u8bed 287K\u95ee\u9898/165K\u56fe\u50cf Rochester Institute of Technology \u8bad\u7ec3\u548c\u8bc4\u4f30\u590d\u6742\u8ba1\u6570\u95ee\u9898\u7684\u89c6\u89c9\u95ee\u7b54\u6a21\u578b GitHub \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#4-ocr","title":"4. OCR","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 LaionCOCO-OCR \u4eceLaion-5B-en\u6570\u636e\u96c6\u4e2d\u751f\u6210\u76846\u4ebf\u6761\u9ad8\u8d28\u91cf\u5408\u6210\u56fe\u50cf\u63cf\u8ff0\u6570\u636e\uff0c\u7528\u4e8e\u89c6\u89c9\u6587\u6863\u7406\u89e3 \u8ba1\u7b97\u673a\u89c6\u89c9 2022 \u82f1\u8bed 6\u4ebf\u6761\u63cf\u8ff0 LAION \u8bad\u7ec3\u89c6\u89c9\u6587\u6863\u7406\u89e3\u6a21\u578b Hugging Face \u662f \u5426 \u8bad\u7ec3 ParsynthOCR 20\u4e07\u6761\u5408\u6210OCR\u6570\u636e\uff0c\u7528\u4e8e\u591a\u8bed\u8a00OCR\u4efb\u52a1 \u8ba1\u7b97\u673a\u89c6\u89c9 2024 \u591a\u8bed\u8a00 20\u4e07\u6761\u6570\u636e HezarAI \u8bad\u7ec3OCR\u6a21\u578b Hugging Face \u662f \u5426 \u8bad\u7ec3 SynthDoG-EN \u7528\u4e8e\u89c6\u89c9\u6587\u6863\u7406\u89e3\u7684\u5408\u6210\u6587\u6863\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u50cf\u548c\u6587\u672c\u5bf9 OCR 2024 \u82f1\u8bed \u672a\u660e\u786e Naver Clova IX \u8bad\u7ec3\u89c6\u89c9\u6587\u6863\u7406\u89e3\u6a21\u578b Hugging Face \u662f \u5426 \u8bad\u7ec3 SynthDoG-ZH \u7528\u4e8eOCR\u8bad\u7ec3\u7684\u5408\u6210\u4e2d\u6587\u6587\u6863\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u6587\u6863\u6837\u5f0f\u548c\u6587\u672c\u5185\u5bb9 OCR 2024 \u4e2d\u6587 50\u4e07\u6837\u672c Naver Clova \u7528\u4e8eOCR\u6a21\u578b\u8bad\u7ec3\u548c\u6587\u6863\u7406\u89e3 Hugging Face \u5426 \u5426 \u8bad\u7ec3 SynthDoG-RU \u7528\u4e8eOCR\u8bad\u7ec3\u7684\u5408\u6210\u4fc4\u8bed\u6587\u6863\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u6587\u6863\u6837\u5f0f\u548c\u6587\u672c\u5185\u5bb9 OCR 2022 \u4fc4\u8bed 50\u4e07\u6837\u672c Naver Clova \u7528\u4e8eOCR\u6a21\u578b\u8bad\u7ec3\u548c\u6587\u6863\u7406\u89e3 Hugging Face \u5426 \u5426 \u8bad\u7ec3 SynthDoG-JP \u7528\u4e8eOCR\u8bad\u7ec3\u7684\u5408\u6210\u65e5\u8bed\u6587\u6863\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u6587\u6863\u6837\u5f0f\u548c\u6587\u672c\u5185\u5bb9 OCR 2022 \u65e5\u8bed 50\u4e07\u6837\u672c Naver Clova \u7528\u4e8eOCR\u6a21\u578b\u8bad\u7ec3\u548c\u6587\u6863\u7406\u89e3 Hugging Face \u5426 \u5426 \u8bad\u7ec3 SynthDoG-KO \u7528\u4e8eOCR\u8bad\u7ec3\u7684\u5408\u6210\u97e9\u8bed\u6587\u6863\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u6587\u6863\u6837\u5f0f\u548c\u6587\u672c\u5185\u5bb9 OCR 2022 \u97e9\u8bed 50\u4e07\u6837\u672c Naver Clova \u7528\u4e8eOCR\u6a21\u578b\u8bad\u7ec3\u548c\u6587\u6863\u7406\u89e3 Hugging Face \u5426 \u5426 \u8bad\u7ec3 IAM \u5305\u542b13,353\u5f20\u624b\u5199\u6587\u672c\u884c\u56fe\u50cf\uff0c\u7531657\u540d\u4f5c\u8005\u4e66\u5199\uff0c\u6807\u6ce8\u5230\u53e5\u5b50\u3001\u884c\u548c\u5355\u8bcd\u7ea7\u522b \u624b\u5199\u6587\u672c\u8bc6\u522b 2021 \u82f1\u8bed 13,353\u5f20\u56fe\u50cf IAM\u56e2\u961f \u7528\u4e8e\u624b\u5199\u6587\u672c\u8bc6\u522b\u7814\u7a76 https://fki.tic.heia-fr.ch/databases/iam-handwriting-database \u5426 \u5426 \u8bc4\u4f30 EST-VQA \u7528\u4e8e\u53cc\u8bed\u573a\u666f\u6587\u672c\u89c6\u89c9\u95ee\u7b54\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e2d\u82f1\u6587\u95ee\u9898\u548c\u7b54\u6848\uff0c\u5f3a\u8c03\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408 \u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u81ea\u7136\u8bed\u8a00\u5904\u7406 2020 \u4e2d\u82f1\u53cc\u8bed 25,239\u56fe\u50cf/28,062\u95ee\u9898 University of Adelaide \u89c6\u89c9\u95ee\u7b54\u3001\u6a21\u578b\u8bc4\u4f30 GitHub \u5426 \u662f \u8bad\u7ec3 + \u8bc4\u4f30 ST-VQA \u5f3a\u8c03\u5229\u7528\u56fe\u50cf\u4e2d\u7684\u6587\u672c\u4fe1\u606f\u8fdb\u884c\u89c6\u89c9\u95ee\u7b54\uff0c\u5305\u542b\u573a\u666f\u6587\u672c\u95ee\u7b54\u4efb\u52a1 \u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u81ea\u7136\u8bed\u8a00\u5904\u7406 2019 \u82f1\u8bed 23,038 \u5f20\u56fe\u7247\uff0c31,791 \u4e2a\u95ee\u7b54\u5bf9 \u897f\u73ed\u7259\u5df4\u585e\u7f57\u90a3\u81ea\u6cbb\u5927\u5b66 \u89c6\u89c9\u95ee\u7b54\u3001\u6a21\u578b\u8bc4\u4f30 Hugging Face \u5426 \u662f \u8bad\u7ec3 + \u8bc4\u4f30 NAF \u63d0\u4f9b\u8868\u5355\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u542b\u6587\u672c\u8fb9\u754c\u6846\u3001\u7c7b\u522b\u3001\u5173\u7cfb\u548c\u8f6c\u5f55\u4fe1\u606f \u6587\u6863\u5206\u6790\u4e0e\u8868\u5355\u7406\u89e3 2019 \u82f1\u8bed 708 \u5f20\u8bad\u7ec3\u56fe\u50cf\uff0c75 \u5f20\u9a8c\u8bc1\u56fe\u50cf\uff0c77 \u5f20\u6d4b\u8bd5\u56fe\u50cf\uff1b \u7f8e\u56fd\u56fd\u5bb6\u6863\u6848\u9986\u3001FamilySearch\u3001Brian Davis\uff08\u4e2a\u4eba\u7814\u7a76\u8005\uff09 \u8868\u5355\u89e3\u6790\u3001\u6587\u6863\u7406\u89e3 GitHub \u5426 \u662f \u8bad\u7ec3 + \u8bc4\u4f30 InfoVQA \u7528\u4e8e\u4fe1\u606f\u56fe\u8868\u89c6\u89c9\u95ee\u7b54\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u6837\u5316\u4fe1\u606f\u56fe\u8868\u53ca\u95ee\u7b54\u6ce8\u91ca \u4fe1\u606f\u53ef\u89c6\u5316\u4e0e\u95ee\u7b54 2021 \u82f1\u8bed 5,485 \u5f20\u56fe\u7247\uff0c30,035 \u4e2a\u95ee\u7b54\u5bf9\uff08\u8bad\u7ec3\u96c6 4,406 \u5f20\u56fe\u7247\uff0c23,946 \u4e2a\u95ee\u7b54\u5bf9\uff1b\u9a8c\u8bc1\u96c6 500 \u5f20\u56fe\u7247\uff0c2,801 \u4e2a\u95ee\u7b54\u5bf9\uff1b\u6d4b\u8bd5\u96c6 579 \u5f20\u56fe\u7247\uff0c3,288 \u4e2a\u95ee\u7b54\u5bf9\uff09 Minesh Mathew \u7b49\u7814\u7a76\u8005 \u4fe1\u606f\u56fe\u8868\u7406\u89e3\u3001\u89c6\u89c9\u95ee\u7b54 DocVQA \u5426 \u662f \u8bad\u7ec3 + \u8bc4\u4f30 HME100K \u5927\u89c4\u6a21\u624b\u5199\u6570\u5b66\u8868\u8fbe\u5f0f\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u624b\u5199\u6570\u5b66\u8868\u8fbe\u5f0f\u8bc6\u522b\u4efb\u52a1 \u6570\u5b66\u8868\u8fbe\u5f0f\u8bc6\u522b 2022 \u4e2d\u82f1\u53cc\u8bed 10 \u4e07\u5f20\u624b\u5199\u6570\u5b66\u8868\u8fbe\u5f0f\u56fe\u50cf\uff0c\u5305\u542b 245 \u4e2a\u7b26\u53f7\u7c7b\u522b\uff08\u8bad\u7ec3\u96c6 74,502 \u5f20\u56fe\u50cf\uff0c\u6d4b\u8bd5\u96c6 24,607 \u5f20\u56fe\u50cf\uff09 Ye Yuan \u624b\u5199\u6570\u5b66\u8868\u8fbe\u5f0f\u8bc6\u522b GitHub \u662f \u5426 \u8bad\u7ec3 + \u8bc4\u4f30 OCRVQA OCR\u2011VQA\u2011200K\u542b20\u4e07\u5c01\u9762\u548c100\u4e07\u95ee\u7b54\uff0c\u6a21\u677f\u751f\u6210\u6539\u5199\u95ee\u9898\uff0c\u6807\u6ce8\u6587\u672c\u5757\u5e76\u5212\u5206\u8bad\u7ec3\u9a8c\u8bc1\u6d4b\u8bd5 \u573a\u666f\u6587\u672c\u7406\u89e3 2019 \u82f1\u6587 207k QA\u5bf9/92k\u56fe\u50cf \u4f50\u6cbb\u4e9a\u7406\u5de5\u5b66\u9662 OCR\u95ee\u7b54\u3001\u89c6\u89c9\u63a8\u7406 https://ocr-vqa.github.io/ \u5426 \u662f \u8bad\u7ec3/\u8bc4\u4f30 SROIE \u626b\u63cf\u6536\u636e\u6587\u672c\u68c0\u6d4b\u4e0e\u8bc6\u522b\u4efb\u52a1 \u6587\u6863\u7406\u89e3 2019 \u82f1\u6587/\u4e2d\u6587 1k \u6536\u636e\u56fe\u50cf ICDAR\u7ade\u8d5b KIE (\u5173\u952e\u4fe1\u606f\u62bd\u53d6) HuggingFace \u8bba\u6587 \u5426 \u662f \u8bc4\u4f30\u57fa\u51c6 POIE \u9762\u5411POI-Query\u7684\u65b0\u9896\u6587\u6863\u7ea7\u4fe1\u606f\u62bd\u53d6\u6570\u636e\u96c6 \u5730\u7406\u6587\u672c\u7406\u89e3 2023 \u82f1\u6587+\u591a\u8bed\u8a00 72k \u56fe\u50cf \u963f\u91cc/\u4e2d\u5c71\u5927\u5b66 \u6587\u6863\u4fe1\u606f\u62bd\u53d6 GitHub \u8bba\u6587 \u5426 \u662f \u8bad\u7ec3/\u8bc4\u4f30 CTW \u4e2d\u6587\u8857\u666f\u6587\u672c\u68c0\u6d4b\u6570\u636e\u96c6 \u573a\u666f\u6587\u672c\u68c0\u6d4b 2017 \u4e2d\u6587 32.5k \u56fe\u50cf  1M+\u5b57\u7b26 \u534e\u4e2d\u79d1\u6280\u5927\u5b66 \u7aef\u5230\u7aef\u6587\u672c\u8bc6\u522b \u5b98\u7f51 \u8bba\u6587 \u662f \u5426 \u8bc4\u4f30\u57fa\u51c6 SynthText \u5408\u6210\u573a\u666f\u6587\u672c\u56fe\u50cf\u6570\u636e\u96c6 \u573a\u666f\u6587\u672c\u68c0\u6d4b 2016 \u82f1\u6587 80\u4e07\u5f20\u5408\u6210\u56fe\u50cf \u725b\u6d25\u5927\u5b66VGG \u6587\u672c\u68c0\u6d4b\u9884\u8bad\u7ec3 GitHub \u8bba\u6587 \u662f \u5426 \u8bad\u7ec3 Art \u5305\u542b\u4e0e\u827a\u672f\u76f8\u5173\u7684\u6545\u4e8b\u6027\u95ee\u9898\u548c\u7b54\u6848\u5bf9\uff0c\u6d89\u53ca\u827a\u672f\u4f5c\u54c1\u7684\u89c6\u89c9\u548c\u77e5\u8bc6\u7406\u89e3 \u827a\u672f 2020 \u82f1\u8bed QA\u5bf9\u6570\u91cf\uff1a\u8bad\u7ec3\u96c669,812\u5bf9\uff0c\u9a8c\u8bc1\u96c65,124\u5bf9\uff0c\u6d4b\u8bd5\u96c64,912\u5bf9 Allen Institute for AI \u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u7814\u7a76 Hugging Face \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 LSVT \u5927\u89c4\u6a21\u8857\u666f\u89c6\u56fe\u6587\u672c\u6570\u636e\u96c6\uff0c\u5305\u542b\u90e8\u5206\u6807\u6ce8\u7684\u6587\u672c\u68c0\u6d4b\u548c\u8bc6\u522b\u6311\u6218\u6570\u636e \u573a\u666f\u6587\u672c\u8bc6\u522b 2019 \u4e2d\u6587 450,000\u5f20\u56fe\u50cf\uff0c\u5176\u4e2d30,000\u5f20\u5168\u6807\u6ce8\uff0c400,000\u5f20\u5f31\u6807\u6ce8 \u534e\u4e3a\u8bfa\u4e9a\u65b9\u821f\u5b9e\u9a8c\u5ba4\u3001\u534e\u4e2d\u79d1\u6280\u5927\u5b66 \u573a\u666f\u6587\u672c\u68c0\u6d4b\u548c\u8bc6\u522b\u7814\u7a76 Hugging Face \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 RCTW-17 \u7528\u4e8e\u8bfb\u53d6\u56fe\u50cf\u4e2d\u4e2d\u6587\u6587\u672c\u7684\u7ade\u8d5b\u6570\u636e\u96c6\uff0c\u5305\u542b\u8857\u666f\u3001\u6d77\u62a5\u3001\u83dc\u5355\u7b49\u591a\u79cd\u573a\u666f\u56fe\u50cf \u573a\u666f\u6587\u672c\u8bc6\u522b 2017 \u4e2d\u6587 12,263\u5f20\u6807\u6ce8\u56fe\u50cf \u534e\u4e2d\u79d1\u6280\u5927\u5b66\u3001Megvii Technology Inc.\u3001Cornell University\u7b49 \u4e2d\u6587\u573a\u666f\u6587\u672c\u68c0\u6d4b\u548c\u8bc6\u522b RCTW\u5b98\u7f51 \u5426 \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 ReCTS \u591a\u65b9\u5411\u81ea\u7136\u573a\u666f\u6587\u672c\u6570\u636e\u96c6\uff0c\u5305\u542b\u62db\u724c\u4e0a\u7684\u6587\u672c\u884c\u548c\u5b57\u7b26\u4f4d\u7f6e\u53ca\u5b57\u7b26\u4ee3\u7801\u6807\u6ce8 \u573a\u666f\u6587\u672c\u8bc6\u522b 2019 \u4e2d\u6587 25,000\u5f20\u56fe\u50cf\uff0c\u7ea6200,000\u6761\u6587\u672c\u884c\u548c600,000\u4e2a\u5b57\u7b26\u6807\u6ce8 \u534e\u4e2d\u79d1\u6280\u5927\u5b66\u3001\u52a0\u5dde\u5927\u5b66\u6d1b\u6749\u77f6\u5206\u6821\u3001\u5fae\u8f6f\u4e9a\u6d32\u7814\u7a76\u9662 \u4e2d\u6587\u573a\u666f\u6587\u672c\u68c0\u6d4b\u548c\u8bc6\u522b OpenDataLab \u5426 \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 MTWI \u591a\u6837\u5f0f\u7f51\u7edc\u56fe\u50cf\u6587\u5b57\u68c0\u6d4b\u4e0e\u8bc6\u522b\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e2d\u82f1\u6587\u6807\u6ce8 \u573a\u666f\u6587\u672c\u8bc6\u522b 2022 \u4e2d\u82f1 10\u4e07+\u56fe\u50cf\uff0c\u5305\u542b\u4e2d\u82f1\u6587\u6807\u6ce8\uff0c\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u5212\u5206 \u963f\u91cc\u5df4\u5df4 OCR\u68c0\u6d4b\u4e0e\u8bc6\u522b\u7814\u7a76 ModelScope \u5426 \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 TextVQA \u9700\u8981\u6a21\u578b\u8bfb\u53d6\u56fe\u50cf\u4e2d\u7684\u6587\u5b57\u4ee5\u56de\u7b54\u95ee\u9898\u7684\u6570\u636e\u96c6 \u89c6\u89c9\u95ee\u7b54 2019 \u82f1\u8bed 45,336\u4e2a\u95ee\u9898\uff0c28,408\u5f20\u56fe\u50cf Facebook AI Research \u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u7814\u7a76 Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 CASIA \u56fe\u50cf\u7be1\u6539\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9e\u548c\u7be1\u6539\u56fe\u50cf\u7684\u6807\u6ce8 \u56fe\u50cf\u7be1\u6539\u68c0\u6d4b 2013 \u4e2d\u82f1 5,123\u5f20\u7be1\u6539\u56fe\u50cf\uff0c1,701\u5f20\u771f\u5b9e\u56fe\u50cf CASIA\u5b9e\u9a8c\u5ba4 \u56fe\u50cf\u7be1\u6539\u68c0\u6d4b\u7814\u7a76 GitHub \u5426 \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 TextOCR \u9488\u5bf9\u4efb\u610f\u5f62\u72b6\u573a\u666f\u6587\u672c\u7684\u68c0\u6d4b\u548c\u8bc6\u522b\u6570\u636e\u96c6 \u573a\u666f\u6587\u672c\u8bc6\u522b 2021 \u82f1\u8bed 28,000\u5f20\u56fe\u50cf\uff0c900,000\u4e2a\u5355\u8bcd\u6807\u6ce8 Facebook AI Research OCR\u68c0\u6d4b\u4e0e\u8bc6\u522b\u7814\u7a76 Kaggle \u5426 \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 Chinese-OCR \u5305\u542b\u4e30\u5bcc\u62cd\u6444\u573a\u666f\u7684\u4e2d\u6587OCR\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6742\u5fd7\u3001\u62a5\u7eb8\u7b49\u591a\u79cd\u91c7\u96c6\u73af\u5883 \u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001OCR 2024 \u4e2d\u6587 5027 \u5f20\u56fe\u7247 \u5317\u4eac\u5b89\u6377\u667a\u5408\u79d1\u6280\u6709\u9650\u516c\u53f8 \u4e2d\u6587OCR\u8bc6\u522b Hugging Face \u5426 \u5426 \u8bc4\u4f30 EATEN \u63d0\u4f9b\u5b9e\u4f53\u611f\u77e5\u7684\u5355\u6b21\u89c6\u89c9\u6587\u672c\u63d0\u53d6\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9e\u548c\u5408\u6210\u7968\u636e\u3001\u62a4\u7167\u7b49\u56fe\u50cf \u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001OCR 2019 \u4e2d/\u82f1/\u6570\u5b57 60 \u4e07\u5408\u6210\u56fe\u50cf\uff0c300k \u771f\u5b9e\u56fe\u50cf \u767e\u5ea6\u89c6\u89c9\u6280\u672f\u90e8 \u5b9e\u4f53\u63d0\u53d6\u3001OCR\u540e\u6821\u6b63 GitHub \u5426 \u5426 \u8bad\u7ec3/\u8bc4\u4f30 COCO-Text \u5927\u89c4\u6a21\u81ea\u7136\u573a\u666f\u6587\u672c\u68c0\u6d4b\u548c\u8bc6\u522b\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u4e86\u6587\u672c\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u548c\u8f6c\u5f55\u4fe1\u606f \u8ba1\u7b97\u673a\u89c6\u89c9\u3001OCR 2016 \u82f1\u6587 63,686 \u5f20\u56fe\u7247\uff0c173,589 \u4e2a\u6807\u6ce8\u6587\u672c\u5b9e\u4f8b Microsoft COCO \u573a\u666f\u6587\u672c\u68c0\u6d4b\u4e0e\u8bc6\u522b COCO-Text \u5426 \u5426 \u8bad\u7ec3/\u8bc4\u4f30 Synthetic Arxiv OCR \u4ecearXiv\u6316\u6398\u7684\u79d1\u5b66\u6587\u732e\u5408\u6210OCR\u6570\u636e\u96c6\uff0c\u7528\u4e8eOCR\u540e\u6821\u6b63\u6a21\u578b\u8bad\u7ec3 \u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001OCR 2023 \u82f1\u6587 2.03 \u4ebf\u5b57\u7b26\u5bf9 University of Illinois OCR\u540e\u6821\u6b63 GitHub \u5426 \u5426 \u8bad\u7ec3 ChartQA \u7528\u4e8e\u56fe\u8868\u95ee\u7b54\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u89c6\u89c9\u548c\u903b\u8f91\u63a8\u7406\u95ee\u9898\uff0c\u6db5\u76d6\u67f1\u72b6\u56fe\u3001\u6298\u7ebf\u56fe\u7b49 \u6570\u636e\u53ef\u89c6\u5316\u3001\u95ee\u7b54 2022 \u82f1\u6587 20,882 \u5f20\u56fe\u8868\uff0c32,719 \u4e2a\u95ee\u7b54\u5bf9 York University, Nanyang Technological University \u56fe\u8868\u95ee\u7b54\u3001\u89c6\u89c9\u63a8\u7406 Hugging Face \u662f \u662f \u8bad\u7ec3/\u8bc4\u4f30 MMTab \u5b66\u672f\u6587\u6863\u4e2d\u8868\u683c\u56fe\u50cf\u4e0e\u5176\u7ed3\u6784\u5316LaTeX\u6e90\u7801\u7684\u5bf9\u9f50\u6570\u636e\u96c6 \u8868\u683c\u56fe\u50cf\u5904\u7406 2024 \u82f1\u6587 22,081 table images \u590d\u65e6\u5927\u5b66 \u8868\u683c\u56fe\u50cf\u8bc6\u522b\u3001\u8868\u683c\u7ed3\u6784\u91cd\u5efa HuggingFace \u5426 \u5426 \u8bad\u7ec3 + \u8bc4\u4f30 PlotQA \u542b\u590d\u6742\u771f\u5b9e\u4e16\u754c\u56fe\u8868\uff08\u6298\u7ebf/\u67f1\u72b6/\u997c\u56fe\uff09\u7684\u53ef\u89c6\u5316\u95ee\u7b54\u6570\u636e\u96c6 \u56fe\u8868\u7406\u89e3 2019 \u82f1\u6587 224,377 \u56fe\u8868 (28.9M QA pairs) IBM Research \u8bc4\u4f30\u6a21\u578b\u5bf9\u56fe\u8868\u5185\u5bb9\u7684\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b GitHub \u5426 \u5426 \u4e3b\u8981\u8bc4\u4f30 FigureQA \u57fa\u4e8e\u5408\u6210\u56fe\u8868\u7684\u4e8c\u5206\u7c7b\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6 \u56fe\u8868\u7406\u89e3 2017 \u82f1\u6587 1,327,368 QA pairs (100k+ images) Maluuba/Microsoft \u6d4b\u8bd5\u6a21\u578b\u5bf9\u57fa\u672c\u56fe\u8868\u5143\u7d20\uff08\u6761\u5f62\u56fe/\u6298\u7ebf\u56fe\uff09\u7684\u7406\u89e3 Official \u5426 \u5426 \u4e3b\u8981\u8bc4\u4f30 VisText \u6587\u672c\u5bc6\u96c6\u578b\u56fe\u50cf\uff08\u6d77\u62a5\u3001\u622a\u56fe\u3001\u6587\u6863\uff09\u7684\u7aef\u5230\u7aef\u6587\u672c\u8bc6\u522b &amp; \u56fe\u6587\u95ee\u7b54\u6570\u636e\u96c6 \u6587\u672c\u8bc6\u522b &amp; \u89c6\u89c9\u95ee\u7b54 2023 \u82f1\u6587 646,605 \u56fe\u50cf\uff083.2M QA pairs\uff09 MIT &amp; Google \u573a\u666f\u6587\u672c\u8bc6\u522b(VQA)\u3001\u7aef\u5230\u7aef\u6587\u6863\u7406\u89e3 HuggingFace \u662f \u662f \u8bad\u7ec3 + \u8bc4\u4f30 LRV-Instruction \u6587\u6863\u5bc6\u96c6\u578b\u591a\u6a21\u6001\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\uff08\u6587\u6863\u3001\u56fe\u8868\u3001\u8868\u683c\u3001\u56fe\u793a\u7b49\uff09 \u591a\u6a21\u6001\u6307\u4ee4\u5fae\u8c03 2023 \u591a\u8bed\u8a00 738k \u89c6\u89c9\u6587\u6863\u6307\u4ee4\u6837\u672c \u82cf\u9ece\u4e16\u8054\u90a6\u7406\u5de5\u5b66\u9662 \u63d0\u5347\u5927\u6a21\u578b\u5728\u89c6\u89c9\u6587\u6863\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u4e0e\u63a8\u7406\u80fd\u529b HuggingFace \u662f \u662f \u8bad\u7ec3\uff08\u6307\u4ee4\u5fae\u8c03\uff09 ArxivQA \u4ecearXiv\u8bba\u6587\u63d0\u53d6\u7684\u56fe\u8868\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b\u79d1\u5b66\u56fe\u8868\u7406\u89e3\u4efb\u52a1 \u591a\u6a21\u6001\u79d1\u5b66\u56fe\u8868\u7406\u89e3 2024 \u82f1\u6587 60\u4e07+\u56fe\u50cf/\u95ee\u9898 \u9999\u6e2f\u4e2d\u6587\u5927\u5b66\u3001\u5fae\u8f6f\u7b49 \u8bad\u7ec3\u4e0e\u8bc4\u4f30\u5927\u6a21\u578b\u5bf9\u79d1\u5b66\u56fe\u8868\u7684\u7406\u89e3\u80fd\u529b Hugging Face \u5426 \u662f \u8bad\u7ec3/\u8bc4\u4f30 TabMWP \u8868\u683c\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\uff0c\u9700\u7ed3\u5408\u8868\u683c\u548c\u6587\u672c\u8fdb\u884c\u6570\u5b66\u63a8\u7406 \u534a\u7ed3\u6784\u5316\u6570\u5b66\u63a8\u7406 2023 \u82f1\u6587 3.8\u4e07\u95ee\u9898 UCLA\u3001\u827e\u4f26\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u6240\u7b49 \u8bc4\u4f30\u6a21\u578b\u5bf9\u8868\u683c\u6570\u636e\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b GitHub \u5426 \u5426 \u8bc4\u4f30 MMC-Inst \u5927\u89c4\u6a21\u591a\u6a21\u6001\u56fe\u8868\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u8986\u76d6\u591a\u79cd\u56fe\u8868\u7c7b\u578b\u548c\u4efb\u52a1 \u901a\u7528\u56fe\u8868\u7406\u89e3 2024 \u82f1\u6587 60\u4e07\u6307\u4ee4\u6837\u672c \u5fae\u8f6f\u3001\u534e\u76db\u987f\u5927\u5b66\u7b49 \u8bad\u7ec3\u56fe\u8868\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08\u5982MMCA\uff09 Hugging Face \u662f \u662f \u8bad\u7ec3 DVQA \u67f1\u72b6\u56fe\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u56fe\u8868\u7ed3\u6784\u7406\u89e3\u80fd\u529b \u8ba1\u7b97\u673a\u89c6\u89c9/\u56fe\u8868\u7406\u89e3 2018 \u82f1\u6587 3.5\u4e07\u56fe\u50cf/\u95ee\u7b54 \u7f57\u5207\u65af\u7279\u7406\u5de5\u5b66\u9662\u7b49 \u8bc4\u4f30\u56fe\u8868\u89e3\u6790\u7b97\u6cd5\u7684\u9c81\u68d2\u6027 GitHub \u5426 \u662f \u8bc4\u4f30 UniChart \u901a\u7528\u56fe\u8868\u7406\u89e3\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u652f\u6301\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\uff08QA/\u6458\u8981/\u8868\u683c\u63d0\u53d6\u7b49\uff09 \u591a\u6a21\u6001\u56fe\u8868\u7406\u89e3 2023 \u82f1\u6587 \u672a\u516c\u5f00\u5177\u4f53\u89c4\u6a21 \u79d1\u514b\u5927\u5b66\u3001\u897f\u8499\u83f2\u838e\u5927\u5b66\u7b49 \u63d0\u4f9b\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5fae\u8c03\u80fd\u529b Gitging Face \u662f \u662f \u8bad\u7ec3/\u8bc4\u4f30 SimChart9K \u5408\u6210\u7684\u56fe\u8868\u6570\u636e\u96c6\uff0c\u901a\u8fc7LLM\u751f\u6210\u7edf\u8ba1\u6570\u636e\u548c\u7ed8\u56fe\u4ee3\u7801\uff0c\u7528\u4e8e\u589e\u5f3a\u56fe\u8868\u611f\u77e5\u548c\u63a8\u7406 \u56fe\u8868\u7406\u89e3\u3001\u591a\u6a21\u6001 2024 \u82f1\u6587\u4e3a\u4e3b 9,536\u5f20\u56fe\u8868 \u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u3001\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66 \u56fe\u8868\u9884\u8bad\u7ec3/\u5fae\u8c03 GitHub \u5426 \u5426 \u9884\u8bad\u7ec3 Chart2Text \u4eceStatista\u6293\u53d6\u7684\u7edf\u8ba1\u56fe\u8868\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u56fe\u8868\u6458\u8981 \u56fe\u8868\u6458\u8981\u3001\u81ea\u7136\u8bed\u8a00\u751f\u6210 2019 \u82f1\u6587 8,305\u5f20\u56fe\u8868 \u6ed1\u94c1\u5362\u5927\u5b66 \u56fe\u8868\u6458\u8981\u751f\u6210\u8bad\u7ec3\u4e0e\u8bc4\u4f30 GitHub \u662f \u5426 \u8bad\u7ec3/\u8bc4\u4f30 FinTabNet \u9488\u5bf9\u8868\u683c\u8bc6\u522b\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u542b\u590d\u6742\u8868\u683c\u7ed3\u6784 \u8868\u683c\u8bc6\u522b\u3001OCR 2024 \u4e2d\u82f1\u53cc\u8bed 112,332\u5f20\u8868\u683c \u534e\u5357\u7406\u5de5\u5927\u5b66\u3001\u817e\u8baf\u4f18\u56fe \u8868\u683c\u7ed3\u6784\u8bc6\u522b\u8bad\u7ec3\u4e0e\u8bc4\u4f30 HuggingFace \u5426 \u5426 \u8bad\u7ec3/\u8bc4\u4f30 SciTSR \u7528\u4e8e\u590d\u6742\u8868\u683c\u7ed3\u6784\u8bc6\u522b\u7684\u6570\u636e\u96c6\uff0c\u5305\u542bPDF\u683c\u5f0f\u7684\u8868\u683c\u53ca\u5176\u7ed3\u6784\u6807\u7b7e\uff0c\u4eceLaTeX\u6e90\u6587\u4ef6\u4e2d\u83b7\u53d6 \u6587\u6863\u5206\u6790 2019 \u82f1\u6587 15,000 (\u8bad\u7ec312,000/\u6d4b\u8bd53,000) \u5317\u4eac\u7406\u5de5\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u6280\u672f\u7cfb \u8868\u683c\u7ed3\u6784\u8bc6\u522b\u548c\u6a21\u578b\u8bad\u7ec3 GitHub \u5426 \u5426 \u8bad\u7ec3/\u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#5-kownledge","title":"5. Kownledge","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 KVQA \u4e16\u754c\u4e0a\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u4e16\u754c\u77e5\u8bc6\u7684\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b 183K \u95ee\u7b54\u5bf9\uff0c\u6d89\u53ca 18K \u547d\u540d\u5b9e\u4f53\u548c 24K \u56fe\u50cf \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u4eba\u5de5\u667a\u80fd 2019 \u82f1\u8bed 183K \u95ee\u7b54\u5bf9\uff0c24K \u56fe\u50cf IISC \u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u7279\u522b\u662f\u9700\u8981\u4e16\u754c\u77e5\u8bc6\u7684\u95ee\u7b54 KVQA \u5b98\u65b9\u7f51\u7ad9 \u662f \u662f \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30 A-OKVQA \u4e00\u4e2a\u9700\u8981\u5e7f\u6cdb\u5e38\u8bc6\u548c\u4e16\u754c\u77e5\u8bc6\u6765\u56de\u7b54\u7684\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ea6 25K \u95ee\u9898\uff0c\u8981\u6c42\u6a21\u578b\u8fdb\u884c\u5e38\u8bc6\u63a8\u7406 \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2022 \u82f1\u8bed \u7ea6 25K \u95ee\u9898\uff0c23.7K \u56fe\u50cf Allen Institute for AI \u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u7279\u522b\u662f\u9700\u8981\u5e38\u8bc6\u548c\u4e16\u754c\u77e5\u8bc6\u7684\u95ee\u7b54 Hugging Face A-OKVQA \u662f \u662f \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30 ViQuAE \u4e00\u4e2a\u5173\u4e8e\u547d\u540d\u5b9e\u4f53\u7684\u77e5\u8bc6\u578b\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b 1190 \u4e2a\u8bad\u7ec3\u6837\u672c\u30011250 \u4e2a\u9a8c\u8bc1\u6837\u672c\u548c 1257 \u4e2a\u6d4b\u8bd5\u6837\u672c \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2022 \u82f1\u8bed 1190 \u8bad\u7ec3\u6837\u672c\uff0c1250 \u9a8c\u8bc1\u6837\u672c\uff0c1257 \u6d4b\u8bd5\u6837\u672c Paul Lerner \u7b49\u4eba \u7528\u4e8e\u77e5\u8bc6\u578b\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5173\u4e8e\u547d\u540d\u5b9e\u4f53\u7684\u95ee\u7b54 GitHub ViQuAE \u662f \u662f \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30 IconQA IconQA \u662f\u4e00\u4e2a\u62bd\u8c61\u56fe\u8868\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\uff0c\u5305\u542b\u56fe\u8868\u548c\u76f8\u5173\u95ee\u9898\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u56fe\u8868\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\u3002 \u56fe\u8868\u7406\u89e3 2021 \u82f1\u8bed 10\u4e07\u4e2a\u56fe\u8868\u53ca\u76f8\u5173\u95ee\u9898 \u65b0\u52a0\u5761\u79d1\u6280\u8bbe\u8ba1\u5927\u5b66 \u56fe\u6807\u7406\u89e3\u8bc4\u4f30 https://opendatalab.com/OpenDataLab/IconQA \u5426 \u662f \u8bc4\u4f30 VisualMRC \u673a\u5668\u9605\u8bfb\u7406\u89e3\u4efb\u52a1\uff0c\u7ed9\u5b9a\u95ee\u9898\u548c\u6587\u6863\u56fe\u50cf\uff0c\u6a21\u578b\u9700\u751f\u6210\u81ea\u7136\u8bed\u8a00\u7b54\u6848 \u6587\u6863\u7406\u89e3 2021 \u4e2d/\u82f1 10,197\u5f20\u56fe\u50cf\uff0c30,562\u4e2a\u95ee\u7b54\u5bf9 NTT Media Intelligence Laboratories \u7528\u4e8e\u673a\u5668\u9605\u8bfb\u7406\u89e3\u548c\u6587\u6863\u7406\u89e3\u7814\u7a76 HuggingFace \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 ChemVLM Data \u7528\u4e8e\u5316\u5b66\u9886\u57df\u7684\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u542b\u5316\u5b66\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u606f \u5316\u5b66 2024 \u4e2d/\u82f1 \u6570\u636e\u89c4\u6a21\u672a\u660e\u786e\uff0c\u5305\u542b\u591a\u79cd\u5316\u5b66\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e Shanghai Artificial Intelligence Laboratory \u7b49 \u7528\u4e8e\u5316\u5b66\u9886\u57df\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u63a8\u7406 GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 ScienceQA \u5305\u542b\u79d1\u5b66\u4e3b\u9898\u7684\u591a\u6a21\u6001\u591a\u9879\u9009\u62e9\u9898\uff0c\u6db5\u76d6\u81ea\u7136\u79d1\u5b66\u3001\u793e\u4f1a\u79d1\u5b66\u548c\u8bed\u8a00\u79d1\u5b66 \u79d1\u5b66\u6559\u80b2 2022 \u82f1\u6587 21,208\u4e2a\u95ee\u9898\uff0c\u6db5\u76d6\u591a\u79cd\u79d1\u5b66\u4e3b\u9898\u548c\u591a\u6a21\u6001\u4e0a\u4e0b\u6587 UCLA \u548c Allen Institute for AI \u7528\u4e8e\u79d1\u5b66\u95ee\u9898\u89e3\u7b54\u548c\u591a\u6a21\u6001\u63a8\u7406\u7814\u7a76 HuggingFace \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 AI2D \u5305\u542b\u8d85\u8fc75000\u5f20\u5c0f\u5b66\u79d1\u5b66\u56fe\u8868\u548c\u8d85\u8fc7150000\u4e2a\u4e30\u5bcc\u6ce8\u91ca\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6 \u79d1\u5b66\u6559\u80b2 2016 \u82f1\u6587 5000+\u5f20\u56fe\u50cf\uff0c150000+\u4e2a\u6ce8\u91ca\uff0c15000+\u4e2a\u591a\u9879\u9009\u62e9\u9898 Allen Institute for AI \u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\u548c\u56fe\u8868\u7406\u89e3\u7814\u7a76 HuggingFace \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 TQA \u7528\u4e8e\u89e3\u51b3\u6559\u79d1\u4e66\u95ee\u7b54\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u6587\u672c\u548c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u8f93\u5165\u3002 \u6559\u80b2/\u79d1\u5b66 2017 \u82f1\u8bed 1076 \u8bfe\uff0c26,260 \u4e2a\u95ee\u9898\uff0c78,338 \u4e2a\u53e5\u5b50\uff0c3,455 \u5f20\u56fe\u50cf AI2 (Allen Institute for AI) \u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u95ee\u7b54\u6a21\u578b Hugging Face \u662f \u662f \u8bad\u7ec3/\u8bc4\u4f30 Wikipedia-QA \u7528\u4e8e\u5f00\u653e\u57df\u95ee\u7b54\u7814\u7a76\u7684\u95ee\u7b54\u8bed\u6599\u5e93\uff0c\u4ece\u7ef4\u57fa\u767e\u79d1\u4e2d\u6536\u96c6\u7684\u95ee\u9898\u548c\u53e5\u5b50\u5bf9\u3002 \u5f00\u653e\u57df\u95ee\u7b54 2015 \u82f1\u8bed \u8bad\u7ec3\u96c6 20,360 \u4e2a\u6837\u672c\uff0c\u9a8c\u8bc1\u96c6 2,733 \u4e2a\u6837\u672c\uff0c\u6d4b\u8bd5\u96c6 6,165 \u4e2a\u6837\u672c Microsoft Research \u8bad\u7ec3\u548c\u8bc4\u4f30\u5f00\u653e\u57df\u95ee\u7b54\u6a21\u578b Hugging Face \u5426 \u5426 \u8bad\u7ec3/\u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#6-grounding","title":"6. Grounding","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 GRIT GRIT\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u652f\u6301\u591a\u79cd\u4f4d\u7f6e\u611f\u77e5\u7684\u5355\u6a21\u6001/\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u5982\u77ed\u8bed\u5b9a\u4f4d\u3001\u6307\u4ee3\u8868\u8fbe\u5f0f\u7406\u89e3\u548c\u751f\u6210\u7b49\u3002 \u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406 2024 \u4e2d\u6587\u3001\u82f1\u6587 \u7ea69061\u4e07\u5f20\u56fe\u50cf\uff0c1.15\u4ebf\u4e2a\u6587\u672c\u7247\u6bb5\uff0c1.37\u4ebf\u4e2a\u5173\u8054\u7684\u8fb9\u754c\u6846 Microsoft Research \u7528\u4e8e\u63d0\u5347\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u591a\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0 Hugging Face \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 gRefCOCO gRefCOCO \u6570\u636e\u96c6\u4e3b\u8981\u7528\u4e8e\u56fe\u50cf\u4e2d\u5bf9\u8c61\u7684\u5f15\u7528\u8868\u8fbe\uff0c\u5305\u542b\u4e86\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u6307\u4ee4\uff0c\u901a\u8fc7\u8fd9\u4e9b\u6307\u4ee4\u6765\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u7684\u5bf9\u8c61\u3002 \u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u56fe\u50cf\u68c0\u7d22\uff0c\u89c6\u89c9\u95ee\u7b54 2016 \u82f1\u6587 \u7ea620,000\u5f20\u56fe\u50cf\uff0c\u5305\u542b\u8d85\u8fc7142,000\u6761\u5f15\u7528 UC Berkeley \u5bf9\u8c61\u5b9a\u4f4d\uff0c\u56fe\u50cf\u68c0\u7d22\uff0c\u89c6\u89c9\u95ee\u7b54 \u94fe\u63a5 \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 Objects365 \u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5305\u542b365\u4e2a\u7c7b\u522b\u3001200\u4e07\u5f20\u56fe\u7247\u548c3000\u4e07\u4e2a\u8fb9\u754c\u6846 \u8ba1\u7b97\u673a\u89c6\u89c9 2019 \u4e2d\u6587/\u82f1\u6587 365\u4e2a\u7c7b\u522b\uff0c200\u4e07\u5f20\u56fe\u7247\uff0c3000\u4e07\u4e2a\u8fb9\u754c\u6846 Objects365 Consortium \u76ee\u6807\u68c0\u6d4b\u3001\u7279\u5f81\u5b66\u4e60\u7b49 Objects365\u5b98\u7f51 \u5426 \u5426 \u8bad\u7ec3/\u8bc4\u4f30 RefCOCO \u4e00\u4e2a\u81ea\u7136\u8bed\u8a00\u5f15\u7528\u8868\u8fbe\u6570\u636e\u96c6\uff0c\u5305\u542b19,894\u5f20\u7167\u7247\u4e2d\u768496,654\u4e2a\u5bf9\u8c61\u7684130,525\u4e2a\u8868\u8fbe \u8ba1\u7b97\u673a\u89c6\u89c9 2014 \u82f1\u6587 19,894\u5f20\u7167\u7247\uff0c96,654\u4e2a\u5bf9\u8c61\uff0c130,525\u4e2a\u8868\u8fbe UNC\uff08\u5317\u5361\u7f57\u6765\u7eb3\u5927\u5b66\u6559\u5802\u5c71\u5206\u6821\uff09 \u81ea\u7136\u8bed\u8a00\u5f15\u7528\u8868\u8fbe\u7814\u7a76\u7b49 Hugging Face \u662f \u5426 \u8bc4\u4f30 RefCOCO+/g RefCOCO\u7684\u6269\u5c55\u7248\u672c\uff0c\u6392\u9664\u4e86\u4f4d\u7f6e\u4ecb\u8bcd\uff0c\u5305\u542b\u66f4\u4e30\u5bcc\u8bed\u4e49\u7684\u8868\u8fbe \u8ba1\u7b97\u673a\u89c6\u89c9 2015 \u82f1\u6587 \u57fa\u4e8eRefCOCO\u6269\u5c55\uff0c\u5177\u4f53\u89c4\u6a21\u672a\u660e\u786e\uff0c\u4f46\u5305\u542b\u66f4\u590d\u6742\u7684\u8bed\u4e49\u8868\u8fbe UNC\uff08\u5317\u5361\u7f57\u6765\u7eb3\u5927\u5b66\u6559\u5802\u5c71\u5206\u6821\uff09 \u81ea\u7136\u8bed\u8a00\u5f15\u7528\u8868\u8fbe\u7814\u7a76\u7b49 GitHub - refer \u662f \u5426 \u8bc4\u4f30 GPT4Gen-RD-BoxCoT \u7528\u4e8e\u591a\u6a21\u6001\u5bf9\u8bdd\u548c\u6307\u4ee3\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u6307\u4ee3\u5bf9\u8bdd\u548c\u5e26\u6846\u7684CoT\u6570\u636e \u591a\u6a21\u6001\u5bf9\u8bdd\u3001\u89c6\u89c9\u95ee\u7b54 2023 \u82f1\u8bed \u672a\u660e\u786e\u5177\u4f53\u89c4\u6a21\uff0c\u4f46\u5305\u542b\u6307\u4ee3\u5bf9\u8bdd\u548c\u5e26\u6846\u7684CoT\u6570\u636e - \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u5bf9\u8bdd\u6a21\u578b\uff0c\u652f\u6301\u6307\u4ee3\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1 GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 All-Seeing-V1 \u7528\u4e8e\u6cdb\u89c6\u89c9\u8bc6\u522b\u548c\u7406\u89e3\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc710\u4ebf\u4e2a\u533a\u57df\u7684\u8bed\u4e49\u6807\u7b7e\u7b49 \u6cdb\u89c6\u89c9\u8bc6\u522b\u3001\u591a\u6a21\u6001\u7406\u89e3 2023 \u82f1\u8bed \u8d85\u8fc710\u4ebf\u4e2a\u533a\u57df\u6807\u6ce8\uff0c1100\u4e07\u5f20\u56fe\u50cf\uff0c350\u4e07\u6982\u5ff5\uff0c1322\u4ebf\u4e2a\u6807\u8bb0\u7684\u8bed\u4e49\u4fe1\u606f OpenGVLab \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u591a\u79cd\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1 Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 All-Seeing-V2 \u63d0\u4f9b\u5173\u7cfb\u5bf9\u8bdd\uff08ReC\uff09\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7406\u89e3\u548c\u751f\u6210\u56fe\u50cf\u4e2d\u5bf9\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb \u6cdb\u89c6\u89c9\u8bc6\u522b\u3001\u5173\u7cfb\u7406\u89e3 2024 \u82f1\u8bed \u5305\u542b127K\u9ad8\u8d28\u91cf\u5173\u7cfb\u5bf9\u8bdd\u6837\u672c\uff0c\u6db5\u76d6\u8be6\u7ec6\u63cf\u8ff0\u3001\u533a\u57df\u63cf\u8ff0\u548c\u5bf9\u8bdd\u4efb\u52a1 OpenGVLab \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u5728\u5173\u7cfb\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u6027\u80fd Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 V3Det \u5927\u89c4\u6a21\u89c6\u89c9\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5305\u542b13204\u4e2a\u7c7b\u522b\u7684\u7cbe\u786e\u6807\u6ce8\u7684\u8fb9\u754c\u6846 \u89c6\u89c9\u76ee\u6807\u68c0\u6d4b 2023 \u82f1\u8bed 243k\u56fe\u50cf\uff0c13204\u4e2a\u7c7b\u522b\uff0c1753k\u8fb9\u754c\u6846\uff0c\u63d0\u4f9b\u7c7b\u522b\u63cf\u8ff0\u548c\u793a\u4f8b\u56fe\u50cf \u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u7b49 \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u5927\u89c4\u6a21\u8bcd\u6c47\u91cf\u7684\u89c6\u89c9\u68c0\u6d4b\u6a21\u578b\uff0c\u652f\u6301\u5f00\u653e\u8bcd\u6c47\u68c0\u6d4b\u4efb\u52a1 GitHub \u5426 \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 TolokaVQA \u4e00\u4e2a\u4f17\u5305\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7ed9\u5b9a\u56fe\u50cf\u548c\u6587\u672c\u95ee\u9898\uff0c\u9700\u8981\u7ed8\u5236\u5305\u56f4\u6846\u4f5c\u4e3a\u7b54\u6848 \u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u81ea\u7136\u8bed\u8a00\u5904\u7406 2023 \u82f1\u8bed 45,199 \u5f20\u56fe\u50cf\u548c\u95ee\u9898\u5bf9\uff0c\u5206\u4e3a\u8bad\u7ec3\u96c6\u3001\u516c\u5171\u6d4b\u8bd5\u96c6\u548c\u79c1\u6709\u6d4b\u8bd5\u96c6 Toloka \u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e5f\u53ef\u7528\u4e8e\u89c6\u89c9\u641c\u7d22\u3001\u589e\u5f3a\u73b0\u5b9e\u3001\u673a\u5668\u4eba\u7b49\u9886\u57df Hugging Face \u662f\uff08\u901a\u8fc7 BLIP-2 \u751f\u6210\uff09 \u662f \u65e2\u6709\u8bad\u7ec3\u4e5f\u6709\u8bc4\u4f30 DsLMF \u7528\u4e8e\u667a\u80fd\u8bc6\u522b\u5730\u4e0b\u957f\u58c1\u91c7\u77ff\u5de5\u4f5c\u9762\u5f02\u5e38\u5de5\u51b5\u7684\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u542b 6 \u7c7b\u76ee\u6807\u7684\u6807\u6ce8 \u91c7\u77ff\u4e1a 2024 \u65e0\uff08\u56fe\u50cf\u6570\u636e\u96c6\uff09 138,004 \u5f20\u56fe\u50cf \u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u53d1\u5e03\u673a\u6784\uff0c\u4f46\u7531\u76f8\u5173\u7814\u7a76\u4eba\u5458\u5f00\u53d1 \u652f\u6301\u5730\u4e0b\u91c7\u77ff\u4e2d\u5f02\u5e38\u72b6\u6001\u7684\u667a\u80fd\u8bc6\u522b\u4e0e\u5206\u7c7b\u7814\u7a76 figshare \u5426 \u5426 \u4e3b\u8981\u7528\u4e8e\u8bc4\u4f30 COCO-ReM \u5bf9 COCO \u6570\u636e\u96c6\u7684\u5b9e\u4f8b\u6807\u6ce8\u8fdb\u884c\u4e86\u6539\u8fdb\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u63a9\u7801\u6807\u6ce8 \u8ba1\u7b97\u673a\u89c6\u89c9 2024 \u65e0\uff08\u56fe\u50cf\u6570\u636e\u96c6\uff09 \u7ea6 118 \u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u548c 5,000 \u5f20\u9a8c\u8bc1\u56fe\u50cf\uff0c\u5e26\u6709\u66f4\u7cbe\u7ec6\u7684\u5b9e\u4f8b\u63a9\u7801 \u7531\u76f8\u5173\u7814\u7a76\u4eba\u5458\u5f00\u53d1 \u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u548c\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5 Hugging Face \u5426 \u5426 \u4e3b\u8981\u7528\u4e8e\u8bc4\u4f30\uff0c\u4e5f\u53ef\u7528\u4e8e\u8bad\u7ec3"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#7-document","title":"7. Document","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 DocReason25K \u7528\u4e8e\u6587\u6863\u9886\u57df\u63a8\u7406\u7684\u6307\u4ee4\u5fae\u8c03\u8bad\u7ec3\u96c6\uff0c\u5305\u542b\u8be6\u7ec6\u63a8\u7406\u89e3\u91ca\uff0c\u7531 GPT3.5 \u6216 GPT4V \u4ea7\u751f \u6587\u6863 2024 \u82f1\u8bed 2.5 \u4e07\u6837\u672c Institute for Intelligent Computing \u591a\u6a21\u6001\u6307\u4ee4\u5fae\u8c03\u3001\u63a8\u7406\u80fd\u529b\u63d0\u5347 Hugging Face \u5426 \u662f \u8bad\u7ec3 DocVQA \u6587\u6863\u56fe\u50cf\u4e0a\u7684\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b 5 \u4e07\u4e2a\u95ee\u9898\uff0c\u8986\u76d6\u591a\u79cd\u6587\u6863\u7c7b\u578b\u548c\u5185\u5bb9 \u6587\u6863 2020 \u82f1\u8bed 12,767 \u56fe\u50cf\uff0c50,000 \u95ee\u9898 CVIT, IIIT Hyderabad \u7b49 \u6587\u6863\u56fe\u50cf\u7684\u89c6\u89c9\u95ee\u7b54\u7814\u7a76 Hugging Face \u5426 \u662f \u8bc4\u4f30 Docmatix \u5927\u89c4\u6a21\u6587\u6863\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b 240 \u4e07\u56fe\u50cf\u548c 950 \u4e07\u95ee\u7b54\u5bf9 \u6587\u6863 2024 \u82f1\u8bed 240 \u4e07\u56fe\u50cf\uff0c950 \u4e07\u95ee\u7b54\u5bf9 Hugging Face M4 \u7b49 \u6587\u6863\u89c6\u89c9\u95ee\u7b54\u6a21\u578b\u7684\u5fae\u8c03 Hugging Face \u5426 \u662f \u8bad\u7ec3 Sujet-Finance-QA-Vision \u8be5\u6570\u636e\u96c6\u5305\u542b\u8d85\u8fc7 10 \u4e07\u4e2a\u57fa\u4e8e 9,800 \u591a\u5f20\u91d1\u878d\u6587\u6863\u56fe\u50cf\u7684\u95ee\u7b54\u5bf9\uff0c\u7528\u4e8e\u91d1\u878d\u6587\u6863\u5206\u6790\u548c\u89c6\u89c9\u95ee\u7b54\u7814\u7a76 \u91d1\u878d 2024 \u82f1\u8bed 9,801 \u5f20\u56fe\u50cf\uff0c107,050 \u4e2a\u95ee\u7b54\u5bf9 Sujet AI \u8bad\u7ec3\u548c\u8bc4\u4f30\u89c6\u89c9\u95ee\u7b54\u6a21\u578b Hugging Face \u662f\uff0c\u5305\u542b\u56fe\u50cf\u63cf\u8ff0 \u662f\uff0c\u5305\u542b\u57fa\u4e8e\u56fe\u50cf\u7684\u95ee\u7b54\u5bf9 \u8bad\u7ec3\u548c\u8bc4\u4f30 BigDocs-7.5M \u4e00\u4e2a\u5927\u578b\u6587\u6863\u7ea7\u6570\u636e\u96c6\uff0c\u9002\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u548c\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u3002 \u4fe1\u606f\u68c0\u7d22\u3001\u6587\u672c\u5206\u7c7b 2022 \u82f1\u8bed 7.5M \u6587\u6863 Microsoft \u6587\u6863\u5206\u7c7b\u3001\u4fe1\u606f\u68c0\u7d22\u3001\u6587\u672c\u5904\u7406 https://bigdocs.github.io/ \u5426 \u5426 \u8bad\u7ec3"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#8-science","title":"8. Science","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 AI2D \u5305\u542b\u8d85\u8fc75000\u5f20\u5c0f\u5b66\u79d1\u5b66\u56fe\u8868\u548c\u8d85\u8fc7150000\u4e2a\u4e30\u5bcc\u6ce8\u91ca\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6 \u79d1\u5b66\u6559\u80b2 2016 \u82f1\u6587 5000+\u5f20\u56fe\u50cf\uff0c150000+\u4e2a\u6ce8\u91ca\uff0c15000+\u4e2a\u591a\u9879\u9009\u62e9\u9898 Allen Institute for AI \u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\u548c\u56fe\u8868\u7406\u89e3\u7814\u7a76 HuggingFace \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 ScienceQA \u5305\u542b\u79d1\u5b66\u4e3b\u9898\u7684\u591a\u6a21\u6001\u591a\u9879\u9009\u62e9\u9898\uff0c\u6db5\u76d6\u81ea\u7136\u79d1\u5b66\u3001\u793e\u4f1a\u79d1\u5b66\u548c\u8bed\u8a00\u79d1\u5b66 \u79d1\u5b66\u6559\u80b2 2022 \u82f1\u6587 21,208\u4e2a\u95ee\u9898\uff0c\u6db5\u76d6\u591a\u79cd\u79d1\u5b66\u4e3b\u9898\u548c\u591a\u6a21\u6001\u4e0a\u4e0b\u6587 UCLA \u548c Allen Institute for AI \u7528\u4e8e\u79d1\u5b66\u95ee\u9898\u89e3\u7b54\u548c\u591a\u6a21\u6001\u63a8\u7406\u7814\u7a76 HuggingFace \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 TQA \u7528\u4e8e\u89e3\u51b3\u6559\u79d1\u4e66\u95ee\u7b54\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u6587\u672c\u548c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u8f93\u5165\u3002 \u6559\u80b2/\u79d1\u5b66 2017 \u82f1\u8bed 1076 \u8bfe\uff0c26,260 \u4e2a\u95ee\u9898\uff0c78,338 \u4e2a\u53e5\u5b50\uff0c3,455 \u5f20\u56fe\u50cf AI2 (Allen Institute for AI) \u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u95ee\u7b54\u6a21\u578b Hugging Face \u662f \u662f \u8bad\u7ec3/\u8bc4\u4f30 ChemVLM Data \u7528\u4e8e\u5316\u5b66\u9886\u57df\u7684\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u542b\u5316\u5b66\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u606f \u5316\u5b66 2024 \u4e2d/\u82f1 \u6570\u636e\u89c4\u6a21\u672a\u660e\u786e\uff0c\u5305\u542b\u591a\u79cd\u5316\u5b66\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e Shanghai Artificial Intelligence Laboratory \u7b49 \u7528\u4e8e\u5316\u5b66\u9886\u57df\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u63a8\u7406 GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#9-conversation","title":"9. Conversation","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 ALiLaVA \u63d0\u4f9b\u4e86140\u4e07\u6761\u7531GPT-4V\u5408\u6210\u7684\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u7528\u4e8e\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b \u89c6\u89c9\u8bed\u8a00\u6a21\u578b 2024 \u82f1\u8bed 1.4M Freedom Intelligence \u8bad\u7ec3\u8f7b\u91cf\u7ea7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b Hugging Face \u662f \u662f \u8bad\u7ec3 SVIT \u63d0\u4f9b\u4e86420\u4e07\u6761\u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u6570\u636e\uff0c\u5305\u62ec\u5bf9\u8bdd\u95ee\u7b54\u3001\u590d\u6742\u63a8\u7406\u95ee\u7b54\u7b49 \u89c6\u89c9\u6307\u4ee4\u8c03\u4f18 2023 \u82f1\u8bed 4.2M Beijing Academy of Artificial Intelligence \u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u7814\u7a76 Hugging Face \u662f \u662f \u8bad\u7ec3 Cambrian-10M \u63d0\u4f9b\u4e861000\u4e07\u6761\u591a\u6a21\u6001\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\u548c\u5bf9\u5e94\u7684\u6587\u672c\u63cf\u8ff0 \u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b 2024 \u82f1\u8bed 10M NYU VisionX \u8bad\u7ec3\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b Hugging Face \u662f \u662f \u8bad\u7ec3 TextOCR-GPT4V \u63d0\u4f9b\u4e86\u57fa\u4e8eGPT-4V\u7684\u6587\u672cOCR\u6570\u636e\uff0c\u5305\u542b\u573a\u666f\u6587\u672c\u8bc6\u522b\u3001\u624b\u5199\u6587\u672c\u8bc6\u522b\u7b49\u4efb\u52a1 \u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09 2023 \u591a\u8bed\u8a00 \u89c4\u6a21\u672a\u660e\u786e Jimmy Carter OCR\u4efb\u52a1\u7814\u7a76 Hugging Face \u662f \u662f \u8bc4\u4f30 MMDU \u591a\u8f6e\u591a\u56fe\u50cf\u5bf9\u8bdd\u7406\u89e3\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb LVLM \u7684\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b \u4eba\u5de5\u667a\u80fd\u3001\u5bf9\u8bdd\u7cfb\u7edf 2024 \u82f1\u8bed 110\u4e2a\u5bf9\u8bdd\uff0c421\u5f20\u56fe\u7247\uff0c1645\u4e2a\u95ee\u7b54\u5bf9\uff0c\u6700\u592720\u5f20\u56fe\u7247\u300117\u8f6e\u5bf9\u8bdd\uff0c18k tokens \u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u7b49 \u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb LVLM \u5728\u591a\u8f6e\u591a\u56fe\u50cf\u5bf9\u8bdd\u4e2d\u7684\u7406\u89e3\u80fd\u529b GitHub \u662f \u662f \u8bc4\u4f30 Viet-ShareGPT4o \u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u7684\u8d8a\u5357\u8bed\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u50cf\u548c\u76f8\u5173\u95ee\u9898\u53ca\u7b54\u6848 \u4eba\u5de5\u667a\u80fd\u3001\u89c6\u89c9\u95ee\u7b54 2024 \u8d8a\u5357\u8bed \u672a\u660e\u786e\u5177\u4f53\u89c4\u6a21\uff0c\u4f46\u5305\u542b\u56fe\u50cf\u548c\u95ee\u7b54\u5bf9 5CD-AI \u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u8d8a\u5357\u8bed\u7684\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b Hugging Face \u662f \u662f \u672a\u660e\u786e RLAIF-V \u901a\u8fc7\u5f00\u6e90 AI \u53cd\u9988\u63d0\u5347 MLLM \u7684\u53ef\u4fe1\u5ea6\uff0c\u5305\u542b\u9ad8\u8d28\u91cf\u53cd\u9988\u6570\u636e\u548c\u63a8\u7406\u5b66\u4e60\u7b97\u6cd5 \u4eba\u5de5\u667a\u80fd\u3001\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b 2024 \u82f1\u8bed \u5305\u542b83,132\u4e2a\u9ad8\u8d28\u91cf\u6bd4\u8f83\u5bf9\uff0c\u6db5\u76d6\u591a\u79cd\u4efb\u52a1\u548c\u9886\u57df RLHF-V \u56e2\u961f \u7528\u4e8e\u63d0\u5347 MLLM \u7684\u53ef\u4fe1\u5ea6\uff0c\u51cf\u5c11\u5e7b\u89c9\uff0c\u589e\u5f3a\u63a8\u7406\u80fd\u529b GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 Laion-GPT4V \u7531 GPT-4V \u751f\u6210\u7684\u89c6\u89c9\u8bed\u8a00\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b\u9ad8\u8d28\u91cf\u7684\u63cf\u8ff0\u3001\u6307\u4ee4\u548c\u7b54\u6848 \u4eba\u5de5\u667a\u80fd\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b 2024 \u82f1\u8bed 130\u4e07\u6837\u672c\uff0c\u6db5\u76d6\u591a\u79cd\u89c6\u89c9\u4efb\u52a1\u548c\u6307\u4ee4\u5bf9 Freedom Intelligence \u7528\u4e8e\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u5347\u5176\u6027\u80fd\u548c\u6548\u7387 Hugging Face \u662f \u662f \u8bad\u7ec3 WildVision-GPT4o \u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLMs) \u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u57fa\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u5728\u7ebf\u5e73\u53f0 \u591a\u9886\u57df 2024 \u82f1\u8bed 20k+ \u804a\u5929\u8bb0\u5f55\uff0c8k+ \u6295\u7968 Allen Institute of AI \u7b49 \u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6027\u80fd Hugging Face \u662f \u662f \u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#10-medical","title":"10. Medical","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 PMC-VQA \u4e00\u4e2a\u5927\u89c4\u6a21\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b227k\u95ee\u7b54\u5bf9\uff0c\u6d89\u53ca149k\u5f20\u56fe\u50cf\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u6001\u548c\u75be\u75c5 \u533b\u5b66 2023 \u82f1\u6587 \u5305\u542b227k\u95ee\u7b54\u5bf9\uff0c149k\u5f20\u56fe\u50cf\uff0c\u8986\u76d6\u591a\u79cd\u6a21\u6001\u548c\u75be\u75c5 \u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u3001\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4 \u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u6a21\u578b\u8bad\u7ec3\u4e0e\u8bc4\u4f30 Hugging Face \u662f \u662f \u8bad\u7ec3\u3001\u8bc4\u4f30 VQA-RAD \u4e00\u4e2a\u5173\u4e8e\u653e\u5c04\u5b66\u56fe\u50cf\u7684\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b2248\u4e2a\u95ee\u7b54\u5bf9\uff0c315\u5f20\u56fe\u50cf \u533b\u5b66 2018 \u82f1\u6587 \u5305\u542b2248\u4e2a\u95ee\u7b54\u5bf9\uff0c315\u5f20\u56fe\u50cf\uff0c\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 Open Science Framework \u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u6a21\u578b\u8bad\u7ec3\u4e0e\u8bc4\u4f30 Hugging Face \u662f \u662f \u8bad\u7ec3\u3001\u8bc4\u4f30 ImageCLEF \u5305\u542b\u591a\u4e2a\u56fe\u50cf\u68c0\u7d22\u548c\u5206\u7c7b\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u4fe1\u606f\u68c0\u7d22\u7814\u7a76 \u533b\u5b66 2008-2011 \u591a\u8bed\u8a00 \u5305\u542b\u591a\u4e2a\u5b50\u6570\u636e\u96c6\uff0c\u5982VCDT\u3001Wikipedia\u56fe\u50cf\u68c0\u7d22\u7b49 ImageCLEF/LifeCLEF \u56fe\u50cf\u68c0\u7d22\u3001\u5206\u7c7b\u7b49\u4efb\u52a1\u7814\u7a76 ImageCLEF\u5b98\u7f51 \u90e8\u5206\u5b50\u6570\u636e\u96c6\u5305\u542b \u90e8\u5206\u5b50\u6570\u636e\u96c6\u5305\u542b \u8bad\u7ec3\u3001\u8bc4\u4f30 SLAKE \u4e00\u4e2a\u53cc\u8bed\u7684\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b14k\u95ee\u7b54\u5bf9\uff0c642\u5f20\u56fe\u50cf\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u6001\u548c\u75be\u75c5 \u533b\u5b66 2021 \u4e2d\u82f1\u53cc\u8bed \u5305\u542b14k\u95ee\u7b54\u5bf9\uff0c642\u5f20\u56fe\u50cf\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u6001\u548c\u75be\u75c5 \u9999\u6e2f\u7406\u5de5\u5927\u5b66\u3001\u56db\u5ddd\u5927\u5b66\u534e\u897f\u533b\u9662 \u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u6a21\u578b\u8bad\u7ec3\u4e0e\u8bc4\u4f30 Hugging Face \u662f \u662f \u8bad\u7ec3\u3001\u8bc4\u4f30 Medical-Diff-VQA \u7528\u4e8e\u80f8\u90e8X\u5149\u56fe\u50cf\u5dee\u5f02\u89c6\u89c9\u95ee\u7b54\u7684\u5927\u578b\u533b\u5b66\u6570\u636e\u96c6\uff0c\u5305\u542b164,324\u5bf9\u56fe\u50cf\u548c700,703\u4e2a\u95ee\u7b54\u5bf9 \u533b\u5b66\u5f71\u50cf 2025 \u82f1\u6587 164,324\u5bf9\u56fe\u50cf\uff0c700,703\u4e2a\u95ee\u7b54\u5bf9 PhysioNet \u7528\u4e8e\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u7279\u522b\u662f\u6bd4\u8f83\u540c\u4e00\u60a3\u8005\u4e0d\u540c\u65f6\u95f4\u7684\u80f8\u90e8X\u5149\u56fe\u50cf\u7684\u53d8\u5316 PhysioNet \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 PMC-CaseReport \u57fa\u4e8ePubMed Central\u7684\u75c5\u4f8b\u62a5\u544a\u6570\u636e\u96c6\uff0c\u5305\u542b317K\u8bad\u7ec3\u5bf9\u548c121K\u6d4b\u8bd5\u56fe\u50cf\u7684VQA\u5bf9 \u533b\u5b66\u6587\u672c 2023 \u82f1\u6587 317K\u8bad\u7ec3\u5bf9\uff0c121K\u6d4b\u8bd5\u56fe\u50cf\u7684VQA\u5bf9 Hugging Face \u7528\u4e8e\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u57fa\u4e8e\u75c5\u4f8b\u62a5\u544a\u751f\u6210\u95ee\u9898\u548c\u7b54\u6848 Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 GMAI-VL (subset) \u7528\u4e8e\u901a\u7528\u533b\u5b66AI\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b5.5M\u6837\u672c\u7684\u5b50\u96c6 \u533b\u5b66\u591a\u6a21\u6001 2024 \u82f1\u6587/\u4e2d\u6587 5.5M\u6837\u672c\u7684\u5b50\u96c6 \u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u3001\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u7b49\u673a\u6784 \u7528\u4e8e\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u3001\u533b\u5b66\u56fe\u50cf\u8bca\u65ad\u7b49\u591a\u6a21\u6001\u4efb\u52a1 GitHub \u662f \u662f \u8bad\u7ec3 PMC \u5305\u542b1.65M\u56fe\u50cf-\u6587\u672c\u5bf9\u7684\u5927\u578b\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u6001\u548c\u75be\u75c5\u7c7b\u578b \u533b\u5b66\u591a\u6a21\u6001 2023 \u82f1\u6587 1.65M\u56fe\u50cf-\u6587\u672c\u5bf9 \u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u3001\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4\u7b49\u673a\u6784 \u7528\u4e8e\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u3001\u56fe\u50cf\u5206\u7c7b\u3001\u56fe\u50cf-\u6587\u672c\u68c0\u7d22\u7b49\u4efb\u52a1 GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 VQA-Med \u4e13\u6ce8\u4e8e\u653e\u5c04\u5b66\u56fe\u50cf\u7684\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b\u6a21\u6001\u3001\u5e73\u9762\u3001\u5668\u5b98\u7cfb\u7edf\u548c\u5f02\u5e38\u7b49\u7c7b\u522b\u95ee\u9898 \u533b\u7597 2019 \u82f1\u8bed \u5305\u542b 4,200 \u5f20\u653e\u5c04\u5b66\u56fe\u50cf\u548c 15,292 \u4e2a\u95ee\u7b54\u5bf9\uff0c\u5206\u4e3a\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6 ImageCLEF 2019 \u7ec4\u7ec7\u56e2\u961f\uff0c\u7531 Asma Ben Abacha \u7b49\u4eba\u521b\u5efa \u8bad\u7ec3\u548c\u8bc4\u4f30\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u7cfb\u7edf Hugging Face\uff08\u65e0\uff09GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 PathVQA \u57fa\u4e8e\u75c5\u7406\u56fe\u50cf\u7684\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u901a\u8fc7\u7f8e\u56fd\u75c5\u7406\u5b66\u59d4\u5458\u4f1a\u8003\u8bd5\u7684 AI \u7cfb\u7edf \u533b\u7597 2020 \u82f1\u8bed \u5305\u542b 4,998 \u5f20\u75c5\u7406\u56fe\u50cf\u548c 32,799 \u4e2a\u95ee\u7b54\u5bf9\uff0c\u5206\u4e3a\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6 University of California San Diego \u7b49\u673a\u6784\uff0c\u7531 Xuehai He \u7b49\u4eba\u521b\u5efa \u8bad\u7ec3\u548c\u8bc4\u4f30\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u7cfb\u7edf Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 MedTrinity-25M MedTrinity-25M \u662f\u4e00\u4e2a\u533b\u5b66\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b 2500 \u4e07\u5bf9\u9ad8\u8d28\u91cf\u7684\u533b\u5b66\u56fe\u50cf\u548c\u6587\u672c\uff0c\u7528\u4e8e\u533b\u5b66\u9886\u57df\u7684\u591a\u6a21\u6001\u7814\u7a76\u548c\u5e94\u7528\u3002 \u533b\u5b66Caption 2024 \u82f1\u8bed 2500\u4e07\u5bf9\u533b\u5b66\u56fe\u50cf\u548c\u6587\u672c - \u533b\u5b66\u591a\u6a21\u6001\u7814\u7a76 - \u662f \u662f \u8bad\u7ec3/\u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#11-gui","title":"11. GUI","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 Screen2Words \u81ea\u52a8\u751f\u6210\u79fb\u52a8 UI \u5c4f\u5e55\u7684\u529f\u80fd\u6027\u8bed\u8a00\u63cf\u8ff0\uff0c\u7528\u4e8e\u8bed\u8a00\u4ea4\u4e92\u548c\u5c4f\u5e55\u7406\u89e3\u4efb\u52a1\u3002 \u79fb\u52a8 UI 2021 \u82f1\u8bed 22,417 \u4e2a Android UI \u5c4f\u5e55\uff0c112,085 \u4e2a\u8bed\u8a00\u63cf\u8ff0 Google Research \u8bad\u7ec3\u548c\u8bc4\u4f30\u81ea\u52a8\u5c4f\u5e55\u603b\u7ed3\u6a21\u578b\uff0c\u7528\u4e8e\u8bed\u8a00\u4ea4\u4e92\u3001\u5c4f\u5e55\u9605\u8bfb\u5668\u589e\u5f3a\u7b49\u5e94\u7528 Hugging Face \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 WebSight \u5c06\u7f51\u9875\u622a\u56fe\u8f6c\u6362\u4e3a HTML \u4ee3\u7801\uff0c\u7528\u4e8e\u7b80\u5316\u7f51\u9875\u5f00\u53d1\u8fc7\u7a0b\u3002 \u7f51\u9875\u5f00\u53d1 2024 \u82f1\u8bed 200 \u4e07\u5bf9 HTML \u4ee3\u7801\u548c\u5bf9\u5e94\u7684\u622a\u56fe Hugging Face \u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u7f51\u9875\u8bbe\u8ba1\u5feb\u901f\u8f6c\u6362\u4e3a\u529f\u80fd\u4ee3\u7801\uff0c\u652f\u6301\u65e0\u4ee3\u7801\u5f00\u53d1\u5de5\u5177 Hugging Face \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 Widget-Caption \u81ea\u52a8\u751f\u6210\u79fb\u52a8 UI \u5143\u7d20\u7684\u8bed\u8a00\u63cf\u8ff0\uff0c\u7528\u4e8e\u63d0\u9ad8\u79fb\u52a8\u5e94\u7528\u7684\u65e0\u969c\u788d\u6027\u548c\u8bed\u8a00\u4ea4\u4e92\u80fd\u529b\u3002 \u79fb\u52a8 UI 2020 \u82f1\u8bed 21,750 \u4e2a\u72ec\u7279\u5c4f\u5e55\uff0c61,285 \u4e2a UI \u5143\u7d20\uff0c162,859 \u4e2a\u8bed\u8a00\u63cf\u8ff0 Google Research \u8bad\u7ec3\u548c\u8bc4\u4f30\u7528\u4e8e\u751f\u6210\u79fb\u52a8 UI \u5143\u7d20\u63cf\u8ff0\u7684\u6a21\u578b\uff0c\u63d0\u9ad8\u65e0\u969c\u788d\u6027 Hugging Face \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 RICOSCA \u7528\u4e8e\u79fb\u52a8 UI \u81ea\u52a8\u5316\u548c\u65e0\u969c\u788d\u6280\u672f\u7814\u7a76\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b UI \u5143\u7d20\u7684\u63cf\u8ff0\u548c\u622a\u56fe\u3002 \u79fb\u52a8 UI 2017 \u82f1\u8bed 18,000 \u4e2a\u5c4f\u5e55\uff0c70,000 \u4e2a UI \u5143\u7d20\uff0c170,000 \u4e2a\u63cf\u8ff0 Google Research \u8bad\u7ec3\u6a21\u578b\u4ee5\u7406\u89e3\u5c4f\u5e55\u3001\u89e3\u91ca\u79fb\u52a8\u754c\u9762\uff0c\u5e76\u5728\u81ea\u52a8\u5316\u548c\u65e0\u969c\u788d\u6280\u672f\u4e2d\u5e94\u7528 Hugging Face \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 SeeClick \u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u7684GUI\u4ee3\u7406\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u754c\u9762\u622a\u56fe\u6765\u6267\u884c\u70b9\u51fb\u548c\u8f93\u5165\u7b49\u64cd\u4f5c\u3002 GUI\u4ee3\u7406 2024 \u82f1\u6587 \u5305\u542b\u7ea6600\u5f20\u622a\u56fe\u30011200\u6761\u6307\u4ee4\uff0c\u6db5\u76d6iOS\u3001Android\u3001macOS\u3001Windows\u548c\u7f51\u9875\u73af\u5883 \u5357\u4eac\u5927\u5b66\u3001\u4e0a\u6d77AI\u5b9e\u9a8c\u5ba4 \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u89c6\u89c9GUI\u4ee3\u7406\uff0c\u63d0\u5347GUI\u5143\u7d20\u5b9a\u4f4d\u80fd\u529b\u3002 Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 ScreenQA \u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u79fb\u52a8\u5e94\u7528\u622a\u56fe\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ea686K\u95ee\u7b54\u5bf9\u548c35K\u622a\u56fe\u3002 \u79fb\u52a8\u5e94\u7528 2022 \u82f1\u6587 \u5305\u542b\u7ea686,025\u4e2a\u95ee\u7b54\u5bf9\uff0c35,352\u5f20\u622a\u56fe\u3002 Google Research \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u5c4f\u5e55\u5185\u5bb9\u7406\u89e3\u6a21\u578b\uff0c\u901a\u8fc7\u95ee\u7b54\u9a8c\u8bc1\u7406\u89e3\u80fd\u529b\u3002 GitHub \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 AMEX \u4e00\u4e2a\u5927\u89c4\u6a21\u7684Android\u8bbe\u5907\u63a7\u5236\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u5c42\u7ea7\u6ce8\u91ca\u548c\u590d\u6742\u4efb\u52a1\u6307\u4ee4\u3002 \u79fb\u52a8\u8bbe\u5907\u63a7\u5236 2024 \u82f1\u6587 \u5305\u542b\u7ea6104K\u622a\u56fe\u3001711K\u5143\u7d20\u529f\u80fd\u63cf\u8ff0\u30013K\u590d\u6742\u6307\u4ee4\u3002 \u4e2d\u79d1\u5927\u3001\u4e0a\u6d77AI\u5b9e\u9a8c\u5ba4 \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u901a\u7528\u79fb\u52a8GUI\u4ee3\u7406\uff0c\u63d0\u5347\u5bf9\u590d\u6742\u4efb\u52a1\u7684\u7406\u89e3\u548c\u6267\u884c\u80fd\u529b\u3002 Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 AITW \u4e00\u4e2a\u5927\u89c4\u6a21\u7684Android\u8bbe\u5907\u63a7\u5236\u6570\u636e\u96c6\uff0c\u5305\u542b\u4eba\u7c7b\u6f14\u793a\u7684\u8bbe\u5907\u4ea4\u4e92\u548c\u6307\u4ee4\u3002 \u79fb\u52a8\u8bbe\u5907\u63a7\u5236 2023 \u82f1\u6587 \u5305\u542b715k\u6f14\u793a\uff0c30k\u552f\u4e00\u6307\u4ee4\uff0c\u6db5\u76d6\u591a\u79cdAndroid\u7248\u672c\u548c\u8bbe\u5907\u7c7b\u578b\u3002 Google Research \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u8bbe\u5907\u63a7\u5236\u6a21\u578b\uff0c\u652f\u6301\u591a\u6b65\u4efb\u52a1\u548c\u590d\u6742\u4ea4\u4e92\u3002 Hugging Face \u662f \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 Odyssey \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u8de8\u5e94\u7528\u5bfc\u822a\u4ee3\u7406\u7684\u7efc\u5408\u6027\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u591a\u79cd\u8de8\u5e94\u7528\u4efb\u52a1 \u79fb\u52a8\u8bbe\u5907GUI 2024 \u82f1\u8bed \u5305\u542b7,735\u4e2a\u6765\u81ea6\u79cd\u79fb\u52a8\u8bbe\u5907\u7684\u5bfc\u822a\u5e8f\u5217\uff0c\u6d89\u53ca201\u4e2a\u5e94\u7528\u548c1,399\u79cd\u5e94\u7528\u7ec4\u5408 OpenGVLab \u8bad\u7ec3\u548c\u8bc4\u4f30\u8de8\u5e94\u7528\u5bfc\u822a\u4ee3\u7406\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c Hugging Face \u5426 \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 UIBert \u7528\u4e8e\u5b66\u4e60\u901a\u7528\u591a\u6a21\u6001UI\u8868\u793a\u7684\u6570\u636e\u96c6\uff0c\u5305\u542bUI\u5143\u7d20\u7684\u56fe\u50cf\u3001\u6587\u672c\u548c\u7ed3\u6784\u5316\u5143\u6570\u636e \u7528\u6237\u754c\u9762 2021 \u82f1\u8bed \u5305\u542b72k\u79fb\u52a8\u5e94\u7528UI\u6570\u636e\uff0c\u6269\u5c55\u4e3a\u76f8\u4f3cUI\u7ec4\u4ef6\u68c0\u7d22\u548c\u5f15\u7528\u8868\u8fbe\u5f0f\u7ec4\u4ef6\u68c0\u7d22\u4efb\u52a1 Google Research \u5b66\u4e60\u901a\u7528\u591a\u6a21\u6001UI\u8868\u793a\uff0c\u63d0\u5347UI\u7406\u89e3\u548c\u4efb\u52a1\u6027\u80fd GitHub \u662f \u5426 \u8bad\u7ec3\u548c\u8bc4\u4f30 AndroidControl \u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30Android\u8bbe\u5907\u63a7\u5236\u4ee3\u7406\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9e\u7528\u6237\u4efb\u52a1\u6f14\u793a \u79fb\u52a8\u8bbe\u5907\u63a7\u5236 2024 \u82f1\u8bed \u5305\u542b15,283\u4e2aAndroid\u5e94\u7528\u4efb\u52a1\u6f14\u793a\uff0c\u6db5\u76d6833\u4e2a\u5e94\u7528\u548c14,548\u4e2a\u72ec\u7279\u4efb\u52a1 Google DeepMind \u8bad\u7ec3\u548c\u8bc4\u4f30\u57fa\u4e8eLLM\u7684UI\u63a7\u5236\u4ee3\u7406\uff0c\u63d0\u5347\u4efb\u52a1\u6267\u884c\u6027\u80fd Hugging Face \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 Mind2Web \u7528\u4e8e\u5f00\u53d1\u548c\u8bc4\u4f30\u80fd\u591f\u9075\u5faa\u8bed\u8a00\u6307\u4ee4\u5728\u4efb\u4f55\u7f51\u7ad9\u4e0a\u5b8c\u6210\u590d\u6742\u4efb\u52a1\u7684\u901a\u7528\u7f51\u7edc\u4ee3\u7406 \u7f51\u7edc\u81ea\u52a8\u5316 2023 \u82f1\u8bed \u5305\u542b2,000\u4e2a\u6765\u81ea137\u4e2a\u7f51\u7ad9\u7684\u4efb\u52a1\uff0c\u6db5\u76d631\u4e2a\u9886\u57df\uff0c\u63d0\u4f9b\u4f17\u5305\u52a8\u4f5c\u5e8f\u5217 The Ohio State University \u5f00\u53d1\u548c\u8bc4\u4f30\u901a\u7528\u7f51\u7edc\u4ee3\u7406\uff0c\u63d0\u5347\u7f51\u7edc\u53ef\u8bbf\u95ee\u6027\u548c\u4efb\u52a1\u6267\u884c\u80fd\u529b Hugging Face \u5426 \u662f \u8bad\u7ec3\u548c\u8bc4\u4f30 OmniACT \u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u81ea\u4e3b\u4ee3\u7406\u6267\u884c\u8ba1\u7b97\u673a\u4efb\u52a1\u80fd\u529b\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u684c\u9762\u548c\u7f51\u9875\u5e94\u7528 \u4eba\u673a\u4ea4\u4e92 2024 \u82f1\u8bed 9802 \u6570\u636e\u70b9 Carnegie Mellon University, Writer.com \u8bc4\u4f30\u591a\u6a21\u6001\u81ea\u4e3b\u4ee3\u7406\u7684\u6267\u884c\u80fd\u529b Hugging Face \u662f \u662f \u8bc4\u4f30 WaveUI \u5305\u542b 25k \u6807\u6ce8\u7684 UI \u5143\u7d20\uff0c\u7528\u4e8e\u589e\u5f3a\u89c6\u89c9 UI \u7406\u89e3\u548c\u4ea4\u4e92\u4efb\u52a1 \u4eba\u673a\u4ea4\u4e92 2024 \u82f1\u8bed 25k \u6570\u636e\u70b9 AgentSea \u7814\u7a76 UI \u7406\u89e3\u548c\u4ea4\u4e92\u4efb\u52a1 Hugging Face \u662f \u5426 \u8bad\u7ec3/\u8bc4\u4f30"},{"location":"%E5%9B%BE%E6%96%87%E5%A4%9A%E6%A8%A1%E6%80%81/01%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BD%92%E7%BA%B31/#12-evaluation","title":"12. Evaluation","text":"\u6570\u636e\u96c6\u540d\u79f0 \u7b80\u4ecb \u9886\u57df \u5e74\u4efd \u8bed\u8a00 \u89c4\u6a21 \u53d1\u5e03\u673a\u6784 \u7528\u9014 \u6570\u636e\u96c6\u94fe\u63a5 \u5305\u542b\u591a\u6a21\u6001Caption\u6570\u636e \u5305\u542b\u591a\u6a21\u6001QA\u6570\u636e \u8bad\u7ec3/\u8bc4\u4f30 MME MME \u662f\u4e00\u4e2a\u591a\u6a21\u6001\u89c6\u9891\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u89c6\u9891\u3001\u5b57\u5e55\u548c\u97f3\u9891\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u89c6\u9891\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002 \u89c6\u9891 2024 \u82f1\u8bed 900\u4e2a\u89c6\u9891\uff0c256\u5c0f\u65f6\u65f6\u957f \u5317\u4eac\u5927\u5b66\u3001\u9999\u6e2f\u5927\u5b66\u7b49 \u89c6\u9891\u5206\u6790\u8bc4\u4f30 MME \u94fe\u63a5 \u662f \u662f \u8bad\u7ec3/\u8bc4\u4f30 MMBench MMBench \u662f\u4e00\u4e2a\u591a\u6a21\u6001\u5927\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u591a\u79cd\u4efb\u52a1\u7c7b\u578b\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u6027\u80fd\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2023 \u82f1\u8bed - - \u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30 https://github.com/open-compass/MMBench \u662f \u662f \u8bc4\u4f30 SEED-Bench-1 SEED-Bench-1 \u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u591a\u79cd\u4efb\u52a1\u7c7b\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u6027\u80fd\u548c\u80fd\u529b\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2024 \u82f1\u8bed - - \u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30 https://github.com/AILab-CVC/SEED-Bench \u662f \u662f \u8bc4\u4f30 MMMU MMMU \u662f\u4e00\u4e2a\u591a\u5b66\u79d1\u591a\u6a21\u6001\u7406\u89e3\u4e0e\u63a8\u7406\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u5404\u79cd\u95ee\u9898\u7c7b\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u7684\u591a\u5b66\u79d1\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2023 \u82f1\u8bed 11500\u4e2a\u95ee\u9898 - \u591a\u5b66\u79d1\u7406\u89e3\u8bc4\u4f30 https://mmmu-benchmark.github.io/ \u662f \u662f \u8bc4\u4f30 POPE POPE \u662f\u4e00\u4e2a\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u5404\u79cd\u4efb\u52a1\u7c7b\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2024 \u82f1\u8bed - - \u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30 https://huggingface.co/datasets/lmms-lab/POPE \u662f \u662f \u8bc4\u4f30 MMBench-Chinese MMBench-Chinese \u662f\u4e00\u4e2a\u4e2d\u6587\u591a\u6a21\u6001\u5927\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u591a\u79cd\u4efb\u52a1\u7c7b\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e2d\u6587\u591a\u6a21\u6001\u6a21\u578b\u7684\u6027\u80fd\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2023 \u4e2d\u6587 - - \u4e2d\u6587\u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30 https://huggingface.co/datasets/lmms-lab/MMBench_CN \u662f \u662f \u8bc4\u4f30 MMSci MMSci \u662f\u4e00\u4e2a\u591a\u6a21\u6001\u79d1\u5b66\u6570\u636e\u96c6\uff0c\u5305\u542b\u79d1\u5b66\u6587\u7ae0\u548c\u56fe\u8868\uff0c\u7528\u4e8e\u79d1\u5b66\u7406\u89e3\u548c\u56fe\u8868\u751f\u6210\u4efb\u52a1\u3002 \u77e5\u8bc6\u3001\u591a\u5b66\u79d1 2024 \u82f1\u8bed 131,393\u7bc7\u6587\u7ae0\uff0c742,273\u4e2a\u56fe\u8868 \u52a0\u5229\u798f\u5c3c\u4e9a\u5927\u5b66\u7b49 \u79d1\u5b66\u7406\u89e3\u548c\u56fe\u8868\u751f\u6210 MMSci \u94fe\u63a5 \u662f \u662f \u8bc4\u4f30"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/","title":"\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u516c\u5f0f\u63a8\u5bfc\u548c\u5e94\u7528\u4e3e\u4f8b(\u4e00)","text":"<p>\u672c\u6587\u5199\u4e8e2023-08-15\u665a\u4e0a\u5341\u70b9</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#_2","title":"\u96f6\u3001\u524d\u8a00","text":"<p>\u4f5c\u4e3a\u673a\u68b0\u52a0\u63a7\u5236\u79d1\u73ed\u51fa\u8eab\u7684\u5927\u5b66\u751f\uff0c\u81ea\u7136\u662f\u5b66\u8fc7\u4f20\u7edf\u63a7\u5236\u7406\u8bba+\u73b0\u4ee3\u63a7\u5236\u7406\u8bba\u7684\uff0c\u60f3\u5f53\u5e74\u7ebf\u6027\u4e8c\u9636\u7cfb\u7edf\u7684\u5948\u594e\u65af\u7279\u56fe\u548c\u4f2f\u5fb7\u56fe\u7684\u7ed8\u5236\u4e5f\u753b\u7684\u5f88\u6e9c\u3002</p> <p>\u53ef\u8bf4\u8d77\u6765\u60ed\u6127\u7684\u662f\uff0c\u76f4\u5230\u73b0\u5728\u6211\u624d\u521a\u521a\u5f04\u61c2\u4e00\u70b9\u6700\u4f18\u63a7\u5236\u7406\u8bba\u7684\u4e00\u70b9\u70b9\u5185\u5bb9\u3002</p> <p>\u7531\u4e8e\u7855\u58eb\u671f\u95f4\u505a\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u6240\u4ee5\u63a7\u5236\u7406\u8bba\u76f8\u5173\u7684\u5185\u5bb9\u90fd\u5feb\u5fd8\u5f97\u5dee\u4e0d\u591a\u4e86\uff0c\u597d\u5728\u5e95\u5b50\u8fd8\u5728\uff0c\u6162\u6162\u8fd8\u80fd\u5c31\u6361\u4e86\u8d77\u6765\u3002</p> <p>\u518d\u52a0\u4e0a\u5b66\u8fc7\u77e9\u9635\u8bba\u540e\uff0c\u5bf9\u4e8e\u77e9\u9635\u6c42\u5bfc\u4e4b\u7c7b\u7684\u4e0d\u518d\u964c\u751f\uff0c\u5bf9\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u63a8\u5bfc\u7684\u63a5\u53d7\u7a0b\u5ea6\u4e5f\u6bd4\u8f83\u5feb\uff0c\u8fd9\u4e48\u6765\u770b\u5b66\u4e60\u7684\u6bcf\u4e00\u5904\u77e5\u8bc6\u90fd\u6709\u7528\u3002</p> <p>\u672c\u6587\u7684\u4e00\u4e9b\u4ecb\u7ecd\u6027\u6587\u5b57\u90fd\u662f\u4ece\u76f8\u5173\u6587\u732e\u6216\u8005\u516c\u4f17\u53f7\u4e0a\u6458\u6284\u7ec4\u5408\u800c\u6765\uff0c\u76f8\u5173\u94fe\u63a5\u4f1a\u653e\u5728\u6587\u7ae0\u672b\u5c3e</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#_3","title":"\u4e00\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u4ecb\u7ecd","text":""},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#11","title":"1.1\u5173\u4e8e\u6ee4\u6ce2","text":"<p>\u63f4\u5f15\u6765\u81ea\u77e5\u4e4e\u5927\u795e\u7684\u89e3\u91ca\u3002</p> <p>\u4e00\u4f4d\u4e13\u4e1a\u8bfe\u7684\u6559\u6388\u7ed9\u6211\u4eec\u4e0a\u8bfe\u7684\u65f6\u5019\uff0c\u66fe\u8c08\u5230\uff1afiltering is weighting\uff08\u6ee4\u6ce2\u5373\u52a0\u6743\uff09\u3002\u6ee4\u6ce2\u7684\u4f5c\u7528\u5c31\u662f\u7ed9\u4e0d\u540c\u7684\u4fe1\u53f7\u5206\u91cf\u4e0d\u540c\u7684\u6743\u91cd\u3002\u6700\u7b80\u5355\u7684loss pass filter\uff0c \u5c31\u662f\u76f4\u63a5\u628a\u4f4e\u9891\u7684\u4fe1\u53f7\u7ed91\u6743\u91cd\uff0c\u800c\u7ed9\u9ad8\u9891\u90e8\u52060\u6743\u91cd\u3002\u5bf9\u4e8e\u66f4\u590d\u6742\u7684\u6ee4\u6ce2\uff0c\u6bd4\u5982\u7ef4\u7eb3\u6ee4\u6ce2, \u5219\u8981\u6839\u636e\u4fe1\u53f7\u7684\u7edf\u8ba1\u77e5\u8bc6\u6765\u8bbe\u8ba1\u6743\u91cd\u3002 \u4ece\u7edf\u8ba1\u4fe1\u53f7\u5904\u7406\u7684\u89d2\u5ea6\uff0c\u964d\u566a\u53ef\u4ee5\u770b\u6210\u6ee4\u6ce2\u7684\u4e00\u79cd\u3002\u964d\u566a\u7684\u76ee\u7684\u5728\u4e8e\u7a81\u51fa\u4fe1\u53f7\u672c\u8eab\u800c\u6291\u5236\u566a\u58f0\u5f71\u54cd\u3002\u4ece\u8fd9\u4e2a\u89d2\u5ea6\uff0c\u964d\u566a\u5c31\u662f\u7ed9\u4fe1\u53f7\u4e00\u4e2a\u9ad8\u7684\u6743\u91cd\u800c\u7ed9\u566a\u58f0\u4e00\u4e2a\u4f4e\u7684\u6743\u91cd\u3002\u7ef4\u7eb3\u6ee4\u6ce2\u5c31\u662f\u4e00\u4e2a\u5178\u578b\u7684\u964d\u566a\u6ee4\u6ce2\u5668\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#12","title":"1.2 \u4f55\u4e3a\u5361\u5c14\u66fc\u6ee4\u6ce2","text":"<p>\u5361\u5c14\u66fc\u6ee4\u6ce2\uff08Kalman filtering\uff09\u4e00\u79cd\u5229\u7528\u7ebf\u6027\u7cfb\u7edf\u72b6\u6001\u65b9\u7a0b\uff0c\u901a\u8fc7\u7cfb\u7edf\u8f93\u5165\u8f93\u51fa\u89c2\u6d4b\u6570\u636e\uff0c\u5bf9\u7cfb\u7edf\u72b6\u6001\u8fdb\u884c\u6700\u4f18\u4f30\u8ba1\u7684\u7b97\u6cd5\u3002</p> <p>\u7531\u4e8e\u89c2\u6d4b\u6570\u636e\u4e2d\u5305\u62ec\u7cfb\u7edf\u4e2d\u7684\u566a\u58f0\u548c\u5e72\u6270\u7684\u5f71\u54cd\uff0c\u6240\u4ee5\u6700\u4f18\u4f30\u8ba1\u4e5f\u53ef\u770b\u4f5c\u662f\u6ee4\u6ce2\u8fc7\u7a0b\u3002</p> <p>Kalman Filter \u7b97\u6cd5\uff0c\u662f\u4e00\u79cd\u9012\u63a8\u9884\u6d4b\u6ee4\u6ce2\u7b97\u6cd5\uff0c\u7b97\u6cd5\u4e2d\u6d89\u53ca\u5230\u6ee4\u6ce2\uff0c\u4e5f\u6d89\u53ca\u5230\u5bf9\u4e0b\u4e00\u65f6\u523b\u6570\u636e\u7684\u9884\u6d4b\u3002Kalman Filter \u7531\u4e00\u7cfb\u5217\u9012\u5f52\u6570\u5b66\u516c\u5f0f\u63cf\u8ff0\u3002\u5b83\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u53ef\u8ba1\u7b97\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u8fc7\u7a0b\u7684\u72b6\u6001\uff0c\u5e76\u4f7f\u4f30\u8ba1\u5747\u65b9\u8bef\u5dee\u6700\u5c0f\u3002</p> <p>Kalman Filter \u4e5f\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u4e00\u79cd\u6570\u636e\u878d\u5408\u7b97\u6cd5\uff08Data fusion algorithm\uff09\uff0c\u5df2\u670950\u591a\u5e74\u7684\u5386\u53f2\uff0c\u662f\u5f53\u4eca\u4f7f\u7528\u6700\u91cd\u8981\u548c\u6700\u5e38\u89c1\u7684\u6570\u636e\u878d\u5408\u7b97\u6cd5\u4e4b\u4e00\u3002Kalman Filter \u7684\u5de8\u5927\u6210\u529f\u5f52\u529f\u4e8e\u5176\u5c0f\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u4f18\u96c5\u7684\u9012\u5f52\u5c5e\u6027\u4ee5\u53ca\u4f5c\u4e3a\u5177\u6709\u9ad8\u65af\u8bef\u5dee\u7edf\u8ba1\u7684\u4e00\u7ef4\u7ebf\u6027\u7cfb\u7edf\u7684\u6700\u4f18\u4f30\u8ba1\u5668\u7684\u72b6\u6001\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#13","title":"1.3\u5e94\u7528\u573a\u666f","text":"<p>\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u4e4b\u524d\u88ab\u5e7f\u6cdb\u7528\u6765\u505a\u52a8\u6001\u7cfb\u7edf\u7684\u72b6\u6001\u4f30\u8ba1\u3001\u9884\u6d4b\u3002\u4e3b\u8981\u7684\u76ee\u7684\u5c31\u662f\u7528\u6765\u4ece\u5e26\u566a\u58f0\u7684\u89c2\u6d4b\u91cf\uff0c\u6bd4\u5982\u5404\u79cd\u4f20\u611f\u5668\u7684\u89c2\u6d4b\uff08IMU\u3001GPS\u3001\u91cc\u7a0b\u8ba1\u7b49\uff09\u4f30\u8ba1\u51fa\u6700\u4f18\u7684\u7cfb\u7edf\u72b6\u6001\uff08state\uff09\u3002\u4e0d\u8fc7\u8981\u660e\u786e\u5f3a\u8c03\u7684\u662f\uff0c\u7531\u4e8e\u6d4b\u91cf\u90fd\u5e26\u6709\u566a\u58f0\uff0c\u4e5f\u5c31\u662f\u968f\u673a\u6027\uff0c\u6240\u4ee5\u771f\u6b63\u51c6\u786e\u7684\u72b6\u6001\u662f\u65e0\u6cd5\u83b7\u77e5\u7684\u3002</p> <p>\u6700\u5c0f\u4e8c\u4e58\u6cd5\u53ef\u4ee5\u4ece\u4e00\u957f\u4e32\u7684\u6d4b\u91cf\u503c\u56de\u5f52\u51fa\u4e00\u4e2a\u6700\u4e3a\u5339\u914d\u7684\u6a21\u578b\u3002\u5361\u5c14\u66fc\u6ee4\u6ce2\u76f8\u6bd4\u4e8e\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff0c\u91c7\u7528\u4e86\u4e00\u79cd\u9012\u5f52\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e00\u65f6\u523b\u53ea\u9700\u8981\u4fdd\u5b58\u4e0a\u4e00\u65f6\u523b\u7684\u72b6\u6001\u3002\u56e0\u6b64\u53ef\u4ee5\u88ab\u7528\u6765\u5904\u7406\u5b9e\u65f6\u4efb\u52a1\u3002</p> <p>\u65af\u5766\u5229\u00b7\u65bd\u5bc6\u7279(Stanley Schmidt)\u9996\u6b21\u5b9e\u73b0\u4e86\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u3002\u5361\u5c14\u66fc\u5728NASA\u57c3\u59c6\u65af\u7814\u7a76\u4e2d\u5fc3\u8bbf\u95ee\u65f6\uff0c\u53d1\u73b0\u4ed6\u7684\u65b9\u6cd5\u5bf9\u4e8e\u89e3\u51b3\u963f\u6ce2\u7f57\u8ba1\u5212\u7684\u8f68\u9053\u9884\u6d4b\u5f88\u6709\u7528\uff0c\u540e\u6765\u963f\u6ce2\u7f57\u98de\u8239\u7684\u5bfc\u822a\u7535\u8111\u4f7f\u7528\u4e86\u8fd9\u79cd\u6ee4\u6ce2\u5668\u3002</p> <p>\u867d\u7136\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u4ece\u7f8e\u56fd\u963f\u6ce2\u7f57\u767b\u6708\u8ba1\u5212\u5230\u5982\u4eca\u5df2\u6709\u51e0\u5341\u5e74\uff0c\u4e14\u76ee\u524d\u6709\u66f4\u5148\u8fdb\u7684\u56e0\u5b50\u56fe\uff08Factor Graph\uff09\u7b97\u6cd5\uff0c\u4f46\u662f\u5728\u5f88\u591a\u9886\u57df\u4f9d\u65e7\u53ef\u4ee5\u770b\u5230\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7684\u8eab\u5f71\uff0c\u7279\u522b\u662f\u5728\u81ea\u52a8\u9a7e\u9a76\u7684\u5404\u4e2a\u6a21\u5757\uff0c\u6bd4\u5982\uff1a\u4eceIMU\u7684\u6570\u636e\uff08\u4e09\u8f74\u52a0\u901f\u5ea6\uff0c\u4e09\u8f74\u89d2\u901f\u5ea6\uff09\u8ba1\u7b97\u51fa\u8fd0\u52a8\u7269\u4f53\u7684\u5f53\u524d\u4f4d\u7f6e\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#_4","title":"\u4e8c\u3001\u57fa\u7840\u77e5\u8bc6\u51c6\u5907","text":""},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#21","title":"2.1 \u5e73\u5747\u503c\u6ee4\u6ce2\u4e2d\u7684\u6570\u636e\u878d\u5408","text":"<p>\u5047\u8bbe\u6211\u4eec\u5bf9\u67d0\u4e00\u4e2a\u7269\u7406\u91cf\u62ff\u4eea\u5668\u8fdb\u884c\u6d4b\u91cf<code>k</code>\u6b21\uff0c\u524d<code>k-1</code>\u6b21\u7684\u5e73\u5747\u503c\u4e3a \\(\\bar x_{k-1}\\) \uff0c\u7b2ck\u6b21\u6d4b\u91cf\u7ed3\u679c\u4e3a \\(x_k\\) \uff0c\u5219\u7b2c<code>k</code>\u6b21\u65f6\u5e73\u5747\u503c\u6ee4\u6ce2\u7ed3\u679c\u8ba1\u7b97\u5982\u4e0b\uff1a</p> \\[ \\begin{align*} \\bar x_{k} &amp;= \\frac{\\bar x_{k-1} * (k - 1) + x_{k}}{k} \\\\            &amp;= \\bar x_{k-1} * (1 - \\frac{1}{k}) + \\frac{1}{k} x_{k} \\\\            &amp;= \\bar x_{k-1} + \\frac{1}{k}(x_k - \\bar x_{k-1}) \\end{align*} \\] <p>\u5728\u5e73\u5747\u503c\u6ee4\u6ce2\u4e2d\uff0c\u65b0\u7684 \\(\\bar x_k\\) \u53ef\u4ee5\u770b\u505a \\(x_k\\) \u548c \\(\\bar x_{k-1}\\) \u7684\u7ebf\u6027\u52a0\u6743\u878d\u5408\uff0c \\(\\frac{1}{k}\\) \u5373\u4e3a\u878d\u5408\u56e0\u5b50\u3002 \\(\\bar x_{k-1}\\) \u4e3a\u8fc7\u5f80\u7684\u72b6\u6001\u503c\uff0c \\(x_k\\) \u4e3a\u6700\u65b0\u7684\u6d4b\u91cf\u503c\uff0c\u5e73\u5747\u503c\u6ee4\u6ce2\u5c31\u53ef\u4ee5\u770b\u505a\u662f\u5bf9\u8fc7\u5f80\u7684\u72b6\u6001\u503c\u548c\u6700\u65b0\u7684\u72b6\u6001\u503c\u7684\u878d\u5408\u3002</p> <p>\u5c06\u4e0a\u8ff0\u516c\u5f0f\u4e2d \\(\\frac{1}{k}\\) \u62bd\u8c61\u4e3a\u4e00\u4e2a\u53ef\u4ee5\u53d8\u5316\u7684\u7cfb\u6570 \\(K\\) \uff0c\u5219\u4e00\u822c\u6027\u7684\u6570\u636e\u7ebf\u6027\u52a0\u6743\u878d\u5408\u516c\u5f0f\u4e3a</p> \\[ \\hat x_k = \\hat x_{k-1} + K_k(z_k - \\hat x_{k-1}) \\] <p>\u8be5\u516c\u5f0f\u53ef\u4ee5\u7406\u89e3\u4e3a</p> <pre><code>\u5f53\u524d\u7684\u4f30\u8ba1\u503c = \u4e0a\u4e00\u6b21\u7684\u4f30\u8ba1\u503c + \u7cfb\u6570 * (\u5f53\u524d\u7684\u6d4b\u91cf\u503c - \u4e0a\u4e00\u6b21\u7684\u4f30\u8ba1\u503c)\n</code></pre> <p>\u5728\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\uff0c\u4e5f\u91c7\u7528\u4e86\u4e0a\u8ff0\u6570\u636e\u878d\u5408\u7684\u601d\u60f3\uff0c\u53ea\u4e0d\u8fc7 \\(K_k\\) \u7684\u503c\u662f\u968f\u7740\u8fed\u4ee3\u52a8\u6001\u53d8\u5316\u7684\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#22","title":"2.2 \u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\u5bf9\u4e8e\u6570\u636e\u7684\u878d\u5408","text":"<p>\u4e3a\u4e86\u63cf\u8ff0\u7cfb\u7edf\u7279\u6027\uff0c\u8fd9\u91cc\u7ed9\u51fa\u7cfb\u7edf\u7684\u72b6\u6001\u65b9\u7a0b\u548c\u6d4b\u91cf\u65b9\u7a0b</p> \\[ \\begin{align*} &amp;x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k-1} \\\\ &amp;z_k = H_k x_k + v_k \\end{align*} \\] <p>\u5176\u4e2d\uff0c \\(A_{k-1}\\) \u4e3a\u72b6\u6001(\u8f6c\u79fb)\u77e9\u9635\uff08Transition Matrix\uff09\uff0c \\(x_{k-1}\\) \u8bb0\u4e3a \\(k-1\\) \u65f6\u523b\u7684\u72b6\u6001\u5411\u91cf\u3002</p> <p>\\(u_{k-1}\\) \u4e3a \\(k-1\\) \u65f6\u523b\u8f93\u5165\uff0c \\(B_{k-1}\\) \u79f0\u4e3a\u63a7\u5236\u77e9\u9635\uff08Control Matrix\uff09\uff0c\u53cd\u6620\u4e86\u7cfb\u7edf\u8f93\u5165\u5230\u7cfb\u7edf\u72b6\u6001\u7684\u6620\u5c04\u5173\u7cfb\u3002</p> <p>\\(w_{k-1}\\) \u662f\u8fc7\u7a0b\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u77e9\u9635\u4e3a \\(Q_{k-1}\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\\(H_k\\) \u4e3a\u6d4b\u91cf\u77e9\u9635\uff08Measurement Matrix\uff09\uff0c\u63cf\u8ff0\u4e86\u4ece\u7cfb\u7edf\u72b6\u6001\u5230\u6d4b\u91cf\u503c\u7684\u8f6c\u6362\u5173\u7cfb\uff08\u4e3e\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u5173\u7cfb\uff0c\u7cfb\u7edf\u72b6\u6001\u662f\u7269\u4f53\u7684\u76f4\u7ebf\u8ddd\u79bb\uff0c\u6d4b\u91cf\u503c\u662f\u4f7f\u7528\u6fc0\u5149\u7b14\u6d4b\u51fa\u6765\u7684\u5149\u4ece\u539f\u70b9\u5230\u7269\u4f53\u7684\u65f6\u95f4\uff0c\u90a3\u4e48 \\(H_k\\) \u5c31\u662f\u5149\u901f\u7684\u5012\u6570\uff09</p> <p>\\(v_k\\) \u662f\u6d4b\u91cf\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u4e3a \\(R_k\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\u6211\u4eec\u8fd8\u9700\u8981\u5f15\u51fa\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b\u548c\u6d4b\u91cf\u4f30\u8ba1\u65b9\u7a0b\u7684\u6982\u5ff5</p> <p>\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b\u662f\u53d6\u5f97\u662f\u6bcf\u4e00\u9879\u7684\u6982\u7387\u6700\u5927\u503c\u5904\u5bf9\u5e94\u7684\u81ea\u53d8\u91cf\u7684\u503c\uff0c\u566a\u58f0 \\(w_{k-1}\\) \u662f\u5747\u503c\u4e3a0\u7684\u9ad8\u65af\u566a\u58f0\uff0c\u56e0\u6b64\u6700\u5927\u6982\u7387\u5bf9\u5e94\u7684\u503c\u4e3a0\u3002</p> \\[ \\begin{align*} &amp;\\hat x^-_k = A_{k - 1}\\hat x^{+}_{k - 1} + B_{k-1}u_{k-1} + 0\\\\ \\end{align*} \\] <p>\u5bf9\u7cfb\u7edf\u72b6\u6001\u5411\u91cf\u4e0a\u9762\u52a0\u4e0a\u4e00\u4e2a\u5e3d\u5b50\u7b26\u53f7\u8868\u793a\u8fd9\u662f\u4e00\u4e2a\u4f30\u8ba1\u91cf\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u5b9e\u9645\u8f93\u51fa\u7684\u91cf\u3002</p> <p>\\(\\hat x^{+}_{k - 1}\\) \u8868\u793a \\(k-1\\) \u65f6\u523b\u65f6\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u540e\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u540e\u9a8c\u4f30\u8ba1\u3002</p> <p>\\(\\hat x^-_k\\) \u8868\u793a\u5f53\u524d\u6839\u636e\u7cfb\u7edf\u72b6\u6001\u65b9\u7a0b\u8ba1\u7b97\u9884\u6d4b\u5f97\u5230\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u5148\u9a8c\u4f30\u8ba1\u3002</p> <p>\u6d4b\u91cf\u4f30\u8ba1\u65b9\u7a0b\u540c\u6837\u5ffd\u7565\u566a\u58f0\u9879\uff0c\u53d8\u6210\u5bf9\u6b64\u65f6\u6d4b\u91cf\u91cf\u7684\u4f30\u8ba1</p> \\[ \\hat z_k = H_k \\hat x^-_k \\] <p>\u7531\u4e8e\u6211\u4eec\u4e0d\u5bf9 \\(z_k\\) \u505a\u6700\u4f18\u4f30\u8ba1\uff0c\u6240\u4ee5\u4e0d\u8d4b\u4e88\u5176\u53f3\u4e0a\u89d2\u7684\u52a0\u51cf\u4e0a\u4e0b\u6807\u3002</p> <p>\u56de\u5230\u5361\u5c14\u66fc\u6ee4\u6ce2\uff0c\u6211\u4eec\u8981\u89c2\u6d4b\u4e00\u4e2a\u7cfb\u7edf\u4e2d\u7684\u4e00\u4e9b\u72b6\u6001\u503c\u6709\u4e24\u79cd\u529e\u6cd5\u3002</p> <p>\u4e00\u79cd\u662f\u901a\u8fc7\u7cfb\u7edf\u7684\u72b6\u6001\u8f6c\u79fb\u65b9\u7a0b\uff0c\u5e76\u7ed3\u5408\u4e0a\u4e00\u65f6\u523b\u7684\u72b6\u6001\u63a8\u5f97\u4e0b\u4e00\u65f6\u523b\u7684\u72b6\u6001\u3002</p> <p>\u4e00\u79cd\u662f\u501f\u52a9\u8f85\u52a9\u7cfb\u7edf\uff08\u6d4b\u91cf\u7cfb\u7edf\uff09\u7684\u6d4b\u91cf\u53cd\u63a8\u51fa\u7cfb\u7edf\u72b6\u6001\u3002</p> <p>\u8fd9\u4e24\u79cd\u65b9\u5f0f\u90fd\u6709\u5404\u81ea\u7684\u4e0d\u786e\u5b9a\u6027\uff08\u542b\u6709\u566a\u58f0\uff09\uff0c\u5361\u5c14\u66fc\u6ee4\u6ce2\u76ee\u6807\u662f\u5c06\u8fd9\u4e24\u8005\u505a\u5230\u6700\u4f18\u7ed3\u5408\uff08\u52a0\u6743\u5e73\u5747\uff09\uff0c\u4f7f\u5f97\u6211\u4eec\u4f30\u8ba1\u7684\u72b6\u6001\u7684\u4e0d\u786e\u5b9a\u6027\u5c0f\u4e8e\u5176\u4e2d\u4efb\u4f55\u4e00\u79cd\u3002</p> <p>\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u76ee\u6807\u662f\u5f97\u5230\u4e00\u4e2a\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1\u91cf\uff08Linear Minimum Mean Square Error, LMMSE\uff09\uff0c\u4f7f\u5176\u6ee1\u8db3\u8be5\u4f30\u8ba1\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee\u8fbe\u5230\u6700\u5c0f\u3002</p> <p>\u5047\u8bbe \\(x_k\\) \u4e3a\u771f\u5b9e\u503c\uff0c\u90a3\u4e48\u5361\u5c14\u66fc\u6ee4\u6ce2\u5c31\u662f\u627e\u5230\u4e00\u4e2a\u5408\u9002\u7684 \\(K_k\\) \u4f7f\u5f97\u4e0b\u9762\u5f0f\u5b50\u4e2d\u7684 \\(\\text{E}({||x_k - \\hat x^+_k||}^2)\\) \u6700\u5c0f\u3002</p> <p>\u6211\u4eec\u6839\u636e\u6d4b\u91cf\u65b9\u7a0b\u53ef\u4ee5\u53cd\u63a8\u51fa\u72b6\u6001\u5411\u91cf\u7684\u6d4b\u91cf\u53cd\u63a8\u503c \\(x_{measure}\\) </p> \\[ x^{measure}_k = H_k^{-1} z_k \\] \\[ \\begin{align*} \\hat x^+_k &amp;= \\hat x^-_{k} + G_k(x^{measure}_k - \\hat x^-_{k}) \\\\            &amp;= \\hat x^-_{k} + G_k H_k^{-1} H_k (x^{measure}_k - \\hat x^-_{k}) \\\\            &amp;= \\hat x^-_{k} + G_k H_k^{-1} (z_k - \\hat z^k) \\\\            &amp;= \\hat x^-_{k} + K_k (z_k - \\hat z^k) \\end{align*} \\] <p>\u4e0a\u8ff0\u5f0f\u5b50\u4e2d\uff0c\u4e3a\u4e86\u5c55\u793a \\(\\hat x^+_k\\) \u7684\u878d\u5408\u8fc7\u7a0b\uff0c\u5c06 \\(K_k\\) \u5b9a\u4e49\u4e3a \\(G_k H_k^{-1}\\) \u3002</p> <p>\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u76ee\u6807\u51fd\u6570\u4e3a</p> \\[ minimize\\ \\text{E}({|x_k - \\hat x^+_k|}^2) = minimize\\ \\text{E}({|x_k - \\hat x^+_k|}*{|x_k - \\hat x^+_k|}^\\text{T}) \\] <p>\u8fd9\u91cc\uff0c\u6211\u4eec\u5c1d\u8bd5\u7b80\u5316\u4e00\u4e0b</p> \\[ \\begin{align*} &amp;\\text{E}({|x_k - \\hat x^+_k|}*{|x_k - \\hat x^+_k|}^\\text{T}) = \\text{D}({x_k - \\hat  x^+_k}) + [\\text{E}({x_k - \\hat x^+_k})]^2 \\\\ \\end{align*} \\] <p>\u8fd9\u91cc \\(x_k\\) \u4e3a\u771f\u5b9e\u503c\uff0c\u8868\u793a\u4e00\u4e2a\u5e38\u6570\uff0c\u6211\u4eec\u5047\u8bbe\u5728\u521d\u59cb\u72b6\u6001\u4e0b\uff08\u5373k=0\uff09\u65f6\uff0c \\(\\hat x^+\\) \u53ef\u4ee5\u51c6\u786e\u7684\u63cf\u8ff0 \\(x_k\\) \uff0c\u5373 \\(\\text E(x_0 - \\hat x^+_0)=0\\) \u3002</p> <p>\u8fd9\u91cc\u6211\u4eec\u5c1d\u8bd5\u5316\u7b80\u4e00\u4e0b \\(x_k - \\hat x^+_k\\) </p> \\[ \\begin{align*} x_k - \\hat x^+_k &amp;= x_k - (\\hat x^-_{k} + K_k (z_k - \\hat z_k)) \\\\                  &amp;= x_k - (\\hat x^-_{k} + K_k(H_k x_k + v_k - H_k \\hat x^-_{k})) \\\\                  &amp;= x_k - \\hat x^-_{k} - K_kH_k x_k - K_kv_k + K_kH_k\\hat x^-_{k} \\\\                  &amp;= (x_k - \\hat x^-_{k}) - K_kH_k(x_k - \\hat x^-_{k}) - K_kv_k \\\\                  &amp;= (I - K_kH_k)(x_k - \\hat x^-_{k}) - K_kv_k \\\\                  &amp;= (I - K_kH_k)[(A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k-1}) - (A_{k - 1}\\hat x^{+}_{k - 1} + B_{k-1}u_{k-1})] - K_kv_k \\\\                  &amp;= (I - K_kH_k)A_{k - 1}(x_{k - 1} - \\hat x^{+}_{k - 1}) + (I - K_kH_k) w_{k-1} - K_kv_k \\\\ \\end{align*} \\] \\[ \\begin{align*} \\text{E}({x_k - \\hat x^+_k}) &amp;= E[(I - K_kH_k)A_{k - 1}(x_{k - 1} - \\hat x^{+}_{k - 1}) + (I - K_kH_k) w_{k-1} - K_kv_k] \\\\                              &amp;= (I - K_kH_k)A_{k - 1}E(x_{k - 1} - \\hat x^{+}_{k - 1})  \\end{align*} \\] \\[ \\begin{align*} \\text{E}({x_k - \\hat x^+_k}) &amp;= E[(I - K_kH_k)(x_k - \\hat x^-_{k}) - K_kv_k] \\\\                              &amp;= (I - K_kH_k)E(x_k - \\hat x^-_{k})  \\end{align*} \\] <p>\u5728\u4e0a\u8ff0\u516c\u5f0f\u4e2d\uff0c \\(z_k\\) \u548c \\(x_k\\) \u9700\u8981\u7406\u89e3\u4e3a\u4e00\u4e2a\u5e38\u91cf\uff0c\u800c\u4e0d\u662f\u670d\u4ece\u67d0\u4e00\u4e2a\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\u3002</p> <p>\u6709\u4e0a\u9762\u7684\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u4e8e\u4e0a\u8ff0\u7ebf\u6027\u7cfb\u7edf\u7684\u5efa\u6a21\u540e\uff0c \\(K_k\\) \u53d6\u4efb\u610f\u503c\uff0c\u90fd\u53ef\u4ee5\u4fdd\u8bc1\u65e0\u504f\u6027\u7684\u4f20\u9012\u3002</p> <p>\u540c\u65f6\u4e5f\u53ef\u4ee5\u770b\u51fa\uff0c\u82e5\u540e\u9a8c\u4f30\u8ba1\u4fdd\u6301\u4e86\u65e0\u504f\u6027\u7684\u4f20\u9012\u6027\uff0c\u5148\u9a8c\u4f30\u8ba1 \\(\\hat x^-_{k}\\) \u4e5f\u662f\u65e0\u504f\u7684\u3002</p> <p>\u4e00\u822c\u7684\u6750\u6599\u4e2d\uff0c\u5e38\u8bf4\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u4f30\u8ba1\u503c\u662f\u65e0\u504f\u4f30\u8ba1\uff0c\u5b9e\u9645\u4e0a\u8fd9\u662f\u7531\u6761\u4ef6\u7684\uff0c\u5176\u4e2d\u8981\u6c42\u7cfb\u7edf\u566a\u58f0\u548c\u91cf\u6d4b\u566a\u58f0\u4e3a\u4e0d\u76f8\u5173\u3001\u96f6\u671f\u671b\u7684\u767d\u566a\u58f0\uff0c\u4e14\u662f\u7ebf\u6027\u7cfb\u7edf\uff0c\u521d\u59cb\u65f6\u523b\u7684\u72b6\u6001\u4f30\u8ba1\u662f\u65e0\u504f\u7684\u3002\u5f53\u8fd9\u4e9b\u6761\u4ef6\u4e0d\u80fd\u6ee1\u8db3\u65f6\uff0cKalman\u6ee4\u6ce2\u7684\u4f30\u8ba1\u7ed3\u679c\u662f\u6709\u504f\u7684\u3002 \u6211\u4eec\u8fd9\u91cc\u662f\u5148\u7ed9\u51fa\u4e86\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u4e00\u822c\u516c\u5f0f\uff0c\u7136\u540e\u518d\u8bc1\u660e\u5176\u65e0\u504f\u6027\u3002 \u5b9e\u9645\u4e0a\u4e5f\u53ef\u4ee5\u8981\u6c42\u5176\u65e0\u504f\uff0c\u8bbe \\(x^+_k = K_1 \\hat x^-_{k} + K_2 x^{measure}_k\\) \uff0c\u4ece\u65e0\u504f\u6027\u4e2d\u63a8\u51fa \\(K_1\\) \u4e0e \\(K_2\\) \u7684\u5173\u7cfb\u3002</p> <p>\u518d\u56de\u5230\u539f\u6765\u7684\u516c\u5f0f</p> \\[ \\begin{align*} \\text{E}({|x_k - \\hat x^+_k|}*{|x_k - \\hat x^+_k|}^\\text{T}) &amp;= \\text{D}({x_k - \\hat  x^+_k}) \\end{align*} \\] <p>\u7531\u6b64\u53ef\u4ee5\u770b\u51fa\uff0c\u4f30\u8ba1\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee\u5c31\u662f\u4f30\u8ba1\u8bef\u5dee\u7684\u65b9\u5dee\u3002</p> <p>\u6211\u4eec\u7ee7\u7eed\u5316\u7b80</p> \\[ \\begin{align*} \\text{E}({|x_k - \\hat x^+_k|}*{|x_k - \\hat x^+_k|}^\\text{T}) &amp;= \\text{E}(\\hat x^+_k - x_k)^2 \\\\                   &amp;= \\text{E}[(\\hat x^+_k - \\text{E}(\\hat x^+_k)) + (\\text{E}(\\hat x^+_k) - x_k)]^2 \\\\                   &amp;= \\text{E}[(\\hat x^+_k - \\text{E}(\\hat x^+_k))]^2 \\\\                   &amp;= \\text D(\\hat x^+_k) \\end{align*} \\] <p>\u8fd9\u91cc\u7528\u7528\u4e0a\u4e86\u65e0\u504f\u4f30\u8ba1\u7684\u6761\u4ef6\uff0c \\(\\text{E}(\\hat x^+_k) = x_k\\) \uff0c\u76ee\u6807\u51fd\u6570\u53ef\u4ee5\u5316\u7b80\u4e3a</p> \\[ minimize\\ \\text{E}({|x_k - \\hat x^+_k|}^2) = minimize\\ \\text{sum}(\\text D(\\hat x^+_k)) \\] <p>\u8fd9\u91cc\u53c8\u5f97\u51fa\u53e6\u5916\u4e00\u4e2a\u91cd\u8981\u7ed3\u8bba\uff0c\u5728\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\uff0c\u6700\u4f18\u4f30\u8ba1\u503c\u662f\u65e0\u504f\u4f30\u8ba1\u7684\u6761\u4ef6\u4e0b\uff0c\u6700\u5c0f\u5316\u4f30\u8ba1\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee\u7b49\u4ef7\u4e8e\u6700\u5c0f\u5316\u4f30\u8ba1\u503c\u7684\u65b9\u5dee\u3002</p> <p>\u56e0\u6b64\uff0c\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u601d\u60f3\u5373\u7ebf\u6027\u878d\u5408\u6240\u6709\u6570\u636e\u6765\u6e90\u7684\u5206\u5e03\uff0c\u6c42\u5404\u4e2a\u5206\u5e03\u7684\u7cfb\u6570K\u4f7f\u878d\u5408\u540e\u7684\u5206\u5e03\u65b9\u5dee\u6700\u5c0f\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#_5","title":"\u4e09\u3001\u516c\u5f0f\u63a8\u5bfc(\u6cd5\u4e00)","text":"<p>\u57282.2\u8282\u6211\u4eec\u7ed9\u51fa\u4e86\u5361\u5c14\u66fc\u6ee4\u6ce2\u4f30\u8ba1\u503c\u516c\u5f0f\u7684\u4e00\u822c\u5f62\u5f0f\uff0c\u4e5f\u9057\u7559\u4e86\u4e00\u4e2a\u95ee\u9898\uff0c\u5373\u5361\u5c14\u66fc\u589e\u76caK\u5982\u4f55\u53bb\u6c42\u3002</p> <p>\u63a5\u77402.2\u8282\u672b\u5c3e\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u76ee\u6807\u51fd\u6570\u5982\u4e0b\uff1a</p> \\[ minimize\\ \\text D(\\hat x^+_k) \\] <p>\u8fd9\u91cc\u9700\u8981\u7528\u5230\u4e00\u4e2a\u57fa\u7840\u516c\u5f0f\uff0c \\(\\text{D}(\\text{X}) = \\text{E}(\\text{X}^2) - (\\text{E}\\text{X})^2\\)  \u3002\u82e5 \\(\\text{E}(\\text{X}) = 0\\) \uff0c\u5219 \\(\\text{D}(\\text{X}) = \\text{E}(\\text{X}^2)\\) </p> \\[ \\begin{align*} \\hat x^+_k &amp;= \\hat x^-_{k} + K_k (z_k - \\hat z^k) \\\\                      &amp;= \\hat x^-_{k} + K_k (H_k x_k + v_k - H_k \\hat x^-_k) \\\\                      &amp;= \\hat x^-_{k} + K_k H_k( x_k - \\hat x^-_k) + K_k v_k \\end{align*} \\] <p>\u7531\u4e8e\u771f\u5b9e\u503c \\(x_k\\) \u53ef\u4ee5\u770b\u505a\u4e00\u4e2a\u5e38\u6570\uff0c\u4e0d\u5305\u542b\u53c2\u6570\uff0c\u5219</p> \\[ \\begin{align*} minimize \\text{E}({|x_k - \\hat x^+_k|}^2) &amp;= minimize\\ \\text D(\\hat x^+_k) \\\\ &amp;= minimize\\ \\text D(\\hat x^-_{k} + K_k H_k( x_k - \\hat x^-_k) + K_k v_k) \\\\ &amp;= minimize\\ \\text D(x^-_{k} - x_k - K_k H_k( x_k - \\hat x^-_k) + K_k v_k) \\\\ &amp;= minimize\\ \\text D((I - K_k H_k)(\\hat x^-_k - x_k) + K_k v_k) \\end{align*} \\] \\[ \\begin{align*} &amp;\\ D((I - K_k H_k)( \\hat x^-_k - x_k) + K_k v_k) \\\\ &amp;= D((I - K_k H_k)( \\hat x^-_k - x_k)) + D(K_k v_k) \\\\ &amp;= E((I - K_k H_k)( \\hat x^-_k - x_k)( \\hat x^-_k - x_k)^T(I - K_k H_k)^T) + E(K_k v_k v_k^T K_k^T ) \\\\ &amp;= (I - K_k H_k)E(( \\hat x^-_k - x_k )( \\hat x^-_k - x_k )^T)(I - K_k H_k)^T + K_kD(v_k)K_k^T \\\\ &amp;= (I - K_k H_k)E(| \\hat x^-_k - x_k |^2)(I - K_k H_k)^T + K_kR_kK_k^T \\end{align*} \\] <p>\u4e3a\u4e86\u6700\u5c0f\u5316\u4e0a\u8ff0\u516c\u5f0f\uff0c\u6211\u4eec\u5c06\u4e0a\u5f0f\u5b9a\u4e49\u4e3a \\(P_k^+\\) \uff08 \\(P_k^+ = \\text{E}({| \\hat x^+_k - x_k|}^2) = \\text D(\\hat x_k^+)\\)  )\uff0c\u7528\u4e8e\u8868\u793a\u72b6\u6001\u4f30\u8ba1\u8bef\u5dee\u77e9\u9635\u3002\u8bb0 \\(P_k^- = E(| \\hat x^-_k - x_k |^2)\\) </p> <p>\u6211\u4eec\u5b9a\u4e49 \\(k\\) \u65f6\u523b\u6700\u4f18\u72b6\u6001\u4f30\u8ba1\u7684\u65b9\u5dee\u548c\uff0c\u5373 \\(\\text D(\\hat x_k^+)\\) \uff08 \\(\\text{E}({|\\hat x^+_k - x_k|}^2)\\) \uff09\u7684\u5bf9\u89d2\u7ebf\u4e4b\u548c\uff08\u56e0\u4e3a\u5bf9\u89d2\u7ebf\u4e0a\u5373\u4e3a\u5404\u4e2a\u72b6\u6001\u5206\u7c7b\u7684\u65b9\u5dee\uff09\uff0c\u4e3a\u6700\u5c0f\u5316 \\(J_k\\) \uff0c\u6211\u4eec\u6709:</p> \\[ J_k = tr(P_k^+) \\] <p>\u4e0b\u9762\u4f1a\u8fdb\u5165\u5b9e\u6570\u5bf9\u77e9\u9635\u7684\u6c42\u5bfc\u73af\u8282\uff0c\u5148\u7ed9\u51fa\u51e0\u4e2a\u57fa\u672c\u516c\u5f0f\uff0c\u5177\u4f53\u8bc1\u660e\u8bfb\u8005\u53ef\u4ee5\u67e5\u9605\u77e9\u9635\u8bba\u76f8\u5173\u4e66\u7c4d\u8fdb\u884c\u63a8\u5bfc</p> \\[ \\begin{align*} &amp;\\frac{\\partial (ABA^T)}{\\partial A} = 2AB \\\\ &amp;tr(AB) = tr(BA) \\\\ &amp;tr(A \\pm B) = tr(A) \\pm tr(B) \\end{align*} \\] <p>\u8bbeY = AXB,\u5df2\u77e5 \\(\\frac{\\partial f}{\\partial Y}\\) , f\u4e3a\u5c06Y\u8f6c\u6362\u4e3a\u4e00\u4e2a\u6807\u91cf\u7684\u51fd\u6570\uff0c\u5219</p> \\[ \\begin{align*} d f &amp;= tr((\\frac{\\partial f}{\\partial Y})^T d Y) \\\\     &amp;= tr((\\frac{\\partial f}{\\partial Y})^T d(AXB)) \\\\     &amp;= tr((\\frac{\\partial f}{\\partial Y})^T Ad(X)B) \\\\     &amp;= tr((\\frac{\\partial f}{\\partial Y})^T Ad(X)B) \\\\     &amp;= tr(B(\\frac{\\partial f}{\\partial Y})^T Ad(X)) \\\\     &amp;= tr(A^T (\\frac{\\partial f}{\\partial Y}) B^T d(X)) \\end{align*} \\] \\[ \\begin{align*} \\frac{\\partial f}{\\partial X} = A^T (\\frac{\\partial f}{\\partial Y}) B^T \\end{align*} \\] <p>\u4e0b\u9762\u8fdb\u5165\u6c42\u5bfc\u5b9e\u64cd\u73af\u8282</p> \\[ \\begin{align*} \\frac{\\partial J_k}{\\partial K_k} &amp;= \\frac{\\partial  tr((I - K_k H_k)P_k^-(I - K_k H_k)^T)} {\\partial K_k} + \\frac{\\partial tr(K_kR_kK_k^T) }{\\partial K_k} \\\\ &amp;= -\\frac{\\partial  tr((I - K_k H_k)P_k^-(I - K_k H_k)^T)} {\\partial (I - K_k H_k)} H_k^T + 2K_kR_k \\\\ &amp;= -2(I - K_k H_k)P_k^-H_k^T + 2K_kR_k \\end{align*} \\] <p>\u4ee4\u4e0a\u5f0f\u4e3a0\uff0c\u6c42\u5f97</p> \\[ K_k = P_k^- H_k^T (R_k + H_k P_k^- H_k^T)^{-1} \\] <p>\u5c06 \\(K_k\\) \u5e26\u5165\u5230 \\(P_k^+\\) \u6c42\u5f97</p> \\[ \\begin{align*} P_k^+ &amp;= (I - K_k H_k)P_k^-(I - K_k H_k)^T + K_kR_kK_k^T \\\\       &amp;= (I - K_k H_k)P_k^-(I - K_k H_k)^T + ((I - K_k H_k)P_k^-H_k^T)K_k^T \\\\       &amp;= (I - K_k H_k)P_k^- - (I - K_k H_k)P_k^-H_k^TK_k^T  + ((I - K_k H_k)P_k^-H_k^T)K_k^T \\\\       &amp;= (I - K_k H_k)P_k^- \\end{align*} \\] <p>\u4e0b\u9762\u518d\u770b \\(P_k^-\\) \u7684\u8ba1\u7b97</p> \\[ \\begin{align*} P_k^- &amp;= E(| \\hat x^-_k - x_k |^2) \\\\       &amp;= E(|(A_{k - 1}\\hat x^{+}_{k - 1} + B_{k-1}u_{k-1}) - (A_{k - 1} x_{k - 1} + B_{k-1}u_{k-1} + w_{k-1})|^2) \\\\       &amp;= E(|A_{k - 1}(\\hat x^{+}_{k - 1} - x_{k - 1}) - w_{k-1}|^2) \\\\       &amp;= E((A_{k - 1}(\\hat x^{+}_{k - 1} - x_{k - 1}) - w_{k-1})(A_{k - 1}(\\hat x^{+}_{k - 1} - x_{k - 1}) - w_{k-1})^T) \\\\       &amp;= A_{k - 1}E(|\\hat x^{+}_{k - 1} - x_{k - 1}|^2)A_{k - 1}^T + E(w_{k-1} w_{k-1}^T) - E(w_{k-1})A_{k - 1}E(\\hat x^{+}_{k - 1} - x_{k - 1}) - A_{k - 1}E(\\hat x^{+}_{k - 1} - x_{k - 1})E(w_{k-1}) \\\\       &amp;= A_{k - 1}E(|\\hat x^{+}_{k - 1} - x_{k - 1}|^2)A_{k - 1}^T + E(w_{k-1} w_{k-1}^T) \\\\       &amp;= A_{k - 1}P_{k-1}^{+}A_{k - 1}^T + Q_{k-1} \\end{align*} \\] <p>\u81f3\u6b64\uff0c\u6211\u4eec\u7ec8\u4e8e\u63a8\u5bfc\u5b8c\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\u7684\u5173\u952e\u53c2\u6570 \\(K_k\\) \u548c \\(P_k^-\\) </p> <p>\u4e0b\u9762\u6574\u7406\u4e00\u4e0b\uff0c\u7ed9\u51fa\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5168\u90e8\u516c\u5f0f</p> <p>\u2460\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b</p> \\[ \\hat x^-_k = A_{k - 1}\\hat x^{+}_{k - 1} + B_{k-1}u_{k-1} \\] <p>\u2461\u6700\u4f18\u72b6\u6001\u4f30\u8ba1\u8fed\u4ee3\u66f4\u65b0\u516c\u5f0f</p> \\[ \\hat x^+_k = \\hat x^-_{k} + K_k (z_k - H_k \\hat x^-_k) \\] <p>\u2462\u5361\u5c14\u66fc\u589e\u76ca\u8ba1\u7b97\u516c\u5f0f</p> \\[ K_k = P_k^- H_k^T (R_k + H_k P_k^- H_k^T)^{-1} \\] <p>\u2463\u6700\u4f18(\u540e\u9a8c)\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u66f4\u65b0\u516c\u5f0f</p> \\[ P_k^+ = (I - K_k H_k)P_k^- \\] <p>\u2464\u5148\u9a8c\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u66f4\u65b0\u516c\u5f0f</p> \\[ P_k^- = A_{k - 1}P_{k-1}^{+}A_{k - 1}^T + Q_{k-1} \\]"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#_6","title":"\u56db\u3001\u7ed3\u8bed","text":"<p>\u6211\u5728\u6807\u9898\u548c\u7b2c\u4e09\u7ae0\u7684\u5730\u65b9\u90fd\u5199\u4e86\u201c\u4e00\u201d\u8fd9\u6837\u7684\u5b57\u6837\uff0c\u8fd9\u4ee3\u8868\u7740\u8fd8\u6709\u4e8c\u4e09\u56db....\uff0c\u6bd5\u7adf\u8fd8\u6709\u4e00\u4e9b\u8bc1\u660e\u65b9\u6cd5\u6ca1\u6709\u603b\u7ed3\uff0c\u8fd8\u6709\u4e00\u4e9b\u5e94\u7528\u6848\u4f8b\u6ca1\u6709\u4e3e\u4f8b\uff0c\u4e0d\u8fc7\u603b\u7b97\u5f00\u4e86\u4e2a\u5934\u3002</p> <p>\u4e00\u76f4\u60f3\u603b\u7ed3\u4e0b\u5361\u5c14\u66fc\u6ee4\u6ce2\u76f8\u5173\u7684\u77e5\u8bc6\uff0c\u770b\u4e86\u7f51\u4e0a\u597d\u591a\u8d44\u6599\u540e\uff0c\u51b3\u5b9a\u4e5f\u53d1\u8868\u4e0b\u81ea\u5df1\u7684\u770b\u6cd5\u548c\u8bc1\u660e\u65b9\u5f0f\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%80/#_7","title":"\u4e94\u3001\u53c2\u8003\u6587\u732e\u548c\u94fe\u63a5","text":"<ul> <li>https://www.zhihu.com/question/331568328/answer/735287556</li> <li>https://zhuanlan.zhihu.com/p/134595781</li> <li>https://zhuanlan.zhihu.com/p/578920168</li> <li>https://zhuanlan.zhihu.com/p/341440139</li> <li>https://mp.weixin.qq.com/s/MQUFI6IlN6JrUz2aju7eWA</li> </ul>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/","title":"\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u516c\u5f0f\u63a8\u5bfc\u548c\u5e94\u7528\u4e3e\u4f8b(\u4e09)","text":"<p>\u672c\u6587\u5199\u4e8e2024\u5e742\u670814\u65e5\u4e0a\u5348\u5341\u70b9\u30012024\u5e743\u670819\u65e5\u665a\u4e0a\u5341\u70b9\u548c2024\u5e743\u670820\u65e5\u665a\u4e0a\u5341\u70b9</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/#_2","title":"\u96f6\u3001\u524d\u8a00","text":"<p>\u9694\u4e86\u4e94\u4e2a\u591a\u6708\uff0c\u62bd\u51fa\u65f6\u95f4\u5b8c\u6210\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5e94\u7528\u7bc7\u3002\u672c\u6765\u4e00\u4e2a\u6708\u524d\u65e9\u5c31\u8ba1\u5212\u597d\u4e86\uff0c\u8fd9\u671f\u95f4\u6709\u4e9b\u4e8b\u4f18\u5148\u7ea7\u6bd4\u8f83\u9ad8\u5c31\u6401\u7f6e\u5230\u73b0\u5728\u3002\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5e94\u7528\u7bc7\u5305\u62ec\u4e24\u79cd\u5e94\u7528\uff0c\u5206\u522b\u662f\u5361\u5c14\u66fc\u6ee4\u6ce2\u529f\u80fd\u548c\u5361\u5c14\u66fc\u9884\u6d4b\u3002\u6b64\u5916\u8fd8\u6709\u5361\u5c14\u66fc\u5e73\u6ed1\u672c\u6587\u6682\u65f6\u4e0d\u6d89\u53ca\u3002\u6839\u636e\u9700\u8981\u8ba1\u7b97\u7684\u65f6\u95f4\u70b9\u76f8\u5bf9\u4e8e\u5df2\u77e5\u65f6\u95f4\u70b9\u6570\u636e\u7684\u65f6\u95f4\u5148\u540e\u987a\u5e8f\uff0c\u5206\u522b\u4e3a\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u5361\u5c14\u66fc\u5e73\u6ed1\u5668\u548c\u5361\u5c14\u66fc\u9884\u62a5\u5668\uff0c\u5177\u4f53\u5185\u5bb9\u53c2\u89c1\u300a\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u516c\u5f0f\u63a8\u5bfc\u548c\u5e94\u7528\u4e3e\u4f8b(\u4e8c\u300b\u4e2d\u7684\u5047\u8bbe\u4e09\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/#_3","title":"\u4e00\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u516c\u5f0f\u56de\u987e","text":"<p>\u7ebf\u6027\u7cfb\u7edf\u7684\u72b6\u6001\u65b9\u7a0b\u548c\u6d4b\u91cf\u65b9\u7a0b\u4f2a</p> \\[ \\begin{align*} &amp;x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k-1} \\\\ &amp;z_k = H_k x_k + v_k \\end{align*} \\] <p>\u5176\u4e2d\uff0c \\(A_{k-1}\\) \u4e3a\u72b6\u6001(\u8f6c\u79fb)\u77e9\u9635\uff08Transition Matrix\uff09\uff0c \\(x_{k-1}\\) \u8bb0\u4e3a \\(k-1\\) \u65f6\u523b\u7684\u72b6\u6001\u5411\u91cf\u3002</p> <p>\\(u_{k-1}\\) \u4e3a \\(k-1\\) \u65f6\u523b\u8f93\u5165\uff0c \\(B_{k-1}\\) \u79f0\u4e3a\u63a7\u5236\u77e9\u9635\uff08Control Matrix\uff09\uff0c\u53cd\u6620\u4e86\u7cfb\u7edf\u8f93\u5165\u5230\u7cfb\u7edf\u72b6\u6001\u7684\u6620\u5c04\u5173\u7cfb\u3002</p> <p>\\(w_{k-1}\\) \u662f\u8fc7\u7a0b\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u77e9\u9635\u4e3a \\(Q_{k-1}\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\\(H_k\\) \u4e3a\u6d4b\u91cf\u77e9\u9635\uff08Measurement Matrix\uff09\uff0c\u63cf\u8ff0\u4e86\u4ece\u7cfb\u7edf\u72b6\u6001\u5230\u6d4b\u91cf\u503c\u7684\u8f6c\u6362\u5173\u7cfb</p> <p>\\(v_k\\) \u662f\u6d4b\u91cf\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u4e3a \\(R_k\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b\u662f\u53d6\u5f97\u662f\u6bcf\u4e00\u9879\u7684\u6982\u7387\u6700\u5927\u503c\u5904\u5bf9\u5e94\u7684\u81ea\u53d8\u91cf\u7684\u503c\uff0c\u566a\u58f0 \\(w_{k-1}\\) \u662f\u5747\u503c\u4e3a0\u7684\u9ad8\u65af\u566a\u58f0\uff0c\u56e0\u6b64\u6700\u5927\u6982\u7387\u5bf9\u5e94\u7684\u503c\u4e3a0\u3002</p> \\[ \\begin{align*} &amp;\\hat x^-_k = A_{k - 1}\\hat x^{+}_{k - 1} + B_{k-1}u_{k-1} + 0\\\\ \\end{align*} \\] <p>\u5bf9\u7cfb\u7edf\u72b6\u6001\u5411\u91cf\u4e0a\u9762\u52a0\u4e0a\u4e00\u4e2a\u5e3d\u5b50\u7b26\u53f7\u8868\u793a\u8fd9\u662f\u4e00\u4e2a\u4f30\u8ba1\u91cf\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u5b9e\u9645\u8f93\u51fa\u7684\u91cf\u3002</p> <p>\\(\\hat x^{+}_{k - 1}\\) \u8868\u793a \\(k-1\\) \u65f6\u523b\u65f6\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u540e\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u540e\u9a8c\u4f30\u8ba1\u3002</p> <p>\\(\\hat x^-_k\\) \u8868\u793a\u5f53\u524d\u6839\u636e\u7cfb\u7edf\u72b6\u6001\u65b9\u7a0b\u8ba1\u7b97\u9884\u6d4b\u5f97\u5230\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u5148\u9a8c\u4f30\u8ba1\u3002</p> <p>\u6d4b\u91cf\u4f30\u8ba1\u65b9\u7a0b\u540c\u6837\u5ffd\u7565\u566a\u58f0\u9879\uff0c\u53d8\u6210\u5bf9\u6b64\u65f6\u6d4b\u91cf\u91cf\u7684\u4f30\u8ba1</p> \\[ \\hat z_k = H_k \\hat x^-_k \\] <p>\u9012\u5f52\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u6240\u6709\u516c\u5f0f\uff08\u7edf\u4e00\u524d\u9762\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u4ecb\u7ecd\u548c\u63a8\u5bfc\u4e00\u4e8c\u4e2d\u7684\u7b26\u53f7\uff09\u6709</p> <p>\u2460\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b</p> \\[ \\begin{align*} \\hat x^-_k = \\hat x(k| k - 1) &amp;= A_{k-1} \\hat x(k - 1| k - 1) + B_{k-1} u_{k-1} \\\\ &amp;= A_{k - 1}\\hat x^{+}_{k - 1} + B_{k-1}u_{k-1}  \\end{align*} \\] <p>\u2461\u6700\u4f18\u72b6\u6001\u4f30\u8ba1\u8fed\u4ee3\u66f4\u65b0\u516c\u5f0f</p> \\[ \\begin{align*} \\hat x^+_k = \\hat x(k| k) &amp;= \\hat x(k | k - 1) + K_{k} \\varepsilon_{k} \\\\ &amp;= \\hat x(k | k - 1) +  K_{k}(z_k - H_k \\hat x(k|k-1)) \\\\ &amp;= \\hat x^-_{k} + K_k (z_k - H_k \\hat x^-_k) \\end{align*} \\] <p>\u2462\u5361\u5c14\u66fc\u589e\u76ca\u8ba1\u7b97\u516c\u5f0f</p> \\[ \\begin{align*} K_k &amp;= P(k|k-1)H_k^T  [H_kP(k|k - 1)H_k^T + R_k]^{-1} \\\\ &amp;= P_k^- H_k^T (R_k + H_k P_k^- H_k^T)^{-1} \\end{align*} \\] <p>\u2463\u5148\u9a8c\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u66f4\u65b0\u516c\u5f0f</p> \\[ P_k^- = A_{k - 1}P(k - 1|k - 1)A_{k - 1}^T + Q_{k-1} \\] <p>\u2464\u6700\u4f18(\u540e\u9a8c)\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u66f4\u65b0\u516c\u5f0f</p> \\[ \\begin{align*} P_k^+ = P(k|k) &amp;= [I - K_kH_k] P(k|k-1) [I - K_kH_k]^T + K_k R_k K_k^T \\\\  &amp;= [I - K_kH_k] P(k|k-1) \\end{align*} \\] <p>\u7b2c\u4e00\u884c\u516c\u5f0f\u6ca1\u6709\u4ee3\u5165\u5361\u5c14\u66fc\u589e\u76ca\u7684 \\(K_k\\) \u8ba1\u7b97\u516c\u5f0f\uff0c\u662f\u6700\u4f18\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u7684\u4e00\u822c\u5f62\u5f0f\uff0c\u4e0d\u8981\u6c42 \\(K_k\\) \u5fc5\u987b\u4e3a\u5361\u5c14\u66fc\u589e\u76ca\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/#_4","title":"\u4e8c\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5b9e\u73b0\u89e3\u8bfb","text":"<p>\u4e0b\u9762\u672c\u6587\u5bf9python\u4e2d\u6ce8\u660e\u7684\u6ee4\u6ce2\u5e93<code>filterpy</code>\u4e2d\u5361\u5c14\u66fc\u6ee4\u6ce2\u90e8\u5206\u8fdb\u884c\u89e3\u8bfb\u3002</p> <p>FilterPy\u662f\u4e00\u4e2a\u5b9e\u73b0\u4e86\u5404\u79cd\u6ee4\u6ce2\u5668\u7684Python\u6a21\u5757\uff0c\u5b83\u5b9e\u73b0\u8457\u540d\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u7c92\u5b50\u6ee4\u6ce2\u5668\u3002\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u8be5\u5e93\u5b8c\u6210\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5b9e\u73b0\u3002\u5176\u4e2d\u7684\u4e3b\u8981\u6a21\u5757\u5305\u62ec\uff1a</p> <ul> <li>filterpy.kalman   \u8be5\u6a21\u5757\u4e3b\u8981\u5b9e\u73b0\u4e86\u5404\u79cd\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u5305\u62ec\u5e38\u89c1\u7684\u7ebf\u6027\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7b49</li> <li>filterpy.common   \u8be5\u6a21\u5757\u4e3b\u8981\u63d0\u4f9b\u652f\u6301\u5b9e\u73b0\u6ee4\u6ce2\u7684\u5404\u79cd\u8f85\u52a9\u51fd\u6570\uff0c\u5176\u4e2d\u8ba1\u7b97\u566a\u58f0\u77e9\u9635\u7684\u51fd\u6570\uff0c\u7ebf\u6027\u65b9\u7a0b\u79bb\u6563\u5316\u7684\u51fd\u6570\u7b49\u3002</li> <li>filterpy.stats   \u8be5\u6a21\u5757\u63d0\u4f9b\u4e0e\u6ee4\u6ce2\u76f8\u5173\u7684\u7edf\u8ba1\u51fd\u6570\uff0c\u5305\u62ec\u591a\u5143\u9ad8\u65af\u7b97\u6cd5\uff0c\u5bf9\u6570\u4f3c\u7136\u7b97\u6cd5\uff0cPDF\u53ca\u534f\u65b9\u5dee\u7b49\u3002</li> <li>filterpy.monte_carlo   \u8be5\u6a21\u5757\u63d0\u4f9b\u4e86\u9a6c\u5c14\u79d1\u592b\u94fe\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\uff0c\u4e3b\u8981\u7528\u4e8e\u7c92\u5b50\u6ee4\u6ce2\u3002</li> </ul> <p>\u5b89\u88c5</p> <pre><code>pip install filterpy==1.4.5\n</code></pre> <p>\u6216\u8005\u5b89\u88c5\u5f00\u53d1\u7248\u672c</p> <pre><code>git clone http://github.com/rlabbe/filterpy\npython setup.py develop\n</code></pre> <p>\u5361\u5c14\u66fc\u6ee4\u6ce2\u5177\u4f53\u5b9e\u73b0\u94fe\u63a5 https://github.com/rlabbe/filterpy/blob/1.4.5/filterpy/kalman/kalman_filter.py</p> <p><code>kalman_filter.py</code> \u8be5\u6587\u4ef6\u5305\u62ec\u5bf9\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u9762\u5411\u5bf9\u8c61\u548c\u51fd\u6570\u5f0f\u7f16\u7a0b\u5b9e\u73b0\uff0c\u672c\u6587\u4ec5\u89e3\u8bfb\u5bf9\u8c61\u5f0f\u5b9e\u73b0\u3002</p> <pre><code># -*- coding: utf-8 -*-\n# pylint: disable=invalid-name, too-many-arguments, too-many-branches,\n# pylint: disable=too-many-locals, too-many-instance-attributes, too-many-lines\n\n\"\"\"\nThis module implements the linear Kalman filter in both an object\noriented and procedural form.\nThe KalmanFilter class implements the filter by storing the various matrices in instance variables, minimizing the amount of bookkeeping you have to do.\n\nAll Kalman filters operate with a predict-&gt;update cycle. The\npredict step, implemented with the method or function predict(),\nuses the state transition matrix F to predict the state in the next\ntime period (epoch). The state is stored as a gaussian (x, P), where\nx is the state (column) vector, and P is its covariance. Covariance\nmatrix Q specifies the process covariance. In Bayesian terms, this\nprediction is called the *prior*, which you can think of colloquially\nas the estimate prior to incorporating the measurement.\n\nThe update step, implemented with the method or function `update()`,\nincorporates the measurement z with covariance R, into the state\nestimate (x, P). The class stores the system uncertainty in S,\nthe innovation (residual between prediction and measurement in\nmeasurement space) in y, and the Kalman gain in k. The procedural\nform returns these variables to you. In Bayesian terms this computes\nthe *posterior* - the estimate after the information from the\nmeasurement is incorporated.\n\nWhether you use the OO form or procedural form is up to you. If\nmatrices such as H, R, and F are changing each epoch, you'll probably\nopt to use the procedural form. If they are unchanging, the OO\nform is perhaps easier to use since you won't need to keep track\nof these matrices. This is especially useful if you are implementing\nbanks of filters or comparing various KF designs for performance;\na trivial coding bug could lead to using the wrong sets of matrices.\n\nThis module also offers an implementation of the RTS smoother, and\nother helper functions, such as log likelihood computations.\n\nThe Saver class allows you to easily save the state of the\nKalmanFilter class after every update\n\nThis module expects NumPy arrays for all values that expect\narrays, although in a few cases, particularly method parameters,\nit will accept types that convert to NumPy arrays, such as lists\nof lists. These exceptions are documented in the method or function.\n\nExamples\n--------\nThe following example constructs a constant velocity kinematic\nfilter, filters noisy data, and plots the results. It also demonstrates\nusing the Saver class to save the state of the filter at each epoch.\n\n.. code-block:: Python\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n    from filterpy.kalman import KalmanFilter\n    from filterpy.common import Q_discrete_white_noise, Saver\n\n    r_std, q_std = 2., 0.003\n    cv = KalmanFilter(dim_x=2, dim_z=1)\n    cv.x = np.array([[0., 1.]]) # position, velocity\n    cv.F = np.array([[1, dt],[ [0, 1]])\n    cv.R = np.array([[r_std^^2]])\n    f.H = np.array([[1., 0.]])\n    f.P = np.diag([.1^^2, .03^^2)\n    f.Q = Q_discrete_white_noise(2, dt, q_std**2)\n\n    saver = Saver(cv)\n    for z in range(100):\n        cv.predict()\n        cv.update([z + randn() * r_std])\n        saver.save() # save the filter's state\n\n    saver.to_array()\n    plt.plot(saver.x[:, 0])\n\n    # plot all of the priors\n    plt.plot(saver.x_prior[:, 0])\n\n    # plot mahalanobis distance\n    plt.figure()\n    plt.plot(saver.mahalanobis)\n\nThis code implements the same filter using the procedural form\n\n    x = np.array([[0., 1.]]) # position, velocity\n    F = np.array([[1, dt],[ [0, 1]])\n    R = np.array([[r_std^^2]])\n    H = np.array([[1., 0.]])\n    P = np.diag([.1^^2, .03^^2)\n    Q = Q_discrete_white_noise(2, dt, q_std**2)\n\n    for z in range(100):\n        x, P = predict(x, P, F=F, Q=Q)\n        x, P = update(x, P, z=[z + randn() * r_std], R=R, H=H)\n        xs.append(x[0, 0])\n    plt.plot(xs)\n\n\nFor more examples see the test subdirectory, or refer to the\nbook cited below. In it I both teach Kalman filtering from basic\nprinciples, and teach the use of this library in great detail.\n\nFilterPy library.\nhttp://github.com/rlabbe/filterpy\n\nDocumentation at:\nhttps://filterpy.readthedocs.org\n\nSupporting book at:\nhttps://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python\n\nThis is licensed under an MIT license. See the readme.MD file\nfor more information.\n\nCopyright 2014-2018 Roger R Labbe Jr.\n\"\"\"\n\nfrom __future__ import absolute_import, division\n\nfrom copy import deepcopy\nfrom math import log, exp, sqrt\nimport sys\nimport warnings\nimport numpy as np\nfrom numpy import dot, zeros, eye, isscalar, shape\nimport numpy.linalg as linalg\nfrom filterpy.stats import logpdf\nfrom filterpy.common import pretty_str, reshape_z\n\n\nclass KalmanFilter(object):\n    r\"\"\" \u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7684\u5177\u4f53\u5b9e\u73b0\uff0c\u4f60\u9700\u8981\u8bbe\u7f6e\u76f8\u5173\u53d8\u91cf\u4e3a\u5408\u7406\u7684\u6570\u503c\uff0c\u9ed8\u8ba4\u503c\u4e0d\u53ef\u4ee5\u5de5\u4f5c\u3002\n\n    \u7b80\u8a00\u4e4b\uff0c\u4f60\u9700\u8981\u9996\u5148\u521b\u5efa\u8be5\u5bf9\u8c61\uff0c\u660e\u786e\u72b6\u6001\u53d8\u91cf\u7684\u7ef4\u5ea6 dim_x\uff0c\u4ee5\u53ca\u89c2\u6d4b\u5411\u91cfz\u7684\u7ef4\u5ea6 dim_z \u3002\n    \u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4f1a\u6709\u5f88\u591a\u6b21\u77e9\u9635\u5f62\u72b6\u68c0\u67e5\uff0c\u6bd4\u5982\u5f53\u4f60\u8bbe\u7f6edim_z=2\uff0c\n    \u7136\u540e\u8bbe\u7f6e\u6d4b\u91cf\u77e9\u9635R\u4e3a3x3\u7684\u77e9\u9635\u65f6\uff0c\u4f60\u4f1a\u5f97\u5230\u4e00\u4e2a\u65ad\u8a00\u9519\u8bef\u3002\n\n    \u5728\u6784\u5efa\u6ee4\u6ce2\u5668\u540e\uff0c\u6ee4\u6ce2\u5668\u6709\u4e00\u4e9b\u9ed8\u8ba4\u503c\u3002\u4f46\u662f\u4f60\u9700\u8981\u8bbe\u7f6e\u6bcf\u4e00\u4e2a\u53d8\u91cf\u503c\u3002\n    \u8fd9\u5f88\u5bb9\u6613\uff0c\u4f60\u53ea\u9700\u8981\u7ed9\u6240\u6709\u7684\u503c\u4ee5\u8d4b\u503c\u7684\u5f62\u5f0f\u4f20\u9012\u7ed9\u6bcf\u4e00\u4e2a\u53d8\u91cf\u5373\u53ef\u3002\n    \u6240\u6709\u8bbe\u7f6e\u503c\u7684\u7c7b\u578b\u4e3anumpy.array\uff0c\u4e0b\u9762\u662f\u4e00\u4e2a\u4f8b\u5b50\u3002\n\n    Examples\n    --------\n\n    \u8fd9\u662f\u4e00\u4e2a\u6ee4\u6ce2\u5668\uff0c\u8ffd\u8e2a\u4f4d\u7f6e\u548c\u901f\u5ea6\uff0c\u4ec5\u4f7f\u7528\u4e00\u4e2a\u4f20\u611f\u5668\u6765\u83b7\u53d6\u5f53\u524d\u7684\u4f4d\u7f6e\n\n    \u9996\u5148\u521b\u5efa\u4e00\u4e2a\u6ee4\u6ce2\u5668\u5bf9\u8c61\u5e76\u6307\u5b9a\u5fc5\u8981\u7684\u4f4d\u7f6e\n    .. code::\n\n        from filterpy.kalman import KalmanFilter\n        f = KalmanFilter (dim_x=2, dim_z=1)\n\n\n    \u7136\u540e\u7ed9\u6bcf\u4e2a\u76f8\u5173\u77e9\u9635\u8bbe\u7f6e\u503c\uff0c\u4e0b\u9762\u662f\u5b9a\u4e49\u72b6\u6001\u521d\u59cb\u503c\n\n        .. code::\n\n            f.x = np.array([[2.],    # position\n                            [0.]])   # velocity\n\n    \u6216\u8005\u4ec5\u4ec5\u91c7\u7528\u4e00\u7ef4\u5411\u91cf\n\n    .. code::\n\n        f.x = np.array([2., 0.])\n\n\n    \u5b9a\u4e49\u72b6\u6001\u8f6c\u79fb\u77e9\u9635F\n\n        .. code::\n\n            f.F = np.array([[1.,1.],\n                            [0.,1.]])\n\n    \u5b9a\u4e49\u6d4b\u91cf\u77e9\u9635H\n\n        .. code::\n\n        f.H = np.array([[1.,0.]])\n\n    \u5b9a\u4e49\u534f\u65b9\u5dee\u77e9\u9635\u521d\u59cb\u503cP. \u6b64\u5904\u6211\u5229\u7528P\u4e3a\u5bf9\u89d2\u9635\u7684\u7279\u6027\uff0c\u521d\u59cb\u5316P\u4e3anp.eye(dim_x), \u56e0\u6b64\u53ea\u9700\u8981\u4e58\u4ee5\u4e00\u4e2a\u503c\u6765\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u5373\u53ef:\n\n    .. code::\n\n        f.P *= 1000.\n\n    \u4e5f\u53ef\u4ee5\u8fd9\u6837\u6765\u5b9a\u4e49:\n\n    .. code::\n\n        f.P = np.array([[1000.,    0.],\n                        [   0., 1000.] ])\n\n    \u7531\u7528\u6237\u6765\u5b9a\u4e49\u54ea\u4e00\u79cd\u6bd4\u8f83\u597d\u7406\u89e3\u4ee5\u53ca\u53ef\u8bfb\u6027\u66f4\u597d\n\n    \u73b0\u5728\u7ed9\u89c2\u6d4b\u566a\u58f0\u8d4b\u503c\uff0c\u6b64\u65f6\u89c2\u6d4b\u566a\u58f0\u662f\u4e00\u4e2a1x1\u7684\u77e9\u9635\uff0c\u6240\u4ee5\u6211\u53ef\u4ee5\u7528\u4e00\u4e2a\u6807\u91cf\u6765\u8868\u793a\u3002\n\n    .. code::\n\n        f.R = 5\n\n    \u4e5f\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e0b\u77e9\u9635\u5f62\u5f0f\u8d4b\u503c:\n\n    .. code::\n\n        f.R = np.array([[5.]])\n\n    \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cR\u9700\u8981\u65f61x1\u76842\u7ef4\u77e9\u9635\uff0c\u5f53\u5176\u662f\u77e9\u9635\u5f62\u5f0f\u7684\u65f6\u5019\u3002\n\n    \u6700\u540e\u6211\u4f1a\u7ed9\u8fc7\u7a0b\u566a\u58f0Q\u77e9\u9635\u8d4b\u503c\uff0c\u8fd9\u91cc\u6211\u5229\u7528\u4e86filterpy\u7684\u53e6\u4e00\u4e2a\u51fd\u6570:\n\n    .. code::\n\n        from filterpy.common import Q_discrete_white_noise\n        f.Q = Q_discrete_white_noise(dim=2, dt=0.1, var=0.13)\n\n\n    \u63a5\u4e0b\u6765\u6211\u4eec\u53ea\u9700\u8981\u6267\u884c predict/update \u5faa\u73af:\n\n    while some_condition_is_true:\n\n    .. code::\n\n        z = get_sensor_reading()\n        f.predict()\n        f.update(z)\n\n        do_something_with_estimate (f.x)\n\n\n    \u4e0b\u9762\u662f\u9762\u5411\u8fc7\u7a0b\u5f0f\u7f16\u7a0b\u65b9\u5f0f\n    **Procedural Form**\n\n    This module also contains stand alone functions to perform Kalman filtering.\n    Use these if you are not a fan of objects.\n\n    **Example**\n\n    .. code::\n\n        while True:\n            z, R = read_sensor()\n            x, P = predict(x, P, F, Q)\n            x, P = update(x, P, z, R, H)\n\n    See my book Kalman and Bayesian Filters in Python [2]_.\n\n\n    \u4f60\u9700\u8981\u8bbe\u7f6e\u5982\u4e0b\u7684\u5c5e\u6027\u6765\u6784\u9020\u5361\u5c14\u66fc\u6ee4\u6ce2\u5bf9\u8c61\u3002\u8bf7\u6ce8\u610f\uff1a\u5728\u5bf9\u8c61\u5b9e\u73b0\u5185\u90e8\u6709\u5404\u79cd\u5404\u6837\u7684\u68c0\u67e5\u6765\u786e\u4fdd\u4f60\u8bbe\u7f6e\u4e86\u6b63\u786e\u7684size\u3002\u7136\u800c\uff0c\u4ecd\u7136\u6709\u53ef\u80fd\u53d1\u751f\u4e00\u4e9bsize\u6ca1\u6709\u8bbe\u7f6e\u597d\u7684\u4f8b\u5b50\u4ee5\u81f3\u4e8e\u7ebf\u6027\u4ee3\u6570\u8fd0\u884c\u4e0d\u80fd\u6b63\u5e38\u8ba1\u7b97\u3002\n    \u4e5f\u6709\u53ef\u80fd\u6ca1\u6709\u4efb\u4f55\u52a8\u9759\u5730\u62a5\u9519\uff0c\u4f60\u53ef\u4ee5\u6700\u540e\u5f97\u5230\u4e00\u4e2a\u80fd\u591f\u8fd0\u884c\u5730\u77e9\u9635\u7ed3\u679c\uff0c\u4f46\u77e9\u9635\u7684\u5f62\u72b6\u5e76\u4e0d\u662f\u4f60\u6240\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u6240\u8bbe\u7f6e\u7684\u90a3\u6837\u3002\n\n    Parameters\n    ----------\n    dim_x : int\n        \u72b6\u6001\u5411\u91cf\u7684\u7ef4\u5ea6\u5927\u5c0f\u3002\u6bd4\u5982\u4f60\u60f3\u8ddf\u8e2a\u4e00\u4e2a\u7269\u4f53\u7684\u5728\u4e8c\u7ef4\u7a7a\u95f4\u7684\u4f4d\u7f6e\u548c\u901f\u5ea6\uff0cdim_x\u5c31\u9700\u8981\u8bbe\u7f6e\u4e3a4.\n        \u8be5\u53d8\u91cf\u7528\u4e8e\u8bbe\u7f6e P\u3001Q\u3001u\u77e9\u9635\u7684\u9ed8\u8ba4\u5f62\u72b6\u3002\n\n    dim_z : int\n        \u6d4b\u91cf\u8f93\u5165\u503c\u7684\u4e2a\u6570\uff0c\u4e5f\u53ef\u4ee5\u770b\u505a\u6d4b\u91cf\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\u3002\u6bd4\u5982\uff0c\u5982\u679c\u4f20\u611f\u5668\u63d0\u4f9b\u4f4d\u7f6e\u5750\u6807 \uff08x\uff0cy\uff09\n        \u90a3\u4e48 dim_z \u5c06\u4f1a\u662f2.\n\n    dim_u : int (optional)\n        \u5916\u90e8\u8f93\u5165\u5411\u91cf\u7684\u7ef4\u5ea6\uff0c\u9ed8\u8ba4\u4e0d\u4f7f\u7528\uff0c\u7ef4\u5ea6\u5927\u5c0f\u4e3a0\u3002\n\n    compute_log_likelihood : bool (default = True)\n        \u9ed8\u8ba4\u6253\u5f00\uff0c\u7528\u6765\u63a7\u5236\u662f\u5426\u8ba1\u7b97 log likelihood\u3002\n\n    Attributes\n    ----------\n    x : numpy.array(dim_x, 1)\n        \u72b6\u6001\u5411\u91cf\uff0c\u6240\u6709\u5173\u4e8e update() \u548c predict() \u7684\u8c03\u7528\u5c06\u4f1a\u66f4\u65b0\u8be5\u53d8\u91cf\u3002\n\n    P : numpy.array(dim_x, dim_x)\n        \u5f53\u524d\u72b6\u6001\u5411\u91cf\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u6240\u6709\u5173\u4e8e update() \u548c predict() \u7684\u8c03\u7528\u5c06\u4f1a\u66f4\u65b0\u8be5\u53d8\u91cf\u3002\n\n    x_prior : numpy.array(dim_x, 1)\n        \u53ea\u8bfb\u53d8\u91cf\u3002x\u7684\u5148\u9a8c\u4f30\u8ba1\u5411\u91cf\uff0c\u4ed6\u4eec\u3002\n        Prior (predicted) state estimate. The *_prior and *_post attributes\n        are for convienence; they store the  prior and posterior of the\n        current epoch. Read Only.\n\n    P_prior : numpy.array(dim_x, dim_x)\n        \u53ea\u8bfb\uff0c\u5148\u9a8c\u8bef\u5deeP_prior\u3002\n\n    x_post : numpy.array(dim_x, 1)\n        \u53ea\u8bfb\uff0c\u540e\u9a8c\u72b6\u6001\u4f30\u8ba1\uff08\u5373\u6700\u4f18\u72b6\u6001\u4f30\u8ba1\uff09\n\n    P_post : numpy.array(dim_x, dim_x)\n        \u53ea\u8bfb\uff0c\u540e\u9a8c\u534f\u65b9\u5dee\u77e9\u9635\n\n    z : numpy.array\n        \u53ea\u8bfb\uff0c\u6700\u540e\u4e00\u6b21\u8c03\u7528update\u51fd\u6570\u4f7f\u7528\u7684\u6d4b\u91cf\u503c\n\n    R : numpy.array(dim_z, dim_z)\n        \u6d4b\u91cf\u503c\u566a\u58f0\u77e9\u9635\n\n    Q : numpy.array(dim_x, dim_x)\n        \u8fc7\u7a0b\u566a\u58f0\u77e9\u9635\n\n    F : numpy.array()\n        \u72b6\u6001\u8f6c\u79fb\u77e9\u9635\n\n    H : numpy.array(dim_z, dim_x)\n        \u89c2\u6d4b\u77e9\u9635\n\n    y : numpy.array\n        \u53ea\u8bfb\uff0c\u6d4b\u91cf\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u7684\u8bef\u5dee\n\n    K : numpy.array(dim_x, dim_z)\n        \u53ea\u8bfb\uff0c\u66f4\u65b0\u6b65\u9aa4\u7684\u5361\u5c14\u66fc\u589e\u76ca\n\n    S :  numpy.array\n        \u53ea\u8bfb\uff0c\u81ea\u52a8\u4e0d\u786e\u5b9a\u6027\u8861\u91cf\u77e9\u9635\uff0cP\u6295\u5f71\u5230\u6d4b\u91cf\u7a7a\u95f4\u4e0b\u5f97\u5230\uff0c\u5373 S = H @ P @ H^T\n\n    SI :  numpy.array\n        \u53ea\u8bfb\uff0c\u81ea\u52a8\u4e0d\u786e\u5b9a\u6027\u8861\u91cf\u77e9\u9635\u7684\u9006\u77e9\u9635\n\n    log_likelihood : float\n        \u53ea\u8bfb\uff0c\u6700\u540e\u4e00\u6b21\u6d4b\u91cf\u7684\u5bf9\u6570\u4f3c\u7136\u503c\u3002\n\n    likelihood : float\n        \u53ea\u8bfb\uff0c\u6700\u540e\u4e00\u6b21\u6d4b\u91cf\u7684\u4f3c\u7136\u503c\u3002\n\n        \u4ece log-likelihood\u8ba1\u7b97\u5f97\u5230\u3002 log-likelihood \u53ef\u4ee5\u662f\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684\u6570\uff0c\u8fd9\u610f\u5473\u7740\n        log-likelihood\u53ef\u4ee5\u662f\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684\u8d1f\u6570\uff0c\u6bd4\u5982-28000. exp(-28000)\u8ba1\u7b97\u7ed3\u679c\u5c06\u4f1a\u662f0.0\n        \u4f1a\u7834\u574f\u91c7\u7528\u8be5\u503c\u7684\u540e\u7eed\u8fd0\u7b97\uff0c\u56e0\u6b64\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u6211\u4eec\u603b\u662f\u8fd4\u56de\u4e00\u4e2asys.float_info.min\n\n    mahalanobis : float\n        \u53ea\u8bfb\uff0c\u65b0\u606f\u5411\u91cf\u7684\u9a6c\u6c0f\u8ddd\u79bb\n\n    inv : function, default numpy.linalg.inv\n        \u6c42\u9006\u51fd\u6570\uff0c\u9ed8\u8ba4\u4e3anumpy.linalg.inv\n        \u5982\u679c\u4f60\u559c\u6b22\u8bbe\u7f6e\u5176\u4ed6\u6c42\u9006\u51fd\u6570\uff0c\u6bd4\u5982Moore-Penrose pseudo inverse\uff0c\u90a3\u4e48\u9700\u8981\u8bbe\u7f6e\uff1a\n        kf.inv = np.linalg.pinv\n\n        \u8be5\u51fd\u6570\u4ec5\u7528\u4e8e\u8ba1\u7b97 self.S\u7684\u9006\u77e9\u9635\uff0c\u5982\u679c\u4f60\u77e5\u9053self.S\u662f\u4e00\u4e2a\u5bf9\u89d2\u9635\u7684\u8bdd\uff0c\u4f60\u53ef\u80fd\u4f1a\u9009\u62e9\n        filterpy.common.inv_diagonal\u51fd\u6570\uff0c\u5176\u6bd4numpy.linalg.inv\u8fd0\u7b97\u6548\u7387\u66f4\u9ad8\u3002\n\n    alpha : float\n        \u8870\u51cf\u673a\u5236\u8bbe\u7f6e\u5e38\u91cf\uff0c\u9ed8\u8ba4\u4e3a1.0\uff0c\u6ca1\u6709\u8870\u51cf\u3002\u5177\u4f53\u542b\u4e49\u770b\u53c2\u8003[1]\n        Fading memory setting. 1.0 gives the normal Kalman filter, and\n        values slightly larger than 1.0 (such as 1.02) give a fading\n        memory effect - previous measurements have less influence on the\n        filter's estimates. This formulation of the Fading memory filter\n        (there are many) is due to Dan Simon [1]_.\n\n    \u53c2\u8003\n    ----------\n\n    .. [1] Dan Simon. \"Optimal State Estimation.\" John Wiley &amp; Sons.\n       p. 208-212. (2006)\n\n    .. [2] Roger Labbe. \"Kalman and Bayesian Filters in Python\"\n       https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python\n\n    \"\"\"\n\n    def __init__(self, dim_x, dim_z, dim_u=0):\n        # \u63a7\u5236\u7ef4\u5ea6\u5927\u5c0f\n        if dim_x &lt; 1:\n            raise ValueError('dim_x must be 1 or greater')\n        if dim_z &lt; 1:\n            raise ValueError('dim_z must be 1 or greater')\n        if dim_u &lt; 0:\n            raise ValueError('dim_u must be 0 or greater')\n\n        # \u72b6\u6001\u5411\u91cf\u7ef4\u5ea6\n        self.dim_x = dim_x\n        # \u6d4b\u91cf\u5411\u91cf\u7ef4\u5ea6\n        self.dim_z = dim_z\n        # \u8f93\u5165\u5411\u91cf\u7ef4\u5ea6\n        self.dim_u = dim_u\n\n        # \u72b6\u6001\u5411\u91cf\n        self.x = zeros((dim_x, 1))        # state\n        # \u4e0d\u786e\u5b9a\u6027\u534f\u65b9\u5dee\n        self.P = eye(dim_x)               # uncertainty covariance\n        # \u8fc7\u7a0b\u566a\u58f0\u534f\u65b9\u5dee\n        self.Q = eye(dim_x)               # process uncertainty\n        # \u63a7\u5236\u77e9\u9635\uff0c\u53cd\u6620\u4e86\u7cfb\u7edf\u8f93\u5165\u5230\u7cfb\u7edf\u72b6\u6001\u7684\u6620\u5c04\u5173\u7cfb\n        self.B = None                     # control transition matrix\n        # \u72b6\u6001\u8f6c\u79fb\u77e9\u9635\n        self.F = eye(dim_x)               # state transition matrix\n        # \u6d4b\u91cf\u77e9\u9635\uff08Measurement Matrix\uff09\uff0c\u63cf\u8ff0\u4e86\u4ece\u7cfb\u7edf\u72b6\u6001\u5230\u6d4b\u91cf\u503c\u7684\u8f6c\u6362\u5173\u7cfb\n        self.H = zeros((dim_z, dim_x))    # Measurement function\n        # \u72b6\u6001\u4e0d\u786e\u5b9a\u6027\u534f\u65b9\u5dee\n        self.R = eye(dim_z)               # state uncertainty\n        # \u8870\u51cf\u673a\u5236\u63a7\u5236\u56e0\u5b50\n        self._alpha_sq = 1.               # fading memory control\n        # \n        self.M = np.zeros((dim_z, dim_z)) # process-measurement cross correlation\n        # \u6d4b\u91cf\u5411\u91cf\uff08\u4e0d\u662f\u8ba1\u7b97\u5f97\u5230\u7684\uff0c\u800c\u662f\u5916\u90e8\u4f20\u5165\u7684\u4f20\u611f\u5668\u83b7\u53d6\u7684\u6d4b\u91cf\u503c\uff09\n        self.z = np.array([[None]*self.dim_z]).T\n\n        # \u5728\u65b0\u606f\u8fc7\u7a0b\u4e2d\u8ba1\u7b97\u589e\u76ca\u548c\u8bef\u5dee\n        # \u8fd9\u91cc\u8bbe\u7f6e\u4e00\u4e9b\u53d8\u91cf\u6765\u4fdd\u5b58\u76f8\u5173\u53d8\u91cf\n        # gain and residual are computed during the innovation step. We\n        # save them so that in case you want to inspect them for various\n        # purposes\n        # \u5361\u5c14\u66fc\u589e\u76ca\n        self.K = np.zeros((dim_x, dim_z)) # kalman gain\n        # \u8bef\u5dee\u53d8\u91cf y = z - dot(H, self.x)\n        self.y = zeros((dim_z, 1))\n        # \u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\n        self.S = np.zeros((dim_z, dim_z)) # system uncertainty\n        # S\u7684\u9006\n        self.SI = np.zeros((dim_z, dim_z)) # inverse system uncertainty\n\n        # identity matrix. Do not alter this.\n        # \u5355\u4f4d\u77e9\u9635\n        self._I = np.eye(dim_x)\n\n        # these will always be a copy of x,P after predict() is called\n        # x\u7684\u5148\u9a8c\u4f30\u8ba1\n        self.x_prior = self.x.copy()\n        # p\u7684\u5148\u9a8c\u4f30\u8ba1\n        self.P_prior = self.P.copy()\n\n        # these will always be a copy of x,P after update() is called\n        # x\u7684\u540e\u9a8c\u4f30\u8ba1\n        self.x_post = self.x.copy()\n        # P\u7684\u540e\u9a8c\u4f30\u8ba1\n        self.P_post = self.P.copy()\n\n        # Only computed only if requested via property\n        # \u5bf9\u6570\u4f3c\u7136\u503c\n        self._log_likelihood = log(sys.float_info.min)\n        # \u4f3c\u7136\u503c\n        self._likelihood = sys.float_info.min\n        # \u9a6c\u6c0f\u8ddd\u79bb\n        self._mahalanobis = None\n\n        # \u6c42\u9006\u51fd\u6570\n        self.inv = np.linalg.inv\n\n\n    def predict(self, u=None, B=None, F=None, Q=None):\n        \"\"\"\n        Predict next state (prior) using the Kalman filter state propagation\n        equations.\n\n        Parameters\n        ----------\n\n        u : np.array\n            \u53ef\u9009\u62e9\u8f93\u5165\uff0c\u5916\u90e8\u63a7\u5236\u5411\u91cf\uff0c\u5982\u679c\u4e0d\u662fNone\uff0c\u90a3\u5c31\u662f\u4ee5Bu\u7684\u8f93\u5165\u7ed9\u7cfb\u7edf\n\n        B : np.array(dim_x, dim_z), or None\n            \u53ef\u9009\u62e9\u8f93\u5165\uff0c\u63a7\u5236\u77e9\u9635\n\n        F : np.array(dim_x, dim_x), or None\n            \u53ef\u9009\u62e9\u8f93\u5165\uff0c\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\n\n        Q : np.array(dim_x, dim_x), scalar, or None\n            \u53ef\u9009\u62e9\u8f93\u5165\uff0c\u63a7\u5236\u566a\u58f0\u534f\u65b9\u5dee\n        \"\"\"\n\n        if B is None:\n            B = self.B\n        if F is None:\n            F = self.F\n        if Q is None:\n            Q = self.Q\n        elif isscalar(Q):\n            Q = eye(self.dim_x) * Q\n\n        # \u8ba1\u7b97x\u7684\u5148\u9a8c\u4f30\u8ba1\n        # x = Fx + Bu\n        if B is not None and u is not None:\n            self.x = dot(F, self.x) + dot(B, u)\n        else:\n            self.x = dot(F, self.x)\n\n        # \u8ba1\u7b97P\u7684\u5148\u9a8c\u4f30\u8ba1\n        # P = FPF' + Q\n        # self._alpha_sq \u5373\u524d\u9762\u7684\u5e38\u91cf\n        self.P = self._alpha_sq * dot(dot(F, self.P), F.T) + Q\n\n        # \u4fdd\u5b58\u5148\u9a8c\n        # save prior\n        self.x_prior = self.x.copy()\n        self.P_prior = self.P.copy()\n\n\n    def update(self, z, R=None, H=None):\n        \"\"\"\n        \u6dfb\u52a0\u65b0\u7684\u6d4b\u91cf\u503c\u7ed9\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\n\n        \u5982\u679cz\u662fNone\uff0c\u4e0d\u4f1a\u8fdb\u884c\u4efb\u4f55\u8ba1\u7b97\u3002\u7136\u800c\uff0cx_post\u548cP_post\u4f1acopy \u5148\u9a8c\uff0c\u5e76\u4e14z\u4f1a\u88ab\u8bbe\u7f6e\u4e3aNone\n\n        Parameters\n        ----------\n        z : (dim_z, 1): array_like\n            \u6d4b\u91cf\u503c\u7528\u4e8eupdate\u51fd\u6570\uff0cz\u53ef\u4ee5\u662f\u6807\u91cf\u5982\u679cdim_z\u662f1\n            \u5426\u5219\u5b83\u9700\u8981\u80fd\u591f\u8f6c\u6362\u4e3a\u4e00\u4e2a\u5217\u5411\u91cf\u3002\n\n        R : np.array, scalar, or None\n            \u53ef\u9009\u62e9\u8f93\u5165\uff0c\u6d4b\u91cf\u566a\u58f0\u534f\u65b9\u5dee\n\n        H : np.array, or None\n            \u53ef\u9009\u62e9\u8f93\u5165\uff0c\u6d4b\u91cf\u77e9\u9635\n        \"\"\"\n\n        # set to None to force recompute\n        # \u4f3c\u7136\u503c\u548c\u9a6c\u6c0f\u8ddd\u79bb\n        self._log_likelihood = None\n        self._likelihood = None\n        self._mahalanobis = None\n\n        # \u5982\u679cz\u4e3a\u7a7a\uff0c\u5219\u76f8\u5173\u540e\u9a8c\u5c31\u7b49\u4e8e\u5148\u9a8c\n        if z is None:\n            self.z = np.array([[None]*self.dim_z]).T\n            self.x_post = self.x.copy()\n            self.P_post = self.P.copy()\n            self.y = zeros((self.dim_z, 1))\n            return\n\n        # \u53d8\u6362z\u4e3a(self.dim_z,)\u7684\u5411\u91cf\n        z = reshape_z(z, self.dim_z, self.x.ndim)\n\n        if R is None:\n            R = self.R\n        elif isscalar(R):\n            R = eye(self.dim_z) * R\n\n        if H is None:\n            H = self.H\n\n        # \u8ba1\u7b97\u8bef\u5deey\n        # y = z - Hx\n        # error (residual) between measurement and prediction\n        self.y = z - dot(H, self.x)\n\n        # \u8ba1\u7b97\u516c\u5171\u9879\n        # common subexpression for speed\n        PHT = dot(self.P, H.T)\n\n        # \u8ba1\u7b97\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\n        # S = HPH' + R\n        # project system uncertainty into measurement space\n        self.S = dot(H, PHT) + R\n        self.SI = self.inv(self.S)\n\n        # \u8ba1\u7b97\u5361\u5c14\u66fc\u6ee4\u6ce2\u589e\u76ca\n        # K = PH'inv(S)\n        # map system uncertainty into kalman gain\n        self.K = dot(PHT, self.SI)\n\n        # \u8ba1\u7b97x\u7684\u540e\u9a8c\u4f30\u8ba1\uff08\u6700\u4f18\u4f30\u8ba1\uff09\n        # x = x + Ky\n        # predict new x with residual scaled by the kalman gain\n        self.x = self.x + dot(self.K, self.y)\n\n        # \u8ba1\u7b97P\u7684\u540e\u9a8c\u4f30\u8ba1 P = (I-KH)P(I-KH)' + KRK' \u6570\u503c\u8ba1\u7b97\u66f4\u7a33\u5b9a\n        # \u4e14 \u975e\u6700\u4f18\u7684K\u4e00\u6837\u9002\u7528\n        # P = (I-KH)P\u662f\u4e00\u822c\u6587\u732e\u4e2d\u51fa\u73b0\u7684\u5316\u7b80\u7684\u516c\u5f0f\n\n        # P = (I-KH)P(I-KH)' + KRK'\n        # This is more numerically stable\n        # and works for non-optimal K vs the equation\n        # P = (I-KH)P usually seen in the literature.\n\n        # \u8ba1\u7b97P\u7684\u540e\u9a8c\u4f30\u8ba1\n        I_KH = self._I - dot(self.K, H)\n        self.P = dot(dot(I_KH, self.P), I_KH.T) + dot(dot(self.K, R), self.K.T)\n\n        # \u5b58\u50a8\u6d4b\u91cf\u503c\u548c\u76f8\u5173\u540e\u9a8c\u4f30\u8ba1\n        # save measurement and posterior state\n        self.z = deepcopy(z)\n        self.x_post = self.x.copy()\n        self.P_post = self.P.copy()\n\n    def predict_steadystate(self, u=0, B=None):\n        \"\"\"\n        \u901a\u8fc7\u5361\u5c14\u66fc\u6ee4\u6ce2\u8ba1\u7b97x\u7684\u5148\u9a8c\u4f30\u8ba1\uff0c\u4ec5\u66f4\u65b0x\uff0cP\u4e0d\u518d\u66f4\u65b0\u3002\n\n        Parameters\n        ----------\n\n        u : np.array\n            \u8f93\u5165\u5411\u91cf\n\n        B : np.array(dim_x, dim_z), or None\n            \u63a7\u5236\u8f6c\u79fb\u77e9\u9635\n        \"\"\"\n\n        if B is None:\n            B = self.B\n\n        # x = Fx + Bu\n        if B is not None:\n            self.x = dot(self.F, self.x) + dot(B, u)\n        else:\n            self.x = dot(self.F, self.x)\n\n        # save prior\n        self.x_prior = self.x.copy()\n        self.P_prior = self.P.copy()\n\n    def update_steadystate(self, z):\n        \"\"\"\n        \u6dfb\u52a0\u4e00\u4e2a\u65b0\u7684\u6d4b\u91cfz\u7ed9\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u4f46\u662f\u4e0d\u518d\u91cd\u65b0\u8ba1\u7b97\u5361\u5c14\u66fc\u589e\u76caK\uff0c\u4ee5\u53ca\u534f\u65b9\u5dee\u77e9\u9635P\u548c\u7cfb\u7edf\u4e0d\u786e\u5b9aS\u3002\n\n        \u4f60\u53ef\u4ee5\u91c7\u7528\u8be5\u51fd\u6570\u7528\u4e8e\u7ebf\u6027\u662f\u4e0d\u53d8\u7cfb\u7edf\uff0c\u56e0\u4e3a\u5361\u5c14\u66fc\u589e\u76ca\u4f1a\u6536\u655b\u5230\u4e00\u4e2a\u56fa\u5b9a\u503c\u3002\n        \u63d0\u524d\u8ba1\u7b97\u8fd9\u4e9b\u503c\u5e76\u6e05\u6670\u5730\u7ed9\u4ed6\u4eec\u8d4b\u503c\uff0c\u6216\u8005\u8fd0\u884c\u91c7\u7528predict/update\u51fd\u6570\u76f4\u5230\u4ed6\u4eec\u6536\u655b\n\n        \u8be5\u51fd\u6570\u7684\u4e3b\u8981\u4f18\u52bf\u662f\u5176\u901f\u5ea6\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5c11\u91cf\u7684\u8ba1\u7b97\uff0c\u660e\u663e\u964d\u4f4e\u4e86\u77e9\u9635\u6c42\u9006\u7684\u8fd0\u7b97\u91cf\n\n        \u9700\u8981\u548cpredict_steadystate\u51fd\u6570\u8054\u5408\u4f7f\u7528\uff0c\u5426\u5219P\u503c\u4f1a\u6ca1\u6709\u8fb9\u754c\u7684\u589e\u957f\n\n        Parameters\n        ----------\n        z : (dim_z, 1): array_like\n            \u7528\u4e8e\u8be5\u66f4\u65b0\u8fc7\u7a0b\u7684\u6d4b\u91cf\u503c\n\n        Examples\n        --------\n        &gt;&gt;&gt; cv = kinematic_kf(dim=3, order=2) # 3D const velocity filter\n        &gt;&gt;&gt; # let filter converge on representative data, then save k and P\n        &gt;&gt;&gt; for i in range(100):\n        &gt;&gt;     cv.predict()\n        &gt;&gt;     cv.update([i, i, i])\n        &gt;&gt;&gt; saved_k = np.copy(cv.K)\n        &gt;&gt;&gt; saved_P = np.copy(cv.P)\n\n        later on:\n\n        &gt;&gt;&gt; cv = kinematic_kf(dim=3, order=2) # 3D const velocity filter\n        &gt;&gt;&gt; cv.K = np.copy(saved_K)\n        &gt;&gt;&gt; cv.P = np.copy(saved_P)\n        &gt;&gt;&gt; for i in range(100):\n        &gt;&gt;     cv.predict_steadystate()\n        &gt;&gt;     cv.update_steadystate([i, i, i])\n        \"\"\"\n\n        # set to None to force recompute\n        self._log_likelihood = None\n        self._likelihood = None\n        self._mahalanobis = None\n\n        if z is None:\n            self.z = np.array([[None]*self.dim_z]).T\n            self.x_post = self.x.copy()\n            self.P_post = self.P.copy()\n            self.y = zeros((self.dim_z, 1))\n            return\n\n        z = reshape_z(z, self.dim_z, self.x.ndim)\n\n        # y = z - Hx\n        # error (residual) between measurement and prediction\n        self.y = z - dot(self.H, self.x)\n\n        # \u4e0d\u518d\u66f4\u65b0\u5361\u5c14\u66fc\u589e\u76ca \u548c P\u7684\u540e\u9a8c\u4f30\u8ba1\n        # x = x + Ky\n        # predict new x with residual scaled by the kalman gain\n        self.x = self.x + dot(self.K, self.y)\n\n        self.z = deepcopy(z)\n        self.x_post = self.x.copy()\n        self.P_post = self.P.copy()\n\n        # set to None to force recompute\n        self._log_likelihood = None\n        self._likelihood = None\n        self._mahalanobis = None\n\n    def get_prediction(self, u=0):\n        \"\"\"\n        \u5728\u4e0d\u66f4\u6539\u6ee4\u6ce2\u5668\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2a\u9636\u6bb5\u7684\u72b6\u6001\n\n        Parameters\n        ----------\n\n        u : np.array\n            optional control input\n\n        Returns\n        -------\n\n        (x, P) : tuple\n            State vector and covariance array of the prediction.\n        \"\"\"\n\n        x = dot(self.F, self.x) + dot(self.B, u)\n        P = self._alpha_sq * dot(dot(self.F, self.P), self.F.T) + self.Q\n        return (x, P)\n\n    def get_update(self, z=None):\n        \"\"\"\n        \u4e0d\u66f4\u6539\u6ee4\u6ce2\u5668\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2a\u4f30\u8ba1\u503c\n\n        Parameters\n        ----------\n\n        z : (dim_z, 1): array_like\n            measurement for this update. z can be a scalar if dim_z is 1,\n            otherwise it must be convertible to a column vector.\n\n        Returns\n        -------\n\n        (x, P) : tuple\n            State vector and covariance array of the update.\n       \"\"\"\n\n        if z is None:\n            return self.x, self.P\n        z = reshape_z(z, self.dim_z, self.x.ndim)\n\n        R = self.R\n        H = self.H\n        P = self.P\n        x = self.x\n\n        # error (residual) between measurement and prediction\n        y = z - dot(H, x)\n\n        # common subexpression for speed\n        PHT = dot(P, H.T)\n\n        # project system uncertainty into measurement space\n        S = dot(H, PHT) + R\n\n        # map system uncertainty into kalman gain\n        K = dot(PHT, self.inv(S))\n\n        # predict new x with residual scaled by the kalman gain\n        x = x + dot(K, y)\n\n        # P = (I-KH)P(I-KH)' + KRK'\n        I_KH = self._I - dot(K, H)\n        P = dot(dot(I_KH, P), I_KH.T) + dot(dot(K, R), K.T)\n\n        return x, P\n\n    def residual_of(self, z):\n        \"\"\"\n        \u8fd4\u56dez\u4e0e\u5148\u9a8c\u4f30\u8ba1\u503c\u7684\u6b8b\u5dee\n        \"\"\"\n        return z - dot(self.H, self.x_prior)\n\n    def measurement_of_state(self, x):\n        \"\"\"\n        \u5c06\n\n        Parameters\n        ----------\n\n        x : np.array\n            kalman state vector\n\n        Returns\n        -------\n\n        z : (dim_z, 1): array_like\n            measurement for this update. z can be a scalar if dim_z is 1,\n            otherwise it must be convertible to a column vector.\n        \"\"\"\n\n        return dot(self.H, x)\n\n    @property\n    def log_likelihood(self):\n        \"\"\"\n        \u8fd4\u56de\u4e0a\u4e00\u6b21\u6d4b\u91cf\u7684\u5bf9\u6570\u4f3c\u7136\u503c\n        \"\"\"\n        if self._log_likelihood is None:\n            self._log_likelihood = logpdf(x=self.y, cov=self.S)\n        return self._log_likelihood\n\n    @property\n    def likelihood(self):\n        \"\"\"\n        \u8fd4\u56de\u4e0a\u4e00\u6b21\u6d4b\u91cf\u7684\u5bf9\u6570\u4f3c\u7136\u503c\n        \"\"\"\n        if self._likelihood is None:\n            self._likelihood = exp(self.log_likelihood)\n            if self._likelihood == 0:\n                self._likelihood = sys.float_info.min\n        return self._likelihood\n\n    @property\n    def mahalanobis(self):\n        \"\"\"\"\n        \u6d4b\u91cf\u7684\u9a6c\u6c0f\u8ddd\u79bb\uff0c\u6bd4\u59823\u8868\u793a\u8ddd\u79bb\u9884\u6d4b\u503c\u4e4b\u95f4\u67093\u4e2a\u6807\u51c6\u5dee\n        Mahalanobis distance of measurement. E.g. 3 means measurement\n        was 3 standard deviations away from the predicted value.\n\n        Returns\n        -------\n        mahalanobis : float\n        \"\"\"\n        if self._mahalanobis is None:\n            self._mahalanobis = sqrt(float(dot(dot(self.y.T, self.SI), self.y)))\n        return self._mahalanobis\n\n    @property\n    def alpha(self):\n        \"\"\"\n        \u8870\u51cf\u673a\u5236\u7cfb\u6570\uff0c1.0\u8868\u8ff0\u4e0d\u8870\u51cf\uff0c\u5927\u4e8e1.\u7684\u503c\u6bd4\u59821.02\u53ef\u4ee5\u8868\u793a\u4e00\u4e2a\u8870\u51cf\u6548\u5e94\uff0c\u4f7f\u5f97\u4e4b\u524d\u7684\u4f30\u8ba1\u503c\n        \u5bf9\u4e8e\u6ee4\u6ce2\u5668\u7684\u5f53\u524d\u7684\u4f30\u8ba1\u503c\u6709\u8f83\u5c0f\u7684\u5f71\u54cd\u3002\n        \"\"\"\n        return self._alpha_sq**.5\n\n    def log_likelihood_of(self, z):\n        \"\"\"\n        log likelihood of the measurement `z`. This should only be called\n        after a call to update(). Calling after predict() will yield an\n        incorrect result.\"\"\"\n\n        if z is None:\n            return log(sys.float_info.min)\n        return logpdf(z, dot(self.H, self.x), self.S)\n\n    @alpha.setter\n    def alpha(self, value):\n        if not np.isscalar(value) or value &lt; 1:\n            raise ValueError('alpha must be a float greater than 1')\n\n        self._alpha_sq = value**2\n</code></pre>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/#_5","title":"\u4e09\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5e94\u7528\u2014\u6ee4\u6ce2","text":"<p>\u5728\u8fd9\u4e2a\u6848\u4f8b\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u6765\u8ddf\u8e2a\u4e00\u8f86\u6c7d\u8f66\u5728\u4e8c\u7ef4\u7a7a\u95f4\u4e2d\u7684\u5300\u901f\u76f4\u7ebf\u8fd0\u52a8\u3002\u6211\u4eec\u5047\u8bbe\u6c7d\u8f66\u5728 x \u8f74\u548c y \u8f74\u4e0a\u4ee5\u6052\u5b9a\u901f\u5ea6\u79fb\u52a8\uff0c\u5047\u8bbe\u6211\u4eec\u4ec5\u80fd\u6d4b\u5f97\u5f53\u524d\u4f4d\u7f6e\uff0c\u4e14\u4f4d\u79fb\u4f20\u611f\u5668\u672c\u8eab\u6d4b\u91cf\u8bef\u5dee\u65b9\u5dee\u548c\u8fc7\u7a0b\u8bef\u5dee\u65b9\u5dee\u5206\u522b\u4e3a1\u548c0.01\u3002</p> <p>\u5efa\u6a21\u8fc7\u7a0b\u5982\u4e0b\uff1a</p> \\[ \\begin{align*} &amp;x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k-1} \\\\ &amp;z_k = H_k x_k + v_k \\end{align*} \\] <p>\u8bbe \\([x_1, x_2, x_3, x_4]\\) \u8868\u793a\u7cfb\u7edf\u72b6\u6001\u3002 \\([x_1, x_2]\\) \u4e3a\u6c7d\u8f66\u4f4d\u79fb\u7684\u503c\uff0c \\([x_3, x_4]\\) \u4e3a\u6c7d\u8f66\u8fd0\u884c\u7684\u4e24\u4e2a\u65b9\u5411\u7684\u5206\u901f\u5ea6\u3002</p> \\[ x =\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\] <p>\u7531\u4e8e\u662f\u5300\u901f\u76f4\u7ebf\u8fd0\u52a8\uff0c\u72b6\u6001\u8f6c\u79fb\u77e9\u9635 \\(A_{k - 1}\\) \u662f\u4e00\u4e2a\u5e38\u6570\u77e9\u9635\uff0c \\(B_{k-1}\\) \u662f\u5168\u96f6\u77e9\u9635\u3002</p> \\[ A = \\begin{bmatrix} 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] <p>\\([1,0,1,0]\\) \u4e2d\u7b2c\u4e8c\u4e2a1\u8868\u793a\u65f6\u95f4\u95f4\u9694\u662f1\u3002</p> <p>\u8fc7\u7a0b\u566a\u58f0\u534f\u65b9\u5dee\u77e9\u9635Q\u4e3a\uff0c</p> \\[ Q = \\begin{bmatrix} 0.01 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0.01 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0.01 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0.01 \\end{bmatrix} \\] <p>\u6d4b\u91cf\u566a\u58f0\u534f\u65b9\u5deeR\u4e3a</p> \\[ R = \\begin{bmatrix} 1 &amp; 0  \\\\ 0 &amp; 1  \\\\ \\end{bmatrix} \\] <p>\u6d4b\u91cf\u77e9\u9635H\u8868\u793a\u4e3a</p> \\[ H = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0  \\end{bmatrix} \\] <p>P\u662f\u5148\u9a8c\u4f30\u8ba1\u7684\u534f\u65b9\u5dee\uff0c\u5bf9\u4e0d\u53ef\u89c2\u5bdf\u7684\u521d\u901f\u5ea6\uff0c\u7ed9\u4e88\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u6027</p> \\[ P = \\begin{bmatrix} 10 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 10 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1000 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1000 \\end{bmatrix} \\] <p>\u5bf9\u4e8e\u4e0d\u53ef\u89c2\u5bdf\u7684 \\(x_3,x_4\\) \uff0c\u8ba4\u4e3a\u5b83\u7684\u8bef\u5dee\u5f88\u5927\u3002</p> <p>\u4e0b\u9762\u662f\u4ee3\u7801</p> <pre><code>import numpy as np\nimport random\nimport matplotlib.pyplot as plt\nfrom filterpy.kalman import KalmanFilter\nfrom filterpy.common import Q_discrete_white_noise, Saver\n\n\n\nx_true = np.arange(0, 100, 0.1)\ny_true = x_true * 10 + 1\n\nx_watched = x_true + np.random.normal(0, 1, (len(x_true),))\ny_watched = y_true + np.random.normal(0, 1, (len(x_true),))\n\n\n# \u8bbe\u7f6e\u521d\u59cb\u72b6\u6001\ninit_point = np.asarray([x_true[0], y_true[0], 0.1, 1])\n\n\nkf = KalmanFilter(dim_x=4, dim_z=2)\n\n# position, velocity\nkf.x = init_point\nkf.F = np.array([\n                 [1, 0, 1, 0], \n                 [0, 1, 0, 1],\n                 [0, 0, 1, 0],\n                 [0, 0, 0, 1],\n                ])\nkf.R = np.array([\n                 [1, 0,], \n                 [0, 1,],\n                ])\nkf.H = np.array([[1, 0, 0, 0],\n                 [0, 1, 0, 0],])\n\nkf.P = np.array([\n                 [10, 0, 0, 0], \n                 [0, 10, 0, 0],\n                 [0, 0, 1000, 0],\n                 [0, 0, 0, 1000],\n                ])\nkf.Q = np.array([\n                 [0.01, 0, 0, 0], \n                 [0, 0.01, 0, 0],\n                 [0, 0, 0.01, 0],\n                 [0, 0, 0, 0.01],\n                ])\n\nx_filtered = []\ny_filtered = []\n\nfor x,y in zip(x_watched[1:], y_watched[1:]):\n    kf.predict()\n    kf.update([x, y])\n    # \u4fdd\u5b58\u6ee4\u6ce2\u540e\u7684\u503c\n    x_filtered.append(kf.x[0])\n    y_filtered.append(kf.x[1])\n\n\nplt.rcParams['font.sans-serif'] = ['SimHei']\nplt.rcParams['axes.unicode_minus'] = False\n\nplt.figure()\nplt.scatter(x_true[::20], y_true[::20], c='r', marker='o', label='\u771f\u5b9e\u503c')\nplt.scatter(x_watched[::20], y_watched[::20], c='b', marker='x', label='\u89c2\u6d4b\u503c')\nplt.scatter(x_filtered[::20], y_filtered[::20], c='g', marker='*', label='\u5361\u5c14\u66fc\u6ee4\u6ce2\u6ee4\u6ce2\u503c')\nplt.legend()\nplt.show()\n</code></pre> <p></p> <p>\u6709\u4e0a\u56fe\u53ef\u4ee5\u770b\u51fa\uff0c\u5c3d\u7ba1\u89c2\u6d4b\u503c\u4f1a\u53d7\u5230\u8bef\u5dee\u5e72\u6270\uff0c\u4f46\u662f\u6ee4\u6ce2\u540e\u7684\u503c\u9010\u6e10\u6536\u655b\u4e8e\u771f\u5b9e\u503c\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/#_6","title":"\u56db\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5e94\u7528\u2014\u9884\u6d4b","text":"<p>\u5728\u9884\u6d4b\u9886\u57df\uff0c\u6709\u4e00\u4e2a\u5341\u5206\u5178\u578b\u7684\u5e94\u7528----\u591a\u76ee\u6807\u8ffd\u8e2a\u3002SORT\uff08Simple Online and Realtime Tracking\uff09\u7b97\u6cd5\u662f\u4e00\u79cd\u7528\u4e8e\u76ee\u6807\u8ddf\u8e2a\u7684\u7b97\u6cd5\uff0c\u5b83\u88ab\u8bbe\u8ba1\u4e3a\u65e2\u7b80\u5355\u53c8\u9ad8\u6548\uff0c\u80fd\u591f\u5728\u5b9e\u65f6\u73af\u5883\u4e2d\u8fd0\u884c\u3002\u8be5\u7b97\u6cd5\u7531Charles Szekeres\u7b49\u4eba\u4e8e2016\u5e74\u63d0\u51fa\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002SORT\u7b97\u6cd5\u7684\u6838\u5fc3\u662f\u91c7\u7528IOU\u5ea6\u91cf\u6765\u8bc4\u4ef7\u9884\u6d4b\u76ee\u6807\u6846\u4e0e\u5019\u9009\u68c0\u6d4b\u76ee\u6807\u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u8fd9\u91cc\u7684\u9884\u6d4b\u5373\u91c7\u7528\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u9884\u6d4b\u529f\u80fd\u3002</p> <p>\u4ee5\u4e0b\u662fSORT\u7b97\u6cd5\u7684\u4e3b\u8981\u6b65\u9aa4\uff1a</p> <ol> <li>\u521d\u59cb\u5316\uff1a\u5728\u89c6\u9891\u5e8f\u5217\u7684\u7b2c\u4e00\u4e2a\u5e27\u4e2d\uff0c\u7b97\u6cd5\u4f1a\u4e3a\u6bcf\u4e2a\u76ee\u6807\u5206\u914d\u4e00\u4e2a\u552f\u4e00\u7684id\uff0c\u5e76\u8bb0\u5f55\u5b83\u4eec\u7684\u4f4d\u7f6e\u548c\u5927\u5c0f\u3002</li> <li>\u9884\u6d4b\uff1a\u5728\u5904\u7406\u6bcf\u4e00\u5e27\u4e4b\u524d\uff0c\u5361\u5c14\u66fc\u6ee4\u6ce2\u4f1a\u6839\u636e\u4e0a\u4e00\u5e27\u7684\u76ee\u6807\u72b6\u6001\uff08\u4f4d\u7f6e\u548c\u5927\u5c0f\uff09\u4ee5\u53ca\u8fd0\u52a8\u6a21\u578b\uff08\u5982\u9ad8\u65af\u5206\u5e03\uff09\u6765\u9884\u6d4b\u5f53\u524d\u5e27\u4e2d\u76ee\u6807\u7684\u53ef\u80fd\u4f4d\u7f6e\u3002</li> <li>\u68c0\u6d4b\uff1a\u5728\u5f53\u524d\u5e27\u4e2d\uff0c\u7b97\u6cd5\u4f1a\u4f7f\u7528\u68c0\u6d4b\u5668\u6765\u8bc6\u522b\u76ee\u6807\u3002\u5bf9\u4e8e\u68c0\u6d4b\u5230\u7684\u6bcf\u4e00\u4e2a\u76ee\u6807\uff0c\u7b97\u6cd5\u4f1a\u751f\u6210\u4e00\u4e2a\u8fb9\u754c\u6846\uff08bounding box\uff09\u5e76\u8ba1\u7b97\u5176\u4e0e\u73b0\u6709\u8ddf\u8e2a\u76ee\u6807\u7684IoU\u3002</li> <li>\u5339\u914d\uff1a\u7b97\u6cd5\u4f1a\u4f7f\u7528IoU\u6765\u8bc4\u4f30\u65b0\u68c0\u6d4b\u5230\u7684\u76ee\u6807\u6846\u4e0e\u73b0\u6709\u8ddf\u8e2a\u76ee\u6807\u6846\u7684\u76f8\u4f3c\u5ea6\u3002\u5982\u679c\u65b0\u76ee\u6807\u7684IoU\u9ad8\u4e8e\u67d0\u4e2a\u9608\u503c\uff08\u901a\u5e38\u4e3a0.5\uff09\uff0c\u5219\u8ba4\u4e3a\u5b83\u662f\u5148\u524d\u8ddf\u8e2a\u76ee\u6807\u7684\u4e00\u4e2a\u5ef6\u7eed\u3002</li> <li>\u66f4\u65b0\uff1a\u5bf9\u4e8e\u90a3\u4e9b\u6210\u529f\u5339\u914d\u7684\u76ee\u6807\uff0c\u7b97\u6cd5\u4f1a\u66f4\u65b0\u5176\u4f4d\u7f6e\u548c\u5927\u5c0f\u3002\u5bf9\u4e8e\u672a\u5339\u914d\u7684\u76ee\u6807\uff0c\u7b97\u6cd5\u4f1a\u521b\u5efa\u65b0\u7684\u8ddf\u8e2a\u6761\u76ee\u3002\u6b64\u5916\uff0c\u5982\u679c\u4e00\u4e2a\u76ee\u6807\u5728\u8fde\u7eed\u51e0\u5e27\u4e2d\u90fd\u6ca1\u6709\u88ab\u68c0\u6d4b\u5230\uff0c\u5b83\u7684\u8ddf\u8e2a\u6761\u76ee\u5c06\u88ab\u79fb\u9664\u3002</li> <li>\u53bb\u91cd\uff1a\u7b97\u6cd5\u4f1a\u68c0\u67e5\u6bcf\u4e00\u5bf9\u8ddf\u8e2a\u76ee\u6807\uff0c\u5e76\u79fb\u9664\u90a3\u4e9b\u4e0e\u5176\u5b83\u76ee\u6807\u6709\u9ad8iou\u503c\u7684\u91cd\u590d\u9879\u3002</li> </ol> <p>SORT\u7b97\u6cd5\u7684\u7279\u70b9\uff1a</p> <ul> <li>\u7b80\u5355\u6027\uff1aSORT\u7684\u7b97\u6cd5\u7ed3\u6784\u7b80\u5355\uff0c\u5bb9\u6613\u5b9e\u73b0\uff0c\u4e0d\u9700\u8981\u590d\u6742\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002</li> <li>\u5b9e\u65f6\u6027\uff1a\u7b97\u6cd5\u8bbe\u8ba1\u8003\u8651\u5230\u4e86\u901f\u5ea6\uff0c\u80fd\u591f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6ee1\u8db3\u5b9e\u65f6\u6027\u8981\u6c42\u3002</li> <li>\u51c6\u786e\u6027\uff1a\u901a\u8fc7iou\u5339\u914d\u548c\u53bb\u91cd\u590d\u5904\u7406\uff0cSORT\u80fd\u591f\u51c6\u786e\u5730\u8ddf\u8e2a\u76ee\u6807\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u573a\u666f\u4e2d\u3002</li> </ul> <p>SORT\u7b97\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u90fd\u6709\u5e94\u7528\uff0c\u5982\u65e0\u4eba\u9a7e\u9a76\u3001\u673a\u5668\u4eba\u5bfc\u822a\u3001\u89c6\u9891\u76d1\u63a7\u7b49\u3002\u7531\u4e8e\u5b83\u7684\u7b80\u5355\u6027\u548c\u5b9e\u65f6\u6027\uff0cSORT\u6210\u4e3a\u4e86\u76ee\u6807\u8ddf\u8e2a\u9886\u57df\u4e2d\u4e00\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u7ebf\u7b97\u6cd5\u3002\u4e0d\u8fc7\uff0c\u5b83\u4e5f\u6709\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u6bd4\u5982\u5728\u76ee\u6807\u5bc6\u96c6\u6216\u906e\u6321\u60c5\u51b5\u4e0b\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e0e\u5176\u4ed6\u7b97\u6cd5\u6216\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002</p> <p>\u4ece\u4e92\u8054\u7f51\u4e0a\u627e\u5230\u7684\u4e00\u4e2aSORT\u6d41\u7a0b\u56fe\u5982\u4e0b\uff1a</p> <p></p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u76f4\u63a5\u89e3\u8bfbSORT\uff08Simple Online and Realtime Tracking\uff09\u6e90\u7801\uff0c\u672c\u6b21\u53c2\u8003\u7684\u6e90\u7801\u6765\u6e90\u4e8e https://github.com/abewley/sort \uff0c\u4f5c\u8005\u662f\u8d6b\u8d6b\u6709\u540d\u7684AB\u5927\u795e\uff0c<code>sort.py</code>\u5355\u4e2a\u6587\u4ef6\u63cf\u8ff0\u4e86\u6574\u4e2a\u7b97\u6cd5\u7684\u5168\u90e8\u5185\u5bb9\u3002</p> <pre><code>\"\"\"\n    SORT: A Simple, Online and Realtime Tracker\n    Copyright (C) 2016-2020 Alex Bewley alex@bewley.ai\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.\n\"\"\"\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom skimage import io\n\nimport glob\nimport time\nimport argparse\nfrom filterpy.kalman import KalmanFilter\n\nnp.random.seed(0)\n\n\ndef linear_assignment(cost_matrix):\n  \"\"\"\n  \u8c03\u7528lapjv\u6216\u5308\u7259\u5229\u7b97\u6cd5\u89e3\u51b3\u53cc\u8fb9\u95ee\u9898/\u6307\u6d3e\u95ee\u9898/\u6700\u4f18\u5339\u914d\u95ee\u9898\u3002\n  \"\"\"\n  try:\n    import lap\n    _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n    return np.array([[y[i],i] for i in x if i &gt;= 0]) #\n  except ImportError:\n    from scipy.optimize import linear_sum_assignment\n    x, y = linear_sum_assignment(cost_matrix)\n    return np.array(list(zip(x, y)))\n\n\ndef iou_batch(bb_test, bb_gt):\n  \"\"\"\n  From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n  \u8ba1\u7b97IOU\n  \"\"\"\n  bb_gt = np.expand_dims(bb_gt, 0)\n  bb_test = np.expand_dims(bb_test, 1)\n\n  xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n  yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n  xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n  yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n  w = np.maximum(0., xx2 - xx1)\n  h = np.maximum(0., yy2 - yy1)\n  wh = w * h\n  o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])                                      \n    + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)                                              \n  return(o)  \n\n\ndef convert_bbox_to_z(bbox):\n  \"\"\"\n  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n    the aspect ratio\n  \u5c06 xyxy \u683c\u5f0f \u8f6c\u6362\u4e3a xysr\u683c\u5f0f\uff0c xy\u8868\u793a\u4e2d\u5fc3\u5e97 s\u548cr\u5206\u522b\u8868\u793a \u9762\u79ef\u548c\u5bbd\u9ad8\u6bd4\n  \"\"\"\n  w = bbox[2] - bbox[0]\n  h = bbox[3] - bbox[1]\n  x = bbox[0] + w/2.\n  y = bbox[1] + h/2.\n  s = w * h    #scale is just area\n  r = w / float(h)\n  return np.array([x, y, s, r]).reshape((4, 1))\n\n\ndef convert_x_to_bbox(x,score=None):\n  \"\"\"\n  Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n  \u5c06 xysr\u683c\u5f0f \u8f6c\u6362\u4e3a xyxy \u683c\u5f0f\uff0c xy\u8868\u793a\u4e2d\u5fc3\u70b9 s \u548c r \u5206\u522b \u8868\u793a \u9762\u79ef \u548c \u5bbd\u9ad8\u6bd4\n  \"\"\"\n  w = np.sqrt(x[2] * x[3])\n  h = x[2] / w\n  if(score==None):\n    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n  else:\n    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n\n\nclass KalmanBoxTracker(object):\n  \"\"\"\n  This class represents the internal state of individual tracked objects observed as bbox.\n  \"\"\"\n  count = 0\n  def __init__(self,bbox):\n    \"\"\"\n    \u521d\u59cb\u5316\u4e00\u4e2a tracker \u91c7\u7528\u6700\u5f00\u59cb\u7684 bbox\n    Initialises a tracker using initial bounding box.\n    \"\"\"\n    # \u5b9a\u4e49\u5300\u901f\u6a21\u578b\n    # define constant velocity model\n    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n    # \u72b6\u6001\u53d8\u91cf x = [u, v, s, r, u', v', s']\n    # u v \u5373 bbox\u7684\u4e2d\u5fc3\u70b9 s \u4e0e r\u4ee3\u8868 \u9762\u79ef\u548c\u5bbd\u9ad8\u6bd4\n    # u' v' \u4ee3\u8868x\u4e0ey\u65b9\u5411\u7684\u901f\u7387 s'\u4ee3\u8868\u9762\u79ef\u53d8\u5316\u7684\u901f\u7387\n    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n    # \u6d4b\u91cf\u77e9\u9635 \u53ea\u6709 [u,v,s,r] \u53ef\u4ee5\u6d4b\u91cf\n    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n    # \u8bbe\u7f6e\u6d4b\u91cf\u566a\u58f0 \n    self.kf.R[2:,2:] *= 10.\n    #give high uncertainty to the unobservable initial velocities\n    # \u9488\u5bf9\u4e0d\u53ef\u6d4b\u91cf\u7684\u90e8\u5206 \u8bef\u5dee\u534f\u65b9\u5dee\u521d\u59cb\u5316\u4e3a\u8f83\u5927\u503c\n    self.kf.P[4:,4:] *= 1000. \n    self.kf.P *= 10.\n    # \u8bbe\u7f6e\u8fc7\u7a0b\u566a\u58f0\uff08\u5668\u4ef6\u672c\u8eab\u8bef\u5dee\uff09\uff0c\u9650\u5236\u901f\u7387\u53d8\u5316\u53d7\u566a\u58f0\u5f71\u54cd\u8f83\u5c0f\uff0c\u56e0\u4e3a\u662f\u5047\u8bbe\u4e3a\u5300\u901f\u8fd0\u52a8\u3002\n    self.kf.Q[-1,-1] *= 0.01\n    self.kf.Q[4:,4:] *= 0.01\n\n    # \u5b9a\u4e49\u521d\u59cb\u72b6\u6001\n    self.kf.x[:4] = convert_bbox_to_z(bbox)\n    self.time_since_update = 0\n    # \u5168\u5c40id\n    self.id = KalmanBoxTracker.count\n    KalmanBoxTracker.count += 1\n    self.history = []\n    # \u8bb0\u5f55update\u6267\u884c\u4e86\u591a\u5c11\u6b21\n    self.hits = 0\n    # \u8bb0\u5f55 predict/update \u4ea4\u66ff\u6267\u884c\u4e86\u591a\u5c11\u6b21\uff0c\u82e5\u4e2d\u95f4\u8fde\u7eed\u6267\u884c\u4e24\u6b21 predict \uff0c\u5219\n    # hit_streak \u5c31\u4f1a\u88ab\u7f6e 0\n    self.hit_streak = 0\n    # \u8bb0\u5f55predict\u6267\u884c\u4e86\u591a\u5c11\u6b21\n    self.age = 0\n\n  def update(self,bbox):\n    \"\"\"\n    Updates the state vector with observed bbox.\n    \"\"\"\n    self.time_since_update = 0\n    self.history = []\n    self.hits += 1\n    self.hit_streak += 1\n    # \u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7684update\u6b65\u9aa4\uff0c\u4f7f\u7528\u89c2\u6d4b\u503c\u66f4\u65b0\u9884\u6d4b\u503c\uff0c\u5f97\u5230\u6700\u4f18\u4f30\u8ba1\n    self.kf.update(convert_bbox_to_z(bbox))\n\n  def predict(self):\n    \"\"\"\n    Advances the state vector and returns the predicted bounding box estimate.\n    \"\"\"\n    if((self.kf.x[6]+self.kf.x[2])&lt;=0):\n      self.kf.x[6] *= 0.0\n    # \u4f7f\u7528kf\u7684\u9884\u6d4b\u529f\u80fd\n    self.kf.predict()\n    self.age += 1\n    # \u8fd9\u91cc\u5982\u679c\u6ca1\u6709\u6267\u884c\u6267\u884c update \u5219 time_since_update \u4e0d\u4f1a\u88ab\u6e05\u96f6\n    # \u5219\u6ee1\u8db3\u6761\u4ef6 hit_streak = 0\n    if(self.time_since_update&gt;0):\n      self.hit_streak = 0\n    self.time_since_update += 1\n    self.history.append(convert_x_to_bbox(self.kf.x))\n    return self.history[-1]\n\n  def get_state(self):\n    \"\"\"\n    Returns the current bounding box estimate.\n    \u8fd4\u56de\u5f53\u524dbbox\u7684\u4f30\u8ba1\n    \"\"\"\n    return convert_x_to_bbox(self.kf.x)\n\n\ndef associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n  \"\"\"\n  Assigns detections to tracked object (both represented as bounding boxes)\n  \u57fa\u4e8e\u68c0\u6d4b\u7ed3\u679c \u73b0\u6709tracker \u548ciou\u9608\u503c\u7ed9detection\u548ctracker\u5206\u7c7b\n  \u5206\u4e3a \u5339\u914d\u68c0\u6d4b\u3001\u672a\u5339\u914d\u68c0\u6d4b\u3001\u672a\u5339\u914dtracker\n  Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n  \"\"\"\n  if(len(trackers)==0):\n    return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n\n  # \u8ba1\u7b97 \u68c0\u6d4b\u7ed3\u679c\u548c trackers\u9884\u6d4b\u7ed3\u679c\u4e4b\u95f4\u7684iou\uff0c\u8fd4\u56de[M, N]\u5f62\u72b6\u7684\u77e9\u9635\n  # M \u4e3a\u68c0\u6d4b\u7ed3\u679c\u77e9\u9635\u7684\u884c\u6570\uff0c\u5373\u4e2a\u6570\n  # N \u4e3atrackers\u7684\u4e2a\u6570\n  iou_matrix = iou_batch(detections, trackers)\n\n  # \u5982\u679ciou_matrix\u77e9\u9635\u4e0d\u4e3a\u7a7a\n  if min(iou_matrix.shape) &gt; 0:\n    a = (iou_matrix &gt; iou_threshold).astype(np.int32)\n    # \u5982\u679c\u53ea\u6709\u6bcf\u4e00\u884c\u6216\u8005\u6bcf\u4e00\u5217\u6700\u591a\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u6ee1\u8db3iou\u9608\u503c\u8981\u6c42\uff0c\u5219\u76f4\u63a5\u53d6\u8be5\u552f\u4e00\u5339\u914d\u7ed3\u679c\u5373\u53ef\n    if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n      matched_indices = np.stack(np.where(a), axis=1)\n    else:\n      # \u91c7\u7528\u5308\u7259\u5229\u7b97\u6cd5 \u5f97\u5230\u6700\u4f18\u5339\u914d\uff0c\u6ce8\u610f\u8fd9\u91cc\u6ca1\u6709\u8003\u8651\u9608\u503c\uff0c\u540e\u9762\u4f1a\u8003\u8651\n      matched_indices = linear_assignment(-iou_matrix)\n  else:\n    # \u6ca1\u6709match\u7684\u5143\u7d20\n    matched_indices = np.empty(shape=(0,2))\n\n  # \u904d\u5386detections\u548ctrackers\u5f97\u5230\u672a\u5339\u914d\u7684detections\u548c\u672a\u5339\u914d\u7684unmatched_trackers\n  unmatched_detections = []\n  for d, det in enumerate(detections):\n    if(d not in matched_indices[:,0]):\n      unmatched_detections.append(d)\n  unmatched_trackers = []\n  for t, trk in enumerate(trackers):\n    if(t not in matched_indices[:,1]):\n      unmatched_trackers.append(t)\n\n  # \u5728\u5df2\u6709\u5339\u914d\uff0c\u8fc7\u6ee4\u6389\u8f83\u4f4e\u7684IOU\u5339\u914d\n  # filter out matched with low IOU\n  matches = []\n  for m in matched_indices:\n    if(iou_matrix[m[0], m[1]]&lt;iou_threshold):\n      unmatched_detections.append(m[0])\n      unmatched_trackers.append(m[1])\n    else:\n      matches.append(m.reshape(1,2))\n  if(len(matches)==0):\n    matches = np.empty((0,2),dtype=int)\n  else:\n    matches = np.concatenate(matches,axis=0)\n\n  return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n\n\nclass Sort(object):\n  def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n    \"\"\"\n    Sets key parameters for SORT\n    \"\"\"\n    # \u5f53\u6ca1\u6709det box\u5173\u8054\u65f6\uff0ctracker \u6700\u957f \u5b58\u6d3b\u5468\u671f\n    self.max_age = max_age\n    # \u5f53\u6709det box\u65f6\uff0c\u6700\u5c11\u5173\u8054\u6b21\u6570\uff08\u5173\u8054min_hits\u6b21\u540e\u624d\u8bbe\u7f6e\u4e3atracker\uff09\n    self.min_hits = min_hits\n    # iou\u9608\u503c\uff0c\u7528\u4e8e \u5361\u5c14\u66fc\u9884\u6d4b\u7ed3\u679c \u548c \u68c0\u6d4b\u7ed3\u679c\u7684\u5339\u914d\n    self.iou_threshold = iou_threshold\n    self.trackers = []\n    # \u7edf\u8ba1\u7b2c\u51e0\u5e27\n    self.frame_count = 0\n\n  def update(self, dets=np.empty((0, 5))):\n    \"\"\"\n    Params:\n      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n    Returns the a similar array, where the last column is the object ID.\n\n    NOTE: The number of objects returned may differ from the number of detections provided.\n    \"\"\"\n    self.frame_count += 1\n    # get predicted locations from existing trackers.\n    trks = np.zeros((len(self.trackers), 5))\n    to_del = []\n    ret = []\n    # \u53bb\u9664\u4e0d\u5408\u6cd5\u7684\u9884\u6d4b\n    for t, trk in enumerate(trks):\n      # \u8c03\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u9884\u6d4b\u529f\u80fd\n      pos = self.trackers[t].predict()[0]\n      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n      if np.any(np.isnan(pos)):\n        to_del.append(t)\n    trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n    for t in reversed(to_del):\n      self.trackers.pop(t)\n    # \u5c06\u9884\u6d4b\u7ed3\u679c\u4e0edetection\u7ed3\u679c\u505a\u5339\u914d\n    matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks, self.iou_threshold)\n\n    # \u5bf9\u4e8ematch\u7684tracker\uff0c\u4f7f\u7528\u89c2\u6d4b\u7ed3\u679c\u66f4\u65b0\u9884\u6d4b\u7ed3\u679c\n    # update matched trackers with assigned detections\n    for m in matched:\n      self.trackers[m[1]].update(dets[m[0], :])\n\n    # \u4e3a\u6ca1\u6709match\u7684\u521d\u59cb\u5316\u65b0\u7684tracker\n    # create and initialise new trackers for unmatched detections\n    for i in unmatched_dets:\n        trk = KalmanBoxTracker(dets[i,:])\n        self.trackers.append(trk)\n\n    # \u904d\u5386\u73b0\u6709tracker \u53bb\u9664\u8fc7\u671f\u7684tracker\n    i = len(self.trackers)\n    for trk in reversed(self.trackers):\n        # \u5f97\u5230\u6700\u4f18\u6ee4\u6ce2\u503c\uff08\u9488\u5bf9\u65b0\u589etracker\u5f97\u5230\u7684\u662f\u521d\u59cb\u503c\uff09\n        d = trk.get_state()[0]\n        # \u5982\u679c\u5f53\u524dtracker\u5df2\u7ecf\u6267\u884c\u4e86update\u51fd\u6570\uff08\u5373\u662f\u5339\u914d\u7684\uff09\u6216\u8005\u662f\u521a\u521a\u521d\u59cb\u5316 \u5219\u6ee1\u8db3 trk.time_since_update = 0\n        # \u5e76\u4e14 \u7684\u6761\u4ef6\u6709\u4e24\u4e2a \u6216\u6761\u4ef6\n        # 1. trk.hit_streak &gt;= self.min_hits \u8868\u793a \u8fde\u7eed\u4ea4\u66ff\u6267\u884c\u6b21\u6570hit_streak\u8981\u5927\u4e8emin_hits\u624d\u7b97\u6709\u6548\u8f68\u8ff9\n        # 2. self.frame_count &lt;= self.min_hits \u8868\u793a\u6700\u5f00\u59cb\u7684\u524dmin_hits\u53ef\u4ee5\u76f4\u63a5\u653e\u884c\n        if (trk.time_since_update &lt; 1) and (trk.hit_streak &gt;= self.min_hits or self.frame_count &lt;= self.min_hits):\n          ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n        i -= 1\n        # \u5982\u679c\u4e00\u76f4\u6267\u884c\u9884\u6d4bpredict\u51fd\u6570\u5374\u4e0d\u6267\u884cupdate\uff0c\u8868\u793a\u8be5\u8f68\u8ff9\u4e00\u76f4\u6ca1\u6709\u5339\u914d\u8fc7\n        # \u82e5\u8be5\u6b21\u6570\u5927\u4e8e max_age \u5219\u4ecetracker\u4e2d\u5220\u9664\n        # remove dead tracklet\n        if(trk.time_since_update &gt; self.max_age):\n          self.trackers.pop(i)\n    if(len(ret)&gt;0):\n      return np.concatenate(ret)\n    return np.empty((0,5))\n</code></pre>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/#_7","title":"\u4e94\u3001\u603b\u7ed3","text":"<p>\u5728\u4e0d\u540c\u7684\u5730\u65b9\u548c\u4e0d\u540c\u65f6\u95f4\u5b8c\u6210\u7684\u4e8c\u4e09\u56db\u4e09\u7ae0\u7684\u5185\u5bb9\u51c6\u5907\uff0c\u62d6\u4e86\u534a\u5e74\u4eca\u5929\u603b\u7b97\u5199\u5b8c\u4e86\u3002\u53ef\u662f\u8fd9\u4ec5\u4ec5\u662f\u4e2a\u5f00\u59cb\uff0c\u6700\u4f18\u5316\u6ee4\u6ce2\u7684\u5927\u95e8\u624d\u521a\u521a\u6253\u5f00\uff0c\u540e\u7eed\u6bd4\u5982\u975e\u7ebf\u6027\u6ee4\u6ce2\u7cfb\u5217\u5185\u5bb9\u5fc5\u7136\u4e5f\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5b66\u4e60\u3002\u52a0\u6cb9\u5427\u5c11\u5e74\uff0c\u603b\u80fd\u6324\u51fa\u4e00\u4e9b\u65f6\u95f4\u6765\u53bb\u4e13\u6ce8\u67d0\u4ef6\u4e8b\u60c5\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%B8%89/#_8","title":"\u53c2\u8003\u94fe\u63a5","text":"<ul> <li>https://github.com/rlabbe/filterpy</li> </ul>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/","title":"\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u516c\u5f0f\u63a8\u5bfc\u548c\u5e94\u7528\u4e3e\u4f8b(\u4e8c)","text":"<p>\u672c\u6587\u5199\u4e8e2023-08-20\u4e0b\u5348\u4e24\u70b9\u30012023-09-09\u665a\u4e0a\u5341\u70b9\u30012023-09-10\u5168\u5929</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#_2","title":"\u4e00\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u53e6\u5916\u4e09\u7c7b\u63a8\u5bfc\u65b9\u5f0f","text":"<p>\u4e0a\u4e00\u7bc7\u5173\u4e8e\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u6587\u7ae0\u7ed9\u51fa\u4e86\u76f4\u63a5\u516c\u5f0f\u63a8\u5bfc\u7684\u65b9\u5f0f\uff0c\u5728\u672c\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6211\u5c06\u7ed9\u51fa\u5361\u5c14\u66fc\u6ee4\u6ce2\u539f\u8bba\u6587\u7684\u8bc1\u660e\u65b9\u5f0f\uff08\u6b63\u4ea4\u6295\u5f71\u5b9a\u7406\uff09\u548c\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u6cd5\u7684\u8bc1\u660e\u65b9\u5f0f\u3002</p> <p>\u901a\u8fc7\u8d1d\u53f6\u65af\u6ee4\u6ce2\u63a8\u5bfc\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u4ee5\u53ca\u7c92\u5b50\u6ee4\u6ce2\u7b49\uff0cB\u7ad9\u4e00\u4f4dup\u4e3b\u8bb2\u7684\u4e0d\u9519\uff0c\u76f4\u63a5\u7ed9\u51fa\u94fe\u63a5\uff0c\u63a8\u8350\u5927\u5bb6\u770b\u4e00\u4e0b</p> <p>https://www.bilibili.com/video/BV1aE411p7VE/</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#_3","title":"\u4e8c\u3001\u57fa\u7840\u77e5\u8bc6\u51c6\u5907","text":""},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#21","title":"2.1 \u6781\u5927\u4f3c\u7136\u4f30\u8ba1","text":"<p>\u5728\u8c08\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u4e4b\u524d\u6211\u60f3\u5148\u7ed9\u51fa\u4e00\u4e9b\u7edf\u8ba1\u63a8\u65ad\u80cc\u666f\u77e5\u8bc6\u3002</p> <p>\u76f4\u81f3\u5f53\u524d\uff0c\u5173\u4e8e\u7edf\u8ba1\u63a8\u65ad\u7684\u4e3b\u5f20\u548c\u60f3\u6cd5\uff0c\u5927\u4f53\u53ef\u4ee5\u7eb3\u5165\u5230\u4e24\u4e2a\u4f53\u7cfb\u4e4b\u5185\uff0c\u5176\u4e00\u53eb\u9891\u7387\u5b66\u6d3e\uff0c\u5176\u7279\u5f81\u662f\u628a\u9700\u8981\u63a8\u65ad\u7684\u53c2\u6570\u03b8\u89c6\u4f5c\u56fa\u5b9a\u4e14\u672a\u77e5\u7684\u5e38\u6570\uff0c\u800c\u6837\u672cX\u662f\u968f\u673a\u7684\uff0c\u5176\u7740\u773c\u70b9\u5728\u6837\u672c\u7a7a\u95f4\uff0c\u6709\u5173\u7684\u6982\u7387\u8ba1\u7b97\u90fd\u662f\u9488\u5bf9X\u7684\u5206\u5e03\u3002</p> <p>\u53e6\u4e00\u6d3e\u53eb\u505a\u8d1d\u53f6\u65af\u5b66\u6d3e\uff0c\u4ed6\u4eec\u628a\u53c2\u6570\u03b8\u89c6\u4f5c\u968f\u673a\u53d8\u91cf\uff0c\u800c\u6837\u672cX\u662f\u56fa\u5b9a\u7684\uff0c\u5176\u7740\u773c\u70b9\u5728\u53c2\u6570\u7a7a\u95f4\uff0c\u91cd\u89c6\u53c2\u6570\u03b8\u7684\u5206\u5e03\uff0c\u56fa\u5b9a\u7684\u64cd\u4f5c\u6a21\u5f0f\u662f\u901a\u8fc7\u53c2\u6570\u7684\u5148\u9a8c\u5206\u5e03\u7ed3\u5408\u6837\u672c\u4fe1\u606f\u5f97\u5230\u53c2\u6570\u7684\u540e\u9a8c\u5206\u5e03\u3002</p> <p>\u4e24\u5b66\u6d3e\u5404\u6709\u5176\u4fe1\u4ef0\u3001\u5185\u5728\u903b\u8f91\u3001\u89e3\u91ca\u529b\u548c\u5c40\u9650\u6027\uff0c\u4ece20\u4e16\u7eaa\u4e0a\u534a\u9875\u81f3\u4eca\uff0c\u4e24\u5927\u5b66\u6d3e\u7684\u8fa9\u8bba\u4ece\u672a\u505c\u6b47\uff0c\u4f46\u5206\u6b67\u5982\u6545\u3002\u8d1d\u53f6\u65af\u5b66\u6d3e\u7684\u53d1\u5c55\u5728\u4e8c\u5341\u4e16\u7eaa\u6ede\u540e\u4e8e\u9891\u7387\u5b66\u6d3e\uff0c\u751a\u81f3\u73b0\u4eca\u4e3b\u6d41\u7edf\u8ba1\u5b66\u6559\u6750\u4ecd\u7136\u4ee5\u9891\u7387\u5b66\u6d3e\u7684\u7406\u8bba\u6846\u67b6\u4e3a\u4e3b\uff0c\u8d1d\u53f6\u65af\u7406\u8bba\u901a\u5e38\u4e00\u7b14\u5e26\u8fc7\u3002\u8fd9\u6216\u8bb8\u53d7\u5230Karl Pearson\uff0cSir Ronald A. Fisher\uff0cEgon Pearson\uff08Karl Pearson\u7684\u513f\u5b50\uff09\u548cJerzy Neyman\u7b49\u4e8c\u5341\u4e16\u7eaa\u4e0a\u534a\u53f6\u7684\u5927\u7edf\u8ba1\u5b66\u5bb6\u7684\u5f71\u54cd\uff0c\u8fd9\u4e9b\u5f53\u65f6\u5177\u6709\u8bdd\u8bed\u6743\u7684\u5927\u7edf\u8ba1\u5b66\u5bb6\u5e76\u4e0d\u8ba4\u53ef\u8d1d\u53f6\u65af\u7406\u8bba\uff08\u5c3d\u7ba1\u4e00\u4e9b\u4eba\u7684\u6587\u7ae0\u91cc\u88ab\u6000\u7591\u4f7f\u7528\u4e86\u8d1d\u53f6\u65af\u7684\u601d\u60f3\uff09\u3002</p> <p>\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u662f\u9891\u7387\u5b66\u6d3e\u6700\u7ecf\u5178\u7684\u65b9\u6cd5\u4e4b\u4e00\uff0c\u8ba4\u4e3a\u771f\u5b9e\u53d1\u751f\u7684\u7ed3\u679c\u7684\u6982\u7387\u5e94\u8be5\u662f\u6700\u5927\u7684\uff0c\u90a3\u4e48\u76f8\u5e94\u7684\u53c2\u6570\uff0c\u4e5f\u5e94\u8be5\u662f\u80fd\u8ba9\u8fd9\u4e2a\u72b6\u6001\u53d1\u751f\u7684\u6982\u7387\u6700\u5927\u7684\u53c2\u6570\u3002</p> <p>\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u662f\u4e00\u79cd\u53c2\u6570\u4f30\u8ba1\u7684\u65b9\u6cd5\u3002\u5b83\u8981\u89e3\u51b3\u8fd9\u6837\u4e00\u4e2a\u95ee\u9898\uff1a\u7ed9\u5b9a\u4e00\u7ec4\u6570\u636e\u548c\u4e00\u4e2a\u53c2\u6570\u5f85\u5b9a\u7684\u6a21\u578b\uff0c\u5982\u4f55\u786e\u5b9a\u6a21\u578b\u7684\u53c2\u6570\uff0c\u4f7f\u5f97\u8fd9\u4e2a\u786e\u5b9a\u53c2\u6570\u540e\u7684\u6a21\u578b\u5728\u6240\u6709\u6a21\u578b\u4e2d\u4ea7\u751f\u5df2\u77e5\u6570\u636e\u7684\u6982\u7387\u6700\u5927\u3002</p> <p>\u5728\u5e38\u89c1\u7684\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u4e2d\uff0c\u6211\u4eec\u5e38\u5e38\u53ef\u4ee5\u7528\u4e8e\u4f30\u8ba1 \\(\\theta\\) \u4e4b\u7c7b\u7684\u53d8\u91cf\uff0c\u4f46\u662f\u5728\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u8bc1\u660e\u8fc7\u7a0b\u4e2d\uff0c\u8bfb\u8005\u9700\u8981\u6ce8\u610f\u7684\u662f\u6211\u4eec\u9700\u8981\u4f30\u8ba1\u7684\u662f \\(x\\) \u7684\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\uff0c\u8fd9\u4e00\u70b9\u8981\u7262\u8bb0\u3002\u9884\u6d4b \\(x\\) \u7684\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u4e5f\u5f88\u7b80\u5355\uff0c\u5373\u5bfb\u627e\u4e00\u4e2a \\(x\\) \u503c\u4f7f\u5f97\u5173\u4e8e \\(x\\) \u7684\u6781\u5927\u4f3c\u7136\u51fd\u6570\u6700\u5927\u5c31\u597d\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#22","title":"2.2 \u6b63\u4ea4\u6295\u5f71\u5b9a\u7406","text":"<p>\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u662f\u5386\u53f2\u89c2\u6d4b\u503c\u7684\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1\u3002\u5728\u51e0\u4f55\u4e0a\uff0c\u5361\u5c14\u66fc\u6ee4\u6ce2\u4f30\u503c\u662f\u72b6\u6001\u53d8\u91cf\u5728\u7531\u89c2\u6d4b\u751f\u6210\u7684\u7ebf\u6027\u7a7a\u95f4\u4e0a\u7684\u5c04\u5f71\u3002</p> <p>\u7531  \\(m \\times 1\\) \u7ef4\u968f\u673a\u53d8\u91cf  \\(y \\in R^m\\) \u7684\u7ebf\u6027\u51fd\u6570\u4f30\u8ba1  \\(n \\times 1\\)  \u7ef4\u968f\u673a\u53d8\u91cf  \\(x \\in R^n\\) \uff0c\u8bb0\u4f30\u503c\u4e3a</p> \\[ \\hat x = Ay + b, b \\in R^n,A \\in R^{n \\times m}, \\hat x \\in R^{n} \\] <p>\u82e5\u4f30\u503c  \\(\\hat{x}\\) \u6781\u5c0f\u5316\u6027\u80fd\u6307\u6807\u4e3a\u6807\u4e3a \\(J=E[(x-\\hat{x})^T(x-\\hat{x})]\\) \uff0c\u5219\u79f0  \\(\\hat{x}\\) \u4e3a\u968f\u673a\u53d8\u91cf \\(x\\) \u7684\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1\u3002</p> <p>\u5c06 \\(\\hat x\\) \u7684\u5177\u4f53\u5f62\u5f0f\u5e26\u5165\u6781\u5c0f\u5316\u6027\u80fd\u6307\u6807\u53ef\u5f97</p> \\[ J = E[(x - Ay - b)^{T}(x - Ay - b)] \\] <p>\u4e3a\u6c42\u6027\u80fd\u6307\u6807\u6781\u5c0f\u503c\uff0c\u5206\u522b\u6c42\u5173\u4e8e\u53d8\u91cf \\(b\\) \u548c\u53d8\u91cf \\(A\\) \u7684\u504f\u5bfc\u6570(\u77e9\u9635\u6c42\u5bfc\u7684\u90e8\u5206\u516c\u5f0f\u53ef\u4ee5\u53c2\u8003\u4e0a\u4e00\u7bc7\u6587\u7ae0)</p> \\[ \\frac {\\partial J}{\\partial b} = -2E(x-b-Ay) = 0 \\] <p>\u6c42\u5f97</p> \\[ b = E(x) - A*E(y) \\] <p>\u5c06 \\(b\\) \u7684\u503c\u5e26\u5165\u5230 \\(J\\) \u7684\u8868\u8fbe\u5f0f\u53ef\u5f97</p> \\[ \\begin{align*} J &amp;= E[(x - Ay - b)^{T}(x - Ay - b)] \\\\ &amp;= \\text{tr} E[(x - Ay - b) (x - Ay - b)^{T}] \\\\ &amp;= \\text{tr} E[(x - Ay - (E(x) - A*E(y)))(x - Ay - (E(x) - A*E(y)))^{T}] \\\\ &amp;= \\text{tr} E[((x - E(x)) - A(y - E(y))) ((x - E(x))^{T} - (y - E(y))^{T}A^T) ] \\\\ &amp;= \\text{tr} E[(x - E(x))(x - E(x))^{T} - A(y - E(y))(x - E(x))^{T} - (x - E(x))(y - E(y))^{T}A^T + A(y - E(y))(y - E(y))^{T}A^T)] \\\\ \\end{align*} \\] <p>\u8bb0</p> \\[ \\begin{align*} &amp; P_{xx} = E[(x - Ex)(x - Ex)^T] \\\\ &amp; P_{xy} = E[(x - Ex)(y - Ey)^T] \\\\ &amp; P_{yx} = E[(y - Ey)(x - Ex)^T] \\\\ &amp; P_{yx}^T = P_{xy} \\\\ &amp; P_{yy} = E[(y - Ey)(y - Ey)^T] \\\\ &amp; P_{xx}^T = P_{xx}, P_{yy}^T = P_{yy} \\end{align*} \\] <p>\u5219</p> \\[ \\begin{align*} J &amp;= \\text{tr} [P_{xx} - AP_{yx} - P_{xy}A^T + AP_{yy}A^T] \\\\ &amp;= \\text{tr} P_{xx} - \\text{tr}(AP_{yx}) - \\text{tr} (P_{xy}A^T) + \\text{tr} (AP_{yy}A^T) \\end{align*} \\] <p>\u6c42\u5bfc\u9884\u5907\u77e5\u8bc6</p> \\[ \\begin{align*} &amp;\\frac{\\partial \\text{tr}(ABA^T)}{\\partial A} = AB + AB^T \\\\ &amp;\\frac{\\partial \\text{tr}(A^TB)}{\\partial A} = \\frac{\\partial \\text{tr}(B A^T)}{\\partial A} = B \\end{align*} \\] <p>\u90a3\u4e48</p> \\[ \\begin{align*} \\frac{\\partial J}{\\partial A} &amp;= - P_{yx}^T - P_{xy} + AP_{yy} + AP_{yy}^T \\\\ &amp;=  - P_{xy} - P_{xy} + AP_{yy} + AP_{yy} \\\\ &amp;= - 2 (P_{xy} - AP_{yy}) \\end{align*} \\] <p>\u4ee4\u4e0a\u5f0f\u7b49\u4e8e\u96f6\uff0c\u53ef\u5f97</p> \\[ A = P_{xy} P_{yy}^{-1} \\] <p>\u5c06 \\(A\\) \u548c \\(b\\) \u5e26\u5165 \\(\\hat x\\) \u53ef\u5f97</p> \\[ \\begin{align*} \\hat x &amp;= Ay + b \\\\ &amp;= Ay + E(x) - A*E(y) \\\\ &amp;= A(y - E(y)) +  E(x) \\\\ &amp;= E(x) + P_{xy} P_{yy}^{-1}(y - E(y)) \\end{align*} \\] <p>\u8fd9\u91cc\u8bf4\u660e\u4e0b\u5404\u4e2a\u53d8\u91cf\u7684\u5f62\u72b6\uff0c \\(E(x) \\in R^{n \\times 1}\\) \uff0c \\(P_{xy} \\in R^{n \\times m}\\) \uff0c \\(P_{yy} \\in R^{m \\times m}\\) \uff0c \\(E(y) \\in R^{m \\times 1}\\) </p> <p>\u5217\u5411\u91cf\u8868\u793a\u4e3a\u4e00\u4e2a\u77e9\u9635\u65f6\uff0c\u53ef\u4ee5\u770b\u505a \\(row\\_number \\times 1\\) \u7684\u77e9\u9635\u3002</p> <p>\u91cd\u8981\u63d0\u793a\uff1a\u51e1\u662f\u5bf9\u53d8\u91cf\u6c42\u7684\u671f\u671b\uff0c\u90fd\u53ef\u4ee5\u770b\u9519\u4e00\u4e2a\u5e38\u6570\u6216\u8005\u5e38\u6570\u77e9\u9635\u3002 \u5728\u540e\u7eed\u6c42\u89e3\u7528\u5230\u6c42\u671f\u671b\u65f6\u7684\u8fd0\u7b97\u516c\u5f0f\u65f6\uff0c\u8fd8\u8bf7\u591a\u52a0\u6ce8\u610f\u8fd9\u4e00\u70b9</p> <p>\u63a8\u8bba1 \u65e0\u504f\u6027  \\(E \\hat x = Ex\\) </p> <p>\u8bc1\u660e\uff1a</p> \\[ E\\hat x = E[Ex + P_{xy} P_{yy}^{-1}(y - Ey)] = Ex + P_{xy} P_{yy}^{-1}(Ey - Ey) = Ex \\] <p>\u63a8\u8bba2 \u6b63\u4ea4\u6027  \\(E[(x - \\hat x) y ^T] = 0\\) </p> <p>\u8bc1\u660e\uff08\u5229\u7528 \\(Ey^T\\) \u662f\u5e38\u6570\u5411\u91cf\u8fd9\u4e00\u6027\u8d28\uff09</p> <p>\u7531\u63a8\u8bba1\u53ef\u5f97\uff0c \\(E(x - \\hat x) = 0\\) \uff0c\u5219\u6709 \\(E(x - \\hat x) \\times Ey^T = E[(x - \\hat x)Ey ^T] = 0\\) </p> \\[ \\begin{align*} E[(x - \\hat x) y ^T] &amp;= E[(x - \\hat x) y ^T] - E[(x - \\hat x)Ey ^T] \\\\ &amp;= E[(x - \\hat x) (y - Ey) ^T] \\\\ &amp;= E[(x - Ex - P_{xy} P_{yy}^{-1}(y - Ey)) (y - Ey) ^T] \\\\ &amp;= E[(x - Ex)(y - Ey) ^T] - P_{xy} P_{yy}^{-1} E[(y - Ey)(y - Ey)^T] \\\\ &amp;= P_{xy} - P_{xy} P_{yy}^{-1}P_{yy} \\\\ &amp;= P_{xy} - P_{xy} \\\\ &amp;= 0 \\end{align*} \\] <p>\u63a8\u8bba3 \\(\\widetilde x = x - \\hat x\\) \u4e0e \\(y\\) \u4e0d\u76f8\u5173</p> <p>\u6839\u636e\u4e0d\u76f8\u5173\u5b9a\u4e49\uff0c\u53ef\u4ee5\u8bc1\u660e\u76f8\u5173\u7cfb\u6570\u4e3a0\uff0c\u76f8\u5173\u7cfb\u6570\u4e3a\u96f6-&gt;\u53ef\u4ee5\u8bc1\u660e\u4e24\u8005\u534f\u65b9\u5dee\u4e3a0\u3002</p> <p>\u6309\u7167\u534f\u65b9\u5dee\u5b9a\u4e49\u53ef\u4ee5\u5199\u51fa\uff08\u5229\u7528\u4e86\u4e0a\u9762\u7684\u8bc1\u660e\u8fc7\u7a0b\uff09</p> \\[ \\begin{align*} cov(\\widetilde x , y) &amp;= E[(\\widetilde x - E\\widetilde x)(y - Ey)^T]  \\\\ &amp;= E[\\widetilde x(y - Ey)^T] \\\\ &amp;= E[(x - \\hat x)(y - Ey)^T] \\\\ &amp;= 0 \\end{align*} \\] <p>\u5c04\u5f71\u7684\u5b9a\u4e49</p> <p>\u5c06 \\(x - \\hat x\\) \u4e0e \\(y\\) \u4e0d\u76f8\u5173\u5b9a\u4e49\u4e3a \\(x - \\hat x\\) \u4e0e \\(y\\) \u6b63\u4ea4\uff08\u5782\u76f4\uff09\uff0c\u8bb0\u4e3a \\((x - \\hat x) \\perp y\\) \uff0c\u5e76\u79f0 \\(\\hat x\\) \u4e3a \\(x\\) \u5728y\u4e0a\u7684\u5c04\u5f71\uff0c\u8bb0\u4e3a \\(\\hat x = proj(x | y)\\) </p> <p>\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1 \\(\\hat x\\) \u7684\u51e0\u4f55\u610f\u4e49\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u5728\u7ebf\u6027\u6d41\u5f62\u4e0a\u5c04\u5f71\u7684\u5b9a\u4e49</p> <p>\u7531\u968f\u673a\u53d8\u91cf \\(y \\in R^m\\) \u5f20\u6210\u7684\u7ebf\u6027\u6d41\u5f62(\u7ebf\u6027\u7a7a\u95f4)\u5b9a\u4e49\u4e3a\u5982\u4e0b\u5f62\u5f0f\u968f\u673a\u53d8\u91cf \\(z \\in R^n\\) \u7684\u96c6\u5408 \\(L(y)\\) ,</p> \\[ L(y) = \\{z | z = Ay + b, \\forall A \\in R^{n \\times m},\\forall b \\in R^n \\} \\] <p>\u63a8\u8bba  \\((x - \\hat x) \\perp z, \\forall z \\in L(y)\\) \uff0c\u8bb0\u4e3a \\((x - \\hat x) \\perp L(y)\\) .</p> <p>\u8bc1\u660e</p> \\[ \\begin{align*} E[(x - \\hat x)z^T] &amp;= E[(x - \\hat x)(Ay + b) ^ T] \\\\ &amp;= E[(x - \\hat x)y^T]A^T + E[(x - \\hat x)]b^T \\\\ &amp;= 0 + 0 \\\\ &amp;= 0 \\end{align*} \\] <p>\u8bbe\u968f\u673a\u53d8\u91cf \\(x \\in R^n\\) \uff0c\u968f\u673a\u53d8\u91cf \\(y(1), ...,y(k) \\in R^m\\) \uff0c\u5f15\u5165\u5408\u6210\u968f\u673a\u53d8\u91cf \\(w\\) \u4e3a</p> \\[ w = (y^T(1), ..., y^T(k))^T \\in R^{km} \\] \\[ L(w) = \\{ y| y = A w + b, \\forall b \\in R^n, \\forall A \\in R^{n \\times km} \\} \\] <p>\u5f15\u5165\u5206\u5757\u77e9\u9635</p> \\[ A = [A_1, ..., A_k], A_i \\in R^{n \\times m} \\] <p>\u5219\u6709</p> \\[ L(w) = \\{ y | y = \\sum_{i = 1}^{k}A_{i}y(i) + b, \\forall A_i \\in R^{n \\times m}, \\forall b \\in R^{n} \\} = L(y(1), ..., y(k)) \\] <p>\u5b9a\u4e49\uff1a\u57fa\u4e8e\u968f\u673a\u53d8\u91cf \\(y(1),...,y(k) \\in R^m\\) \u5bf9\u968f\u673a\u53d8\u91cf \\(x \\in R^n\\) \u7684\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1 \\(\\hat x\\) \u5b9a\u4e49\u4e3a</p> \\[ \\hat x = proj(x|w) \\triangleq proj(x | y(1), ..., y(k)) \\] <p>\u4e5f\u79f0\u4e3a \\(\\hat x\\) \u4e3a \\(x\\) \u5728\u7ebf\u6027\u6d41\u5f62 \\(L(w)\\) \u6216 \\(L(y(1), ..., y(k))\\) \u4e0a\u7684\u5c04\u5f71\u3002</p> <p>\u5c04\u5f71\u7684\u6027\u8d281:\u5728\u7ebf\u6027\u7a7a\u95f4\u4e0a\u6295\u5f71\u57fa\u5e95\u7684\u6027\u8d28</p> <p>\u8bbe \\(x \\in R^n\\) \u4e3a\u96f6\u5747\u503c\u968f\u673a\u5411\u91cf\uff0c \\(y(1), ...,y(k) \\in R^m\\) \u4e3a\u96f6\u5747\u503c\uff0c\u4e92\u4e0d\u76f8\u5173\uff08\u6b63\u4ea4\uff09\u7684\u968f\u673a\u53d8\u91cf\uff0c\u5219\u6709</p> \\[ proj(x | y(1), ..., y(k)) = \\sum_{i = 1}^k proj(x | y(i)) \\] <p>\u5373 \\(x\\) \u5728\u7531 \\(y(1), ... , y(k)\\) \u5f20\u6210\u7684\u7ebf\u6027\u6d41\u5f62$ L(y(1), ..., y(k))  \\(\u4e0a\u7684\u5c04\u5f71\u7b49\u4e8e\u5b83\u5728\u7531\u6bcf\u4e00\u4e2a\\) y(i) \\(\u5f20\u6210\u7684\u7ebf\u6027\u6d41\u5f62\u4e0a\u7684\u5c04\u5f71\u4e4b\u548c\uff0c\u5373\\) x \\(\u5728\u5168\u7a7a\u95f4\u4e0a\u7684\u5c04\u5f71\u7b49\u4e8e\u5b83\u5728\u76f8\u4e92\u6b63\u4ea4\u7684\u5b50\u7a7a\u95f4\u4e0a\u7684\u5c04\u5f71\u4e4b\u548c\u3002\u8fd9\u5927\u5927\u7b80\u5316\u4e86\u5c04\u5f71\u7684\u8ba1\u7b97\u3002\u56e0\u6b64\uff0c\u82e5\\) y(1), ..., y(k)$\u662f\u975e\u6b63\u4ea4\u7684\uff0c\u95ee\u9898\u662f\u5982\u4f55\u4f7f\u5b83\u4eec\u6b63\u4ea4\u5316\uff0c\u8fd9\u5c06\u5f15\u5165\u540e\u9762\u7684\u65b0\u606f\u7684\u6982\u5ff5\u3002</p> <p>\u8bc1\u660e \u8bb0\u5408\u6210\u5411\u91cf \\(w = (y^T(1), ... , y^T(k)) \\in R^{km}\\) \uff0c\u6ce8\u610f \\((Ex = \\mathbf 0, Ew = \\mathbf 0 \uff0c P_{y(i)y(j)} = \\mathbf  0(i  e j), E[y(i)y(j)^T] = \\mathbf 0(i  e j))\\) \uff0c\u5219\u5e94\u7528\u5c04\u5f71\u516c\u5f0f\u6709</p> \\[ \\begin{align*} &amp;proj(x| y(1), ..., y(k))  \\\\ &amp;= proj(x |w) \\\\ &amp;= Ex + P_{xw}P_{ww}^{-1}(w - Ew) \\\\ &amp;= P_{xw}P_{ww}^{-1}w \\\\ &amp;= E[xw^T]E[ww^T]w \\\\ &amp;= E[x\\begin{bmatrix} y(1) \\\\ \\vdots \\\\ y(k) \\\\ \\end{bmatrix}^T]E[\\begin{bmatrix} y(1) \\\\ \\vdots \\\\ y(k) \\\\ \\end{bmatrix} \\begin{bmatrix} y(1) \\\\ \\vdots \\\\ y(k) \\\\ \\end{bmatrix}^T] \\begin{bmatrix} y(1) \\\\ \\vdots \\\\ y(k) \\\\ \\end{bmatrix} \\\\ &amp;= E[x(y^T(1), ..., y^T(k))] \\begin{bmatrix} E[y(1)y^T(1)] &amp;  &amp; \\mathbf 0 \\\\  &amp; \\ddots &amp; \\\\ \\mathbf 0 &amp; &amp; E[y(k)y^T(k)] \\end{bmatrix}^{-1} \\begin{bmatrix} y(1) \\\\ \\vdots \\\\ y(k) \\\\ \\end{bmatrix} \\\\ &amp;= E[x(y^T(1), ..., y^T(k))] \\begin{bmatrix} E^{-1}[y(1)y^T(1)] &amp;  &amp; \\mathbf 0 \\\\  &amp; \\ddots &amp; \\\\ \\mathbf 0 &amp; &amp; E^{-1}[y(k)y^T(k)] \\end{bmatrix} \\begin{bmatrix} y(1) \\\\ \\vdots \\\\ y(k) \\\\ \\end{bmatrix} \\\\ &amp;= (E[xy^T(1)], ..., E[xy^T(k)]) \\begin{bmatrix} E^{-1}[y(1)y^T(1)] y(1) \\\\ \\vdots \\\\ E^{-1}[y(k)y^T(k)] y(k) \\\\ \\end{bmatrix} \\\\ &amp;= \\sum_{i = 1}^{k} E[xy^T(i)] E^{-1}[y(i)y^T(i)] y(i) \\\\ &amp;= (\\sum_{i = 1}^{k} E[(x - Ex)(y(i) - Ey(i))^T] E^{-1}[(y(i) - Ey(i))(y(i) - Ey(i))^T] (y(i) - Ey(i)) + Ex) \\\\ &amp;= \\sum_{i = 1}^{k} (P_{xy(i)} P^{-1}_{y(i)y(i)} (y(i) - Ey(i)) + Ex) \\\\ &amp;= \\sum_{i = 1}^{k} proj(x | y(i)) \\end{align*} \\] <p>\u5c04\u5f71\u7684\u6027\u8d282:\u7ebf\u6027\u53ef\u52a0\u6027</p> <p>\u8bbe\u968f\u673a\u53d8\u91cf \\(x \\in R^p, z \\in R^l\\) \uff0c\u968f\u673a\u53d8\u91cf \\(Ax + Bz \\in R^n, A \\in R^{n \\times p}, B \\in R^{n \\times q}\\) \uff0c\u968f\u673a\u53d8\u91cf \\(y \\in R^m\\) \uff0c\u5219\u6709</p> \\[ proj(Ax + Bz | y) = A proj(x | y) + B proj(z | y) \\] <p>\u8bc1\u660e\uff08\u4ee4 \\(w = Ax + Bz\\) \uff09</p> \\[ \\begin{align*} &amp;proj(Ax + Bz | y) \\\\ &amp;= E(w) +  P_{wy} P_{yy}^{-1}(y - Ey) \\\\ &amp;= E(Ax + Bz) +  P_{(Ax + Bz)y} P_{yy}^{-1}(y - Ey) \\\\ &amp;= AEx + BEz + (AP_{xy} + B P_{zy}) P_{yy}^{-1} (y - Ey) \\\\ &amp;= AEx + AP_{xy} P_{yy}^{-1} (y - Ey) +  BEz + B P_{zy} P_{yy}^{-1} (y - Ey) \\\\ &amp;= A(Ex + P_{xy} P_{yy}^{-1} (y - Ey)) + B(Ez + P_{zy} P_{yy}^{-1} (y - Ey)) \\\\ &amp;= Aproj(x|y) + Bproj(z|y) \\end{align*} \\] <p>\u5c04\u5f71\u7684\u6027\u8d283\uff1a\u5206\u91cf\u53ef\u62c6\u6027</p> <p>\u8bbe\u968f\u673a\u53d8\u91cf \\(x \\in R^n\\) \uff0c\u968f\u673a\u53d8\u91cf \\(y \\in R^m\\) \uff0c\u8bb0 \\(x\\) \u7684\u5206\u91cf\u5f62\u5f0f\u4e3a</p> \\[ x = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\\\ \\end{bmatrix} \\] <p>\u5219\u6709\u5173\u7cfb</p> \\[ proj(x | y) = \\begin{bmatrix} proj(x_1 | y) \\\\ \\vdots \\\\ proj(x_n | y) \\\\ \\end{bmatrix} \\] <p>\u8bc1\u660e</p> \\[ \\begin{align*} &amp; proj(x | y) \\\\ &amp;= Ex + P_{xy}P_{yy}^{-1}(y - Ey) \\\\ &amp;= \\begin{bmatrix} Ex_1 \\\\ \\vdots \\\\ Ex_n \\\\ \\end{bmatrix} + E\\{ \\begin{bmatrix} x_1 - Ex_1 \\\\ \\vdots \\\\ x_n - Ex_n \\\\ \\end{bmatrix} (y - Ey)^T \\} P_{yy}^{-1}(y - Ey) \\\\ &amp;= \\begin{bmatrix} Ex_1 \\\\ \\vdots \\\\ Ex_n \\\\ \\end{bmatrix} + E \\begin{bmatrix} (x_1 - Ex_1)(y - Ey)^T \\\\ \\vdots \\\\ (x_n - Ex_n)(y - Ey)^T \\\\ \\end{bmatrix}  P_{yy}^{-1}(y - Ey) \\\\ &amp;= \\begin{bmatrix} Ex_1 \\\\ \\vdots \\\\ Ex_n \\\\ \\end{bmatrix} +  \\begin{bmatrix} E[(x_1 - Ex_1)(y - Ey)^T] P_{yy}^{-1}(y - Ey) \\\\ \\vdots \\\\ E[(x_n - Ex_n)(y - Ey)^T] P_{yy}^{-1}(y - Ey) \\\\ \\end{bmatrix}   \\\\ &amp;= \\begin{bmatrix} Ex_1 \\\\ \\vdots \\\\ Ex_n \\\\ \\end{bmatrix} +  \\begin{bmatrix} P_{x_1y} P_{yy}^{-1}(y - Ey) \\\\ \\vdots \\\\ P_{x_ny} P_{yy}^{-1}(y - Ey) \\\\ \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} Ex_1 + P_{x_1y} P_{yy}^{-1}(y - Ey) \\\\ \\vdots \\\\ Ex_n + P_{x_ny} P_{yy}^{-1}(y - Ey) \\\\ \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} proj(x_1|y) \\\\ \\vdots \\\\ proj(x_n|y) \\\\ \\end{bmatrix} \\end{align*} \\] <p>\u8fd9\u4e2a\u6027\u8d28\u8bf4\u660e\u968f\u673a\u53d8\u91cf \\(x\\) \u5728\u7ebf\u6027\u6d41\u884c \\(L(y)\\) \u4e0a\u7684\u5c04\u5f71\u7684\u6bcf\u4e2a\u5206\u91cf\u4e3a \\(x\\) \u7684\u76f8\u5e94\u5206\u91cf\u5728\u7ebf\u6027\u6d41\u884c \\(L(y)\\) \u4e0a\u7684\u5c04\u5f71\u3002\u6362\u8a00\u4e4b\uff0c\u968f\u673a\u53d8\u91cf \\(x\\) \u7684\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1\u7684\u6bcf\u4e2a\u5206\u91cf\u7b49\u4e8e \\(x\\) \u7684\u76f8\u5e94\u7684\u5206\u91cf\u7684\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1\uff0c\u5373\u5168\u5c40\u6700\u4f18\u4f30\u8ba1\u7b49\u4e8e\u5c40\u90e8\u6700\u4f18\u4f30\u8ba1\u3002</p> <p>\u65b0\u606f\u5e8f\u5217\u7684\u5b9a\u4e49</p> <p>\u8bbe \\(y(1),y(2),...,y(k), ... \\in R^m\\) \u662f\u5b58\u5728\u4e8c\u9636\u77e9\u7684\u968f\u673a\u5e8f\u5217\uff0c\u5b83\u7684\u65b0\u606f\u5e8f\u5217\uff08\u65b0\u606f\u8fc7\u7a0b\uff09\u5b9a\u4e49\u4e3a</p> \\[ \\varepsilon(k) = y(k) - proj(y(k) | y(1), ...,y(k-1)), k = 1,2,... \\] <p>\u5e76\u5b9a\u4e49 \\(y(k)\\) \u7684\u4e00\u6b65\u6700\u4f18\u9884\u62a5\u4f30\u503c\u4e3a</p> \\[ \\hat y(k | k - 1) = proj(y(k) | y(1), ...,y(k-1)) \\] <p>\u56e0\u800c\u65b0\u606f\u5e8f\u5217\u53ef\u5b9a\u4e49\u4e3a</p> \\[ \\varepsilon(k) = y(k) - \\hat y(k | k - 1), k=1,2,... \\] <p>\u5176\u4e2d\u89c4\u5b9a \\(\\hat y(1 | 0) = Ey(1)\\) \uff0c\u8fd9\u4fdd\u8bc1 \\(E \\varepsilon(1) = 0\\) .</p> <p>\u65b0\u606f\u7684\u51e0\u4f55\u610f\u4e49\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ef\u770b\u5230 \\(\\varepsilon(k) \\perp L(y(1), ..., y(k - 1))\\) </p> <p></p> <p>\u65b0\u606f\u5e8f\u5217\u7684\u65e0\u504f\u6027\u548c\u4e92\u4e0d\u76f8\u5173</p> <p>\u65b0\u606f\u5e8f\u5217 \\(\\varepsilon(k)\\) \u662f\u96f6\u5747\u503c\u767d\u566a\u58f0\u3002</p> <p>\u8bc1\u660e \u7531\u63a8\u8bba \\(Ex = E \\hat x\\) \u53ef\u77e5\u5c04\u5f71\u662f\u65e0\u504f\u5dee\u7684\uff0c\u6545\u6709</p> \\[ \\begin{align*} E \\varepsilon(k) &amp;= Ey(k) -  E\\hat y(k | k - 1) \\\\ &amp;= Ey(k) - Ey(k) \\\\ &amp;= 0 (k \\ge 1) \\end{align*} \\] <p>\u767d\u566a\u58f0(\u4e24\u4e24\u4e92\u4e0d\u76f8\u5173)\u8bc1\u660e\uff1a</p> <p>\u8bbe \\((i  eq j)\\) \uff0c\u4e0d\u59a8\u8bbe \\(i &gt; j\\) \uff0c\u56e0 \\(\\varepsilon(i) \\perp L(y(1), ..., y(i - 1))\\) \uff0c\u4e14\u6709 \\(L(y(1), ... , y(j)) \\subset L(y(1), ..., y(i-1))\\) \uff0c\u6545\u6709 \\(\\varepsilon(i) \\perp L(y(1), ... , y(j))\\) \u3002</p> <p>\u800c \\(\\varepsilon(j) = y(j) - \\hat y(j | j - 1) \\in L(y(1), ... , y(j))\\) , \u56e0\u800c \\(\\varepsilon(i) \\perp  \\varepsilon(j)\\) , \u5373 \\(E[\\varepsilon(i)\\varepsilon^T(j)] = 0\\) \uff0c\u6545 \\(\\varepsilon(i)\\) \u662f\u767d\u566a\u58f0\uff0c\u8bc1\u6bd5\u3002</p> <p>\u4e0a\u8ff0\u8bc1\u660e\u8868\u660e\u65b0\u606f\u5e8f\u5217\u662f\u6b63\u4ea4\u5e8f\u5217\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u606f\u5e8f\u5217\u5b9e\u73b0\u4e86\u975e\u6b63\u4ea4\u968f\u673a\u5e8f\u5217\u7684\u6b63\u4ea4\u5316\u3002\u7531\u5c04\u5f71\u7684\u6027\u8d281:\u5728\u7ebf\u6027\u7a7a\u95f4\u4e0a\u6295\u5f71\u57fa\u5e95\u7684\u6027\u8d28\u53ef\u77e5\uff0c\u5728\u7531\u65b0\u606f\u5e8f\u5217\u5f20\u6210\u7684\u7ebf\u6027\u6d41\u884c\u4e0a\u7684\u5c04\u5f71\u5c06\u5927\u5927\u7b80\u5316\u5c04\u5f71\u7684\u8ba1\u7b97\u3002</p> <p>\u8fd9\u6837\u95ee\u9898\u5c31\u8f6c\u6362\u4e3a \\(L(\\varepsilon(1), ..., \\varepsilon(k)) = L(y(1), ..., y(k))\\) \u8fd9\u4e2a\u8f6c\u6362\u662f\u5426\u6210\u7acb\uff1f\u5373\u65b0\u606f\u5e8f\u5217 \\(\\varepsilon(k)\\) \u4e0e\u539f\u5e8f\u5217 \\(y(k)\\) \u662f\u5426\u542b\u6709\u76f8\u540c\u7684\u7edf\u8ba1\u4fe1\u606f\uff1f\u4e0b\u9762\u6211\u4eec\u5c06\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898</p> <p>\u65b0\u606f\u5e8f\u5217\u5f20\u6210\u7684\u7a7a\u95f4\u4e0e\u539f\u7ebf\u6027\u7a7a\u95f4\u7684\u7b49\u4ef7\u6027</p> <p>\u65b0\u606f\u5e8f\u5217 \\(\\varepsilon(k) (\u4e0e\u539f\u5e8f\u5217)y(k)\\) \u542b\u6709\u76f8\u540c\u7684\u7edf\u8ba1\u65b0\u606f\uff0c\u5373 \\((y(1), ..., y(k))\\) \u4e0e \\((\\varepsilon(1), ..., \\varepsilon(k))\\) \u5f20\u6210\u76f8\u540c\u7684\u7ebf\u6027\u6d41\u5f62\uff0c\u5373</p> \\[ L(\\varepsilon(1), ... , \\varepsilon(k)) = L(y(1), ..., y(k)), k = 1,2,.. \\] <p>\u8bc1\u660e \u7531\u5c04\u5f71\u516c\u5f0f\u548c\u5b9a\u4e49\uff0c\u6bcf\u4e2a \\(\\varepsilon(k)\\) \u662f \\(y(1),...,y(k)\\) \u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u8fd9\u5f15\u51fa \\(\\varepsilon(k) \\in L(y(1),...,y(k))\\) \uff0c\u4ece\u800c\u6709 \\(L(\\varepsilon(1),...\\varepsilon(k)) \\subset L(y(1), ..., y(k))\\) \u3002</p> <p>\u4e0b\u8bc1 \\(y(k) \\in L(\\varepsilon(1), ..., \\varepsilon(k))\\) .</p> <p>\u4e8b\u5b9e\u4e0a\uff0c\u6211\u4eec\u7531\u65b0\u606f\u5e8f\u5217\u7684\u5b9a\u4e49\u548c\u5f52\u7eb3\u6cd5\u53ef\u77e5</p> \\[ \\begin{align*} &amp; y(1) = \\varepsilon(1) + \\hat y(1 | 0) = \\varepsilon(1) + Ey(1) \\in L(\\varepsilon (1)), \\\\ &amp; y(1) = \\varepsilon(2) + \\hat y(2 | 1) = \\varepsilon(2) + proj(y(2) | y(1)) \\in L(y (1), \\varepsilon (2)) \\subset L(\\varepsilon (1), \\varepsilon (2)), \\\\ &amp;\\vdots \\\\\\ &amp; y(k) = \\varepsilon(k) + proj(y(k) | y(k-1),...,y(1)) \\in L(y (1), y(2), ...,y(k-1), \\varepsilon (k)) \\subset L(\\varepsilon (1), \\varepsilon (2), ... \\varepsilon (k)) \\end{align*} \\] <p>\u8fd9\u5f15\u51fa \\(L(y(1), ..., y(k)) \\subset L(\\varepsilon (1), \\varepsilon (2), ... \\varepsilon (k))\\) \uff0c\u6545\u6709 \\(L(\\varepsilon(1), ... , \\varepsilon(k)) = L(y(1), ..., y(k))\\) \u3002</p> <p>\u63a8\u8bba\uff1a</p> \\[ proj(x|y(1), ..., y(k)) = proj(x|L(y(1),...,y(k))) = proj(x|L(\\varepsilon (1),...,\\varepsilon(k))) = proj(x|\\varepsilon(1), ..., \\varepsilon(k)) \\] <p>\u9012\u63a8\u5c04\u5f71\u516c\u5f0f</p> <p>\u8bbe\u968f\u673a\u53d8\u91cf \\(x \\in R^n\\) \uff0c\u968f\u673a\u5e8f\u5217 \\(y(1), ..., y(k), ... \\in R^m\\) \uff0c\u4e14\u5b83\u4eec\u5b58\u5728\u4e8c\u9636\u70ac\uff0c\u5219\u6709\u9012\u63a8\u5c04\u5f71\u516c\u5f0f</p> \\[ proj(x | y(1), ..., y(k)) = proj(x | y(1), ..., y(k - 1)) + E[x \\varepsilon^T(k)][E(\\varepsilon(k)\\varepsilon^T(k))]^{-1} \\varepsilon(k) \\] <p>\u8bc1\u660e \u5f15\u5165\u5408\u6210\u5411\u91cf</p> \\[ \\varepsilon = \\begin{bmatrix} \\varepsilon_1 \\\\ \\vdots \\\\ \\varepsilon_k \\\\ \\end{bmatrix} \\] <p>\u5e94\u7528\u548c\u5c04\u5f71\u516c\u5f0f\uff0c\u5e76\u6ce8\u610f \\(E\\varepsilon(1) = 0\\) \uff0c\u6709</p> \\[ \\begin{align*} proj(x | y(1),  \\cdots , y(k)) &amp;= proj(x | \\varepsilon(1),  \\cdots , \\varepsilon(k)) \\\\ &amp;= proj(x | \\varepsilon) \\\\ &amp;= Ex + P_{x\\varepsilon} P_{\\varepsilon \\varepsilon}^{-1} \\varepsilon \\\\ &amp;= Ex + E[(x - Ex) \\varepsilon] P_{\\varepsilon \\varepsilon}^{-1} \\varepsilon \\\\ &amp;= Ex + E[x \\varepsilon] P_{\\varepsilon \\varepsilon}^{-1} \\varepsilon -  ExE\\varepsilon P_{\\varepsilon \\varepsilon}^{-1} \\varepsilon \\\\ &amp;= Ex + E[x \\varepsilon] P_{\\varepsilon \\varepsilon}^{-1} \\varepsilon \\\\ &amp;= Ex + E[x[\\varepsilon^T_1,  \\cdots , \\varepsilon^T_k]] E^{-1}( \\begin{bmatrix} \\varepsilon_1 \\\\ \\vdots \\\\ \\varepsilon_k \\\\ \\end{bmatrix} [\\varepsilon^T_1,  \\cdots , \\varepsilon^T_k] ) \\begin{bmatrix} \\varepsilon_1 \\\\ \\vdots \\\\ \\varepsilon_k \\\\ \\end{bmatrix} \\\\ &amp;= Ex + E([x\\varepsilon^T_1,  \\cdots , x\\varepsilon^T_k]) \\begin{bmatrix} E^{-1}[\\varepsilon_1 \\varepsilon_1^T] &amp;  &amp; \\mathbf 0 \\\\  &amp; \\ddots &amp; \\\\ \\mathbf 0 &amp; &amp; E^{-1}[\\varepsilon_k \\varepsilon_k^T] \\end{bmatrix} \\begin{bmatrix} \\varepsilon_1 \\\\ \\vdots \\\\ \\varepsilon_k \\\\ \\end{bmatrix} \\\\ &amp;= Ex + E([x\\varepsilon^T_1,  \\cdots , x\\varepsilon^T_k]) \\begin{bmatrix} E^{-1}[\\varepsilon_1 \\varepsilon_1^T] \\varepsilon_1 \\\\ \\vdots \\\\ E^{-1}[\\varepsilon_k \\varepsilon_k^T] \\varepsilon_k \\\\ \\end{bmatrix} \\\\ &amp;= Ex + \\sum_{i = 1}^{k} E[x \\varepsilon_i^T] E^{-1}[\\varepsilon_i \\varepsilon_i^T] \\varepsilon_i \\\\ &amp;= Ex + \\sum_{i = 1}^{k-1} E(x \\varepsilon_i^T) E^{-1}[\\varepsilon_i \\varepsilon_i^T] \\varepsilon_i + E[x \\varepsilon_k^T] E^{-1}[\\varepsilon_k \\varepsilon_k^T] \\varepsilon_k \\\\ &amp;= proj(x | \\varepsilon_1, \\varepsilon_2,  \\cdots , \\varepsilon_{k-1}) + E[x \\varepsilon_k^T] E^{-1}[\\varepsilon_k \\varepsilon_k^T] \\varepsilon_k \\\\ &amp;= proj(x | y(1), \\cdots , y(k-1)) + E[x \\varepsilon_k^T] E^{-1}[\\varepsilon_k \\varepsilon_k^T] \\varepsilon_k  \\end{align*} \\] <p>\u9012\u63a8\u5c04\u5f71\u516c\u5f0f\u5373\u63a8\u5bfc\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u51fa\u53d1\u70b9\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#23","title":"2.3 \u524d\u7f6e\u77e5\u8bc6\u56de\u987e","text":"<p>\u4e3a\u4e86\u63cf\u8ff0\u7cfb\u7edf\u7279\u6027\uff0c\u8fd9\u91cc\u7ed9\u51fa\u7cfb\u7edf\u7684\u72b6\u6001\u65b9\u7a0b\u548c\u6d4b\u91cf\u65b9\u7a0b</p> \\[ \\begin{align*} &amp;x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k-1} \\\\ &amp;z_k = H_k x_k + v_k \\end{align*} \\] <p>\u5176\u4e2d\uff0c \\(A_{k-1}\\) \u4e3a\u72b6\u6001(\u8f6c\u79fb)\u77e9\u9635\uff08Transition Matrix\uff09\uff0c \\(x_{k-1}\\) \u8bb0\u4e3a \\(k-1\\) \u65f6\u523b\u7684\u72b6\u6001\u5411\u91cf\u3002</p> <p>\\(u_{k-1}\\) \u4e3a \\(k-1\\) \u65f6\u523b\u8f93\u5165\uff0c \\(B_{k-1}\\) \u79f0\u4e3a\u63a7\u5236\u77e9\u9635\uff08Control Matrix\uff09\uff0c\u53cd\u6620\u4e86\u7cfb\u7edf\u8f93\u5165\u5230\u7cfb\u7edf\u72b6\u6001\u7684\u6620\u5c04\u5173\u7cfb\u3002</p> <p>\\(w_{k-1}\\) \u662f\u8fc7\u7a0b\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u77e9\u9635\u4e3a \\(Q_{k-1}\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\\(H_k\\) \u4e3a\u6d4b\u91cf\u77e9\u9635\uff08Measurement Matrix\uff09\uff0c\u63cf\u8ff0\u4e86\u4ece\u7cfb\u7edf\u72b6\u6001\u5230\u6d4b\u91cf\u503c\u7684\u8f6c\u6362\u5173\u7cfb\uff08\u4e3e\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u5173\u7cfb\uff0c\u7cfb\u7edf\u72b6\u6001\u662f\u7269\u4f53\u7684\u76f4\u7ebf\u8ddd\u79bb\uff0c\u6d4b\u91cf\u503c\u662f\u4f7f\u7528\u6fc0\u5149\u7b14\u6d4b\u51fa\u6765\u7684\u5149\u4ece\u539f\u70b9\u5230\u7269\u4f53\u7684\u65f6\u95f4\uff0c\u90a3\u4e48 \\(H_k\\) \u5c31\u662f\u5149\u901f\u7684\u5012\u6570\uff09</p> <p>\\(v_k\\) \u662f\u6d4b\u91cf\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u4e3a \\(R_k\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\u6211\u4eec\u8fd8\u9700\u8981\u5f15\u51fa\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b\u548c\u6d4b\u91cf\u4f30\u8ba1\u65b9\u7a0b\u7684\u6982\u5ff5</p> <p>\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b\u662f\u53d6\u5f97\u662f\u6bcf\u4e00\u9879\u7684\u6982\u7387\u6700\u5927\u503c\u5904\u5bf9\u5e94\u7684\u81ea\u53d8\u91cf\u7684\u503c\uff0c\u566a\u58f0 \\(w_{k-1}\\) \u662f\u5747\u503c\u4e3a0\u7684\u9ad8\u65af\u566a\u58f0\uff0c\u56e0\u6b64\u6700\u5927\u6982\u7387\u5bf9\u5e94\u7684\u503c\u4e3a0\u3002</p> \\[ \\begin{align*} &amp;\\hat x^-_k = A_{k - 1}\\hat x^{+}_{k - 1} + B_{k-1}u_{k-1} + 0\\\\ \\end{align*} \\] <p>\u5bf9\u7cfb\u7edf\u72b6\u6001\u5411\u91cf\u4e0a\u9762\u52a0\u4e0a\u4e00\u4e2a\u5e3d\u5b50\u7b26\u53f7\u8868\u793a\u8fd9\u662f\u4e00\u4e2a\u4f30\u8ba1\u91cf\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u5b9e\u9645\u8f93\u51fa\u7684\u91cf\u3002</p> <p>\\(\\hat x^{+}_{k - 1}\\) \u8868\u793a \\(k-1\\) \u65f6\u523b\u65f6\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u540e\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u540e\u9a8c\u4f30\u8ba1\u3002</p> <p>\\(\\hat x^-_k\\) \u8868\u793a\u5f53\u524d\u6839\u636e\u7cfb\u7edf\u72b6\u6001\u65b9\u7a0b\u8ba1\u7b97\u9884\u6d4b\u5f97\u5230\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u5148\u9a8c\u4f30\u8ba1\u3002</p> <p>\u6d4b\u91cf\u4f30\u8ba1\u65b9\u7a0b\u540c\u6837\u5ffd\u7565\u566a\u58f0\u9879\uff0c\u53d8\u6210\u5bf9\u6b64\u65f6\u6d4b\u91cf\u91cf\u7684\u4f30\u8ba1</p> \\[ \\hat z_k = H_k \\hat x^-_k \\] <p>\u7531\u4e8e\u6211\u4eec\u4e0d\u5bf9 \\(z_k\\) \u505a\u6700\u4f18\u4f30\u8ba1\uff0c\u6240\u4ee5\u4e0d\u8d4b\u4e88\u5176\u53f3\u4e0a\u89d2\u7684\u52a0\u51cf\u4e0a\u4e0b\u6807\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#_4","title":"\u4e09\u3001\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u6cd5","text":"<p>\u5148\u9a8c\u77e5\u8bc6\uff1a</p> <p>\u591a\u7ef4\u6b63\u6001\u5206\u5e03\u6ee1\u8db3\u4e24\u4e2a\u89c4\u5f8b\uff1a</p> <ol> <li>\u6b63\u6001\u5206\u5e03\u52a0\u51cf\u4e00\u4e2a\u56fa\u5b9a\u5e38\u6570\u5411\u91cf\uff0c\u7136\u540e\u5728\u4e58\u4ee5\u4e00\u4e2a\u56fa\u5b9a\u5e38\u6570\u975e\u96f6\u77e9\u9635\uff0c\u5176\u5206\u5e03\u8fd8\u662f\u6b63\u6001\u5206\u5e03\u3002\u4e14\u6ee1\u8db3</li> </ol> \\[ \\begin{align*} &amp;X \\sim N(\\mu, \\Sigma) \\\\ &amp;AX+b \\sim N(b+u, A\\Sigma A^{T}) \\end{align*} \\] <ol> <li>\u4e24\u4e2a\u72ec\u7acb\u7684\u6b63\u592a\u5206\u5e03\u76f8\u52a0\u540e\u8fd8\u662f\u6b63\u6001\u5206\u5e03</li> </ol> \\[ \\begin{align*} &amp;X \\sim N(\\mu_1, \\Sigma_1) \\\\ &amp;Y \\sim N(\\mu_2, \\Sigma_2) \\\\ &amp;X \\pm Y \\sim N(\\mu_1 \\pm \\mu_2, \\Sigma_1 + \\Sigma_2) \\end{align*} \\] <p>\u5047\u8bbe\u968f\u673a\u53d8\u91cfX\u6709D\u7ef4\uff0c\u5219 \\(X \\sim N(\\mu, \\Sigma)\\) \u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u4e3a</p> \\[ f_{X}(x) = \\frac{1}{(2 \\pi)^{D/2} \\det^{1/2}(\\Sigma)} \\exp\\left ({-\\frac{1}{2}}(x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right) \\] <p>\u5728\u5df2\u77e5\u968f\u673a\u53d8\u91cfX\u7684\u4e24\u79cd\u53ef\u80fd\u5206\u5e03\u540e\uff0c\u6211\u4eec\u5982\u4f55\u7ed9\u51faX\u7684\u6700\u53ef\u80fd\u53d6\u503c\uff08\u6700\u4f18\u4f30\u8ba1\uff09\u5462\uff1f</p> <p>\u5982\u679c\u91c7\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\uff0c\u53ea\u9700\u8981\u5199\u51fa\u4f3c\u7136\u51fd\u6570\uff0c\u7136\u540e\u6c42\u51fa\u4f7f\u5f97\u4f3c\u7136\u51fd\u6570\u6700\u5927\u7684X\u5373\u53ef\u3002</p> <p>\u5728\u4e24\u79cd\u5206\u5e03\u72ec\u7acb\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5c06\u4f3c\u7136\u51fd\u6570\u5b9a\u4e49\u4e3a\u4e24\u79cd\u5206\u5e03\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u76f8\u4e58\u3002</p> <p>\u8fd9\u91cc\u6211\u4eec\u8bd5\u7740\u6c42\u51fa\u72b6\u6001\u503c\u5148\u9a8c\u4f30\u8ba1\u7684\u5206\u5e03\u548c\u72b6\u6001\u503c\u6d4b\u91cf\u503c\u7684\u5206\u5e03\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u4e0d\u80fd\u5ffd\u7565\u566a\u58f0\u7684\u5b58\u5728\uff0c\u56e0\u4e3a\u6211\u4eec\u6c42\u5f97\u662f\u4e00\u4e2a\u5206\u5e03\uff0c\u800c\u4e0d\u662f\u5177\u4f53\u7684\u4f30\u8ba1\u503c\u3002</p> \\[ \\begin{align*} &amp;x^{prior}_k = A_{k - 1} \\hat x^+_{k - 1} + B_{k-1}u_{k-1} + w_{k-1} = \\hat x^-_k + w_{k-1} \\\\ &amp;x^{measure}_{k} = H_k^{-1}(z_k - v_k)  = H_k^{-1}z_k - H_k^{-1}v_k \\end{align*} \\] <p>\u5176\u4e2d \\(\\hat x^{+}_{k - 1}\\) \u8868\u793a \\(k-1\\) \u65f6\u523b\u65f6\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u540e\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u540e\u9a8c\u4f30\u8ba1\u503c\u3002</p> <p>\\(\\hat x^-_k\\) \u8868\u793a\u5f53\u524d\u6839\u636e\u7cfb\u7edf\u72b6\u6001\u65b9\u7a0b\u8ba1\u7b97\u9884\u6d4b\u5f97\u5230\u7684\u72b6\u6001\u5411\u91cf\uff0c\u4e5f\u79f0\u4e3a\u72b6\u6001\u5411\u91cf\u7684\u5148\u9a8c\u4f30\u8ba1\u503c\u3002</p> <p>\\(x_{measure}\\) \u662f\u6839\u636e\u6d4b\u91cf\u503c\u53cd\u63a8\u7684\u72b6\u6001\u5411\u91cf\u7684\u503c</p> <p>\u6839\u636e</p> \\[ x^{measure}_{k} = H_k^{-1}(z_k - v_k)  = H_k^{-1}z_k - H_k^{-1}v_k \\] <p>\\(H_k^{-1}z_k\\) \u662f\u4e00\u4e2a\u5e38\u6570\u5411\u91cf\uff0c\u53ef\u4ee5\u770b\u51fa \\(x^{measure}_{k} \\sim N(H_k^{-1}z_k, H_k^{-1}R_k{H_k^{-1}}^T)\\) </p> <p>\u6211\u4eec\u5047\u8bbe\u521d\u59cb\u72b6\u6001 \\(x_0^-\\) \u670d\u4eceN( \\(\\hat x_0^-, \\Theta_0^-\\) )\uff0c \\(x_{-1}^+\\) \u670d\u4eceN \\((\\hat x_{-1}^+, D_0^+)\\) \u5206\u5e03\uff0c\u6839\u636e</p> \\[ x^{prior}_k = A_{k - 1} \\hat x^+_{k - 1} + B_{k-1}u_{k-1} + w_{k-1} = \\hat x^-_k + w_{k-1} \\] <p>\u6709\u5982\u4e0b\u4f20\u9012\u6027</p> \\[ \\begin{align*} &amp;x^{prior}_0 = A_{-1} \\hat x^+_{-1} + B_{-1}u_{-1} + w_{-1} = \\hat x^-_0 + w_{-1} \\sim N(\\hat x_0^-, D_0^-), D_0^- = \\Theta_0^- + Q_{-1} =  A_{-1} D_0^+ A_{-1}^T + Q_{-1}\\\\ &amp;\\hat x^+_0 = \\hat x^-_{0} + G_0(x^{measure}_0 - \\hat x^-_{0}) \\text{\u4f5c\u4e3a\u4e24\u4e2a\u72ec\u7acb\u6b63\u592a\u5206\u5e03\u76f8\u52a0\u7684\u7ed3\u679c\uff0c\u4f9d\u7136\u662f\u4e00\u4e2a\u6b63\u6001\u5206\u5e03\uff0c\u5047\u8bbe\u5176\u65b9\u5dee\u4e3a}P_1^+ \\\\ &amp;x^{prior}_1 = A_{0} \\hat  x^+_{0} + B_{0}u_{0} + w_{0} = \\hat x^-_1 + w_{0} \\sim N(\\hat x_1^-, D_1^-), D_1^- =  A_{0} D_1^+ A_{0}^T + Q_{0} \\\\ &amp;x^{prior}_2 = \\hat x^-_2 + w_{1} \\sim N(\\hat x_2^-, D_2^-), D_2^- =  A_{1} D_2^+ A_{1}^T + Q_{1} \\\\ &amp; ......  \\end{align*} \\] <p>\u4ece\u4e0a\u9762\u516c\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 \\(x^{prior}_k\\) \u7684\u5206\u5e03</p> \\[ x^{prior}_k = A_{k - 1} \\hat x^+_{k - 1} + B_{k-1}u_{k-1} + w_{k-1} = \\hat x^-_k + w_{k-1} \\sim N(\\hat x_k^-, D_k^-) \\] <p>\u4ece\u4e0a\u9762\u516c\u5f0f\u4e5f\u53ef\u4ee5\u770b\u51fa\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5148\u9a8c\u72b6\u6001\u65b9\u5dee\u66f4\u65b0\u65b9\u7a0b\uff1a</p> \\[ D_k^- = A_{k - 1}D_{k-1}^{+}A_{k - 1}^T + Q_{k-1} \\] <p>\u5728\u4e0a\u4e00\u7bc7\u6587\u7ae0\u6211\u4eec\u5728\u63a8\u5bfc\u5361\u5c14\u66fc\u6ee4\u6ce2\u5728\u521d\u59cb\u6761\u4ef6\u6ee1\u8db3\u4e00\u5b9a\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u5177\u5907\u65e0\u504f\u4f20\u9012\u6027\u3002</p> <p>\u5728\u63a8\u5bfc\u8fc7\u7a0b\u4e2d\uff0c\u5728\u65e0\u504f\u6027\u6ee1\u8db3\u6761\u4ef6\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230  \\(E(x_k - \\hat x^-_{k}) = 0\\) ,\u5219</p> \\[ \\begin{align*} P_k^- = E(| \\hat x^-_k - x_k |^2) &amp;= E(| \\hat x^-_k - x_k |^2) + E^2(x_k - \\hat x^-_{k}) \\\\ &amp;= D(x^-_k - x_k) (x_k\u53ef\u4ee5\u770b\u505a\u4e00\u4e2a\u5e38\u91cf) \\\\ &amp;= D(x^-_k) = D_k^- \\end{align*} \\] <p>\u540c\u7406\u6211\u4eec\u4e5f\u53ef\u4ee5\u63a8\u5bfc\u5f97\u5230 \\(P_k^+ = D_k^+\\) \u3002</p> <p>\u4ece\u800c\u6211\u4eec\u5148\u7ed9\u51fa\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e2d\u5148\u9a8c\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u66f4\u65b0\u516c\u5f0f</p> \\[ P_k^- = A_{k - 1}P_{k-1}^{+}A_{k - 1}^T + Q_{k-1} \\] <p>\u81ea\u6b64\uff0c\u6211\u4eec\u62e5\u6709\u5bf9\u72b6\u6001\u7684\u4e24\u4e2a\u4f30\u8ba1 \\(x^{prior}_k\\) \u3001 \\(x^{measure}_{k}\\) \uff0c\u4e0b\u9762\u7684\u95ee\u9898\u5c31\u53ef\u4ee5\u8f6c\u6362\u4e3a\u5982\u4f55\u5bf9\u8fd9\u4e24\u4e2a\u5206\u5e03\u8fdb\u884c\u878d\u5408\uff1f</p> <p>\u5982\u679c\u662f\u5355\u4e2a\u5206\u5e03\uff0c\u6211\u4eec\u76f4\u63a5\u4ee4\u4f30\u8ba1\u503c  \\(\\hat x = E(X)\\)</p> <p>\u6309\u7167\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6211\u4eec\u9996\u5148\u5b9a\u4e49\u4f3c\u7136\u51fd\u6570\u4e3a</p> \\[ L(x) = f_{prior}(x) \\cdot f_{measure}(x) \\] <p>\u7136\u540e\u53d6\u5bf9\u6570</p> \\[ \\log L(x) = \\log f_{prior}(x) + \\log f_{measure}(x) \\] <p>\u76ee\u6807\u51fd\u6570\u4e3a</p> \\[ maximize\\ L(x) = maximize\\ \\log L(x) \\] \\[ \\begin{align*} \\log L(x) &amp;=  \\log f_{prior}(x) + \\log f_{measure}(x) \\\\           &amp;=    \\log \\frac{1}{(2 \\pi)^{D/2} \\det^{1/2}(D_{prior})} \\exp\\left ({-\\frac{1}{2}}(x - \\mu_{prior})^T D_{prior}^{-1} (x - \\mu_{prior}) \\right) \\\\ &amp;+ \\log \\frac{1}{(2 \\pi)^{D/2} \\det^{1/2}(D_{prior})} \\exp\\left ({-\\frac{1}{2}}(x - \\mu_{measure})^T D_{measure}^{-1} (x - \\mu_{measure}) \\right) \\\\           &amp;= {-\\frac{1}{2}}(x - \\mu_{prior})^T D_{prior}^{-1} (x - \\mu_{prior}) + {-\\frac{1}{2}}(x - \\mu_{measure})^T D_{measure}^{-1} (x - \\mu_{measure}) + C  \\end{align*} \\] <p>\u4ee4\u4e0a\u8ff0\u516c\u5f0f\u6700\u5927\uff0c\u5bf9\u9f50\u6c42\u5bfc</p> \\[ \\begin{align*} \\frac{\\partial \\log L(x)}{x} &amp;= {-\\frac{1}{2}} 2 (x - \\mu_{prior})^T D_{prior}^{-1} {-\\frac{1}{2}} 2 (x - \\mu_{measure})^T D_{measure}^{-1} \\\\ &amp;= (\\mu_{prior} - x)^T D_{prior}^{-1} + (\\mu_{measure} - x)^T D_{measure}^{-1} \\\\ &amp;= \\mu_{prior}^TD_{prior}^{-1} + \\mu_{measure}^TD_{measure}^{-1} - x^T(D_{prior}^{-1} + D_{measure}^{-1}) \\end{align*} \\] <p>\u4ee4\u4e0a\u5f0f\u7b49\u4e8e0\u6c42\u5f97</p> \\[ \\begin{align*} &amp;x^T = (\\mu_{prior}^TD_{prior}^{-1} + \\mu_{measure}^TD_{measure}^{-1})(D_{prior}^{-1} + D_{measure}^{-1})^{-1} \\\\ &amp;x = ((\\mu_{prior}^TD_{prior}^{-1} + \\mu_{measure}^TD_{measure}^{-1})(D_{prior}^{-1} + D_{measure}^{-1})^{-1})^T \\\\ &amp;x = tranpose ((D_{prior}^{-1} + D_{measure}^{-1})^{-1}) ({D_{prior}^{-1}}^T\\mu_{prior} + {D_{measure}^{-1}}^T \\mu_{measure}) \\\\ \\end{align*} \\] <p>\u6839\u636e\u534f\u65b9\u5dee\u77e9\u9635\u7684\u5bf9\u79f0\u6027</p> \\[ \\begin{align*} x &amp;= (D_{prior}^{-1} + D_{measure}^{-1})^{-1} ( D_{prior}^{-1} \\mu_{prior} +  D_{measure}^{-1}  \\mu_{measure}) \\\\ &amp;= D_{prior} (D_{prior} + D_{measure})^{-1} D_{measure} ({D_{prior}^{-1}} \\mu_{prior} + {D_{measure}^{-1}}  \\mu_{measure}) \\\\ &amp;= D_{measure} (D_{prior} + D_{measure})^{-1} D_{prior} ({D_{prior}^{-1}} \\mu_{prior} + {D_{measure}^{-1}}  \\mu_{measure}) \\\\ &amp;= D_{measure} (D_{prior} + D_{measure})^{-1}(\\mu_{prior} + D_{prior}{D_{measure}^{-1}}  \\mu_{measure}) \\\\ &amp;= D_{measure} (D_{prior} + D_{measure})^{-1} (( (D_{prior} + D_{measure}) D_{measure}^{-1})\\mu_{prior} \\\\ &amp;+ (E- (D_{prior} + D_{measure}) D_{measure}^{-1})\\mu_{prior}+ D_{prior}{D_{measure}^{-1}}  \\mu_{measure}) \\\\ &amp;= D_{measure} (D_{prior} + D_{measure})^{-1} ( (D_{prior} + D_{measure}) D_{measure}^{-1}\\mu_{prior} \\\\ &amp; + D_{prior}{D_{measure}^{-1}}^T (\\mu_{measure} - \\mu_{prior})) \\\\ &amp;= \\mu_{prior} + D_{measure} (D_{prior} + D_{measure})^{-1}D_{prior}{D_{measure}^{-1}}  (\\mu_{measure} - \\mu_{prior}) \\\\ &amp;= \\mu_{prior} + (D_{prior}^{-1} + D_{measure}^{-1})^{-1}{D_{measure}^{-1}}  (\\mu_{measure} - \\mu_{prior}) \\\\ &amp;= \\mu_{prior} + (D_{measure} D_{prior}^{-1} + E)^{-1}  (\\mu_{measure} - \\mu_{prior}) \\\\ &amp;= \\mu_{prior} + (D_{measure} D_{prior}^{-1} + D_{prior} D_{prior}^{-1})^{-1}  (\\mu_{measure} - \\mu_{prior}) \\\\ &amp;= \\mu_{prior} + D_{prior} (D_{measure} + D_{prior})^{-1}  (\\mu_{measure} - \\mu_{prior}) \\\\ \\end{align*} \\] <p>\u8fd9\u91cc\u9700\u8981\u7528\u5230\u4e00\u4e2a\u7b80\u5355\u7684\u6c42\u9006\u516c\u5f0f</p> \\[ (A+B)^{-1} = B^{-1}(B^{-1} + A^{-1}) A^{-1} \\] <p>\u6839\u636e</p> \\[ D_{measure} = H_k^{-1}R_k{H_k^{-1}}^T \\\\ D_{prior} = P_{k}^- \\] <p>\u5219\u6839\u636e\u4e0a\u7bc7\u6587\u7ae0\u4e2d\u7684\u5f62\u5f0f\uff0c\u5bf9\u6bd4\u53ef\u4ee5\u6c42\u5f97</p> \\[ \\begin{align*} G_k &amp;= D_{prior} (D_{measure} + D_{prior})^{-1} \\\\ &amp;= P_{k}^-(H_k^{-1}R_k{H_k^{-1}}^T + P_{k}^-)^{-1} \\\\ &amp;= P_{k}^-((H_k^{-1}H_k)(H_k^{-1}R_k{H_k^{-1}}^T + P_{k}^-)(H_k^{T}{H_k^{T}}^{-1}))^{-1} \\\\ &amp;= P_{k}^-((H_k^{-1})(R_k + H_kP_{k}^-H_k^{T})({H_k^{T}}^{-1}))^{-1} \\\\ &amp;= P_{k}^-{H_k^{T}}(R_k + H_kP_{k}^-H_k^{T})^{-1}H_k \\\\ \\end{align*} \\] \\[ K_k = G_kH_k^{-1} = P_{k}^-{H_k^{T}}(R_k + H_kP_{k}^-H_k^{T})^{-1} \\] <p>\u81f3\u6b64\uff0c\u6211\u4eec\u91c7\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u6cd5\u6c42\u5f97\u5361\u5c14\u66fc\u589e\u76ca\u7684\u8fc7\u7a0b\u63a8\u5bfc\u5b8c\u6bd5\uff0c\u5269\u4f59\u53c2\u6570\u8bc1\u660e\u548c\u4e0a\u7bc7\u6587\u7ae0\u76f8\u540c\u8fd9\u91cc\u4e0d\u518d\u8d58\u8ff0\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#_5","title":"\u56db\u3001\u6b63\u4ea4\u6295\u5f71\u5b9a\u7406\u8bc1\u660e\u6cd5\uff08\u539f\u7248\u8bc1\u660e\u65b9\u6cd5\uff09","text":"<p>\u4e3a\u4e86\u9632\u6b62\u8bfb\u8005\u9057\u5fd8\uff0c\u8fd9\u91cc\u518d\u7ed9\u51fa\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u8868\u8fbe\u5f0f</p> \\[ \\begin{align*} &amp;x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k - 1} \\\\ &amp;z_k = H_k x_k + v_k \\end{align*} \\] <p>\u5176\u4e2d\uff0c \\(A_{k-1} \\in R^{n \\times n}\\) \u4e3a\u72b6\u6001(\u8f6c\u79fb)\u77e9\u9635\uff08Transition Matrix\uff09\uff0c \\(x_{k-1}\\) \u8bb0\u4e3a \\(k-1\\) \u65f6\u523b\u7684\u72b6\u6001\u5411\u91cf\u3002 \\(x_{k-1} \\in R^n\\) </p> <p>\\(u_{k-1} \\in R^n\\) \u4e3a \\(k-1\\) \u65f6\u523b\u8f93\u5165\uff0c \\(B_{k-1} \\in R^{n \\times l}\\) \u79f0\u4e3a\u63a7\u5236\u77e9\u9635\uff08Control Matrix\uff09\uff0c\u53cd\u6620\u4e86\u7cfb\u7edf\u8f93\u5165\u5230\u7cfb\u7edf\u72b6\u6001\u7684\u6620\u5c04\u5173\u7cfb\u3002</p> <p>\\(w_{k-1} \\in R^n\\) \u662f\u8fc7\u7a0b\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u77e9\u9635\u4e3a \\(Q_{k-1} \\in R^{n \\times n}\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\\(H_k \\in R^{m \\times n}\\) \u4e3a\u6d4b\u91cf\u77e9\u9635\uff08Measurement Matrix\uff09\uff0c\u63cf\u8ff0\u4e86\u4ece\u7cfb\u7edf\u72b6\u6001\u5230\u6d4b\u91cf\u503c\u7684\u8f6c\u6362\u5173\u7cfb\uff08\u4e3e\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u5173\u7cfb\uff0c\u7cfb\u7edf\u72b6\u6001\u662f\u7269\u4f53\u7684\u76f4\u7ebf\u8ddd\u79bb\uff0c\u6d4b\u91cf\u503c\u662f\u4f7f\u7528\u6fc0\u5149\u7b14\u6d4b\u51fa\u6765\u7684\u5149\u4ece\u539f\u70b9\u5230\u7269\u4f53\u7684\u65f6\u95f4\uff0c\u90a3\u4e48 \\(H_k\\) \u5c31\u662f\u5149\u901f\u7684\u5012\u6570\uff09</p> <p>\\(v_k \\in R^{m}\\) \u662f\u6d4b\u91cf\u566a\u58f0\uff0c\u6211\u4eec\u5047\u5b9a\u5176\u7b26\u5408\u5747\u503c\u4e3a0\uff0c\u534f\u65b9\u5dee\u4e3a \\(R_k \\in R^{m \\times m}\\) \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\u5047\u8bbe1 \\(w_k\\) \u548c \\(v_k\\) \u662f\u96f6\u5747\u503c\u3001\u534f\u65b9\u5dee\u77e9\u9635\u5206\u522b\u4e3a \\(Q_k\\) \uff0c \\(R_k\\) \u7684\u4e0d\u76f8\u5173\u767d\u566a\u58f0 $$ Ew_k = 0, Ev_k = 0 \\ E[w_i w^T_j] = 0(i  e j), E[v_i v^T_j] = 0 (i  e j) \\ E[w_i v_j^T] = 0, \\forall i,j $$</p> <p>\u5047\u8bbe2 \u521d\u59cb\u72b6\u6001\u503c \\(x_0\\) \u3001\u566a\u58f0\u9879 \\(w_k\\) \u3001 \\(v_k\\) \u548c\u7cfb\u7edf\u8f93\u5165 \\(u_{k}\\) \u4e92\u4e0d\u76f8\u5173</p> \\[ Ex_0 = \\mu_0, E[(x_0 - \\mu_0) (x_0 - \\mu_0)^T] = P_0 \\\\ u_0 = 0 \\] <p>\u5047\u8bbe3 \u6bcf\u4e00\u4e2a\u65f6\u523b\u7684\u7cfb\u7edf\u8f93\u5165 \\(u_{k}\\) \u4e92\u4e0d\u76f8\u5173\uff0c\u4e14\u6709 \\(Eu_k = u_k\\) </p> <p>Kalman\u6ee4\u6ce2\u95ee\u9898\u662f\uff1a\u57fa\u4e8e\u89c2\u6d4b \\(z_1, ...., z_k\\) \uff0c\u6c42\u72b6\u6001 \\(x_j\\) \u7684\u7ebf\u6027\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1 \\(\\hat x(j | k)\\) \uff0c\u5b83\u7684\u6781\u5c0f\u5316\u6027\u80fd\u6307\u6807\u4e3a</p> \\[ J = E[(x_j - \\hat x(j|k))^T (x_j - \\hat x(j|k))] \\] <ul> <li>\u5f53 \\(j = k\\) \u662f\uff0c \\(\\hat x(j | k)\\) \u79f0\u4e3a\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668</li> <li>\u5f53 \\(j &gt; k\\) \u662f\uff0c \\(\\hat x(j | k)\\) \u79f0\u4e3a\u5361\u5c14\u66fc\u9884\u62a5\u5668</li> <li>\u5f53 \\(j &lt; k\\) \u662f\uff0c \\(\\hat x(j | k)\\) \u79f0\u4e3a\u5361\u5c14\u66fc\u5e73\u6ed1\u5668</li> </ul> <p>\u4e0b\u9762\u8ba8\u8bbaj = k\u65f6</p> <p>\u5728\u6027\u80fd\u6307\u6807 \\(J\\) \u7684\u6761\u4ef6\u4e0b\uff0c\u95ee\u9898\u5f52\u7ed3\u4e3a\u6c42\u5c04\u5f71</p> \\[ \\hat x(j|k) = proj(x_j|z_1, ..., z_k) \\] <p>\u75312.2\u7ae0\u8282\u9012\u63a8\u5c04\u5f71\u516c\u5f0f\u6709\u9012\u63a8\u5173\u7cfb</p> \\[ \\hat x(k| k) = \\hat x(k | k - 1) + K_{k} \\varepsilon_{k} \\\\ K_{k} = E[x_{k} \\varepsilon_{k}^T] E^{-1}[\\varepsilon_{k} \\varepsilon_{k}^T] \\] <p>\u79f0 \\(K_{k}\\) \u4e3a \\(k\\) \u65f6\u523b\u5361\u5c14\u66fc\u589e\u76ca\uff0c\u5bf9 \\(x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k-1}\\) \u4e24\u8fb9\u9879\u53d6\u6295\u5f71\u6709</p> \\[ \\hat x(k| k - 1) = A_{k-1} \\hat x(k - 1| k - 1) + B_{k-1}proj(u_{k-1}| z_1, \\cdots, z_{k-1}) + proj(w_{k-1}| z_1, \\cdots, z_{k-1}) \\] <p>\u7531 \\(x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k}\\) \u8fed\u4ee3\u6709</p> \\[ x_k \\in L(w_{k - 1}, \\cdots , w_0, x_0, u_{k-1}, \\cdots, u_0) \\] <p>\u5e94\u7528 \\(z_k = H_k x_k + v_k\\) \u6709</p> \\[ z_{k-1} \\in L(v_{k-1}, w_{k - 2}, \\cdots , w_0, x_0, u_{k-2}, \\cdots, u_0) \\] <p>\u8fd9\u5f15\u51fa</p> \\[ L(z_1, \\cdots, z_{k - 1}) \\subset L(v_{k-1}, \\cdots, v_1, w_{k - 2}, \\cdots , w_0, u_{k-2}, \\cdots, u_0,  x_0) \\] <p>\u7531\u6b64\u5f0f\u548c\u5047\u8bbe1\u3001\u5047\u8bbe2\u6709</p> \\[ w_{k - 1} \\perp L(z_1, \\cdots, z_{k-1}) \\\\ u_{k - 1} \\perp L(z_1, \\cdots, z_{k-1}) \\] <p>\u5e94\u7528\u5c04\u5f71\u516c\u5f0f\u548c \\(Ew_{k - 1} = 0\\) \u53ef\u5f97</p> \\[ proj(w_{k-1}| z_1, \\cdots, z_{k-1}) = 0 \\] \\[ proj(u_{k-1}| z_1, \\cdots, z_{k-1}) = Eu_{k - 1} = u_{k-1} \\] <p>\u4e8e\u662f</p> \\[ \\hat x(k| k - 1) = A_{k-1} \\hat x(k - 1| k - 1) + B_{k-1}proj(u_{k-1}| z_1, \\cdots, z_{k-1}) + proj(w_{k-1}| z_1, \\cdots, z_{k-1}) \\] <p>\u53ef\u4ee5\u5316\u7b80\u4e3a</p> \\[ \\hat x(k| k - 1) = A_{k-1} \\hat x(k - 1| k - 1) + B_{k-1} u_{k-1} \\] <p>\u5bf9 \\(z_k = H_k x_k + v_k\\) \u4e24\u8fb9\u53d6\u6295\u5f71\u5f97</p> \\[ \\hat z(k|k - 1) = H_k \\hat x(k|k-1) + proj(v_k | z_1, \\cdots, z_{k-1}) \\] <p>\u7531\u5047\u8bbe1\u3001\u5047\u8bbe2\u548c \\(L(z_1, \\cdots, z_{k - 1}) \\subset L(v_{k-1}, \\cdots, v_1, w_{k - 2}, \\cdots , w_0, u_{k-2}, \\cdots, u_0,  x_0)\\) \u53ef\u5f97</p> \\[ v_k \\perp L(z_1, \\cdots, z_{k - 1}) \\] <p>\u6545\u6709</p> \\[ proj(v_k | z_1, \\cdots, z_{k-1}) = 0 \\] <p>\u4e8e\u662f\u6709</p> \\[ \\hat z(k|k - 1) = H_k \\hat x(k|k-1) \\] <p>\u518d\u770b\u65b0\u606f\u8868\u8fbe\u5f0f</p> \\[ \\varepsilon_{k} = z_k - \\hat z(k | k - 1) = z_k - H_k \\hat x(k|k-1) \\] <p>\u8bb0\u6ee4\u6ce2\u6700\u4f18\u4f30\u8ba1\u503c\u8bef\u5dee\u4e3a</p> \\[ \\begin{align*} &amp;\\widetilde x(k|k) = x_k - \\hat x(k | k) \\\\ &amp;P(k|k) = E[\\widetilde x(k|k) \\widetilde x^T  (k|k)] \\\\ &amp;\\widetilde x(k|k - 1) = x_{k} - \\hat x(k | k - 1) \\\\ &amp;P(k|k - 1) = E[\\widetilde x(k|k - 1) \\widetilde x^T  (k|k - 1)] \\\\ &amp;\\widetilde x(k - 1|k - 1) = x_{k - 1} - \\hat x(k -1| k - 1) \\\\ &amp;P(k - 1|k - 1) = E[\\widetilde x(k - 1|k - 1) \\widetilde x^T  (k - 1|k - 1)] \\end{align*} \\] <p>\u7ed3\u5408 \\(z_k = H_k x_k + v_k\\) \u548c \\(\\varepsilon_{k} =  z_k - H_k \\hat x(k|k-1)\\) \u6709\u65b0\u606f\u8868\u8fbe\u5f0f</p> \\[ \\begin{align*} \\varepsilon_{k} &amp;= z_k - H_k \\hat x(k|k-1) \\\\ &amp;= H_k x_k + v_k - H_k \\hat x(k|k-1) \\\\ &amp;= H_k(x_k - \\hat x(k|k-1)) + v_k \\\\ &amp;= H_k \\widetilde x(k|k - 1) + v_k \\end{align*} \\] <p>\u7ed3\u5408 \\(x_k = A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k - 1}\\) \u548c \\(\\hat x(k| k - 1) = A_{k-1} \\hat x(k - 1| k - 1) + B_{k-1} u_{k-1}\\) \u53ef\u5f97</p> \\[ \\begin{align*} \\widetilde x(k|k - 1) &amp;= x_{k} - \\hat x(k | k - 1) \\\\ &amp;= A_{k - 1}x_{k - 1} + B_{k-1}u_{k-1} + w_{k - 1} - (A_{k-1} \\hat x(k - 1| k - 1) + B_{k-1} u_{k-1}) \\\\ &amp;= A_{k - 1}(x_{k - 1} - \\hat x(k - 1| k - 1)) + w_{k-1} \\\\ &amp;= A_{k - 1} \\widetilde x(k - 1|k - 1) + w_{k - 1} \\end{align*} \\] <p>\u7531 \\(\\hat x(k| k) = \\hat x(k | k - 1) + K_{k} \\varepsilon_{k}\\) \u53ef\u4ee5\u63a8\u5f97</p> \\[ \\begin{align*} \\widetilde x(k|k) &amp;= x_k - \\hat x(k | k) \\\\ &amp;= x_k - \\hat x(k | k - 1) - K_{k} \\varepsilon_{k} \\\\ &amp;= \\widetilde x(k|k - 1) - K_{k} \\varepsilon_{k} \\end{align*} \\] <p>\u5c06 \\(\\varepsilon_k = H_k \\widetilde x(k|k - 1) + v_k\\) \u4ee3\u5165\u4e0a\u5f0f\u53ef\u5f97</p> \\[ \\begin{align*} \\widetilde x(k|k) &amp;= \\widetilde x(k|k - 1) - K_{k} \\varepsilon_{k} \\\\ &amp;= \\widetilde x(k|k - 1) - K_{k} [H_k \\widetilde x(k|k - 1) + v_k] \\\\ &amp;= [I - K_kH_k] \\widetilde x(k|k - 1) - K_k v_k \\end{align*} \\] <p>\u5176\u4e2d \\(I \\in R^{n \\times n}\\) \u3002</p> <p>\u56e0\u4e3a</p> \\[ \\widetilde x(k - 1|k - 1) = x_{k-1} - \\hat x(k - 1| k - 1) \\in L(v_{k-1}, \\cdots, v_1, w_{k - 2}, \\cdots , w_0, u_{k-1}, \\cdots, u_0,  x_0) \\] <p>\u6545\u6709</p> \\[ w_{k - 1} \\perp \\widetilde x(k|k - 1) \\] <p>\u5219\u6709</p> \\[ E[w_{k - 1} \\widetilde x^T(k|k - 1)] = 0 \\] <p>\u7ed3\u5408 \\(\\widetilde x(k|k - 1) = A_{k - 1} \\widetilde x(k - 1|k - 1) + w_{k - 1}\\) \u548c\u4e0a\u5f0f\u53ef\u5f97</p> \\[ \\begin{align*} P(k|k - 1) &amp;= E[\\widetilde x(k|k - 1) \\widetilde x^T  (k|k - 1)] \\\\ &amp;= A_{k - 1}P(k - 1|k - 1)A_{k - 1}^T + Q_{k-1} \\end{align*} \\] <p>\u56e0\u4e3a</p> \\[ \\widetilde x(k|k - 1) = x_{k} - \\hat x(k | k - 1) \\in L(v_{k-1}, \\cdots, v_1, w_{k - 1}, \\cdots , w_0, u_{k-1}, \\cdots, u_0,  x_0) \\] <p>\u6545\u6709</p> \\[ v_k \\perp \\widetilde x(k|k - 1) \\] <p>\u4ece\u800c\u5f15\u51fa</p> \\[ E[v_k \\widetilde x^T(k|k - 1)] = 0 \\] <p>\u4e8e\u662f\uff0c\u7531 \\(\\varepsilon_{k} = H_k \\widetilde x(k|k - 1) + v_k\\) \u53ef\u5f97</p> \\[ E[\\varepsilon_{k} \\varepsilon_{k}^T] = H_kP(k|k - 1)H_k^T + R_k \\] <p>\u4e5f\u7531 \\(\\widetilde x(k|k) = [I - K_kH_k]x(k|k - 1) - K_k v_k\\) \u53ef\u5f97</p> \\[ P(k|k) = [I - K_kH_k] P(k|k-1) [I - K_kH_k]^T + K_k R_k K_k^T \\] <p>\u4e0b\u9762\u6c42\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u589e\u76ca \\(K_k\\) \uff0c\u5df2\u77e5 \\(K_k = E[x_{k} \\varepsilon_{k}^T] E^{-1}[\\varepsilon_{k} \\varepsilon_{k}^T]\\) \u3002</p> <p>\u6ce8\u610f\uff0c\u5e94\u7528 \\(\\varepsilon_{k} = H_k \\widetilde x(k|k - 1) + v_k\\) \u6709</p> \\[ \\begin{align*} E[x_k \\varepsilon_{k}^T] &amp;= E[(\\hat x(k|k - 1) + \\widetilde x(k|k - 1))(H_k \\widetilde x(k|k - 1) + v_k)^T] \\end{align*} \\] <p>\u6709\u5c04\u5f71\u6b63\u4ea4\u6027\u8d28\u53ef\u5f97</p> \\[ \\hat x(k|k - 1) \\perp \\widetilde x(k|k - 1) \\] <p>\u4e14\u6709 \\(v_k \\perp \\widetilde x(k|k - 1), v_k \\perp \\hat x(k|k - 1)\\) \uff0c\u4e8e\u662f\u6709</p> \\[ \\begin{align*} E[x_k \\varepsilon_{k}^T] &amp;= E[(\\hat x(k|k - 1) + \\widetilde x(k|k - 1))(H_k \\widetilde x(k|k - 1) + v_k)^T] \\\\ &amp;= P(k|k-1)H_k^T \\end{align*} \\] <p>\u5219\u5361\u5c14\u66fc\u589e\u76ca</p> \\[ \\begin{align*} K_k &amp;= E[x_{k} \\varepsilon_{k}^T] E^{-1}[\\varepsilon_{k} \\varepsilon_{k}^T] \\\\ &amp;= P(k|k-1)H_k^T  [H_kP(k|k - 1)H_k^T + R_k]^{-1} \\end{align*} \\] <p>\u5c06\u4e0a\u5f0f\u5e26\u5165 \\(P(k|k)\\) \u53ef\u5f97</p> \\[ \\begin{align*} P(k|k) &amp;= [I - K_kH_k] P(k|k-1) [I - K_kH_k]^T + K_k R_k K_k^T \\\\ &amp;= [I - K_kH_k] P - [I - K_kH_k] PH_k^TK_k^T + K_k R_k K_k^T \\\\ &amp;= [I - K_kH_k] P -  PH_k^TK_k^T + K_kH_kPH_k^TK_k^T + K_k R_k K_k^T \\\\ &amp;= [I - K_kH_k] P -  PH_k^TK_k^T + K_k(H_kPH_k^T + R_k) K_k^T \\\\ &amp;= [I - K_kH_k] P -  PH_k^TK_k^T + PH_k^T(H_kPH_k^T + R_k)^{-1}(H_kPH_k^T + R_k) K_k^T \\\\ &amp;= [I - K_kH_k] P -  PH_k^TK_k^T + PH_k^TK_k^T  \\\\ &amp;= [I - K_kH_k] P \\end{align*} \\] <p>\u5373</p> \\[ P(k|k) = [I - K_kH_k] P(k|k-1) \\] <p>\u7efc\u4e0a\u9012\u5f52\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u6240\u6709\u516c\u5f0f\u6709</p> <p>\u2460\u72b6\u6001\u9884\u6d4b\u65b9\u7a0b</p> \\[ \\hat x(k| k - 1) = A_{k-1} \\hat x(k - 1| k - 1) + B_{k-1} u_{k-1} \\] <p>\u2461\u6700\u4f18\u72b6\u6001\u4f30\u8ba1\u8fed\u4ee3\u66f4\u65b0\u516c\u5f0f</p> \\[ \\begin{align*} \\hat x(k| k) &amp;= \\hat x(k | k - 1) + K_{k} \\varepsilon_{k} \\\\ &amp;= \\hat x(k | k - 1) +  K_{k}(z_k - H_k \\hat x(k|k-1)) \\end{align*} \\] <p>\u2462\u5361\u5c14\u66fc\u589e\u76ca\u8ba1\u7b97\u516c\u5f0f</p> \\[ K_k = P(k|k-1)H_k^T  [H_kP(k|k - 1)H_k^T + R_k]^{-1} \\] <p>\u2463\u5148\u9a8c\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u66f4\u65b0\u516c\u5f0f</p> \\[ P_k^- = A_{k - 1}P(k - 1|k - 1)A_{k - 1}^T + Q_{k-1} \\] <p>\u2464\u6700\u4f18(\u540e\u9a8c)\u4f30\u8ba1\u8bef\u5dee\u534f\u65b9\u5dee\u66f4\u65b0\u516c\u5f0f</p> \\[ P(k|k) = [I - K_kH_k] P(k|k-1) \\] <p>\u4ee5\u4e0a\u5c31\u662f\u91c7\u7528\u6b63\u4ea4\u6295\u5f71\u5b9a\u7406\u6765\u8bc1\u660e\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5168\u90e8\u8fc7\u7a0b\uff0c\u5927\u90e8\u5206\u8fc7\u7a0b\u53c2\u8003\u9093\u8001\u5e08\u7684\u300a\u6700\u4f18\u4f30\u8ba1\u7406\u8bba\u53ca\u5176\u5e94\u7528\uff1a\u5efa\u6a21\u3001\u6ee4\u6ce2\u3001\u4fe1\u606f\u878d\u5408\u4f30\u8ba1\u300b\u3002\u6211\u53bb\u9664\u4e86\u5361\u5c14\u66fc\u9884\u6d4b\u6b65\u9aa4\u5e76\u5c06\u5b57\u6bcd\u7edf\u4e00\u4e3a\u672c\u6587\u7684\u8868\u793a\u65b9\u6cd5\u3002</p> <p>\u8bfb\u8005\u53ef\u4ee5\u5c06 \\(P(k|k)\\) \u7406\u89e3\u4e3a \\(P_k^+\\) \uff0c\u5176\u4f59\u7b26\u53f7\u4e5f\u53ef\u4ee5\u4e00\u4e00\u5bf9\u5e94\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#_6","title":"\u4e94\u3001\u7ed3\u8bed","text":"<p>\u5f53\u5199\u5230\u8fd9\u91cc\u7684\u65f6\u5019\u6211\u7ec8\u4e8e\u53ef\u4ee5\u677e\u4e00\u53e3\u6c14\u4e86\uff0c\u5fd9\u6d3b\u4e86\u4e09\u5468\u3002\u67e5\u9605\u4e86\u5927\u91cf\u8d44\u6599\uff0c\u4e5f\u9a8c\u8bc1\u4e86\u4e00\u4e9b\u9519\u8bef\u8bc1\u660e\u65b9\u6cd5\u3002</p> <p>\u6bd4\u5982\u201c\u5229\u7528\u4e24\u4e2a\u9ad8\u65af\u5206\u5e03\u76f8\u4e58\u4f9d\u7136\u662f\u9ad8\u65af\u5206\u5e03\u201d\u8fd9\u79cd\u8bf4\u6cd5\u662f\u9519\u8bef\u7684\u3002\u4e3b\u8981\u7cbe\u529b\u8fd8\u662f\u5361\u5728\u4e86\u5bf9\u4e8e\u6b63\u4ea4\u6295\u5f71\u5b9a\u7406\u7684\u7406\u89e3\u4e0a\uff0c\u5bf9\u4e8e\u77e9\u9635\u5f62\u5f0f\u7684\u53d8\u91cf\u6c42\u671f\u671b\u4ee5\u53ca\u5bf9\u4e8e\u662f\u5426\u4e3a\u5e38\u6570\u90a3\u91cc\u7406\u89e3\u4e86\u6574\u6574\u4e00\u5468\uff0c\u5728\u5468\u672b\u7684\u4e00\u4e2a\u4e0a\u5348\u987f\u609f\u4e86\uff0c\u4e5f\u7b97\u529f\u592b\u4e0d\u8d1f\u6709\u5fc3\u4eba\u5427\u3002</p> <p>\u8fd9\u4e00\u7cfb\u5217\u4e0b\u4e00\u7bc7\u6587\u7ae0\u5c06\u4f1a\u5c06\u4e00\u4e9b\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u5177\u4f53\u5e94\u7528\u4e86\uff0c\u6bd4\u5982\u8fc7\u6ee4\u566a\u58f0\u8fd8\u6709\u5176\u5728\u76ee\u6807\u8ffd\u8e2a\u4e2d\u7684\u5e94\u7528\u3002</p> <p>\u67e5\u8d44\u6599\u5199\u6587\u7ae0\u672c\u8eab\u5c31\u662f\u4e00\u4e2a\u5b66\u4e60\u7684\u8fc7\u7a0b\uff0c\u8fd8\u662f\u8981\u8010\u7740\u6027\u5b50\u4ed4\u7ec6\u53bb\u7406\u89e3\u3002\u611f\u8c22\u9093\u8001\u5e08\u7684\u8457\u4f5c\uff0c\u8001\u7684\u6559\u79d1\u4e66\u771f\u7684\u7ecf\u5178\u3002\u76f8\u6bd4\u8f83\u4e8e\u56fd\u5916\u6559\u6750\u7684\u7ffb\u8bd1\u7248\u672c\uff0c\u8fd8\u662f\u9093\u8001\u5e08\u5199\u7684\u66f4\u52a0\u900f\u5f7b\uff0c\u53ef\u60dc\u5df2\u7ecf\u7edd\u7248\u4e86\u3002\u4e0d\u77e5\u9053\u73b0\u5728\u7684\u6559\u6750\u8fd8\u4f1a\u7ed9\u51fa\u8fd9\u6837\u6709\u8010\u5fc3\u7684\u8bc1\u660e\u65b9\u6cd5\u4e86\u3002</p>"},{"location":"%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E6%8E%A8%E5%AF%BC%E4%BA%8C/#_7","title":"\u516d\u3001\u53c2\u8003\u6587\u732e\u548c\u94fe\u63a5","text":"<ul> <li>https://zhuanlan.zhihu.com/p/428356533</li> <li>https://zhuanlan.zhihu.com/p/598418848</li> <li>https://blog.csdn.net/qq_33866593/article/details/103035289</li> <li>\u300a\u6700\u4f18\u4f30\u8ba1\u7406\u8bba\u53ca\u5176\u5e94\u7528\uff1a\u5efa\u6a21\u3001\u6ee4\u6ce2\u3001\u4fe1\u606f\u878d\u5408\u4f30\u8ba1\u300b\u9093\u81ea\u7acb\u8457</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2021%E5%B9%B412%E6%9C%8825%E6%97%A5%2016%E6%97%B604%E5%88%8649%E7%A7%92/","title":"Network Slimming-\u795e\u7ecf\u7f51\u7edc\u526a\u679d\u7684\u7cbe\u7ec6\u63a7\u5236\u5b9e\u73b0","text":"<p>\u672c\u6587\u5199\u4e8e2022\u5e741\u670817\u65e516\u65f6</p> <p>\u672c\u6587\u4ecb\u7ecd\u5982\u4f55\u590d\u73b0\u7f51\u7edc\u526a\u679d\u4e2d\u7684\u4e00\u7bc7\u7ecf\u5178\u7684\u6587\u7ae0Learning Efficient Convolutional Networks Through Network Slimming \u8be5\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cdchannel-level\u7684\u88c1\u526a\u65b9\u6848\uff0c\u53ef\u4ee5\u901a\u8fc7\u7a00\u758f\u5316\u5c3a\u5ea6\u56e0\u5b50\uff08BN\u5c42\u7684scaling factor\uff09\u6765\u88c1\u6389\u201c\u4e0d\u91cd\u8981\u201d\u7684channel\u3002\u5373\u901a\u8fc7BN\u5c42\u7684scale factor\u6743\u91cd\u7684\u5927\u5c0f\u6765\u53cd\u5e94\u5176\u5bf9\u5e94\u7684channel\u7684\u91cd\u8981\u6027\uff0c\u7136\u540e\u6309\u7167scale factor\u7edd\u5bf9\u503c\u7684\u5927\u5c0f\u6392\u5217\u540e\u767e\u5206\u6bd4\u8bbe\u5b9a\u4e00\u4e2a\u9608\u503c\uff08\u6bd4\u5982\u526a\u638930%\uff0c\u90a3\u4e48\u5c31\u4ece\u5c0f\u5230\u5927\u6392\u5217\uff0c\u53d6\u6392\u572830%\u4f4d\u7f6e\u7684\u6570\u4f5c\u4e3a\u9608\u503c\uff09\uff0c\u526a\u6389\u4e0d\u90a3\u4e48\u91cd\u8981\u7684\u8f93\u51fa\u901a\u9053\u6240\u5bf9\u5e94\u7684\u6743\u91cd\uff0c\u4ece\u800c\u5b9e\u73b0\u7ed3\u6784\u5316\u526a\u679d\u3002 \u4e3a\u4e86\u4fdd\u8bc1scale factor\u7684\u7a00\u758f\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u7ed9\u5176\u52a0\u4e0al1 norm\u7684\u6b63\u5219\u5f97\u5230\u7a00\u758f\u89e3\u3002 \u601d\u8003\uff1a\u8f93\u51fa\u901a\u9053\u5220\u9664\u540e\uff0c\u8fd8\u9700\u8981\u8c03\u6574\u4ec0\u4e48\u5462\uff1f \u8fd8\u9700\u8981\u8c03\u6574\u4e0b\u4e00\u5c42\u7684\u8f93\u5165\uff0c\u53ea\u4fdd\u7559\u4e0e\u5176\u4e0a\u4e00\u5c42\u4fdd\u7559\u8f93\u51fa\u5bf9\u5e94\u7684\u90e8\u5206\uff0c\u6240\u4ee5\u5bf9channel\u7684\u526a\u679d\u5f71\u54cd\u4e24\u5c42\uff0c\u5373\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel\u548c\u4e0b\u4e00\u5c42\u7684\u8f93\u5165channel\u7684\u526a\u679d\u3002 \u5728\u590d\u73b0\u4e4b\u524d\uff0c\u4e0d\u59a8\u5148\u8ba8\u8bba\u4e00\u4e2a\u6bd4\u8f83\u6df1\u5c42\u7684\u95ee\u9898\u3002\u526a\u679d\u7684\u672c\u8d28\u771f\u7684\u662f\u7b5b\u9009\u91cd\u8981\u7684\u6743\u91cd\u5417\uff1f \u4e2a\u4eba\u611f\u89c9\u5e76\u4e0d\u662f\uff0c\u5728\u4f7f\u7528\u8be5\u6587\u7ae0\u7684\u65b9\u6cd5\u505a\u5b9e\u9a8c\u7684\u65f6\u5019\uff0c\u8bef\u6253\u8bef\u649e\u6ca1\u6709\u8bbe\u7f6el1\u6b63\u5219\uff0c\u7136\u540e\u8bad\u7ec3\u5f97\u5230\u7684\u7ed3\u679c\u4e0e\u8bbe\u7f6el1\u6b63\u5219\u5f97\u5230\u7684\u7ed3\u679c\u6ca1\u5565\u533a\u522b\uff0c\u4e5f\u5c1d\u8bd5\u8fc7\u8bbe\u7f6e\u8fc7\u4e0d\u540cl1\u6b63\u5219\u7cfb\u6570\uff0c\u4f46\u662f\u5f97\u5230\u7684\u7ed3\u8bba\u76f8\u540c\u3002\u5f53l1\u7cfb\u6570\u8bbe\u7f6e\u592a\u5927\u7684\u65f6\u5019\u53cd\u800c\u4f1a\u5bfc\u81f4\u8fd8\u4e0d\u5982\u4e0d\u52a0\u3002 Rethinking the Value of Network Pruning\u6307\u51fa\u526a\u679d\u7684\u672c\u8d28\u5e76\u4e0d\u5e94\u8be5\u662f\u9009\u62e9\u91cd\u8981\u7684\u6743\u91cd\uff0c\u800c\u662f\u786e\u5b9a\u6743\u91cd\u7684\u6570\u91cf\uff0c\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u4e5f\u53ef\u4ee5\u8fbe\u5230\u539f\u6765\u7684\u6027\u80fd\u3002\u6240\u4ee5\u526a\u679d\u662f\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u641c\u7d22\u9886\u57df\u7684\u5b50\u4e00\u4e2a\u5b50\u4efb\u52a1\uff0c\u81ea\u7136\u53ef\u4ee5\u91c7\u7528\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u641c\u7d22\u76f8\u5173\u7684\u65b9\u6cd5\u6765\u505a\u3002 \u7136\u800cNAS\u5374\u4e0d\u662f\u201c\u4e00\u822c\u73a9\u5bb6\u201d\u53ef\u4ee5\u505a\u7684\uff0c\u56e0\u6b64\u9488\u5bf9\u5c0f\u6a21\u578b\u548c\u5c0f\u578b\u4efb\u52a1\uff0c\u4f7f\u7528\u526a\u679d\u5f97\u5230\u4e00\u4e2a\u66f4\u52a0\u7d27\u51d1\u7684\u7ed3\u6784\uff0c\u6211\u8ba4\u4e3a\u4e5f\u662f\u8f83\u4e3a\u9002\u5408\u7684\u4e00\u4e2a\u65b9\u6848\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2021%E5%B9%B412%E6%9C%8825%E6%97%A5%2016%E6%97%B604%E5%88%8649%E7%A7%92/#_1","title":"\u6a21\u578b\u5b9a\u4e49\u548c\u8bad\u7ec3\u8fc7\u7a0b","text":"<p>\u63a5\u4e0b\u6765\u5c31\u8bf4\u4e0b\u5982\u4f55\u4f7f\u7528pytorch\u5b9e\u73b0\u5427 \u6211\u4eec\u5bf9\u901a\u8fc7bn\u5c42\u8861\u91cf\u5176\u5bf9\u5e94\u7b97\u5b50\uff0c\u6b64\u5904\u5047\u8bbe\u4e3a\u5377\u79ef\u5c42\uff0c\u90a3\u9700\u8981</p> <ol> <li>bn\u5c42\u5bf9\u8c61\u4e0econv\u5bf9\u8c61\u7684\u8fde\u63a5\u5417\uff0c\u76ee\u7684\u662f\u53ef\u4ee5\u901a\u8fc7bn\u627e\u5230\u5176\u5bf9\u5e94conv\u5c42\u3002</li> <li>\u4e3a\u4e86\u66f4\u6539conv\u5c42\u7684\u7ed3\u6784\uff0c\u90a3\u4e48\u6211\u4eec\u8fd8\u9700\u8981\u5f97\u5230conv\u5c42\u7684\u53cc\u4eb2\u5bf9\u8c61\u8282\u70b9\u3002</li> <li>\u4e3a\u4e86\u66f4\u6539\u83b7\u5f97\u4e0b\u4e00\u5c42\u6216\u8005\u4e0a\u4e00\u5c42conv\u7684\u7ed3\u6784\uff0c\u6211\u4eec\u8fd8\u9700\u8981\u5efa\u7acbconv\u5c42\u4e0econv\u5c42\u4e4b\u95f4\u7684\u8054\u7cfb\u3002</li> </ol> <p>\u901a\u8fc7\u4ee5\u4e0a\u5206\u6790\uff0c\u6211\u4eec\u53ef\u4ee5\u8bbe\u5b9a\u8fd9\u6837\u4e00\u4e2aConv\u805a\u5408\u5c42 \u5b9e\u73b0\u5982\u4e0b\u529f\u80fd\uff1a</p> <ol> <li>\u91cc\u9762\u7684bn\u53ef\u4ee5\u901a\u8fc7\u4e00\u5b9a\u65b9\u5f0f\u8bbf\u95ee\u7236\u8282\u70b9</li> <li>bn\u53ef\u4ee5\u901a\u8fc7\u4e00\u5b9a\u65b9\u5f0f\u8bbf\u95ee\u5176\u5bf9\u5e94conv</li> <li>\u53ef\u4ee5\u901a\u8fc7\u4e00\u5b9a\u65b9\u5f0f\u8bbf\u95ee\u5176\u4e0a\u4e00\u4e2aConv\u548c\u4e0b\u4e00\u4e2aConv</li> </ol> <pre><code>class ModuleWrapper:\n    def __init__(self, module) -&gt; None:\n        self.module = module\ndef autopad(k, p=None):\n    # Pad to 'same'\n    if p is None:\n        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n    return p\nclass Conv(nn.Module):\n    # Standard convolution\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True, inplace=True):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(Conv, self).__init__()\n        self._conv_configs = {\n            'in_channels': c1,\n            'out_channels': c2,\n            'kernel_size': k,\n            'stride': s,\n            'padding': autopad(k, p),\n            'groups': g,\n            'bias': False\n        }\n        self.conv = nn.Conv2d(**self._conv_configs)\n        self.bn = nn.BatchNorm2d(c2)\n        self.bn.conv = ModuleWrapper(self.conv)\n        # \u6807\u8bb0\u8981\u4e0d\u8981\u5bf9\u5f53\u524d\u5377\u79ef\u7684\u8f93\u51fa\u8fdb\u884c\u88c1\u526a\n        self.bn.is_pruned = False\n        self.bn.last_bn = ModuleWrapper(None)\n        self.bn.next_bn = ModuleWrapper(None)\n        self.bn.parent = ModuleWrapper(self)\n        self.act = nn.ReLU(inplace=inplace) if act is True else (act if isinstance(act, nn.Module) else nn.Identity())\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\n    def set_bn(self, bn):\n        ori_bn = self.bn\n        bn.conv = ori_bn.conv\n        bn.is_pruned = ori_bn.is_pruned\n        bn.last_bn = ori_bn.last_bn\n        bn.next_bn = ori_bn.next_bn\n        bn.parent = ori_bn.parent\n        self.bn = bn\n    def set_conv(self, conv):\n        self.conv = conv\n    def set_pruned(self, is_pruned):\n        self.bn.is_pruned = is_pruned\n    def set_last_bn(self, last_bn):\n        self.bn.last_bn.module = last_bn\n    def set_next_bn(self, next_bn):\n        self.bn.next_bn.module = next_bn\n    def set_last_conv(self, conv):\n        self.bn.last_bn.module = conv.bn\n    def set_next_conv(self, conv):\n        self.bn.next_bn.module = conv.bn\n    def get_conv_config_params(self):\n        return self._conv_configs\n</code></pre> <p>\u4ee5\u4e0a\u4ee3\u7801\u662f\u5c06bn\u4f5c\u4e3a\u53cc\u5411\u94fe\u8868\u4e2d\u7684\u4e00\u4e2a\u8282\u70b9\uff0c\u901a\u8fc7<code>ModuleWrapper</code>\u5305\u88f9\u9700\u8981\u8bbf\u95ee\u7684\u7ed3\u70b9\uff0c\u8fd9\u4e48\u505a\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u964d\u4f4e\u591a\u4e2a\u8282\u70b9\u7684\u8026\u5408\uff0c\u56e0\u4e3a<code>nn.Module</code>\u7c7b\u91cd\u5199\u4e86<code>__setitem__</code>\u548c<code>__getitem__</code>\u65b9\u6cd5\uff0c\u4f1a\u5c06<code>nn.Module</code>\u5b9e\u4f8b\u653e\u5165\u4e00\u4e2a\u4e13\u95e8\u7684dict\u4e2d\uff0c\u5c06\u5176\u89c6\u4e3a\u5176\u5b50Module\uff0c\u53cc\u4eb2\u8282\u70b9training\u72b6\u6001\u7684\u53d8\u5316\u4f1a\u5f71\u54cd\u5176\u5b50\u8282\u70b9\u7684\u53d8\u6362\uff0c\u663e\u7136\u8fd9\u4e0d\u662f\u6211\u4eec\u60f3\u8981\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u4f7f\u7528<code>ModuleWrapper</code>\u5305\u62ec<code>nn.Module</code>\u4e3a\u4e00\u4e2a\u666e\u901a\u5bf9\u8c61\uff0c\u5c3d\u7ba1\u8fd9\u4e48\u505a\u4e0d\u591f\u4f18\u96c5\u3002 \u6211\u4eec\u8bbe\u5b9a\u4e86bn\u7684\u5982\u4e0b\u5c5e\u6027</p> <pre><code># \u6807\u8bb0\u8981\u4e0d\u8981\u5bf9\u5f53\u524d\u5377\u79ef\u7684\u8f93\u51fa\u8fdb\u884c\u88c1\u526a\nself.bn.is_pruned = False\nself.bn.last_bn = ModuleWrapper(None)\nself.bn.next_bn = ModuleWrapper(None)\nself.bn.parent = ModuleWrapper(self)\n</code></pre> <ol> <li><code>is_pruned</code>\u5f53\u524dbn\u5c42\u662f\u5426\u9700\u8981\u88c1\u51cf</li> <li><code>last_bn</code> \u4e0e\u8868\u793a\u5f53\u524dbn\u5c42\u6240\u5c5e\u7684Conv\u5c42\u8fde\u63a5\u7684\u4e0a\u4e00\u4e2aConv\u5c42\u7684bn\u5c42</li> <li><code>next_bn</code> \u540c\u7406</li> <li><code>parent</code> bn\u5c42\u7684parent\uff0c\u5373\u53cc\u4eb2\u8282\u70b9\uff0c\u6307\u5411Conv\u5c42</li> <li>\u8bbe\u5b9aconv\u548cbn\u65b9\u6cd5:<code>set_conv</code>\u3001<code>set_bn</code></li> <li>\u83b7\u5f97\u5377\u79ef\u914d\u7f6e\u53c2\u6570:<code>get_conv_config_params</code></li> </ol> <p>\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u65b9\u5f0f\u8bbf\u95ee\u5404\u4e2a\u8282\u70b9</p> <pre><code># \u6267\u884c\u5230\u6b64\u8868\u793a\u5df2\u7ecf\u6784\u9020\u597d\u4e86\u8fde\u63a5\u5173\u7cfb... \u5047\u8bbe bn \u5bf9\u8c61 \u4e3a\u904d\u5386\u7684\u65f6\u5019\u7684 module\n# \u8bbf\u95eebn\u7684\u7236\u4eb2\u8282\u70b9\nConv = module.parent.module\n# \u8bbf\u95eebn\u6240\u5c5e\u7684conv\nconv_node = Conv.conv\n# \u8bbf\u95ee\u4e0a\u4e00\u5c42bn\nlast_bn = module.last_bn.module\n# \u4e0a\u6587\u4e0a\u4e00\u5c42conv\nlast_conv = last_bn.parent.module.conv\n</code></pre> <p>\u901a\u8fc7\u6784\u9020\u4e0a\u9762\u7684\u94fe\u8868\u548c\u6811\u7684\u5f62\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u65b9\u4fbf\u7684\u83b7\u5f97bn\u5c42\u76f8\u5173\u7684\u8282\u70b9\u3002 \u4e0d\u8fc7\u5728\u6784\u9020\u6a21\u578b\u65f6\u9700\u8981\u6211\u4eec\u81ea\u5df1\u6784\u9020\u51fa\u8fd9\u79cd\u8fde\u63a5\u5173\u7cfb\u6765 \u4e0b\u9762\u4e3e\u4e00\u4e2a\u4f8b\u5b50</p> <pre><code>class Block(nn.Sequential):\n    def __init__(self, c1, c2, n=3):\n        super(Block, self).__init__(*[\n            Conv(c1,c2,k=3,s=1)  for _ in range(n)])\n        childrens = list(self.children())\n        if n &gt;= 2:\n            for i in range(n - 1):\n\n                childrens[i].set_next_conv(childrens[i + 1])\n            for i in range(1, n):\n                childrens[i].set_last_conv(childrens[i - 1])\n</code></pre> <p>\u901a\u8fc7\u4e0a\u9762\u4f8b\u5b50\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\uff0c\u6211\u4eec\u6bcf\u5199\u4e00\u4e2a\u6a21\u5757\uff0c\u5c31\u9700\u8981\u9700\u8981\u5c06\u8fd9\u79cd\u8fde\u63a5\u5173\u7cfb\u6784\u9020\u6e05\u695a\uff0c\u6b64\u5916\u6a21\u5757\u4e0e\u6a21\u5757\u4e4b\u95f4\u7684\u8fde\u63a5\u5173\u7cfb\u4e5f\u8981\u6784\u9020\u6e05\u9664\uff0c\u8fd9\u91cc\u5c31\u4e0d\u518d\u5c55\u793a \u5728\u8bad\u7ec3\u4e4b\u524d\uff0c\u6211\u4eec\u8fd8\u9700\u8981\u505a\u4e00\u4e9b\u51c6\u5907\uff0c\u6211\u4eec\u9700\u8981\u8bbe\u5b9abn\u5c42\u7684<code>is_pruned</code>\u72b6\u6001\u6765\u6807\u8bb0\u5f53\u524dbn\u662f\u5426\u9700\u8981\u88ab\u526a\u679d\uff0c\u4ee5\u65b9\u4fbf\u540e\u7eed\u52a0\u6b63\u5219loss\u3002 \u8fd9\u91cc\u6211\u76f4\u63a5\u7ed9\u51fa\u9700\u8981<code>is_pruned=True</code>\u7684\u6761\u4ef6\uff0c\u5373\u8bbe\u5b9a\u4e86<code>next_bn.module</code>\u4e0d\u4e3a\u7a7a\u5373\u53ef\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u4fdd\u8bc1\u6211\u4eec\u5bf9\u5f53\u524d\u8282\u70b9\u7684\u8f93\u51fachannel\u548c\u4e0b\u4e00\u4e2a\u8282\u70b9\u7684\u8f93\u5165channel\u7684\u4fee\u6539\u7684\u8bbf\u95ee\u8fc7\u7a0b\u4e0d\u4f1a\u5931\u8d25\u3002</p> <pre><code>pruned_dict = set()\nfor name, module in model.named_modules():\n    if isinstance(module, nn.BatchNorm2d) and hasattr(module, 'is_pruned'):\n        if module.next_bn.module is not None:\n            module.is_pruned = True\n            pruned_dict.add(name)\n            print('module', name, 'is_pruned == True')\n</code></pre> <p>\u81f3\u6b64\u6211\u4eec\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u5c31\u53ef\u4ee5\u4f7f\u7528\u5982\u4e0b\u65b9\u5f0f\u52a0\u6b63\u5219\u9879</p> <pre><code>l1_norm_loss = 0\nlambda = 5e-6\nfor name,module in model.named_modules():\n    if name in pruned_dict:\n        l1_norm_loss += lambda* torch.abs(module.weight).sum()\nloss += l1_norm_loss\n</code></pre> <p>\u8fd9\u91cc\u6211\u76f4\u63a5\u7ed9\u51fa\u4e86\u591a\u5361\u4e0b\u5904\u7406\u7684\u65b9\u6848\uff0c\u5373\u5c06module\u7684name\u653e\u5165<code>set</code>\u4e2d\uff0c\u5355\u5361\u4e0b\u4e5f\u53ef\u4ee5\u76f4\u63a5\u5224\u65ad<code>is_pruned</code>\u5c5e\u6027\uff0c\u56e0\u4e3a\u591a\u5361\u4e0b\u8bad\u7ec3\u4f1a\u5c06<code>BatchNorm</code>\u8f6c\u6210<code>SyncBatchNorm</code>\uff0c\u6211\u4eec\u81ea\u5df1\u8bbe\u8ba1\u7684\u5c5e\u6027\u4f1a\u4e22\u5931\uff0c\u53ea\u80fd\u8bad\u7ec3\u5b8c\u6210\u540e\u518d\u5c06\u6743\u91cd\u5bfc\u51fa\u5230\u5355\u5361\u4e0b\u5b9a\u4e49\u7684model\u4e2d\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2021%E5%B9%B412%E6%9C%8825%E6%97%A5%2016%E6%97%B604%E5%88%8649%E7%A7%92/#_2","title":"\u6a21\u578b\u526a\u679d\u8fc7\u7a0b","text":"<p>\u526a\u679d\u7684\u8fc7\u7a0b\uff1a</p> <ol> <li>\u83b7\u53d6\u6240\u6709\u9700\u8981\u526a\u679d\u7684bn\u7684weight</li> <li>\u5bf9weight\u6392\u5e8f\uff0c\u786e\u5b9a\u9608\u503c</li> <li>\u6784\u9020\u4e00\u4e2a\u5f85\u526a\u679d\u7684\u65b0\u6a21\u578b\uff0c\u7ed3\u6784\u4e0e\u5185\u90e8\u547d\u540d\u65b9\u5f0f\u4e0e\u65e7\u6a21\u578b\u5b8c\u5168\u4e00\u6837\uff08\u8fd9\u91cc\u6211\u4eec\u5728\u51fd\u6570\u5916\u9762\u6784\u9020\u597d\uff0c\u76f4\u63a5\u4f20\u5165\uff09</li> <li> <p>\u904d\u5386\u65b0\u6a21\u578b\u6240\u6709\u9700\u8981\u526a\u679d\u7684bn\u5c42\u5f00\u59cb\u526a\u679d</p> </li> <li> <p>\u66ff\u6362\u5f53\u524d\u5c42\u7684conv</p> </li> <li>\u786e\u5b9a\u8f93\u51fachannel\u7684mask</li> <li>\u5224\u65ad\u5f53\u524d\u5c42\u7684\u8f93\u5165channel\u662f\u5426\u9700\u8981\u88ab\u526a\u679d\uff0c\u5e76\u786e\u5b9amask</li> <li>\u6784\u9020\u65b0\u7684conv\uff0c\u66ff\u6362\u539f\u6765\u7684conv</li> <li>\u6784\u9020\u65b0\u7684bn\uff0c\u66ff\u6362\u539f\u6765\u7684bn</li> <li>\u5904\u7406\u4e0b\u4e00\u4e2amodule\u7684\u8f93\u5165</li> </ol> <p>\u7efc\u4e0a\uff0c\u6211\u4eec\u7ed9\u51fa\u526a\u679d\u7684\u4ee3\u7801\u5b9e\u73b0</p> <pre><code>import torch\nimport torch.nn as nn\nfrom copy import deepcopy\ndef prune_model(model, new_model, percent = 0.4):\n    total = 0\n    for module in model.modules():\n        if isinstance(module, nn.BatchNorm2d) and getattr(module, 'is_pruned', False):\n            total += module.weight.data.shape[0]\n    print('total',total)\n    total_bn_weights = torch.zeros(total)\n    index = 0\n    for module in model.modules():\n        if isinstance(module, nn.BatchNorm2d) and getattr(module, 'is_pruned', False):\n            size = module.weight.data.shape[0]\n            total_bn_weights[index:(index+size)] = module.weight.detach().data.abs()\n            index += size\n    topk_values,_ = torch.topk(total_bn_weights ,k = int(total * percent), sorted=True, largest=False)\n    threhold = topk_values[-1]\n    pruned = 0\n    reserved_channels = dict()\n    channel_masks = dict()\n    for name, module in model.named_modules():\n        if isinstance(module, nn.BatchNorm2d) and getattr(module, 'is_pruned', False):\n            weight_copy = module.weight.detach().data.abs()\n            mask = weight_copy.gt(threhold).float()\n            pruned += mask.shape[0] - torch.sum(mask).item()\n\n#             module.weight.data.mul_(mask)\n#             module.bias.data.mul_(mask)\n            reserved_channels[name] = torch.sum(mask).item()\n            channel_masks[name] = mask.clone()\n    # new_model = deepcopy(model)\n    new_model.load_state_dict(model.state_dict())\n    # \u8fd9\u91cc\u662f\u4e3a\u4e86\u6839\u636ename\u8bbf\u95ee\u65e7\u6a21\u578b\u4e2d\u7684\u53c2\u6570\n    def get_module(model, name):\n        tokens = name.split('.')\n        sub_tokens = tokens\n        cur_mod = model\n        for s in sub_tokens:\n            cur_mod = getattr(cur_mod, s)\n        return cur_mod\n    for name, module in new_model.named_modules():\n        module.name = name\n        if name in reserved_channels:\n            module.is_pruned = True\n    for name, module in new_model.named_modules():\n        if name in reserved_channels:\n            reserved_channel =  reserved_channels[name]\n            module_parent = module.parent.module\n            mask = channel_masks[name].bool()\n            # \u53ea\u5173\u6ce8\u5f53\u524dmodule\n            conv_config_params = module_parent.get_conv_config_params()\n            # \u5224\u65ad\u662f\u5426\u7cbe\u7b80\u8f93\u5165channel\n            new_in_channels = conv_config_params['in_channels']\n            last_bn_weight_mask = torch.ones(new_in_channels).to(torch.bool)\n            if module.last_bn.module is not None and getattr(module.last_bn.module, 'is_pruned', False):\n                last_bn_weight_mask = channel_masks[module.last_bn.module.name]\n                new_in_channels = int(torch.sum(last_bn_weight_mask))\n                last_bn_weight_mask = last_bn_weight_mask.bool()\n            new_output_channels = int(reserved_channel)\n            new_configs = deepcopy(conv_config_params)\n            new_configs['in_channels'] = new_in_channels\n            new_configs['out_channels'] = new_output_channels\n            new_conv = nn.Conv2d(**new_configs)\n            ori_bn_parent = get_module(model,name).parent.module\n            ori_weight = ori_bn_parent.conv.weight.detach().data\n            ori_weight = ori_weight[mask,:,:,:]\n            ori_weight = ori_weight[:,last_bn_weight_mask,:,:]\n            new_conv.weight.data.copy_(ori_weight)\n            if new_configs['bias']:\n                ori_bias = module_parent.conv.bias.detach().data\n                new_conv.bias.data.copy_(ori_bias[mask])\n            module_parent.set_conv(new_conv)\n            # \u66f4\u6539bn\n            new_bn = nn.BatchNorm2d(new_output_channels, eps=module.eps, momentum=module.momentum, affine=module.affine, track_running_stats=module.track_running_stats)\n            new_bn.weight.data.copy_(module.weight.data[mask])\n            new_bn.bias.data.copy_(module.bias.data[mask])\n            if new_bn.track_running_stats:\n                new_bn.running_mean.data.copy_(module.running_mean.data[mask])\n                new_bn.running_var.data.copy_(module.running_var.data[mask])\n                new_bn.num_batches_tracked.data.copy_(module.num_batches_tracked.data)\n            module_parent.set_bn(new_bn)\n            # \u5982\u679c\u4e0b\u4e00\u4e2amodule\u6ca1\u6709\u526a\u679d\uff0c\u90a3\u4e48\u9700\u8981\u66f4\u6539\u5904\u7406\u4e0b\u4e00\u4e2amodude\u7684\u8f93\u5165\n            if module.next_bn.module is not None and getattr(module.next_bn.module, 'is_pruned', True) == False:\n                # \u66f4\u6539\u4e0b\u4e00\u4e2amodule\u7684\u8f93\u5165\n                next_module_parent = module.next_bn.module.parent.module\n                next_conv_config_params = deepcopy(next_module_parent.get_conv_config_params())\n                next_conv_config_params['in_channels'] = new_output_channels\n                new_conv = nn.Conv2d(**next_conv_config_params)\n                ori_conv= get_module(model,next_module_parent.conv.name)\n                ori_weight = ori_conv.weight.detach().data\n                ori_weight = ori_weight[:,mask,:,:]\n                new_conv.weight.data.copy_(ori_weight)\n                next_module_parent.set_conv(new_conv)\n    return new_model\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2021%E5%B9%B412%E6%9C%8825%E6%97%A5%2016%E6%97%B604%E5%88%8649%E7%A7%92/#_3","title":"\u7ed3\u8bed","text":"<p>\u7f51\u7edc\u526a\u679d\u662f\u4e00\u4e2a\u5728\u53d1\u5c55\u7684\u7814\u7a76\u65b9\u5411\uff0c\u6709\u5f88\u591a\u7ecf\u5178\u7684\u6587\u7ae0\u503c\u5f97\u53bb\u63a2\u7d22\u3002\u526a\u679d\u7684\u81ea\u52a8\u5316\u8fc7\u7a0b\u4ee5\u53ca\u5176\u771f\u6b63\u7684\u843d\u5730\u4e2d\u662f\u5426\u4f1a\u7528\u5230\u526a\u679d\u6765\u505a\u5904\u7406\u5462\uff1f\u8fd9\u6216\u8bb8\u8981\u672a\u6765\u7684\u6211\u6765\u7ed9\u81ea\u5df1\u4e00\u4e2a\u7b54\u6848\u3002 \u6216\u8bb8\uff0ctorch\u5b98\u65b9\u4f1a\u51fa\u4e00\u4e2a\u5de5\u5177\uff0c\u4ee5\u4e00\u79cd\u76f4\u63a5\u66f4\u6539\u8ba1\u7b97\u56fe\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\uff0c\u5c31\u50cf\u91cf\u5316\u548cnihui\u5927\u4f6c\u7684PNNX\u90a3\u6837\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B401%E6%9C%8817%E6%97%A5%2010%E6%97%B647%E5%88%8629%E7%A7%92/","title":"\u6a21\u578b\u538b\u7f29\u6846\u67b6nncf\u6a21\u578b\u91cf\u5316\u4e2dQAT\u91cf\u5316\u53c2\u6570\u7684\u68af\u5ea6\u63a8\u5bfc","text":"<p>\u672c\u6587\u5199\u4e8e2022\u5e7401\u670817\u65e5 10\u65f647\u5206</p> <p>NNCF\uff08https://github.com/openvinotoolkit/nncf\uff09\u662f\u82f1\u7279\u5c14\u4e3a\u81ea\u5bb6\u6a21\u578b\u63a8\u7406\u6846\u67b6openvino\u63a8\u51fa\u7684\u4e00\u6b3e\u6a21\u578b\u538b\u7f29\u6846\u67b6\uff0c\u652f\u6301Quantization\u3001Binarization\u3001Sparsity\u548cFilter pruning\u3002\u76f8\u5173\u7684\u8bba\u6587\u53ef\u4ee5\u5728https://arxiv.org/abs/2002.08679\u4e0b\u8f7d\u3002\u505a\u9879\u76ee\u65f6\u9700\u8981\u7528\u5230\u5728\u82f1\u7279\u5c14CPU\u4e0a\u7684\u91cf\u5316\u529f\u80fd\u3002\u5728\u770b\u8be5\u4ed3\u5e93\u7684\u91cf\u5316\u6e90\u7801\u7684\u65f6\u5019\uff0c\u91cf\u5316\u53c2\u6570\u7684\u6c42\u5bfc\u56f0\u6270\u4e86\u6211\u597d\u591a\u5929\uff0c\u4e00\u76f4\u548c\u4f2a\u91cf\u5316\u7684\u524d\u5411\u4f20\u64ad\u5bf9\u4e0d\u4e0a\uff0c\u6700\u7ec8\u53d1\u73b0\u662f\u4f5c\u8005\u7684\u53d8\u91cf\u540d\u8bef\u5bfc\u4e86\u6211\uff0c\u4e0b\u9762\u7ed9\u51fa\u5728nncf\u4e2d\u91cf\u5316\u7684\u4ee3\u7801\u548c\u516c\u5f0f\u63a8\u5bfc\u8fc7\u7a0b\u3002 \u8fd9\u91cc\u7b80\u5355\u8d77\u89c1\uff0c\u4ee5\u5bf9\u79f0\u91cf\u5316\u4e3a\u4f8b\uff0c\u6765\u770bNNCF\u4e2d\u7684QAT\u91cf\u5316\u539f\u7406 \u6253\u5f00git\u4ed3\u5e93\uff0c\u627e\u5230<code>nncf/torch/extensions/src/quantization/cpu/functions_cpu.cpp</code>\uff0c\u53ef\u4ee5\u770b\u5230\u4f2a\u91cf\u5316\u7684\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u65b9\u5f0f\u3002 \u8fd9\u91cc\u9996\u5148\u8d34\u51fa\u4f2a\u91cf\u5316\u7684\u524d\u5411\u4f20\u64ad\u7684\u4ee3\u7801</p> <pre><code>template &lt;typename scalar_t&gt;\nat::Tensor q_cpu_forward(\n        at::Tensor input,\n        at::Tensor input_low,\n        at::Tensor input_range,\n        scalar_t levels) {\n    at::Tensor s = (levels - 1) / input_range;\n\n    auto output = at::max(at::min(input, input_low + input_range), input_low);\n    output -= input_low;\n    output *= s;\n    output = output.round_();\n    output = output.div_(s);\n    output += input_low;\n    return output;\n}\n</code></pre> <p>\u540c\u65f6\u901a\u8fc7\u5e95\u90e8\u7684\u4ee3\u7801</p> <pre><code>PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n  m.def(\"Quantize_forward\", &amp;q_forward, \"Quantize forward\");\n  m.def(\"Quantize_backward\", &amp;q_backward, \"Quantize backward\");\n}\n</code></pre> <p>\u641c\u7d22<code>Quantize_forward</code>\u53ef\u4ee5\u8ffd\u6eaf\u5230<code>nncf/nncf/torch/quantization/quantize_functions.py</code>\u6587\u4ef6\uff0c\u8fd9\u91cc\u627e\u5230\u4e86\u5bf9\u79f0\u91cf\u5316\u7684torch function\u5b9a\u4e49</p> <pre><code>class QuantizeSymmetric(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input_, scale, level_low, level_high, levels):\n        input_low = scale * (level_low / level_high)\n        input_range = scale - input_low\n\n        if input_.is_cuda:\n            if not input_.is_contiguous():\n                warnings.warn(\"input_ is not contiguous!\", RuntimeWarning)\n                input_ = input_.contiguous()\n            output = QuantizedFunctionsCUDA.Quantize_forward(input_, input_low, input_range, levels)\n        else:\n            output = QuantizedFunctionsCPU.Quantize_forward(input_, input_low, input_range, levels)\n        ctx.save_for_backward(input_, input_low, input_range)\n        ctx.levels = levels\n        ctx.level_low = level_low\n        ctx.level_high = level_high\n        return output\n    @staticmethod\n    def backward(ctx, grad_output):\n        input_, input_low, input_range = ctx.saved_tensors\n        levels = ctx.levels\n        level_low = ctx.level_low\n        level_high = ctx.level_high\n        if grad_output.is_cuda:\n            if not grad_output.is_contiguous():\n                warnings.warn(\"grad_output is not contiguous!\", RuntimeWarning)\n                grad_output = grad_output.contiguous()\n            grad_input, _, grad_scale = QuantizedFunctionsCUDA.Quantize_backward(\n                grad_output, input_, input_low, input_range, levels, level_low, level_high\n            )\n        else:\n            grad_input, _, grad_scale = QuantizedFunctionsCPU.Quantize_backward(\n                grad_output, input_, input_low, input_range, levels, level_low, level_high, False\n            )\n        return grad_input, grad_scale, None, None, None\n</code></pre> <p>\u7efc\u5408\u4e0a\u9762\u7684<code>forward</code>\u51fd\u6570\u548cc++\u7684\u4ee3\u7801\uff0c\u53ef\u4ee5\u5199\u51fa\u524d\u5411\u4f20\u64ad\u7684\u516c\u5f0f</p> \\[ s = \\frac{levels - 1}{q_{range}} \\] \\[ q_{low} = scale * \\frac{level_{low}}{level_{high}} \\] \\[ q_{range} = scale - q_{low} \\] \\[ q_{high} = q_{low} + q_{range} \\] \\[ \\operatorname{fakequantize}( x,q_{low},q_{range} ) = \\frac{round(s \\cdot (\\operatorname{clip}(x, q_{low}, q_{high}) - q_{low}))}{s} + q_{low} \\] <p>\u4e0b\u9762\u8d34\u51fa\u53cd\u5411\u4f20\u64ad\u7684\u4ee3\u7801</p> <pre><code>template &lt;typename scalar_t&gt;\nstd::vector&lt;at::Tensor&gt; q_cpu_backward(\n        at::Tensor grad_output,\n        at::Tensor input,\n        at::Tensor input_low,\n        at::Tensor input_range,\n        scalar_t levels,\n        scalar_t levels_low,\n        scalar_t levels_high,\n        bool is_asymmetric) {\n    auto output = q_cpu_forward&lt;scalar_t&gt;(input, input_low, input_range, levels);\n    auto reverted_range = 1 / input_range;\n    scalar_t alpha = levels_low / levels_high;\n    auto mask_hi = input.gt(input_low + input_range);\n    auto mask_lo = input.lt(input_low);\n    auto err = at::sub(output, input);\n    err.mul_(reverted_range);\n    err = err.masked_fill_(mask_hi, 1);\n    err = err.masked_fill_(mask_lo, alpha);\n    err = err.mul_(grad_output);\n    auto grad_input_range = err;\n    sum_like(grad_input_range, input_range);\n    auto grad_input = grad_output.clone();\n    auto outside_mask = mask_hi.add_(mask_lo);\n    grad_input = grad_input.masked_fill_(outside_mask, 0);\n    if (is_asymmetric) {\n        auto grad_input_low = grad_output.clone();\n        auto all_ones = torch::ones_like(outside_mask);\n        grad_input_low = grad_input_low.masked_fill_(at::__xor__(all_ones, outside_mask), 0);\n        sum_like(grad_input_low, input_low);\n        return {grad_input, grad_input_low, grad_input_range};\n    }\n    auto dummy_variable = torch::autograd::make_variable(at::empty(input_low.sizes()), true);\n    return {grad_input, dummy_variable, grad_input_range};\n}\n</code></pre> <p>\u6b64\u65f6\uff0c\u6211\u4eec\u5148\u53ea\u5173\u6ce8\u5bf9\u79f0\u7684\u60c5\u51b5\uff0c\u4e0a\u9762\u4ee3\u7801\u4e2d<code>grad_input_range</code>\u8868\u793a\u7684\u5e76\u4e0d\u662f\u5bf9<code>input_range</code>\u7684\u504f\u5bfc\u6570\uff0c\u800c\u662f<code>scale</code>\u7684\u504f\u5bfc\u6570\uff0c\u539f\u56e0\u53ef\u4ee5\u770b\u4e0b\u524d\u9762<code>QuantizeSymmetric</code>\u7c7b\u7684\u6e90\u4ee3\u7801</p> <pre><code>grad_input, _, grad_scale = QuantizedFunctionsCPU.Quantize_backward(\n                grad_output, input_, input_low, input_range, levels, level_low, level_high, False\n            )\n</code></pre> <p>\u4ece\u8be5\u884c\u4ee3\u7801\u53ef\u4ee5\u770b\u51fa<code>grad_input_range</code>\u8d4b\u503c\u7ed9\u4e86<code>grad_scale</code>\u3002\u4e5f\u5c31\u662f\u8bf4<code>grad_input_range</code>\u4ee3\u8868<code>scale</code>\u7684\u504f\u5bfc\u6570\uff0c\u90a3\u4e48\u53cd\u5411\u4f20\u64ad\u7684\u65f6\u5019\u5bf9<code>grad_input_range</code>\u5c31\u597d\u89e3\u91ca\u4e86\u3002\u8fd9\u91cc\u7ed9\u51fa\u4f2a\u91cf\u5316\u7684\u8f93\u51fa\u5bf9\u8f93\u5165<code>x</code>\u548c<code>scale</code>\u7684\u516c\u5f0f</p> \\[ output := fakequantize( x,q_{low},q_{range} ) \\] \\[ \\nabla_{x} fakequantize( x,q_{low},q_{range} ) = \\begin{cases} 1&amp;\\text{ if } q_{low} \\leq x \\leq q_{high}, \\\\ 0&amp;\\text{ if } x &lt; q_{low} \\ or \\  x &gt; q_{high}. \\end{cases} \\] \\[ \\nabla_{scale} fakequantize( x,q_{low},q_{range} )  = \\begin{cases} \\frac{(output-x)(1 - \\frac{level_{low}}{level_{high}})}{q_{range}} &amp;\\\\ \\text{if}~q_{low} \\leq x \\leq q_{high} \\\\ \\frac{level_{low}}{level_{high}} &amp;\\text { if } x &lt; q_{low}, \\\\ 1  &amp; \\text { if } x &gt; q_{high} .\\end{cases} \\] <p><code>levels</code>\u8868\u793a\u91cf\u5316\u533a\u95f4\u53ef\u4ee5\u8868\u793a\u7684\u603b\u4e2a\u6570\uff0c\u6bd4\u59828\u4f4d\u7684\u60c5\u51b5\u4e0b<code>levels = 256</code>\u3002\u7531\u4e8e\u662f\u5bf9\u79f0\u91cf\u5316\uff0c<code>scale</code>\u4e3a\u552f\u4e00\u7684\u91cf\u5316\u53c2\u6570\uff0c\u5176\u4f59\u7684\u91cf\u5316\u53c2\u6570\u6bd4\u5982 \\(q_{low}\\) \u3001 \\(q_{range}\\) \u3001 \\(q_{high}\\) \u90fd\u53ef\u4ee5\u7531 \\(scale\\) \u6240\u8868\u793a\u3002  \\(level_{low}\\) \u8868\u793a\u91cf\u5316\u533a\u95f4\u7684\u6700\u5c0f\u503c\uff0c \\(level_{high}\\) \u8868\u793a\u91cf\u5316\u533a\u95f4\u7684\u6700\u5927\u503c\u3002 \\(round\\) \u64cd\u4f5c\u8868\u793a\u56db\u820d\u4e94\u5165\u53d6\u6574\uff08round\uff09\u64cd\u4f5c\u3002 \\(fakequantize( x,q_{low},q_{range} )\\) \u8868\u793a\u5bf9\u8f93\u5165x\u7684\u7ebf\u6027\u4f2a\u91cf\u5316\u51fd\u6570\u3002 $ \\nabla_{x} fakequantize( x,q_{low},q_{range} )$ \u548c $ \\nabla_{scale} fakequantize( x,q_{low},q_{range} )$ \u8868\u793a\u4f2a\u91cf\u5316\u51fd\u6570\u5bf9 \\(x\\) \u548c \\(scale\\) \u7684\u504f\u5bfc\u6570\u3002 \u5173\u4e8e\u516c\u5f0f\u5bf9scale\u6c42\u504f\u5bfc\u7684\u4e2d\u7b2c\u4e00\u4e2a\u6761\u4ef6\u7684\u63a8\u5bfc\u8fc7\u7a0b\u5982\u4e0b\uff0c\u8fd9\u91cc\u9700\u8981\u7528\u5230STE\uff08straight through estimator\uff09\u5047\u8bbe\uff0c\u5373\u5bf9round\u51fd\u6570\u4e2d\u81ea\u53d8\u91cf\u6c42\u504f\u5bfc\u7ea6\u7b49\u4e8e\u628around\u51fd\u6570\u53bb\u6389\u540e\u7684\u7ed3\u679c\u3002</p> \\[ \\begin{align*} \\nabla_{s} fakequantize( x,q_{low},q_{range} ) &amp;= -\\frac{1}{s^2} round(s \\cdot (x - q_{low})) + \\frac{1}{s}(x - q_{low}) \\\\ &amp;= \\frac{1}{s}[(x - q_{low}) - (output - q_{low})] \\\\ &amp;= \\frac{1}{s}(x - output) \\end{align*} \\] \\[ \\begin{align*} &amp; \\nabla_{q_{low}} fakequantize( x,q_{low},q_{range} ) = \\frac{1}{s} (-s) + 1 = 0 \\\\  &amp; \\nabla_{q_{range}} s = - \\frac{levels - 1}{{q_{range}}^2} = -s \\cdot \\frac{1}{q_{range}} \\\\ &amp; \\nabla_{scale} q_{range} = 1 - \\frac{level_{low}}{level_{high}} \\end{align*} \\] <p>\u6574\u5408\u4ee5\u4e0a\u516c\u5f0f\u5f97</p> \\[ \\begin{align*} \\nabla_{scale} fakequantize( x,q_{low},q_{range} ) &amp;=  \\nabla_{s} output \\cdot  \\nabla_{q_{range}} s \\cdot  \\nabla_{scale} q_{range} +  \\nabla_{q_{low}} output \\cdot  \\nabla_{scale} q_{low} \\\\ &amp;= \\frac{1}{s}(x - output) \\cdot (-s \\cdot \\frac{1}{q_{range}}) \\cdot (1 - \\frac{level_{low}}{level_{high}}) \\\\ &amp;= \\frac{output - x}{q_{range}}(1 - \\frac{level_{low}}{level_{high}}) \\end{align*} \\] <p>\u5728NNCF\u4e2d\u4ee3\u7801\u6ca1\u6709 \\((1 - \\frac{level_{low}}{level_{high}})\\) \u8fd9\u4e00\u5e38\u6570\u9879\uff0c\u53ef\u80fd\u662f\u56e0\u4e3aNNCF\u4e3a\u4e86\u7b80\u5316\u8fd0\u7b97\uff0c\u5bf9\u91cf\u5316\u53c2\u6570\u548c\u6a21\u578b\u53c2\u6570\u4f7f\u7528\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u5c06\u8be5\u5e38\u6570\u9879\u5408\u5e76\u5230\u5b66\u4e60\u7387\u4e2d\u3002\u5176\u4ed6\u6761\u4ef6\u7684\u8bc1\u660e\u76f8\u5bf9\u7b80\u5355\uff0c\u5148\u5bf9\u524d\u5411\u4f20\u64ad\u7684\u516c\u5f0f\u5316\u7b80\u5c31\u53ef\u4ee5\u6c42\u5f97\uff0c\u8fd9\u91cc\u5c31\u4e0d\u5728\u7ed9\u51fa\u3002</p> <p>\u7efc\u4e0a\uff0cNNCF\u5bf9\u91cf\u5316\u53c2\u6570\u7684\u6c42\u5bfc\u4f9d\u7136\u91c7\u7528LSQ\u548cTQT\u7684\u65b9\u6cd5\uff0c\u53ea\u662f\u53d8\u6362\u4e86\u53c2\u6570\uff0c\u8fd9\u91cc\u9700\u8981\u91c7\u7528\u591a\u5143\u51fd\u6570\u5fae\u5206\u7684\u529e\u6cd5\u5bf9 \\(scale\\) \u8fdb\u884c\u6c42\u504f\u5bfc\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8805%E6%97%A5%2016%E6%97%B630%E5%88%8647%E7%A7%92/","title":"\u5bf9\u6a21\u578b\u91cf\u5316\u6846\u67b6mqbench\u6dfb\u52a0openvino\u63a8\u7406\u683c\u5f0f\u652f\u6301","text":"<p>\u672c\u6587\u5199\u4e8e2022\u5e7402\u670805\u65e5 16\u65f630\u5206</p> <p>\u5546\u6c64\u5f00\u6e90\u7684\u91cf\u5316\u6846\u67b6mqbench\u652f\u6301QAT\u7b97\u6cd5\u4ee5\u53ca\u5bf9\u591a\u79cd\u63a8\u7406\u6846\u67b6\uff08NNIE\u3001TensorRT\u7b49\uff09\u7684\u90e8\u7f72\u652f\u6301\uff0c\u53ef\u80fd\u7531\u4e8e\u5546\u6c64\u5185\u90e8\u5728Intel CPU\u8fd9\u79cd\u901a\u7528\u786c\u4ef6\u4e0b\u7684\u573a\u666f\u4e0d\u591a\uff0c\u7f3a\u5c11\u5bf9Intel \u90e8\u7f72\u6846\u67b6openvino\u7684\u652f\u6301\uff0c\u672c\u6587\u5c06\u4ecb\u7ecd\u91c7\u7528mqbenc\u91cf\u5316\u540e\u7684\u6a21\u578b\u5982\u4f55\u91c7\u7528openvino\u53bb\u90e8\u7f72\u3002 \u5b8c\u6574\u4ee3\u7801\u89c1 https://github.com/ModelTC/MQBench (\u6ca1\u9519\uff0c\u76f8\u5173\u4ee3\u7801\u8fdb\u8fc7PR\u5df2\u7ecfmerge\u8fdb\u5b98\u65b9github)</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8805%E6%97%A5%2016%E6%97%B630%E5%88%8647%E7%A7%92/#openvino","title":"openvino \u63a8\u7406\u683c\u5f0f\u7684\u5bf9\u9f50","text":"<p>openvino\u5b98\u65b9\u5b9e\u9645\u4e0a\u662f\u6709\u5b98\u65b9\u6a21\u578b\u538b\u7f29\u6846\u67b6\u7684\uff0c\u53ebnncf\uff0c\u6211\u4e4b\u524d\u8fd8\u5199\u8fc7\u4e00\u7bc7\u6587\u7ae0\u4e13\u95e8\u4ecb\u7ecdnncf\u4e0b\u7684\u91cf\u5316\u3002\u8fd9\u91cc\u7ed9\u51fanncf\u91cf\u5316\u7684\u6587\u6863\u5730\u5740\uff1aReadme\u3002\u7ed9\u51fa\u7684\u6587\u6863\u548c\u6e90\u7801\u662f\u5bf9\u4e0d\u4e0a\u7684\uff0c\u4e0d\u63a8\u8350\u53bb\u770b\uff0c\u4f46\u662f\u7528\u8d77\u6765\u5728\u663e\u5b58\u5360\u7528\u4e0anncf\u7684\u6a21\u578b\u4f18\u4e8e\u57fa\u4e8etorch.fx\u7684mqbench\uff0c\u4e3b\u8981\u539f\u56e0\u5728\u4e8enncf\u91cf\u5316\u4e0d\u5bf9batchnorm\u8fdb\u884c\u5408\u5e76\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u5176\u53c2\u6570\u5c31\u662f\u5b8c\u5168\u548c<code>FakeQuantize</code>\u4e2d\u7684\u53c2\u6570\u5b8c\u5168\u5bf9\u5e94\u7684\uff0c\u56e0\u6b64\u5176\u548copenvino\u7684\u63a8\u7406\u7ed3\u679c\u662f\u5b8c\u5168\u5bf9\u9f50\u7684\u3002 openvino\u4e2d\u7684\u91cf\u5316\u6a21\u578b\u91c7\u7528onnx\uff0c\u65b0\u6dfb\u4e86\u4e00\u4e2a<code>FakeQuantize</code>\u7684op\u6765\u8868\u793a<code>FakeQuantize</code>\u7684\u8f93\u51fa\u6240\u5bf9\u5e94\u7684\u7b97\u5b50\u9700\u8981\u5728\u4f4e\u6bd4\u7279\u4e0b\u53bb\u8fd0\u7b97\u3002<code>FakeQuantize</code>\u7684\u7b97\u5b50\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> \u53ef\u4ee5\u770b\u5230<code>FakeQuantize</code>\u4e00\u5171\u4e94\u4e2a\u8f93\u5165\uff0c\u4e00\u4e2a<code>levels</code>\u7684\u5c5e\u6027\u3002\u8fd9\u91cc\u9700\u8981\u660e\u786e\u8f93\u5165\u548c\u5c5e\u6027\u7684\u5404\u4e2a\u542b\u4e49\uff0c\u9700\u8981\u53c2\u8003nncf\u4e2d\u7684\u5bfc\u51faonnx\u65f6\u5019\u7684\u6e90\u7801\u3002 \u5730\u5740\uff1a<code>nncf/torch/quantization/quantize_functions.py</code> \u53c2\u8003\u6e90\u7801\uff1a</p> <pre><code>class ExportQuantizeToFakeQuantize(torch.autograd.Function):\n    @staticmethod\n    def symbolic(g, input_, levels, input_low, input_high, output_low, output_high):\n        return g.op(add_domain(\"FakeQuantize\"), input_, input_low, input_high, output_low, output_high, levels_i=levels)\n    @staticmethod\n    def forward(ctx, input_, levels, input_low, input_high, output_low, output_high):\n        return torch.clone(input_)\n    @staticmethod\n    def backward(ctx, grad_output):\n        # backward is not used during export\n        return grad_output\n</code></pre> <p>\u641c\u7d22<code>ExportQuantizeToFakeQuantize</code> \u5f97\u5230layer\u5b9a\u4e49  </p> <p>\u5730\u5740<code>nncf/torch/quantization/layers.py</code> Line 249</p> <pre><code>def run_export_quantization(self, x: torch.Tensor):\n        if self._export_mode == QuantizerExportMode.FAKE_QUANTIZE:\n            x, levels, input_low, input_high = self._prepare_fq_export_quantization(x)\n            return ExportQuantizeToFakeQuantize.apply(x, levels, input_low, input_high, input_low, input_high)\n</code></pre> <p>\u4ece\u8fd9\u91cc\u53ef\u4ee5\u770b\u51fa output_low = input_low output_high = input_high \u8ffd\u6eaf<code>_prepare_fq_export_quantization</code>\u65b9\u6cd5</p> <pre><code>def _prepare_fq_export_quantization(self, x: torch.Tensor):\n         x, level_high, level_low, input_low, input_high = self._prepare_export_quantization(x)\n         with no_jit_trace():\n             levels = level_high - level_low + 1\n         return x, levels, input_low, input_high\n</code></pre> <p>\u8ffd\u6eaf<code>_prepare_export_quantization</code>\u65b9\u6cd5\uff0c\u8fd9\u91cc\u4ee5\u5bf9\u79f0\u91cf\u5316\u4e3a\u4f8b</p> <pre><code>def _prepare_export_quantization(self, x: torch.Tensor):\n         with no_jit_trace():\n             input_low, input_high = self._get_input_low_input_high(self.scale,self.level_low,self.level_high,self.eps)\n             level_low = self.level_low\n             level_high = self.level_high\n             if self._half_range:\n                 x = torch.min(torch.max(x, input_low), input_high)\n                 level_low = 2 * self.level_low\n                 level_high = 2 * self.level_high + 1\n                 input_low, input_high = self._get_input_low_input_high(level_high / self.level_high * self.scale,level_low,level_high,self.eps)\n         return x, level_high, level_low, input_low, input_high\n</code></pre> <p>\u7ee7\u7eed\u8ffd\u6eaf<code>self.level_low</code> \u627e\u5230<code>calculate_level_ranges</code>\u65b9\u6cd5\uff0c\u8fd9\u91cc\u4e0d\u518d\u8d34\u4ee3\u7801\uff0c\u76f4\u63a5\u8bf4\u7ed3\u8bba <code>self.level_low</code>\u548c<code>self.level_high</code>\u5206\u522b\u8868\u793a\u91cf\u5316\u533a\u95f4\u7684\u6700\u5c0f\u503c\u548c\u6700\u5927\u503c\uff0c\u8ddf\u91cf\u5316\u5230\u6709\u7b26\u53f7\u6570\u8fd8\u662f\u65e0\u7b26\u53f7\u6570\u548c\u91cf\u5316\u7684\u4f4d\u6570\u6709\u5173\u3002 \u7efc\u5408\u300a\u6a21\u578b\u538b\u7f29\u6846\u67b6nncf\u6a21\u578b\u91cf\u5316\u4e2dQAT\u91cf\u5316\u53c2\u6570\u7684\u68af\u5ea6\u63a8\u5bfc\u300b\u8fd9\u4e00\u7bc7\u6587\u7ae0\u7684\u516c\u5f0f\uff0c\u603b\u7ed3\u5404\u4e2a\u53d8\u91cf\u542b\u4e49</p> \\[ s=\\frac{level_{high}-level_{low}}{q_{range}} \\] \\[ q_{high} = q_{low} + q_{range} \\] \\[ \\operatorname{fakequantize}( x,q_{low},q_{range} ) = \\frac{round(s \\cdot (\\operatorname{clip}(x, q_{low}, q_{high}) - q_{low}))}{s} + q_{low} \\] <p>\u516c\u5f0f\u4e2d\u7684 \\(q_{low},q_{high}\\) \u5373\u5bf9\u5e94\u6e90\u7801\u4e2d\u7684<code>input_low</code>\u3001<code>input_high</code> \u7136\u800c\uff0cmqbench\u4e2d\u91c7\u7528\u7684\u662f\u91cf\u5316\u7684\u6807\u51c6\u516c\u5f0f\uff0c\u5982\u4f55\u5bf9\u5e94\u5462\uff1f\u6216\u8005\u8bf4\u4e24\u79cd\u516c\u5f0f\u5982\u4f55\u8f6c\u6362\u5462\uff1f \u9996\u5148\u7ed9\u51fa\u91cf\u5316\u7684\u6807\u51c6\u516c\u5f0f</p> \\[ \\operatorname{fakequantize}( x,scale,zeropoint) = scale * (clip(round(\\frac{x}{scale} + zeropoint),level_{low},level_{high}) - zeropoint) \\] <p>\u4e5f\u5c31\u662f\u9700\u8981\u627e\u5230 \\(q_{low},q_{high}\\) \u4e0e \\(scale,zeropoint\\) \u7684\u5bf9\u5e94\u5173\u7cfb \u5bf9openvino\u4e2d<code>FakeQuantize</code>\u7684\u8868\u793a\u516c\u5f0f\u8fdb\u884c\u53d8\u6362</p> \\[ sinv := \\frac{1}{s} \\] \\[ \\begin{align*} \\operatorname{fakequantize}( x,q_{low},q_{range} ) &amp;= \\frac{round(s \\cdot (\\operatorname{clip}(x, q_{low}, q_{high}) - q_{low}))}{s} + q_{low} \\\\ &amp;= sinv \\cdot round( (\\operatorname{clip}(\\frac{x - q_{low}}{sinv}, 0, \\frac{q_{range}}{sinv}))) + q_{low} \\\\ &amp;= sinv  \\cdot [round( \\operatorname{clip}(\\frac{x - q_{low}}{sinv}, 0, \\frac{q_{range}}{sinv})) + \\frac{q_{low}}{sinv}] \\\\ &amp;= sinv  \\cdot [\\operatorname{clip}(round(\\frac{x - q_{low}}{sinv}), 0,level_{high}-level_{low}) + \\frac{q_{low}}{sinv}] \\\\ &amp;= sinv  \\cdot [\\operatorname{clip}(round(\\frac{x}{sinv} + ( level_{low} - \\frac{q_{low}}{sinv})), level_{low},level_{high}) - (level_{low}-\\frac{q_{low}}{sinv})] \\end{align*} \\] <p>\u5bf9\u6bd4\u516c\u5f0f\u53ef\u4ee5\u5f97\u5230</p> \\[ s=\\frac{level_{high}-level_{low}}{q_{range}} \\] \\[ q_{high} = q_{low} + q_{range} \\] \\[ scale=1/s \\] \\[ zeropoint=level_{low}-s \\cdot q_{low} \\] <p>\u901a\u8fc7\u4ee5\u4e0a\u5316\u7b80\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b\u7ec4\uff0c\u89e3\u51fa\u6765\u65e2\u53ef\u4ee5\u5f97\u5230\u4e24\u79cd\u8868\u793a\u65b9\u6cd5\u7684\u8f6c\u6362\u5173\u7cfb \u4e0b\u9762\u7ed9\u51fa\u8f6c\u6362\u4ee3\u7801</p> <pre><code>scale = np.abs(np.asarray(scale, dtype=np.float64).reshape(-1))\nzero_point = np.asarray(np.round(zero_point), dtype=np.int64).reshape(-1)\nlevel_range = np.round(level_high) - np.round(level_low)\n\ninput_range = scale * level_range\ninput_high = (np.round(level_high).astype(np.int64) - zero_point).astype(np.float64) * input_range / level_range\n\ninput_low = input_high - input_range\n</code></pre> <p>\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0czero_point \u8981\u6c42\u662f\u4e00\u4e2a\u5b9a\u70b9\u6570\uff0c\u4e14\u4f4d\u4e8e\u91cf\u5316\u533a\u95f4\u5185\u3002scale\u8981\u6c42\u4e3a\u5927\u4e8e0\u7684\u503c\u3002 zero_point\u7684\u5904\u7406\u5728mqbench\u7684\u5904\u7406\u4e2d\u4e5f\u53ef\u4ee5\u770b\u5230</p> <pre><code>zero_point = (zero_point.round() - zero_point).detach() + zero_point\n</code></pre> <p>\u4e0b\u9762\u987a\u4fbf\u7ed9\u51fa<code>qmin</code>,<code>qmax</code>\u5230<code>scale</code>\u3001<code>zeropoint</code></p> <pre><code>y_scale = (input_high - input_low) / (level_high - level_low)\ny_zero_point = (level_low * input_high - level_high * input_low) / (input_high - input_low)\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8805%E6%97%A5%2016%E6%97%B630%E5%88%8647%E7%A7%92/#mqbench-onnx","title":"\u5bf9mqbench onnx\u7b97\u5b50\u7684\u66ff\u6362","text":"<p>\u4e3b\u8981\u662f\u5c06mqbench\u81ea\u5b9a\u4e49\u7684\u4f2a\u91cf\u5316\u7b97\u5b50\u5168\u90e8\u8f6c\u6362\u4e3a<code>FakeQuantize</code> \u516c\u5f0f\u4e0a\u4e2a\u5c0f\u7ed3\u5df2\u7ecf\u8ba8\u8bba\u8fc7\uff0c\u4e0b\u9762\u76f4\u63a5\u7ed9\u51faonnx\u8282\u70b9\u7684\u66ff\u6362\u4ee3\u7801</p> <pre><code>for node in graph.node:\n    # code ...\n    # Create a node (NodeProto)\n    fakeq_inputnames = [item % tensor_name for item in ['input_min_%s', 'input_max_%s','output_min_%s','output_max_%s']]\n    node_def = helper.make_node(\n    'FakeQuantize', # node name\n    [tensor_name, *fakeq_inputnames], # inputs\n    [output_name], # outputs\n    levels=levels, # Attributes\n    domain=\"org.openvinotoolkit\",\n    name=node.name\n    )\n    node_defs.append(node_def)\n    scale = np.abs(np.asarray(scale, dtype=np.float64).reshape(-1))\n    zero_point = np.clip(np.asarray(np.round(zero_point), dtype=np.int64).reshape(-1), a_min=qmin, a_max=qmax)\n    qrange = np.round(qmax) - np.round(qmin)\n\n    input_range = scale * qrange\n    input_high = (np.round(qmax).astype(np.int64) - zero_point).astype(np.float64) * input_range / qrange\n\n    input_low = input_high - input_range\n\n    input_low_size = input_low.size\n    try:\n        next_node = inp2node[node.output[0]][0][0]\n        fake_node = out2node[next_node.input[1]]\n        tensor = name2data[fake_node.input[0]]\n        shape_length = len(tensor.shape)\n        new_shape = [-1, ] + [1,] * (shape_length - 1)\n\n    except:\n        new_shape = [-1, ]\n    if input_low_size != 1:\n        input_low = input_low.reshape(*new_shape)\n        input_high = input_high.reshape(*new_shape)\n    input_low = input_low.astype(np.float32)\n    input_high = input_high.astype(np.float32)\n    for initializer_name,value_tensor in zip(fakeq_inputnames,[input_low, input_high, input_low, input_high]):\n        if initializer_name in insert_initializer_names:\n            continue\n        initializer = numpy_helper.from_array(value_tensor)\n        initializer.name = initializer_name\n        insert_initializer_names.add(initializer_name)\n        graph.initializer.append(initializer)\n</code></pre> <p>\u6b64\u5904\u4ee3\u7801\u7684<code>qmax,qmin</code>\u8868\u793a<code>level_low</code>,<code>level_high</code>\u3002 \u5220\u9664\u8fd9\u4e9b\u8282\u70b9\u4ee5\u540e\uff0c\u9700\u8981\u5bf9\u6574\u4e2aonnx\u6a21\u578b\u6267\u884c\u4e00\u904d\u62d3\u6251\u6392\u5e8f\uff0c\u5220\u9664\u65e0\u7528\u7684<code>initializer</code></p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8805%E6%97%A5%2016%E6%97%B630%E5%88%8647%E7%A7%92/#reluunsigned-activation","title":"Relu\u7b49unsigned activation\u5728\u5bf9\u79f0\u91cf\u5316\u65f6\u7684\u7279\u6b8a\u64cd\u4f5c","text":"<p>\u8bbe\u7f6e\u91cf\u5316\u65b9\u5f0f\u4e3a\u5bf9\u79f0\u91cf\u5316\u65f6\uff0c\u4e3a\u4e86\u5145\u5206\u5229\u7528\u91cf\u5316\u533a\u95f4\uff0cnncf\u7684setting\u662f\u5c06\u91cf\u5316\u533a\u95f4\u8c03\u6574\u4e3a</p> \\[ [0, 2^{numbits} - 1] \\] <p>\u5bf9\u5e94\u64cd\u4f5c\u4ee3\u7801\u4e3a</p> <pre><code>aqconfig_8bit = copy.deepcopy(qconfig.activation)\naq_symmetry = True if is_symmetric_quant(qconfig.activation.p.keywords['qscheme']) else False\naqconfig_8bit.p.keywords['quant_min'] = 0\naqconfig_8bit.p.keywords['quant_max'] = 2 ** 8 - 1\n\naqconfig_8bit.p.keywords['factory_kwargs'] = {'not_calc_quant_min_max':True}\nfor node in node_to_quantize_output:\n    if aq_symmetry:\n        if node.op == \"call_module\" and isinstance(modules[node.target], self.module_type_to_quant_unsigned):\n            logger.info(\"Set {} post act quantize to 8 bit unsigned type.\".format(node.name))\n            fake_quantizer = aqconfig_8bit()\n</code></pre> <p>\u5176\u5b9e\uff0c\u8fd9\u91cc\u8fd8\u6d89\u53ca\u5230\u66f4\u4e3a\u590d\u6742\u7684\u5904\u7406\u903b\u8f91\uff0c\u6bd4\u5982upsample\u7684\u7684\u8f93\u5165\u662fRelu\u540e\u7684\u7ed3\u679c\u7684\u8bdd\uff0cupsample\u540e\u9762\u7684FQ\u7b97\u5b50\u4f9d\u7136\u662funsigned\u7c7b\u578b\u7684\uff0c\u8fd9\u91cc\u6211\u91c7\u7528bfs\u5c42\u5e8f\u904d\u5386\u83b7\u5f97\u8f93\u5165\u5c42\u7684\u8f93\u51fa\u7ed3\u679c\u662f\u5426\u662funsigned\u7684\uff0c\u5982\u679c\u6709\u4e00\u4e2a\u4e0d\u662funsigned\uff0c\u90a3\u4e48\u5f53\u524d\u5c42\u7684FQ\u5c31\u662fsigned\u7684\u3002 \u5982\u679c\u8f93\u5165\u5c42\u6ca1\u6709\u627e\u5230\uff0c\u90a3\u4e48\u5c31\u6536\u96c6\u6240\u6709\u8f93\u5165\u5c42\u7684\u6240\u6709\u8f93\u5165\u5c42\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8805%E6%97%A5%2016%E6%97%B630%E5%88%8647%E7%A7%92/#weight-7bit","title":"weight \u7684 7bit\u91cf\u5316","text":"<p>\u4e3a\u4e86\u89e3\u51b3\u5728AVX2 and AVX-512\u6307\u4ee4\u96c6\u4e0b\u76848bit\u8ba1\u7b97<code>overflow</code>\u95ee\u9898\uff0cnncf\u4e2dweight\u5168\u90e8\u91c7\u75287bit\u91cf\u5316\u3002\u8fd9\u91cc\u5982\u679c\u4e0d\u8fdb\u884c\u5904\u7406\uff0c\u786e\u5b9e\u4f1a\u9020\u6210openvino\u63a8\u7406\u7ed3\u679c\u4e0etorch\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u4e00\u81f4\u3002\u56e0\u6b64\u9700\u8981\u5728\u91cf\u5316\u65f6\u5bf9weight\u7684\u91cf\u5316\u8fc7\u7a0b\u505a\u7279\u6b8a</p> <pre><code>def _weight_quant(self, model: GraphModule, qconfig):\n    logger.info(\"Replace module to qat module.\")\n    wqconfig_8bit = copy.deepcopy(qconfig)\n    wq_symmetry = True if is_symmetric_quant(qconfig.weight.p.keywords['qscheme']) else False\n    numbits = 8\n    logger.info('Now all weight quantizers will effectively use only 7 bits out of 8 bits. This resolves the overflow issue problem on AVX2 and AVX-512 machines.')\n    wqconfig_8bit.weight.p.keywords['quant_min'] = -2 ** (numbits - 2) if wq_symmetry else 0\n\n    wqconfig_8bit.weight.p.keywords['quant_max'] = 2 ** (numbits - 2) - 1 if wq_symmetry else 2 ** (numbits - 1) - 1\n\n    wqconfig_8bit.weight.p.keywords['factory_kwargs'] = {'not_calc_quant_min_max':True}\n    flattened_qconfig_dict = get_flattened_qconfig_dict({'': wqconfig_8bit})\n    propagate_qconfig_(model, flattened_qconfig_dict)\n    self._qat_swap_modules(model, self.additional_qat_module_mapping)\n    return model\n</code></pre> <p>\u8fd8\u9700\u8981\u5728ObserverBase\u4ee3\u7801\u4e2d\u589e\u52a0\u4e00\u70b9\u903b\u8f91 \u5728<code>__init__</code>\u521d\u59cb\u5316\u65b9\u6cd5\u4e2d\u6dfb\u52a0</p> <pre><code>factory_kwargs = deepcopy(factory_kwargs)\nself.not_calc_quant_min_max = factory_kwargs.pop('not_calc_quant_min_max', False) if isinstance(factory_kwargs,dict) else False\n</code></pre> <p>\u4fee\u6539<code>_calculate_qmin_qmax</code>\u65b9\u6cd5</p> <pre><code>@torch.jit.export\ndef _calculate_qmin_qmax(self) -&gt; Tuple[int, int]:\n        if self.has_customized_qrange:\n            # some code ...\n            if self.not_calc_quant_min_max:\n                quant_min, quant_max = self.quant_min, self.quant_max\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8805%E6%97%A5%2016%E6%97%B630%E5%88%8647%E7%A7%92/#_1","title":"\u5199\u5728\u6700\u540e","text":"<p>\u8be5\u9879\u76ee\u597d\u6bd4\u673a\u68b0\u884c\u4e1a\u7684\u9006\u5411\u5de5\u7a0b\uff0c\u4e0d\u8fc7\u96be\u5ea6\u76f8\u5bf9\u5c0f\u4e00\u4e9b\u3002\u901a\u8fc7\u5bf9nncf\u7684\u5206\u6790\uff0c\u4f7f\u5f97\u4e00\u822c\u7684\u8bad\u7ec3\u6846\u67b6\u90fd\u53ef\u4ee5\u6309\u7167\u4ee5\u4e0a\u7684setting\u5b9e\u73b0\u5230openvino\u4e0b\u7684\u8f6c\u6362\uff0c\u4e5f\u7b97\u5bf9mqbench\u505a\u4e86\u70b9\u8d21\u732e\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/","title":"\u4e00\u6587\u603b\u7ed3TensorRT\u4e0b\u4e24\u79cd\u91cf\u5316\u65b9\u5f0fQAT\u548cPTQ\u7684\u90e8\u7f72","text":"<p>\u672c\u6587\u5199\u4e8e2022\u5e742\u670821\u65e5 12\u65f619\u5206</p> <p>\u672c\u6587\u4e3b\u8981\u662f\u4ee3\u7801\u4e3a\u4e3b\uff0c\u4e0d\u6d89\u53caQAT\u8bad\u7ec3loss\u4e0d\u6536\u655b\u5982\u4f55\u89e3\u51b3\u7b49\u8bad\u7ec3\u6280\u5de7\u3002 PTQ\u548cQAT\u4e24\u79cd\u6982\u5ff5\u5982\u679c\u8bfb\u8005\u8fd8\u4e0d\u61c2\uff0c\u5efa\u8bae\u5148\u4e86\u89e3\u540e\u518d\u6765\u770b\u672c\u7bc7\u6587\u7ae0\u3002 \u672c\u6587\u6240\u6709\u7248\u672c\u4e3aTensorRT8.0\u7248\u672c\uff0ctrt7.2\u5f00\u59cb\u652f\u6301\u7528\u4e8eQAT\u7528\u7684set dynamic range API\uff0c8.0\u5f00\u59cb\u652f\u6301onnx\u4e2d<code>Q/DQ</code>\u7b97\u5b50\u7684\u89e3\u6790\uff0c\u672c\u6587\u89e3\u6790\u6765\u4f1a\u5bf9\u8fd9\u4e24\u79cd\u65b9\u5f0f\u505a\u8bf4\u660e\u3002 \u672c\u6587\u5168\u90e8\u4ee3\u7801\u4e3a\u4e86\u65b9\u4fbf\u6f14\u793a\uff0c\u4e3b\u8981\u4e3apython\uff0c\u7531\u4e8eAPI\u57fa\u672c\u4e00\u81f4\uff0cC++\u7248\u672c\u8bf7\u81ea\u884c\u79fb\u690d\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#tensorrtptq","title":"\u4e00\u3001TensorRT\u81ea\u5e26PTQ","text":"<p>\u4ee5\u91cf\u5316resnet50\u4e3a\u4f8b</p> <pre><code>import torch\nimport os\nimport sys\nimport torch.nn.functional as F\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nimport torchvision.models as models\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport tqdm\nimport tensorrt as trt\nimport os\nimport pycuda.driver as cuda\nimport pycuda.autoinit\nfrom PIL import Image\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport os\nimport os.path as osp\ndef test(model, device, test_loader):\n     old_training_state = model.training\n     model.eval()\n     test_loss = 0\n     correct = 0\n     lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n     for data, target in tqdm.tqdm(test_loader):\n         data, target = data.to(device), target.to(device)\n         with torch.no_grad():\n             output = model(data)\n         test_loss += lossLayer(output, target).item()\n         pred = output.argmax(dim=1, keepdim=True)\n         correct += pred.eq(target.view_as(pred)).sum().item()\n     test_loss /= len(test_loader.dataset)\n     model.train(old_training_state)\n     print('\nTest set: Average loss: {:.4f}, Accuracy: {:.3f}%\n'.format(\n         test_loss, 100. * correct / len(test_loader.dataset)\n     ))\n</code></pre> <p>\u51c6\u5907\u6570\u636e</p> <pre><code># change valdir to your imagenet dataset validation directory\nvaldir = '~/MyAICode/dataset/ImageNet/val'\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\nval_loader = torch.utils.data.DataLoader(\n         datasets.ImageFolder(valdir, transforms.Compose([\n             transforms.Resize(256),\n             transforms.CenterCrop(224),\n             transforms.ToTensor(),\n             normalize,\n         ])),batch_size=128, shuffle=False, num_workers=24, pin_memory=True)\n</code></pre> <p>\u6d4b\u8bd5\u539f\u59cb\u6a21\u578b\u7cbe\u5ea6\u5e76\u5bfc\u51faonnx</p> <pre><code>resnet50 = models.resnet50(pretrained=True)\ndevice = torch.device('cuda')\nresnet50.to(device)\n# consistent with reported at https://pytorch.org/vision/stable/models.html\ntest(resnet50, device, val_loader)\nresnet50 = resnet50.to('cpu')\ntorch.onnx.export(resnet50.cpu().eval(), torch.rand(1,3,224,224), 'resnet50.onnx', input_names=['input'],output_names=['output'],\n                  dynamic_axes={'input':{0:'batch'}, 'output':{0:'batch'}}, do_constant_folding=True)\n</code></pre> <p>\u51c6\u5907\u6821\u6b63\u5668</p> <pre><code>class ImageNetEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n     def __init__(self, val_data, cache_file, batch_size=32):\n         # Whenever you specify a custom constructor for a TensorRT class,\n         # you MUST call the constructor of the parent explicitly.\n         trt.IInt8EntropyCalibrator2.__init__(self)\n         self.cache_file = cache_file\n         # Every time get_batch is called, the next batch of size batch_size will be copied to the device and returned.\n         normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n         self.data = datasets.ImageFolder(val_data, transforms.Compose([\n             transforms.Resize(256),\n             transforms.CenterCrop(224),\n             transforms.ToTensor(),\n             normalize,\n         ]))\n         self.dataset_length = len(self.data)\n         self.batch_size = batch_size\n         self.current_index = 0\n         # Allocate enough memory for a whole batch.\n         self.device_input = cuda.mem_alloc(4 * 3 * 224 * 224 * self.batch_size)\n     def get_batch_size(self):\n         return self.batch_size\n     # TensorRT passes along the names of the engine bindings to the get_batch function.\n     # You don't necessarily have to use them, but they can be useful to understand the order of\n     # the inputs. The bindings list is expected to have the same ordering as 'names'.\n     def get_batch(self, names):\n         if self.current_index + self.batch_size &gt; self.dataset_length:\n             return None\n         current_batch = int(self.current_index / self.batch_size)\n         if current_batch % 10 == 0:\n             print(\"Calibrating batch {:}, containing {:} images\".format(current_batch, self.batch_size))\n         batch = np.ascontiguousarray(torch.cat([self.data[i][0] for i in range(self.current_index, self.current_index + self.batch_size)], dim = 0).numpy().ravel())\n         cuda.memcpy_htod(self.device_input, batch)\n         self.current_index += self.batch_size\n         return [self.device_input]\n     def read_calibration_cache(self):\n         # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n         if os.path.exists(self.cache_file):\n             with open(self.cache_file, \"rb\") as f:\n                 return f.read()\n     def write_calibration_cache(self, cache):\n         with open(self.cache_file, \"wb\") as f:\n             f.write(cache)\n     def get_algorithm(self):\n         return trt.CalibrationAlgoType.MINMAX_CALIBRATION\n</code></pre> <pre><code>class ModelData(object):\n     MODEL_PATH = \"resnet50.onnx\"\n     OUTPUT_NAME = \"output\"\n     # The original model is a float32 one.\n     DTYPE = trt.float32\n</code></pre> <pre><code>TRT_LOGGER = trt.Logger()\ndef GiB(val):\n     return val * 1 &lt;&lt; 30\n</code></pre> <p>\u51c6\u5907\u6784\u5efa\u63a8\u7406engine</p> <pre><code># This function builds an engine from a onnx model.\ndef build_int8_engine(onnx_filepath, calib, max_batch_size=32):\n     explicit_batch = 1 &lt;&lt; (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n     # trt.Runtime(TRT_LOGGER) as runtime\n     with trt.Builder(TRT_LOGGER) as builder, builder.create_network(explicit_batch) as network, \\\\\n         builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser:\n         # We set the builder batch size to be the same as the calibrator's, as we use the same batches\n         # during inference. Note that this is not required in general, and inference batch size is\n         # independent of calibration batch size.\n         builder.max_batch_size = max_batch_size\n         config.max_workspace_size = GiB(1) # 8G\n         config.set_flag(trt.BuilderFlag.INT8)\n         config.set_flag(trt.BuilderFlag.FP16)\n         config.int8_calibrator = calib\n         # Parse model file\n         with open(onnx_filepath, 'rb') as model:\n             if not parser.parse(model.read()):\n                 for error in range(parser.num_errors):\n                     TRT_LOGGER.log(TRT_LOGGER.ERROR, parser.get_error(error))\n                 raise ValueError('Failed to parse the ONNX file.')\n         TRT_LOGGER.log(TRT_LOGGER.INFO, f'input number: {network.num_inputs}')\n         TRT_LOGGER.log(TRT_LOGGER.INFO, f'output number: {network.num_outputs}')\n         # set optimization profile\n         profile = builder.create_optimization_profile()\n         input_name = network.get_input(0).name\n         profile.set_shape(input_name, min=(1, 3, 224, 224), opt=(min(32,max_batch_size), 3, 224, 224), max=(max_batch_size, 3, 224, 224))\n         config.add_optimization_profile(profile)\n         # Build engine and do int8 calibration.\n         # \u76f4\u63a5\u6784\u9020\u53ef\u4ee5\u5e8f\u5217\u5316\u7684\u6a21\u578b\n#         plan = builder.build_serialized_network(network, config)\n         # \u53cd\u5e8f\u5217\u5316\n#         return runtime.deserialize_cuda_engine(plan)\n         engine = builder.build_engine(network, config)\n         with open('int8.engine', \"wb\") as f:\n             f.write(engine.serialize())\n         return engine\n</code></pre> <pre><code>val_data = '~/MyAICode/dataset/ImageNet/val'\ncalibration_cache = \"imagenet_calibration.cache\"\ncalib = ImageNetEntropyCalibrator(val_data, cache_file=calibration_cache, batch_size = 64)\n</code></pre> <pre><code># Inference batch size can be different from calibration batch size.\nbatch_size = 256\nonnx_file = ModelData.MODEL_PATH\nengine = build_int8_engine(onnx_file, calib, batch_size)\n</code></pre> <p>\u51c6\u5907input/output\u663e\u5b58\u7533\u8bf7\u548ccuda stream\u76f8\u5173</p> <pre><code>def load_test_case(pagelocked_buffer, img):\n     copy_size = img.ravel().size\n     np.copyto(pagelocked_buffer[:int(copy_size)], img.ravel())\n# Simple helper data class that's a little nicer to use than a 2-tuple.\nclass HostDeviceMem(object):\n     def __init__(self, host_mem, device_mem):\n         self.host = host_mem\n         self.device = device_mem\n     def __str__(self):\n         return \"Host:\" + str(self.host) + \"Device:\" + str(self.device)\n     def __repr__(self):\n         return self.__str__()\n# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\ndef allocate_buffers(engine):\n     inputs = []\n     outputs = []\n     bindings = []\n     stream = cuda.Stream()\n     print('max_batch_size', engine.max_batch_size)\n     for binding in engine:\n         print('binding', binding, engine.get_binding_shape(binding),engine.get_binding_dtype(binding))\n         size = trt.volume(engine.get_binding_shape(binding)[1:]) * engine.max_batch_size\n         print(size)\n         dtype = trt.nptype(engine.get_binding_dtype(binding))\n         # Allocate host and device buffers\n         host_mem = cuda.pagelocked_empty(size, dtype)\n         device_mem = cuda.mem_alloc(host_mem.nbytes)\n         # Append the device buffer to device bindings.\n         bindings.append(int(device_mem))\n         # Append to the appropriate list.\n         if engine.binding_is_input(binding):\n             inputs.append(HostDeviceMem(host_mem, device_mem))\n         else:\n             outputs.append(HostDeviceMem(host_mem, device_mem))\n     return inputs, outputs, bindings, stream\n</code></pre> <pre><code>inputs, outputs, bindings, stream = allocate_buffers(engine)\n</code></pre> <p>\u63a8\u7406\u51fd\u6570</p> <pre><code># This function is generalized for multiple inputs/outputs.\n# inputs and outputs are expected to be lists of HostDeviceMem objects.\ndef do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n     # Transfer input data to the GPU.\n     [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n     # Run inference.\n     context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n     # Transfer predictions back from the GPU.\n     [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n     # Synchronize the stream\n     stream.synchronize()\n     # Return only the host outputs.\n     return [out.host for out in outputs]\n</code></pre> <p>\u4f7f\u7528trt\u505a\u63a8\u7406\uff0c\u5e76\u6d4b\u8bd5\u6a21\u578b\u7cbe\u5ea6</p> <pre><code>def test_tensorrt(engine, test_loader):\n     test_loss = 0\n     correct = 0\n     lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n     with engine.create_execution_context() as context:\n         context.set_optimization_profile_async(0, stream.handle)\n         for data, target in test_loader:\n             data = data.numpy()\n             input_shape = engine.get_binding_shape(0)\n             input_shape[0] = data.shape[0]\n             context.set_binding_shape(0,input_shape)\n             if not context.all_binding_shapes_specified:\n                 raise RuntimeError(\"Not all input dimensions are specified for the exeuction context\")\n             load_test_case(inputs[0].host, data)\n             # =======================================\n             # The common do_inference function will return a list of outputs - we only have one in this case.\n             pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream, batch_size=data.shape[0])\n             output = torch.as_tensor(pred[0]).view(-1, 1000)[:data.shape[0]]\n             test_loss += lossLayer(output, target).item()\n             pred = output.argmax(dim=1, keepdim=True)\n             correct += pred.eq(target.view_as(pred)).sum().item()\n         # del context if not reuse\n         del context\n     test_loss /= len(test_loader.dataset)\n     print('\nTest set: Average loss: {:.4f}, Accuracy: {:.3f}%\n'.format(\n         test_loss, 100. * correct / len(test_loader.dataset)\n     ))\n</code></pre> <p>\u6d4b\u901f\u51fd\u6570</p> <pre><code>import time\ndef test_tensorrt_for_test(engine):\n     test_loss = 0\n     correct = 0\n     lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n     i = 0\n     total_time_span = 0\n     with engine.create_execution_context() as context:\n         context.set_optimization_profile_async(0, stream.handle)\n         input_shape = engine.get_binding_shape(0)\n         input_shape[0] = engine.max_batch_size\n         context.set_binding_shape(0,input_shape)\n         if not context.all_binding_shapes_specified:\n             raise RuntimeError(\"Not all input dimensions are specified for the exeuction context\")\n         # warm up\n         print('input_shape', input_shape)\n         data = np.random.rand(*input_shape).astype(np.float32)\n         load_test_case(inputs[0].host, data)\n         for i in range(10):\n             pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream, batch_size=engine.max_batch_size)\n         for i in range(100):\n#             data = np.random.rand(*input_shape).astype(np.float32)\n#             load_test_case(inputs[0].host, data)\n             # =======================================\n             # The common do_inference function will return a list of outputs - we only have one in this case.\n             start_time = time.time()\n             pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream, batch_size=engine.max_batch_size)\n             time_span = time.time() - start_time\n             total_time_span += time_span\n         total_time_span /= 100.0\n         print('total_time_span', total_time_span)\n         # del context if not reuse\n         del context\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#int8","title":"INT8 \u63a8\u7406","text":"<pre><code># change valdir to your imagenet dataset validation directory\nvaldir = '~/MyAICode/dataset/ImageNet/val'\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\ntest_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(valdir, transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        normalize,\n])),batch_size=256, shuffle=False, num_workers=24, pin_memory=True)\n</code></pre> <pre><code>test_tensorrt(engine, test_loader)\n#\u7ed3\u679c\u4e3a Test set: Average loss: 0.9614, Accuracy: 76.090%\ntest_tensorrt_for_test(engine)\n# \u7ed3\u679c\u4e3a total_time_span 0.03211389064788819 \u5728 RTX 2080TI\u4e0a\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#fp16","title":"FP16","text":"<pre><code>def build_engine(onnx_filepath, enable_fp16 = False, trt_logger = None, max_batch_size = 256):\n    explicit_batch = 1 &lt;&lt; (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    trt_logger = trt_logger or trt.Logger(trt.Logger.VERBOSE)\n    with trt.Builder(trt_logger) as builder, builder.create_network(explicit_batch) as network, \\\\\n        builder.create_builder_config() as config, trt.OnnxParser(network, trt_logger) as parser:\n        config.max_workspace_size = GiB(1)\n        if enable_fp16:\n            config.set_flag(trt.BuilderFlag.FP16)\n        # Parse model file\n        with open(onnx_filepath, 'rb') as model:\n            if not parser.parse(model.read()):\n                for error in range(parser.num_errors):\n                    trt_logger.log(trt_logger.ERROR, parser.get_error(error))\n                raise ValueError('Failed to parse the ONNX file.')\n        trt_logger.log(trt_logger.INFO, f'input number: {network.num_inputs}')\n        trt_logger.log(trt_logger.INFO, f'output number: {network.num_outputs}')\n        input_name = network.get_input(0).name  # input_image_A\n        # set optimization profile\n        profile = builder.create_optimization_profile()\n        profile.set_shape(input_name, min=(1, 3, 224, 224), opt=(max_batch_size, 3, 224, 224), max=(max_batch_size, 3, 224, 224))\n        config.add_optimization_profile(profile)\n        builder.max_batch_size = max_batch_size\n        engine = builder.build_engine(network, config)\n        if enable_fp16:\n            with open('fp16.engine', \"wb\") as f:\n                f.write(engine.serialize())\n        else:\n            with open('fp32.engine', \"wb\") as f:\n                f.write(engine.serialize())\n        return engine\n</code></pre> <pre><code>batch_size = 256\nonnx_file = ModelData.MODEL_PATH\nengine = build_engine(onnx_file, enable_fp16=True, max_batch_size=batch_size)\n</code></pre> <pre><code>inputs, outputs, bindings, stream = allocate_buffers(engine)\n</code></pre> <pre><code>test_tensorrt(engine, test_loader)\n# Test set: Average loss: 0.9619, Accuracy: 76.106%\ntest_tensorrt_for_test(engine)\n# total_time_span 0.05484504699707031\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#fp32","title":"FP32","text":"<pre><code>batch_size = 256\nonnx_file = ModelData.MODEL_PATH\nengine = build_engine(onnx_file, enable_fp16=False, max_batch_size=batch_size)\ninputs, outputs, bindings, stream = allocate_buffers(engine)\n</code></pre> <pre><code>test_tensorrt(engine, test_loader)\n# Test set: Average loss: 0.9618, Accuracy: 76.130%\ntest_tensorrt_for_test(engine)\n# total_time_span 0.18927677154541014\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#_1","title":"\u603b\u7ed3","text":"<p>\u901a\u8fc7\u4e0a\u9762int8\u3001fp16\u3001fp32\u7684\u6d4b\u901f\u5b9e\u9a8c\u53ef\u4ee5\u770b\u5230int8\u7684\u52a0\u901f\u6548\u679c\u8fd8\u662f\u975e\u5e38\u660e\u663e\u7684\uff0c\u5e76\u4e14\u672c\u5c0f\u8282\u7ed9\u51fa\u4e86\u4f7f\u7528\u81ea\u5e26PTQ\u505aint8\u63a8\u7406\u7684\u57fa\u672c\u6d41\u7a0b\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#dynamic_rangeapiqat","title":"\u4e8c\u3001\u4f7f\u7528\u8bbe\u7f6edynamic_range\u7684api\u505aQAT","text":"<p>\u672c\u7ae0\u4f7f\u7528MQBench\u6a21\u578b\u91cf\u5316\u6846\u67b6\u5bf9\u6a21\u578b\u505aPTQ\u548cQAT\uff0c\u8fd9\u91ccQAT\u7684\u7ed3\u679c\u65e0\u6cd5\u6f14\u793a\uff0c\u4e0d\u8fc7\u8fc7\u7a0b\u4ee3\u7801\u4e0e\u4f18\u5316\u6a21\u578b\u6ca1\u6709\u533a\u522b\uff0c\u6240\u4ee5\u8bfb\u8005\u5728\u8fc1\u79fb\u5230\u81ea\u5df1\u7684\u9879\u76ee\u4e2d\u65f6\uff0c\u53ef\u4ee5\u81ea\u884c\u586b\u5145\uff0c\u4e5f\u53ef\u4ee5\u53bbMQBench\u5b98\u65b9git\u590d\u5236\u3002 \u9996\u5148\uff0c\u5bfc\u51fa\u76f8\u5173\u5305</p> <pre><code>import torch\nimport os\nimport sys\n# \u6211\u8fd9\u91cc\u6ca1\u6709\u5b89\u88c5\uff0c\u6240\u4ee5\u91c7\u7528\u8fd9\u79cd\u65b9\u5f0f\u52a0\u5165\u5e93\nsys.path.insert(0, os.path.abspath('./MQBench'))\nfrom mqbench.convert_deploy import convert_deploy\nfrom mqbench.prepare_by_platform import prepare_by_platform, BackendType\nfrom mqbench.utils.state import enable_calibration, enable_quantization\nimport mqbench\nfrom mqbench.convert_deploy import convert_deploy\nimport torchvision.models as models\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport tqdm\nimport tensorrt as trt\nimport os\nimport pycuda.driver as cuda\nimport pycuda.autoinit\nfrom PIL import Image\nimport numpy as np\n</code></pre> <p>\u5bfc\u51faonnx\u6b65\u9aa4\u4e0e\u4e0a\u4e00\u7ae0\u8282\u6ca1\u6709\u5dee\u522b\uff0c\u6240\u4ee5\u8fd9\u91cc\u7701\u7565\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#mqbench","title":"MQBench \u91cf\u5316\u8fc7\u7a0b","text":"<pre><code>model = resnet50.cpu().train()\nmodel_mqbench = prepare_by_platform(model, BackendType.Tensorrt)\nenable_calibration(model_mqbench)\nmodel_mqbench.to(device)\nmodel_mqbench.eval()\n# calibration loop PTQ process\nfor data, target in tqdm.tqdm(val_loader):\n        data, target = data.to(device), target.to(device)\n        with torch.no_grad():\n            model_mqbench(data)\n# \u4e0b\u9762\u53ef\u4ee5\u81ea\u884c\u5b9a\u4e49QAT\u6b65\u9aa4\nenable_quantization(model_mqbench)\nmodel_mqbench.train()\n# QAT loop ...\n</code></pre> <p>\u6d4b\u8bd5\u91cf\u5316\u6a21\u578b\u6a21\u578b\u7cbe\u5ea6\uff0ctest\u51fd\u6570\u4e0e\u4e0a\u4e00\u7ae0\u76f8\u540c</p> <pre><code>test(model_mqbench, device, val_loader)\n</code></pre> <p>\u5bfc\u51faonnx</p> <pre><code>input_shape_dict={'input': [256, 3, 224, 224]}\nconvert_deploy(model_mqbench.eval(), BackendType.Tensorrt, input_shape_dict, model_name=\"resnet50-mqbench\")\n</code></pre> <p>\u7531\u4e8e\u8fd9\u91cconnx\u8f93\u51fa\u65f6\u9759\u6001\u8f93\u5165\uff0c\u4e3a\u4e86\u652f\u6301\u52a8\u6001batch\u6211\u8fd9\u91cc\u9700\u8981\u6539\u4e00\u4e0b</p> <pre><code>import onnx\ndef change_input_dim(model):\n    # Use some symbolic name not used for any other dimension\n    sym_batch_dim = \"N\"\n    # or an actal value\n    actual_batch_dim = 1\n    # The following code changes the first dimension of every input to be batch-dim\n    # Modify as appropriate ... note that this requires all inputs to\n    # have the same batch_dim\n    inputs = model.graph.input\n    for input in inputs:\n        # Checks omitted.This assumes that all inputs are tensors and have a shape with first dim.\n        # Add checks as needed.\n        dim1 = input.type.tensor_type.shape.dim[0]\n        # update dim to be a symbolic value\n        dim1.dim_param = sym_batch_dim\n        # or update it to be an actual value:\n#         dim1.dim_value = actual_batch_dim\ndef apply(transform, infile, outfile):\n    model = onnx.load(infile)\n    transform(model)\n    onnx.save(model, outfile)\napply(change_input_dim, \"resnet50-mqbench_deploy_model.onnx\", \"resnet50-mqbench_deploy_model.onnx\")\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#onnxengine","title":"\u91cf\u5316\u540e\u5bfc\u51fa\u7684onnx\u8f6cengine","text":"<pre><code>import onnx\nimport json\ndef onnx2trt(onnx_model,\n             trt_path,\n             dataset_path,\n             max_batch_size=256,\n             batch_size=1,\n             cali_batch=10,\n             log_level=trt.Logger.ERROR,\n             max_workspace_size=1 &lt;&lt; 30,\n             device_id=0,\n             mode='fp32',\n             dynamic_range_file=None):\n    if os.path.exists(trt_path):\n        print(f'The \"{trt_path}\" exists. Remove it and continue.')\n        os.remove(trt_path)\n    device = torch.device('cuda:{}'.format(device_id))\n    # create builder and network\n    logger = trt.Logger(log_level)\n    builder = trt.Builder(logger)\n    EXPLICIT_BATCH = 1 &lt;&lt; (int)(\n        trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    network = builder.create_network(EXPLICIT_BATCH)\n    builder.max_batch_size = max_batch_size\n    # parse onnx\n    parser = trt.OnnxParser(network, logger)\n    if isinstance(onnx_model, str):\n        onnx_model = onnx.load(onnx_model)\n    if not parser.parse(onnx_model.SerializeToString()):\n        error_msgs = ''\n        for error in range(parser.num_errors):\n            error_msgs += f'{parser.get_error(error)}\n'\n        raise RuntimeError(f'parse onnx failed:\n{error_msgs}')\n    config = builder.create_builder_config()\n    config.max_workspace_size = max_workspace_size\n    if mode == 'int8':\n        config.set_flag(trt.BuilderFlag.INT8)\n        config.set_flag(trt.BuilderFlag.FP16)\n        if dynamic_range_file:\n            with open(dynamic_range_file, 'r') as f:\n                dynamic_range = json.load(f)['tensorrt']['blob_range']\n            for input_index in range(network.num_inputs):\n                input_tensor = network.get_input(input_index)\n                if input_tensor.name in dynamic_range:\n                    amax = dynamic_range[input_tensor.name]\n                    input_tensor.dynamic_range = (-amax, amax)\n                    print(f'Set dynamic range of {input_tensor.name} as [{-amax}, {amax}]')\n            for layer_index in range(network.num_layers):\n                layer = network[layer_index]\n                output_tensor = layer.get_output(0)\n                if output_tensor.name in dynamic_range:\n                    amax = dynamic_range[output_tensor.name]\n                    output_tensor.dynamic_range = (-amax, amax)\n                    print(f'Set dynamic range of {output_tensor.name} as [{-amax}, {amax}]')\n        else:\n            from calibrator import ImagenetCalibrator\n            calidir = os.path.join(dataset_path, 'cali')\n            dataset = datasets.ImageFolder(calidir, transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])]))\n            cali_num = min(len(dataset), batch_size * cali_batch)\n            cali_dataset = torch.utils.data.Subset(dataset, indices=torch.arange(cali_num))\n            cali_loader = torch.utils.data.DataLoader(cali_dataset, batch_size=batch_size, shuffle=False,\n                                                      num_workers=1, pin_memory=False)\n            calibrator = ImagenetCalibrator(cali_loader, cache_file='imagenet.cache')\n            config.int8_calibrator = calibrator\n            print(f'Calibration Set!')\n    # create engine\n    with torch.cuda.device(device):\n        # set optimization profile\n        input_name = network.get_input(0).name\n        profile = builder.create_optimization_profile()\n        profile.set_shape(input_name, min=(1, 3, 224, 224), opt=(max_batch_size, 3, 224, 224), max=(max_batch_size, 3, 224, 224))\n        config.add_optimization_profile(profile)\n        builder.max_batch_size = max_batch_size\n        engine = builder.build_engine(network, config)\n    with open(trt_path, mode='wb') as f:\n        f.write(bytearray(engine.serialize()))\n    return engine\n</code></pre> <pre><code>engine = onnx2trt('resnet50-mqbench_deploy_model.onnx','resnet50-mqbench-int8.engine','',dynamic_range_file='./resnet50-mqbench_clip_ranges.json', mode=\"int8\")\n</code></pre> <p>\u63a5\u4e0b\u6765\u6b65\u9aa4\u4e0e\u4e0a\u4e00\u7ae0\u6ca1\u4ec0\u4e48\u533a\u522b</p> <pre><code>def load_test_case(pagelocked_buffer, img):\n    copy_size = img.ravel().size\n    np.copyto(pagelocked_buffer[:int(copy_size)], img.ravel())\n# Simple helper data class that's a little nicer to use than a 2-tuple.\nclass HostDeviceMem(object):\n    def __init__(self, host_mem, device_mem):\n        self.host = host_mem\n        self.device = device_mem\n    def __str__(self):\n        return \"Host:\n\" + str(self.host) + \"\nDevice:\n\" + str(self.device)\n    def __repr__(self):\n        return self.__str__()\n# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\ndef allocate_buffers(engine):\n    inputs = []\n    outputs = []\n    bindings = []\n    stream = cuda.Stream()\n    print('max_batch_size', engine.max_batch_size)\n    for binding in engine:\n        print('binding', binding, engine.get_binding_shape(binding),engine.get_binding_dtype(binding))\n        size = trt.volume(engine.get_binding_shape(binding)[1:]) * engine.max_batch_size\n        print(size)\n        dtype = trt.nptype(engine.get_binding_dtype(binding))\n        # Allocate host and device buffers\n        host_mem = cuda.pagelocked_empty(size, dtype)\n        device_mem = cuda.mem_alloc(host_mem.nbytes)\n        # Append the device buffer to device bindings.\n        bindings.append(int(device_mem))\n        # Append to the appropriate list.\n        if engine.binding_is_input(binding):\n            inputs.append(HostDeviceMem(host_mem, device_mem))\n        else:\n            outputs.append(HostDeviceMem(host_mem, device_mem))\n    return inputs, outputs, bindings, stream\ninputs, outputs, bindings, stream = allocate_buffers(engine)\n# This function is generalized for multiple inputs/outputs.\n# inputs and outputs are expected to be lists of HostDeviceMem objects.\ndef do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n    # Transfer input data to the GPU.\n    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n    # Run inference.\n    context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n    # Transfer predictions back from the GPU.\n    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n    # Synchronize the stream\n    stream.synchronize()\n    # Return only the host outputs.\n    return [out.host for out in outputs]\ndef test_tensorrt(engine, test_loader):\n    test_loss = 0\n    correct = 0\n    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n    with engine.create_execution_context() as context:\n        context.set_optimization_profile_async(0, stream.handle)\n        for data, target in test_loader:\n            data = data.numpy()\n            input_shape = engine.get_binding_shape(0)\n            input_shape[0] = data.shape[0]\n            context.set_binding_shape(0,input_shape)\n            if not context.all_binding_shapes_specified:\n                raise RuntimeError(\"Not all input dimensions are specified for the exeuction context\")\n            load_test_case(inputs[0].host, data)\n            # =======================================\n            # The common do_inference function will return a list of outputs - we only have one in this case.\n\n            pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream, batch_size=data.shape[0])\n            output = torch.as_tensor(pred[0]).view(-1, 1000)[:data.shape[0]]\n            test_loss += lossLayer(output, target).item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n        # del context if not reuse\n        del context\n    test_loss /= len(test_loader.dataset)\n    print('\nTest set: Average loss: {:.4f}, Accuracy: {:.3f}%\n'.format(\n        test_loss, 100. * correct / len(test_loader.dataset)\n\n    ))\nimport time\ndef test_tensorrt_for_test(engine):\n    test_loss = 0\n    correct = 0\n    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n    i = 0\n    total_time_span = 0\n    with engine.create_execution_context() as context:\n        context.set_optimization_profile_async(0, stream.handle)\n        input_shape = engine.get_binding_shape(0)\n        input_shape[0] = engine.max_batch_size\n        context.set_binding_shape(0,input_shape)\n        if not context.all_binding_shapes_specified:\n            raise RuntimeError(\"Not all input dimensions are specified for the exeuction context\")\n        # warm up\n        print('input_shape', input_shape)\n        data = np.random.rand(*input_shape).astype(np.float32)\n        load_test_case(inputs[0].host, data)\n        for i in range(10):\n            pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream, batch_size=engine.max_batch_size)\n        for i in range(100):\n#             data = np.random.rand(*input_shape).astype(np.float32)\n#             load_test_case(inputs[0].host, data)\n            # =======================================\n            # The common do_inference function will return a list of outputs - we only have one in this case.\n\n            start_time = time.time()\n            pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream, batch_size=engine.max_batch_size)\n            time_span = time.time() - start_time\n\n            total_time_span += time_span\n        total_time_span /= 100.0\n        print('total_time_span', total_time_span)\n        # del context if not reuse\n        del context\n</code></pre> <p>\u6d4b\u8bd5\u7cbe\u5ea6\u548c\u901f\u5ea6</p> <pre><code># change valdir to your imagenet dataset validation directory\nvaldir = '~/MyAICode/dataset/ImageNet/val'\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\ntest_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(valdir, transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        normalize,\n])),batch_size=256, shuffle=False, num_workers=24, pin_memory=True)\n</code></pre> <pre><code>test_tensorrt(engine, test_loader)\n# Test set: Average loss: 0.9699, Accuracy: 75.804%\ntest_tensorrt_for_test(engine)\n# total_time_span 0.032126998901367186\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#_2","title":"\u603b\u7ed3","text":"<p>\u4ece\u4e0a\u9762\u5b9e\u9a8c\u53ef\u4ee5\u770b\u51fa\u7ecf\u8fc7MQBench\u7684PTQ\u6240\u5f97\u7cbe\u5ea6\u8981\u7a0d\u900aTRT\u81ea\u5e26\u7684\uff0c\u8fd9\u91cc\u4e3a\u4e86\u4e00\u81f4\uff0c\u6211\u90fd\u662f\u91c7\u7528\u76f8\u540c\u7684\u7b97\u6cd5\uff0c\u539f\u56e0\u6682\u65f6\u672a\u77e5\uff0c\u53ef\u80fd\u662fTRT\u5185\u90e8\u591a\u8dd1\u4e86\u4e00\u4e9bepoch\uff0c\u4e0d\u8fc7\u5dee\u7684\u4e0d\u591a\u3002MQBench\u4e3b\u653bQAT\u7b97\u6cd5\uff0c\u56e0\u6b64\u4e5f\u7b97\u5404\u6709\u6240\u957f\u5427\u3002\u4e0d\u8fc7\u503c\u5f97\u9ad8\u5174\u7684\u662f\uff0cMQBench\u8fd9\u79cd\u91c7\u7528\u8bbe\u7f6e<code>dynamic range</code>\u7684\u65b9\u5f0f\u63a8\u7406\u901f\u5ea6\u548c\u5b98\u65b9PTQ\u7684\u6ca1\u5dee\u522b\uff0c\u6240\u4ee5\u4f7f\u7528MQBench\u505aQAT\u5f97\u5230\u7684\u6a21\u578b\u5f97\u5230\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u4f9d\u7136\u4f1a\u5f88\u660e\u663e\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/2022%E5%B9%B402%E6%9C%8821%E6%97%A5%2012%E6%97%B619%E5%88%8614%E7%A7%92/#onnxqdq","title":"\u4e09\u3001\u4f7f\u7528onnx\u7684Q/DQ\u7b97\u5b50","text":"<p>\u8be5\u65b9\u6cd5\u4e0e<code>Q/DQ</code>\u7b97\u5b50\u63d2\u5165\u7b97\u5b50\u4f4d\u7f6e\u6709\u5173\uff0c\u5177\u4f53\u53ef\u4ee5\u53c2\u8003trt\u5b98\u65b9\u6587\u7ae0\u548c\u5b98\u65b9\u5b9e\u73b0git\u4e2d\u7684\u91cf\u5316\u5de5\u5177\u3002 \u5730\u5740\u4e3a<code>https://github.com/NVIDIA/TensorRT/tree/master/tools/pytorch-quantization</code> \u65e2\u7136<code>dynamic range</code>\u7684\u65b9\u5f0f\u53ef\u4ee5\u7528\uff0c\u8fd9\u79cd\u65b9\u5f0f\u7559\u5728\u4ee5\u540e\u7814\u7a76\u5427\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/","title":"\u5bf9\u57fa\u4e8eKL\u6563\u5ea6\u786e\u5b9a\u91cf\u5316\u53c2\u6570\u65b9\u6cd5\u7684\u539f\u7406\u6027\u89e3\u8bfb","text":"<p>\u672c\u6587\u5199\u4e8e2024\u5e7407\u670814\u65e5 \u65e9\u4e0a\u5341\u70b9</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_1","title":"\u96f6. \u524d\u8a00","text":"<p>\u57288bit\u6a21\u578b\u91cf\u5316\u4e2d\uff0cNVIDIA\u63d0\u51fa\u7684\u57fa\u4e8eKL\u6563\u5ea6\u7684\u5bf9\u79f08bit\u91cf\u5316\u65b9\u6848\u662f\u4e3b\u6d41\u7684\u65b9\u6848\u3002</p> <p>\u8be5\u65b9\u6848\u7531\u82f1\u4f1f\u8fbe\u57282017\u5e74\u7684\u4e00\u4e2aPPT\u4e2d\u9996\u6b21\u63d0\u51fa\uff0c\u5f53\u65f6\u5e76\u6ca1\u6709\u5f00\u6e90\uff0c\u4ec5\u5f00\u653e\u4e86\u90e8\u5206\u4f2a\u4ee3\u7801\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002</p> <p></p> <p>\u518d\u5230\u540e\u6765\uff0c\u968f\u7740<code>pytorch_quantization</code>\u7684\u5f00\u6e90\uff0c\u4f5c\u4e3aPTQ\u7684\u4e3b\u6d41\u65b9\u6cd5\u4e4b\u4e00\uff0c\u8be5\u65b9\u6cd5\u6e90\u4ee3\u7801\u4e5f\u968f\u4e4b\u5f00\u6e90\u3002</p> <p>https://github.com/NVIDIA/TensorRT/blob/release/8.6/tools/pytorch-quantization/pytorch_quantization/calib/histogram.py</p> <p>\u4f46\u662f\u7f51\u4e0a\u5173\u4e8e\u8be5\u65b9\u6cd5\u7684\u539f\u7406\u6027\u89e3\u8bfb\u5927\u591a\u542b\u7cca\u4e0d\u6e05\uff0c\u7406\u89e3\u5f88\u6d45\u3002</p> <p>\u672c\u6587\u4f5c\u8005\u7ecf\u8fc7\u6570\u6b21\u601d\u8003\uff0c\u5199\u4e0b\u672c\u6587\u7ed9\u51fa\u8be5\u65b9\u6cd5\u539f\u7406\u4e0a\u7684\u89e3\u91ca\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_2","title":"\u4e00. \u91cd\u65b0\u601d\u8003\u6a21\u578b\u91cf\u5316\u8fc7\u7a0b","text":"<p>\u6a21\u578b\u91cf\u5316\u662f\u6307\u5c06\u795e\u7ecf\u7f51\u7edc\u7684\u6d6e\u70b9\u7b97\u6cd5\u8f6c\u6362\u4e3a\u5b9a\u70b9\u3002\u6a21\u578b\u91cf\u5316\u8fc7\u7a0b\u53ef\u4ee5\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u5c06\u6a21\u578b\u4ece FP32 \u8f6c\u6362\u4e3a INT8\uff0c\u4ee5\u53ca\u4f7f\u7528 INT8 \u8fdb\u884c\u63a8\u7406\u3002</p> <p>\u795e\u7ecf\u7f51\u7edc\u7684\u63a8\u7406\u7531\u6d6e\u70b9\u8fd0\u7b97\u6784\u6210\u3002<code>FP32</code> \u548c <code>INT8</code> \u7684\u503c\u57df\u662f [(2\u2212 \\(2^{23}\\) )\u00d7 \\(2^{127}\\) ,( \\(2^{23}\\)  - 2)\u00d7 \\(2^{127}\\) ] \u548c [\u2212128,127] \uff0c\u800c\u53d6\u503c\u6570\u91cf\u5927\u7ea6\u5206\u522b\u4e3a  \\(2^{32}\\)  \u548c  \\(2^8\\)  \u3002<code>FP32</code> \u53d6\u503c\u8303\u56f4\u975e\u5e38\u5e7f\uff0c\u56e0\u6b64\uff0c\u5c06\u7f51\u7edc\u4ece <code>FP32</code> \u8f6c\u6362\u4e3a <code>INT8</code> \u5e76\u4e0d\u50cf\u6570\u636e\u7c7b\u578b\u8f6c\u6362\u622a\u65ad\u90a3\u6837\u7b80\u5355\u3002</p> <p></p> <p>\u4e00\u822c\uff0c\u5b9a\u4e49\u7ebf\u6027\u91cf\u5316\u64cd\u4f5c\u516c\u5f0f\uff1a</p> \\[ X_{quant} = clip(round(\\frac{X}{scale} + zero\\_point), q_{min}, q_{max}) \\] <p>\u53cd\u91cf\u5316\u516c\u5f0f\u4e3a</p> \\[ X_{dequant} = (X_{quant} - zero\\_point) * scale \\] <p>\u5176\u4e2d round \u8868\u793a\u820d\u5165\u64cd\u4f5c\uff0cclip \u622a\u65ad\u8d85\u8fc7\u91cf\u5316\u57df\u8303\u56f4\uff0czero_point\u8868\u793a\u91cf\u5316\u504f\u79fb\u96f6\u70b9\uff0cscale\u8868\u793a\u91cf\u5316\u7f29\u653e\u7cfb\u6570\u3002</p> <p>\u4ece\u4e0a\u9762\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\uff0c\u4e00\u4e2a\u5f20\u91cf\u7684\u91cf\u5316\u8bef\u5dee\u6765\u6e90\u4e8e\u622a\u65ad\u8bef\u5dee\u548c\u820d\u5165\u8bef\u5dee\u3002</p> <p>\u6839\u636e\u504f\u79fb\u91cfzero_point\u662f\u5426\u4e3a 0\uff0c\u53ef\u4ee5\u5c06\u6d6e\u70b9\u6570\u7684\u7ebf\u6027\u91cf\u5316\u5206\u4e3a\u4e24\u7c7b-\u5bf9\u79f0\u91cf\u5316\u548c\u975e\u5bf9\u79f0\u91cf\u5316\u3002</p> <p>\u5728NVIDIA\u63d0\u51fa\u7684\u57fa\u4e8eKL\u6563\u5ea6\u7684\u5bf9\u79f08bit\u91cf\u5316\u65b9\u6848\u4e2d\uff0c\u53c2\u6570\u786e\u5b9a\u5982\u4e0b</p> \\[ \\begin{align*} &amp;q_{min} = -127 \\\\ &amp;q_{max} = 127 \\\\ &amp;zero\\_point = 0 \\end{align*} \\] <p>\u552f\u4e00\u9700\u8981\u786e\u5b9a\u5c31\u662f\u91cf\u5316\u7f29\u653e\u7cfb\u6570<code>scale</code>\uff0c\u5982\u679c\u91c7\u7528\u6700\u5927\u533a\u95f4\u503c\u65b9\u5f0f\u786e\u5b9a<code>scale</code>\uff0c\u5219scale\u53ef\u4ee5\u4e0b\u9762\u65b9\u5f0f\u8ba1\u7b97</p> \\[ scale = \\frac{X_{max} - X_{min}} {Q_{max} - Q_{min}} \\] <p>\u4f46\u8fd9\u79cd\u65b9\u5f0f\u4e0d\u4e00\u5b9a\u6700\u4f18\uff0c\u6bd4\u5982\u6709\u4e00\u4e2a\u5f02\u5e38\u70b9\u503c\u5f88\u5927\uff0c\u5f15\u5165\u4e4b\u540e\u5bfc\u81f4\u4e0a\u5f0f\u5206\u5b50\u5f88\u5927\uff0c\u4ece\u800c<code>scale</code>\u503c\u5f88\u5927\u3002</p> <p>\u7f29\u653e\u7cfb\u6570\u5f88\u5927\u4f1a\u5bfc\u81f4 \\(X\\) \u4e2d\u7684\u8f83\u5927\u8303\u56f4\u5185\u7684\u6570\u6620\u5c04\u5230\u4e00\u4e2a\u6574\u6570\u4f4d\u7f6e\u4e0a\uff0c\u5728\u53cd\u91cf\u5316\u8fc7\u7a0b\u4e2d\u5f15\u8d77\u8f83\u5927\u91cf\u5316\u8bef\u5dee\uff0c\u6240\u4ee5\u8ba1\u7b97scale\u65f6\u5019\uff0c\u4e0a\u9762\u7684\u5206\u5b50\u4e0d\u4e00\u5b9a\u975e\u5f97\u662f\u539f\u6765float\u6570\u503c\u7684\u8303\u56f4\u5927\u5c0f\u3002</p> <p>\u7531\u6b64\uff0cNVIDIA\u63d0\u51fa\u901a\u8fc7\u8861\u91cf\u7ecf\u8fc7\u591a\u4e2a\u5019\u9009<code>scale</code>\u53c2\u6570\u91cf\u5316\u53cd\u91cf\u5316\u7684\u5206\u5e03\u4e0e\u539f\u59cb\u5206\u5e03\u7684\u6700\u5c0f\u7684KL\u6563\u5ea6\u786e\u5b9a\u91c7\u7528\u54ea\u4e2a<code>scale</code>\u3002</p> <p>\u5df2\u77e5\u539f\u59cb\u6570\u636e\u5206\u5e03\uff0c\u5c06\u539f\u59cb\u6570\u636e\u5206\u5e03 \u91c7\u7528 \u4e00\u79cd\u91cf\u5316\u53cd\u91cf\u5316\u65b9\u5f0f\uff0c\u4f7f\u5f97\u8be5\u65b9\u6cd5\u5f97\u5230\u7684\u5206\u5e03\u4e0e\u539f\u59cb\u5206\u5e03KL\u6563\u5ea6\u6700\u5c0f,\u8fd9\u5c31\u662fKL\u6821\u51c6\u7684\u6838\u5fc3\u601d\u60f3</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_3","title":"\u4e8c. \u539f\u59cb\u6570\u636e\u5206\u5e03\u8868\u793a","text":"<p>\u73b0\u5b9e\u4e16\u754c\u7684\u6a21\u62df\u503c\u9700\u8981\u7ecf\u8fc7\u79bb\u6563\u5316\u624d\u53ef\u4ee5\u5728\u6570\u5b57\u4e16\u754c\u8fdb\u884c\u8868\u793a\uff0c\u6211\u4eec\u5e38\u5e38\u91c7\u7528\u7d2f\u52a0\u6765\u8868\u793a\u79ef\u5206\uff0c\u91c7\u7528\u9891\u7387\u76f4\u65b9\u56fe\u6765\u8868\u793a\u4e00\u4e2a\u6982\u7387\u5206\u5e03\u3002</p> <p>\u539f\u59cb\u6570\u636e\u7684\u8868\u793a\u81ea\u7136\u4e5f\u91c7\u7528\u9891\u7387\u76f4\u65b9\u56fe\u6765\u8868\u793a\uff0c\u5c06\u539f\u59cb\u6570\u636e\u5212\u5206<code>N</code>\u4e2a\u5c0f\u533a\u95f4\uff0c\u7edf\u8ba1\u843d\u5728\u8fd9\u4e9b\u4e2a\u5c0f\u533a\u95f4\u4e0a\u7684\u6570\u7684\u4e2a\u6570\uff0c\u8fdb\u800c\u4ee3\u8868\u539f\u59cb\u6570\u636e\u5206\u5e03\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_4","title":"\u4e09. \u5982\u4f55\u91cf\u5316\u4e00\u4e2a\u9891\u7387\u76f4\u65b9\u56fe","text":"<p>\u518d\u56de\u987e\u6570\u503c\u91cf\u5316\u8fc7\u7a0b\uff0c\u6309\u7167KL\u6563\u5ea6\u9971\u548c\u91cf\u5316\u65b9\u5f0f\u91cf\u5316</p> \\[ \\begin{align*} &amp; X_{quant} = clip(round(\\frac{abs(X)}{scale}), 0, 127) \\\\ &amp; X_{dequant} = X_{quant}  * scale \\end{align*} \\] <p>\u91cf\u5316\u7684\u8fc7\u7a0b\u672c\u8d28\u4e0a\u662f\u5c06X\u4e0a\u7684\u6570\u653e\u5230[0, 1), [1, 2), [2, 3), ... [127, 128) \u5171128\u4e2a\u533a\u95f4\u4e0a\u9762</p> <pre><code>\u5373\nx / scale \u5c5e\u4e8e [0, 0.5) \u653e\u5230 [0, 1)\nx / scale \u5c5e\u4e8e [0.5, 1.5) \u653e\u5230 [1, 2)\nx / scale \u5c5e\u4e8e [1.5, 2.5) \u653e\u5230 [2, 3)\n...\n</code></pre> <p>\u5728int8\u8868\u793a\u4e2d\uff0c[a, a+1)\u4ec5\u5305\u542b\u4e00\u4e2a\u6570a</p> <p>\u56de\u5230X\u7684\u539f\u59cb\u5206\u5e03\u4e0a\uff0c\u9996\u5148\u5bf9X\u8fdb\u884c\u5207\u5206\u4e3a\u82e5\u5e72\u4e2a\u5c0f\u533a\u95f4\uff08\u533a\u95f4\u4e2a\u6570\u4e00\u822c\u8fdc\u5927\u4e8e\u91cf\u5316\u533a\u95f4\u4e2a\u6570\uff09\uff0c\u90a3\u4e48\u5bf9\u4e8eX\u4e2d\u5c5e\u4e8e \u5c0f\u533a\u95f4[a, b)\u7684\u6570\u6765\u8bf4\uff0c\u5e94\u8be5\u5982\u4f55\u91cf\u5316\u5462\uff1f\u6216\u8005\u8bf4\u5e94\u8be5\u600e\u6837\u5c06\u8fd9\u4e9b\u6570\u653e\u5230128\u4e2a\u91cf\u5316\u533a\u95f4\u4e0a\u9762\u5462\uff1f</p> <p>\u9996\u5148 \u5047\u8bbe \u4e00\u4e2a\u5408\u9002\u7684scale \u5df2\u7ecf\u5b58\u5728\u4e14\u627e\u5230\uff0c\u90a3\u4e48 X / scale \u5728 [a / scale, b / scale) \u533a\u95f4\u7684\u4e2a\u6570 \u5c31\u7b49\u4e8e X \u5728 [a, b) \u4e0a\u7684\u4e2a\u6570\uff0c\u5219 [a / scale, b / scale) \u4e2d\u7684\u6570 \u5e94\u8be5\u7b97\u5230 \u54ea\u4e00\u5757\u91cf\u5316\u533a\u95f4\u4e2d\u4e0a\u9762\u53bb\u5462\uff1f \u8fd9\u4e2a\u65f6\u5019\u9700\u8981\u5206\u6210\u4e24\u79cd\u60c5\u51b5\u8ba8\u8bba</p> <ol> <li>[a / scale, b / scale) \u5b8c\u5168\u5c5e\u4e8e\u91cf\u5316\u5206\u5e03\u533a\u95f4[x1, x2) \u533a\u95f4\uff0c\u5219\u6beb\u65e0\u7591\u95ee\uff0c\u91cf\u5316\u5206\u5e03\u4e2d[x1, x2) \u533a\u95f4\u9891\u7387\u6570\u91cf\u52a0\u4e0a[a / scale, b / scale)\u6570\u91cf\u5373\u53ef</li> <li>[a / scale, b / scale) \u4e0e [x1, x2)\uff0c[x3, x4) \u90fd\u6709\u4ea4\u96c6\uff0c\u90a3\u4e48\u8fd9\u4e2a\u65f6\u5019\u5c31\u9700\u8981\u7279\u6b8a\u5904\u7406\uff0c\u8003\u8651\u600e\u4e48\u5c06    [a / scale, b / scale) \u4e2d\u7684\u9891\u6570\u5206\u914d\u5230[x1, x2)\uff0c[x3, x4)\u4e2d\u53bb</li> </ol> <p>\u9488\u5bf9\u7b2c\u4e8c\u79cd\u60c5\u51b5\u6709\u4e09\u79cd\u65b9\u6848</p> <ol> <li>\u627e\u5230\u539f\u6765\u7684\u6570\u636eX\uff0c\u91cd\u65b0\u8ba1\u7b97X / scale\u76f4\u63a5.\u5206\u914d\uff08\u4e0d\u53ef\u53d6\uff0c\u540e\u7eed\u4f1a\u8ba8\u8bba\u4e3a\u4ec0\u4e48)</li> <li>TensorRT \u5f3a\u5236\u6574\u9664\u65b9\u6848\uff0c\u4ece\u539f\u59cb\u5206\u5e03\u533a\u95f4\u91cf\u5316\u5230\u533a\u95f4\u6570\u91cf\u8f83\u5c0f\u7684\u91cf\u5316\u533a\u95f4\uff0c \u5f3a\u5236\u8981\u6c42\u539f\u59cb\u5206\u5e03\u533a\u95f4\u4e2d\u7684\u5355\u4e2a\u533a\u95f4 \u53ea\u5bf9\u5e94\u5230 \u91cf\u5316\u533a\u95f4\u4e2d\u7684\u5355\u4e2a\u533a\u95f4\u4e2d\u53bb\uff08\u6216\u8005\u820d\u5f03\u6389\uff0c\u76f4\u63a5\u4e0d\u5bf9\u5e94)\uff0cpytorch-quantification tools \u4e2d\u6e90\u7801\u76ee\u524d\u8ba1\u7b97\u65b9\u5f0f\u4e3a [a / scale, b / scale) \u76f4\u63a5\u7b97\u843d\u5728\u91cf\u5316\u533a\u95f4\u7684\u7b2c int(a / scale) \u4e2a\u4e2d</li> <li>ncnn \u63d2\u503c\u65b9\u6848\uff0c[a / scale, b / scale)\u4e2d\u9891\u6570\u4e3ap\uff0c \u5047\u8bbe\u5176\u533a\u95f4\u843d\u5230 [x1, x2)\u90e8\u5206\u6bd4\u91cd\u4e3a0.3\uff0c\u843d\u5230[x3, x4)\u6bd4\u91cd\u4e3a0.7\uff0c\u5219[x1, x2) \u4f1a\u52a0\u4e0a p * 0.3\u7684\u9891\u6570\uff0c[x3, x4) \u4f1a\u52a0\u4e0a p * 0.7\u7684\u9891\u6570</li> </ol> <p>\u7b2c\u4e00\u79cd\u65b9\u6848\u9700\u8981\u7edf\u8ba1\u5e76\u5b58\u50a8\u5168\u90e8\u7684\u6fc0\u6d3b\u503c\uff0c\u4e00\u822c\u6765\u8bb2\uff0c\u591a\u4e2a\u6821\u51c6\u8f93\u5165\u6570\u636e\u4f1a\u4ea7\u751f\u591a\u4e2a\u6fc0\u6d3b\u503c\u3002\u8fd9\u4e9b\u503c\u5360\u7684\u5185\u5b58\u662f\u5f88\u9ad8\u7684\uff0c\u82e5\u5355\u6b21\u6821\u51c6\u5168\u90e8\u6fc0\u6d3b\u503c\u9700\u89812G\u7684\u5b58\u50a8\u7a7a\u95f4\uff0c\u90a3\u4e48100\u6b21\u5c31\u9700\u8981200G\u7684\u5185\u5b58\u5b58\u50a8\u6216\u8005\u786c\u76d8\u5b58\u50a8\uff0c\u8fd9\u5bf9\u4e8e\u4e00\u822c\u7528\u6237\u6765\u8bb2\u662f\u4e0d\u53ef\u53d6\u7684\u3002</p> <p>\u6240\u4ee5\u5728\u6570\u636e\u6536\u96c6\u73af\u8282\uff0c\u4e00\u822c\u751f\u6210\u9891\u7387\u76f4\u65b9\u56fe\u4e4b\u540e\u539f\u59cbX\u5c31\u4e0d\u518d\u4fdd\u5b58\u4e86\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_5","title":"\u56db. \u5019\u9009\u5f85\u91cf\u5316\u533a\u95f4\u7684\u6784\u9020","text":"<p>\u518d\u56de\u987eX\u7684\u8868\u793a\u5f62\u5f0f\uff0cX\u8868\u793a\u6210\u4e00\u4e2a\u9891\u7387\u5206\u5e03\uff0c\u7531\u82e5\u5e72\u4e2a\u533a\u95f4\u4ee5\u53ca\u8be5\u533a\u95f4\u7684\u4e0a\u7684\u9891\u6570\u7ec4\u6210\u3002 \u76ee\u6807\u662f\u5c06\u4e00\u4e2a \u539f\u59cb\u6570\u636e\u9891\u7387\u5206\u5e03 \u6309\u7167\u4e00\u5b9a\u65b9\u5f0f \u91cf\u5316\u53cd\u91cf\u5316 \u4f7f\u5f97 \u53cd\u91cf\u5316\u540e\u7684\u9891\u7387\u5206\u5e03 \u4e0e \u539f\u59cb\u6570\u636e\u9891\u7387\u5206\u5e03 KL\u6563\u5ea6\u8f83\u5c0f\uff0c\u90a3\u4e48\u5019\u9009\u5206\u5e03\u5e94\u8be5\u5982\u4f55\u6784\u9020\u5462\uff1f</p> <p>\u8bd5\u7740\u518d\u601d\u8003\u4e0b\u4e0a\u9762\u7684 \u6700\u5927\u8303\u56f4\u5bf9\u9f50\u6821\u51c6 \u8ba1\u7b97\u91cf\u5316\u53c2\u6570\u7684\u65b9\u5f0f\uff0c\u56de\u60f3\u4e0b\u8fd8\u6709\u5176\u4ed6\u8ba1\u7b97\u91cf\u5316\u53c2\u6570\u7684\u65b9\u6cd5\u4e48\uff1f \u5f53\u7136\u6709\uff0c\u6bd4\u5982\u6309\u7167 \u6570\u636e\u4e2d 0.99 \u5927\u7684\u5f53\u505a\u5176\u6700\u5927\u503c\u7136\u540e\u6309\u7167\u6700\u5927\u503c\u5bf9\u9f50\u6821\u51c6\u65b9\u5f0f\u8ba1\u7b97\u91cf\u5316\u53c2\u6570</p> <p>\u4e3a\u4ec0\u4e48\u53d60.99\u5927\u5462\uff1f\u8fd9\u662f\u56e0\u4e3a\u5728\u6fc0\u6d3b\u503c\u5f53\u4e2d\u53ef\u80fd\u5b58\u5728\u4e00\u4e9b\u503c\u8fc7\u5927\u7684\u5f02\u5e38\u70b9\uff0c\u5176\u5bf9\u4e8e\u6a21\u578b\u7cbe\u5ea6\u7684\u8d21\u732e\u5e76\u4e0d\u5927\uff0c\u4f46\u662f\u4f1a\u5f71\u54cd\u91cf\u5316\u7cbe\u5ea6\u3002</p> <p>\u90a3\u4e48\u662f\u4e0d\u662f\u5728\u5f53\u524d\u533a\u95f4\u6784\u9020\u4e2d\u4e5f\u53ef\u4ee5\u57fa\u4e8e\u201c\u5f02\u5e38\u70b9\u820d\u53bb\u201d\u7684\u601d\u8def\u6765\u6784\u9020\u5019\u9009\u5206\u5e03\u5462\uff1f</p> <p>\u7531\u6b64\u5f15\u51fa\u5019\u9009\u533a\u95f4\u7684\u6784\u9020\u65b9\u5f0f\uff0c\u5373\u4ece\u539f\u59cb\u9891\u7387\u5206\u5e03\u4e2d\u4ece\u5934\u5f00\u59cb\u622a\u53d6\u4e00\u90e8\u5206\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_6","title":"\u4e94. \u6a21\u62df\u5f02\u5e38\u70b9\u4e22\u5f03\u64cd\u4f5c","text":"<p>\u5728\u5019\u9009\u5206\u5e03\u91cf\u5316\u4e0e\u53cd\u91cf\u5316\u8fc7\u7a0b\u4e2d\u4e0d\u8003\u8651\u5047\u8bbe\u7684\u201c\u5f02\u5e38\u70b9\u533a\u95f4\u201d\u7684\u503c\uff0c\u5373\u4e3a\u201c\u4e22\u5f03\u201d\u64cd\u4f5c\u3002</p> <p>\u4e24\u4e2a\u9891\u7387\u5206\u5e03\u7684KL\u8ba1\u7b97\uff0c\u53ef\u4ee5\u7edf\u4e00\u53bb\u9664\u5f02\u5e38\u70b9\u533a\u95f4\u540e\u7684\u5c3a\u5ea6\u4e0a\u8fdb\u884c\u8ba1\u7b97\u3002</p> <p>\u539f\u59cb\u5206\u5e03\u5c06\u7591\u4f3c\u201c\u5f02\u5e38\u70b9\u201d\u533a\u95f4\u7684\u9891\u6570\u52a0\u5230\u65b0\u6784\u9020\u7684\u5019\u9009\u9891\u6570\u5206\u5e03\u7684\u6700\u540e\u4e00\u4e2a\u533a\u95f4\u4e0a\u3002</p> <p>\u8fd9\u8868\u793a\u4ec5\u4ec5\u662f\u6000\u7591\uff0c\u539f\u59cb\u53c2\u8003\u5206\u5e03\u4ecd\u9700\u8981\u8003\u8651\u8fd9\u4e9b\u70b9\u3002</p> <p>\u5982\u679c\u8fd9\u4e9b\u70b9\u5f88\u5c11\uff0c\u52a0\u5230\u672b\u5c3e\u4e5f\u5bf9\u539f\u59cb\u5206\u5e03\u6574\u4f53\u5f71\u54cd\u4e0d\u5927\uff0c\u5219KL\u6563\u5ea6\u8ba1\u7b97\u7ed3\u679c\u4f1a\u6bd4\u8f83\u5c0f\uff0c\u90a3\u4e48\u8868\u793a\u8fd9\u4e9b\u70b9\u53ef\u4ee5\u53bb\u9664\u3002\u53cd\u4e4b\u5219\u4e0d\u53ef\u4ee5\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_7","title":"\u516d. \u53cd\u91cf\u5316\u65f6\u533a\u95f4\u5206\u914d\u7684\u6620\u5c04\u5173\u7cfb","text":"<p>\u4ece\u4e00\u4e2a\u5927\u533a\u95f4\u5230\u5c0f\u533a\u95f4\u91cf\u5316\u6620\u5c04\u64cd\u4f5c\u524d\u9762\u5df2\u7ecf\u786e\u5b9a\u4e86\uff0c\u53cd\u91cf\u5316\u5982\u4f55\u5206\u914d\u6620\u5c04\u5173\u7cfb\uff0c\u6a21\u62df\u91cf\u5316\u8bef\u5dee\uff1f</p> <p>\u6bd4\u5982\u539f\u59cb\u5206\u5e03[a,b)\u548c[c,d)\u533a\u95f4\u540c\u65f6\u6620\u5c04\u5230\u91cf\u5316\u533a\u95f4[x1,x2)</p> <p>\u5219\u53cd\u91cf\u5316\u65f6\uff0c [x1, x2) \u5230 [a,b) \u548c [c,d) \u5e94\u8be5\u5982\u4f55\u5206\u914d\uff1f</p> <p>TensorRT\u91c7\u7528\u7684\u662f\u5e73\u5747\u5206\u914d\u7684\u505a\u6cd5 \u5206\u522b\u7ed9 [a,b) \u548c [c,d) \u5206\u914d \u5176 50% \u7684\u9891\u6570</p> <p>ncnn\u91c7\u7528\u7684\u662f\u8ba1\u7b97[a,b) \u548c [c,d)\u5bf9\u4e8e [x1, x2)\u7684\u8d21\u732e\uff0c\u5373\u524d\u9762\u8bf4\u7684\u843d\u5728[a,b)\u65f6\u5019\u7684\u6bd4\u91cd\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_8","title":"\u4e03. \u5355\u4e2a\u5019\u9009\u5206\u5e03\u7684\u91cf\u5316\u53cd\u91cf\u5316\u4ee3\u7801\u89e3\u8bfb","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n\nnp.random.seed(1)\n\n# \u6a21\u62df\u539f\u59cbactivation \u6570\u636e\ndata = np.random.randn(1, 64, 112, 112)\ndata = data.reshape(-1)\ndata = np.abs(np.clip(data, a_min=-4, a_max=4))\n\nfigure = plt.figure(figsize=(17, 3))\nplt.subplot(1, 5, 1)\n# \u5bf9\u6570\u636e\u8fdb\u884c\u79bb\u6563\u5316 \u67e5\u770b\u6570\u636e\u5206\u5e03\nplt.hist(data, bins=2048)\nplt.title('original data distribution')\n\n\n# Tensor \u91cf\u5316\u8bbe\u7f6e  \u5bf9\u79f0\u91cf\u5316 \u91cf\u5316zero-point = 0 \u4e14 \u6709\u7b26\u53f7\u91cf\u5316=&gt; \u91cf\u5316\u8303\u56f4\u4e3a[-127, 127] (-128\u4f1a\u820d\u6389)\n# \u5bf9Activation\u91c7\u7528per-tensor \u91cf\u5316\uff0c\u5373\u6574\u4e2atensor\u91c7\u7528\u4e00\u4e2ascale\u503c\nnum_bits = 8\nunsigned = False\nnbins = 1 &lt;&lt; (num_bits - 1 + int(unsigned))\n\nquant_max_int_value = nbins - 1\n\n#  =&gt; [0 - 127]\n# \u91c7\u7528 \u6700\u5927\u503c\u5bf9\u9f50\u6821\u51c6\u65b9\u5f0f\u8ba1\u7b97 \u91cf\u5316\u53c2\u6570\ndynamic_range = np.abs(data).max()\nscale = dynamic_range / quant_max_int_value\n# \u91cf\u5316\nquantized_data = np.clip(np.round(data / scale), -quant_max_int_value, quant_max_int_value)\n# \u53cd\u91cf\u5316\ndequantized_data = quantized_data * scale\n\n\n# \u67e5\u770b\u91cf\u5316\u540e\u4e0a\u8ff0\u5206\u5e03\nplt.subplot(1, 5, 2)\nplt.hist(quantized_data, bins=128)\nplt.title('quantized data using max calibration')\nplt.subplot(1, 5, 3)\nplt.hist(dequantized_data, bins=128)\nplt.title('dequantized data using max calibration')\n\n\n# \u76f4\u65b9\u56fe\u91cf\u5316\n# \u6a21\u62df\u5bf9\u6574\u4e2a\u5206\u5e03\u7684\u91cf\u5316\u8fc7\u7a0b\n# \u76f4\u63a5\u9488\u5bf9\u76f4\u65b9\u56fe\u8fdb\u884c\u91cf\u5316\nori_distribution, bin_edges = np.histogram(data, bins=2048, range=(0, dynamic_range))\n\n\n# \u5df2\u77e5\u539f\u59cb\u6570\u636e\u5206\u5e03\uff0c\u9700\u8981\u5c06\u539f\u59cb\u6570\u636e\u5206\u5e03 \u91c7\u7528 \u4e00\u79cd\u91cf\u5316\u53cd\u91cf\u5316 \u65b9\u5f0f \n# \u4f7f\u5f97\u8be5\u65b9\u6cd5\u5f97\u5230\u7684\u5206\u5e03\u4e0e\u539f\u59cb\u5206\u5e03KL\u6563\u5ea6\u6700\u5c0f\n# \u8fd9\u5c31\u662fKL\u6821\u51c6\u7684\u6838\u5fc3\u601d\u60f3\n\n\n# \u9009\u62e9\u5019\u9009\u533a\u95f4\uff0c\u8868\u793a\u5019\u9009\u533a\u95f4\u5bf9\u5e94\u539f\u59cb\u5206\u5e03\u4e2d\u7684\u622a\u53d6\u533a\u95f4\u4e2a\u6570\ncandidate_i = 2048\n# \u5019\u9009\u533a\u95f4\u5728\u91cf\u5316\u533a\u95f4\u4e0a\u7684\u5750\u6807\u5212\u5206\n# \u5019\u9009\u533a\u95f4\u4e2dcandidate_i \u4e2a\u7684\u5b50\u533a\u95f4\u5e94\u8be5\u4e0e  128\u4e2a\u91cf\u5316\u5b50\u533a\u95f4\u5982\u4f55\u5bf9\u5e94\n# \u6bd4\u5982 \u5982\u4f55 [a, b) \u6620\u5c04\u5230 [0, 1) \uff1f \u7b54\uff1a\u6ee1\u8db3int(a / scale) == 0\n# \u751f\u6210 [0, x1), [x1, x2), .... [x_{nbins-1}, x_{nbins}) \u8fd9\u4e9b\u533a\u95f4\n# \u5171 nbins + 1 \u8fb9\u7f18\u70b9\uff0c\u8868\u793anbins\u4e2a\u5c0f\u533a\u95f4\u3002\n# \u5373\u5c06 [0, candidate_i] nbins\u7b49\u5206\nspace = np.linspace(0, candidate_i, num=nbins + 1)\n# \u5047\u8bbe candidate_i / scale_d = nbins\n# \u5b9a\u4e49\u539f\u59cb\u5206\u5e03\u7b2ci\uff08i\u4ece0\u5f00\u59cb\uff09\u4e2a\u5b50\u533a\u95f4[a, b)\uff0c\u5355\u4e2a\u5b50\u533a\u95f4\u957f\u5ea6\u4e3ad\uff0c\u5219 [a, b) \n# \u5bf9\u5e94\u5230 \u91cf\u5316\u533a\u95f4\u7684\u7b2c int(i / scale_d) \u91cc\u9762\uff0c\u800ci = a / d\n# \u5373[a / scale, b / scale) \u5bf9\u5e94\u5230\u91cf\u5316\u533a\u95f4\u7684 \u7b2c int(a / d / scale_d) \u4e2a\n# \u4e5f\u5c31\u662f [int(a / d / scale_d), int(a / d / scale_d) + 1)\u533a\u95f4\u4e0a\n# \u5b9a\u4e49 max_i \u4e3a candidate_i \u5bf9\u5e94\u7684\u533a\u95f4\u7aef\u70b9\u503c\uff0c\u4e5f\u5c31\u662f max_i = candidate_i * d\n# \u91cf\u5316\u53c2\u6570 scale = max_i / nbins = candidate_i * d / nbins = scale_d * d\n# \u5219[a / scale, b / scale) \u5f3a\u5236\u5f52\u5c5e\u4e8e \u91cf\u5316\u533a\u95f4 [int(a / scale), int(a / scale) + 1)\u4e0a\n\n# range(candidate_i) \u8868\u793a\u6bcf\u4e2a\u533a\u95f4\u7684\u8d77\u70b9\u7684\u7d22\u5f15\uff08\u53ea\u8003\u8651\u8d77\u59cb\u70b9\u503c\uff09\n# \u4e0b\u9762\u8fd9\u53e5\u8bdd\u8868\u793a\u6839\u636e\u539f\u59cb\u533a\u95f4\u7684\u8d77\u59cbindex \u67e5\u770b\u5176\u843d\u5728\u91cf\u5316\u533a\u95f4\u7684\u54ea\u4e00\u5757\u4e0a\n# \u51cf\u4e00\u7528\u4e8e\u8ba1\u7b97\u6700\u7ec8\u7d22\u5f15\uff08\u8ba1\u7b97\u673a\u4e16\u754c \u7d22\u5f15\u4ece0\u5f00\u59cb\uff09 \ndigitized_space = np.digitize(range(candidate_i), space) - 1\n\n\n# digitized_space\u662f\u4e00\u4e2alength\u4e3acandidate_i\u7684list index\u8868\u793acandidate_i\u4e2d\u7684\u533a\u95f4\u7d22\u5f15\n# digitized_space[index] \u8868\u793a ori_distribution[index] \u8fd9\u4e2a\u533a\u95f4\u5e94\u8be5\u6620\u5c04\u5230 \u91cf\u5316\u533a\u95f4\u4e2d\u7684\u54ea\u4e00\u4e2a\u7d22\u5f15\n# \u7279\u6b8a\u5904\u7406\uff0c\u53bb\u9664\u6389\u4e3a\u539f\u59cb\u5206\u5e03\u4e2d0\u7684\u7a7a\u6863\uff0c\u4e0d\u518d\u53c2\u4e0e\u8ba1\u7b97\u3002\ndigitized_space[ori_distribution[:candidate_i] == 0] = -1\n\nnew_density_counts = np.zeros(nbins, dtype=np.float64)\n# \u6620\u5c04\u5230\u91cf\u5316\u64cd\u4f5c\nfor idx, digitized in enumerate(digitized_space):\n    if digitized != -1:\n        new_density_counts[digitized] += ori_distribution[idx]\n\n\nplt.subplot(1, 5, 4)\nx_draw = np.linspace(0, nbins, num=nbins + 1)\nplt.bar(x_draw[:-1], new_density_counts, width=np.diff(x_draw), edgecolor=\"black\", align=\"edge\")\nplt.title('quantized data using kl calibration')\n\n\n# \u6a21\u62df \u53cd\u91cf\u5316\u8fc7\u7a0b =&gt; x * scale\u4e4b\u540e\u7684\u503c\u5e94\u8be5\u5982\u4f55\u5206\u914d\n# digitized_space i=&gt;val i\u5b58\u7684\u662f\u539f\u59cb\u5206\u5e03\u7d22\u5f15\u503c val\u5b58\u7684\u662f\u91cf\u5316\u533a\u95f4\u7684\u7d22\u5f15\u503c\n# \u539f\u59cb\u5206\u5e03\u7d22\u5f15\nfrom collections import Counter\n# \u5bf9\u4e8e digitized_space \u8fdb\u884c\u7edf\u8ba1\uff0c\u7edf\u8ba1\u4e00\u4e2aval \u6709\u591a\u5c11\u4e2ai\n# \u65b9\u4fbf\u53cd\u91cf\u5316\u64cd\u4f5c\ncounter = Counter(digitized_space)\nfor key, val in counter.items():\n    if key != -1:\n        # \u8bb0\u5f55\u7ed9\u6bcf\u4e2a\u539f\u59cb\u533a\u95f4\u5206\u914d\u591a\u5c11\u9891\u6570\n        new_density_counts[key] = new_density_counts[key] / val\n\n\n# digitized_space i=&gt;val i\u5b58\u7684\u662f\u539f\u59cb\u5206\u5e03\u7d22\u5f15\u503c val\u5b58\u7684\u662f\u91cf\u5316\u533a\u95f4\u7684\u7d22\u5f15\u503c\n# \u6a21\u62df \u53cd\u91cf\u5316\u8fc7\u7a0b\nnew_density = np.zeros(candidate_i, dtype=np.float64)\nfor idx, digitized in enumerate(digitized_space):\n    if digitized != -1:\n        new_density[idx] = new_density_counts[digitized]\n\n\nplt.subplot(1, 5, 5)\nx_draw = np.linspace(0, 1, num=candidate_i + 1)\n\nplt.bar(x_draw[:-1] * dynamic_range, new_density, width=np.diff(x_draw * dynamic_range), edgecolor=\"black\", align=\"edge\")\nplt.title('dequantized data using kl calibration')\n\n\nplt.tight_layout()\nplt.savefig('show.png')\n</code></pre> <p>\u4ee3\u7801\u4e2d\u7684\u6ce8\u91ca\u5e94\u8be5\u5f88\u6e05\u6670\u4e86\uff0c\u4e0b\u9762\u7ed9\u51fa\u8f93\u51fa\u56fe\u50cf</p> <p></p> <p>\u7531\u4e0a\u56fe\u53ef\u77e5\uff0c\u9891\u7387\u76f4\u65b9\u56fe\u7684\u91cf\u5316\u4e0e\u53cd\u91cf\u5316\u5177\u6709\u6a21\u62df\u539f\u59cb\u6570\u503c\u7ef4\u5ea6\u91cf\u5316\u4e0e\u53cd\u91cf\u5316\u7684\u529f\u6548\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#kl_1","title":"\u516b. \u591a\u4e2a\u5019\u9009\u5206\u5e03\u786e\u5b9a\u6700\u5c0fKL\u4ee3\u7801\u89e3\u8bfb","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef entropy(pk, qk, axis=0):\n    \"\"\"Calculate the entropy of a distribution for given probability values.\n\n\n    compute the Kullback-Leibler divergence\n    ``S = sum(pk * log(pk / qk), axis=axis)``.\n\n    This routine will normalize `pk` and `qk` if they don't sum to 1.\n\n    Parameters\n    ----------\n    pk : sequence\n        Defines the (discrete) distribution. ``pk[i]`` is the (possibly\n        unnormalized) probability of event ``i``.\n    qk : sequence,\n        Sequence against which the relative entropy is computed. Should be in\n        the same format as `pk`.\n    axis: int, optional\n        The axis along which the entropy is calculated. Default is 0.\n\n    Returns\n    -------\n    S : float\n        The calculated entropy.\n\n\n    \"\"\"\n\n    pk = np.asarray(pk, dtype=np.float64)\n    pk = 1.0* pk / np.sum(pk, axis=axis, keepdims=True)\n\n    qk = np.asarray(qk, dtype=np.float64)\n    pk, qk = np.broadcast_arrays(pk, qk)\n    eps = 1e-6\n    qk += eps\n    qk = 1.0* qk / np.sum(qk, axis=axis, keepdims=True)\n    vec = pk * np.log(pk / qk)\n    # \u53c2\u8003 https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.rel_entr.html\n    vec[np.logical_and(pk == 0,qk &gt;= 0)] = 0\n    vec[np.logical_or(pk &lt; 0, qk &lt; 0)] = np.nan\n    S = np.sum(vec, axis=axis)\n    return S\n\n\nnp.random.seed(1)\n\n# \u6a21\u62df\u539f\u59cbactivation \u6570\u636e\ndata = np.random.randn(1, 64, 112, 112)\ndata = data.reshape(-1)\ndata = np.abs(np.clip(data, a_min=-4, a_max=4))\n\nfigure = plt.figure(figsize=(17, 3))\nplt.subplot(1, 5, 1)\n# \u5bf9\u6570\u636e\u8fdb\u884c\u79bb\u6563\u5316 \u67e5\u770b\u6570\u636e\u5206\u5e03\nplt.hist(data, bins=2048)\nplt.title('original data distribution')\n\n\n# Tensor \u91cf\u5316\u8bbe\u7f6e  \u5bf9\u79f0\u91cf\u5316 \u91cf\u5316zero-point = 0 \u4e14 \u6709\u7b26\u53f7\u91cf\u5316=&gt; \u91cf\u5316\u8303\u56f4\u4e3a[-127, 127] (-128\u4f1a\u820d\u6389)\n# \u5bf9Activation\u91c7\u7528per-tensor \u91cf\u5316\uff0c\u5373\u6574\u4e2atensor\u91c7\u7528\u4e00\u4e2ascale\u503c\nnum_bits = 8\nunsigned = False\nnbins = 1 &lt;&lt; (num_bits - 1 + int(unsigned))\n\nquant_max_int_value = nbins - 1\n\n# float =&gt; [0 - 127]\n# \u91c7\u7528 \u6700\u5927\u503c\u5bf9\u9f50\u6821\u51c6\u65b9\u5f0f\u8ba1\u7b97 \u91cf\u5316\u53c2\u6570\ndynamic_range = np.abs(data).max()\nscale = dynamic_range / quant_max_int_value\n# \u91cf\u5316\nquantized_data = np.clip(np.round(data / scale), -quant_max_int_value, quant_max_int_value)\n# \u53cd\u91cf\u5316\ndequantized_data = quantized_data * scale\n\n\n# \u67e5\u770b\u91cf\u5316\u540e\u4e0a\u8ff0\u5206\u5e03\nplt.subplot(1, 5, 2)\nplt.hist(quantized_data, bins=128)\nplt.title('quantized data using max calibration')\nplt.subplot(1, 5, 3)\nplt.hist(dequantized_data, bins=2048)\nplt.title('dequantized data using max calibration')\n\n\n# \u76f4\u65b9\u56fe\u91cf\u5316\n# \u6a21\u62df\u5bf9\u6574\u4e2a\u5206\u5e03\u7684\u91cf\u5316\u8fc7\u7a0b\n# \u76f4\u63a5\u9488\u5bf9\u76f4\u65b9\u56fe\u8fdb\u884c\u91cf\u5316\nori_distribution, bin_edges = np.histogram(data, bins=2048, range=(0, dynamic_range))\n\nstart_i = 128\ndivergences = []\n\nfor i in range(start_i, 2048+1, 1):\n\n    candidate_i = i\n\n    space = np.linspace(0, candidate_i, num=nbins + 1)\n\n    digitized_space = np.digitize(range(candidate_i), space) - 1\n\n\n    digitized_space[ori_distribution[:candidate_i] == 0] = -1\n\n    new_density_counts = np.zeros(nbins, dtype=np.float64)\n    # \u6620\u5c04\u5230\u91cf\u5316\u64cd\u4f5c\n    for idx, digitized in enumerate(digitized_space):\n        if digitized != -1:\n            new_density_counts[digitized] += ori_distribution[idx]\n\n\n    from collections import Counter\n    # \u5bf9\u4e8e digitized_space \u8fdb\u884c\u7edf\u8ba1\uff0c\u7edf\u8ba1\u4e00\u4e2aval \u6709\u591a\u5c11\u4e2ai\n    # \u65b9\u4fbf\u53cd\u91cf\u5316\u64cd\u4f5c\n    counter = Counter(digitized_space)\n    for key, val in counter.items():\n        if key != -1:\n            # \u8bb0\u5f55\u7ed9\u6bcf\u4e2a\u539f\u59cb\u533a\u95f4\u5206\u914d\u591a\u5c11\u9891\u6570\n            new_density_counts[key] = new_density_counts[key] / val\n\n\n    # digitized_space i=&gt;val i\u5b58\u7684\u662f\u539f\u59cb\u5206\u5e03\u7d22\u5f15\u503c val\u5b58\u7684\u662f\u91cf\u5316\u533a\u95f4\u7684\u7d22\u5f15\u503c\n    # \u6a21\u62df \u53cd\u91cf\u5316\u8fc7\u7a0b\n    new_density = np.zeros(candidate_i, dtype=np.float64)\n    for idx, digitized in enumerate(digitized_space):\n        if digitized != -1:\n            new_density[idx] = new_density_counts[digitized]\n\n    reference_density = ori_distribution[:candidate_i]\n    reference_density[-1] += np.sum(ori_distribution[candidate_i:])\n\n    ent = entropy(reference_density, new_density)\n    divergences.append(ent)\n\n\n# \u6c42\u51fa\u6392\u5728\u540e\u9762\u7684\u6700\u5c0f\u503c\uff0c\uff08\u4ea4\u53c9\u71b5\u540c\u7b49\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u5019\u9009\u5206\u5e03\u533a\u95f4\u8d8a\u591a\u5305\u62ec\u7684\u70b9\u4e5f\u5c31\u8d8a\u591a\uff0c\u91cf\u5316\u7cbe\u5ea6\u4e5f\u5c31\u8d8a\u9ad8\uff09\nlast_argmin = len(divergences) - 1 - np.argmin(divergences[::-1])\ncalib_amax = bin_edges[last_argmin + start_i]\n\nscale = calib_amax / quant_max_int_value\n# \u91cf\u5316\nquantized_data = np.clip(np.round(data / scale), -quant_max_int_value, quant_max_int_value)\n# \u53cd\u91cf\u5316\ndequantized_data = quantized_data * scale\n\nplt.subplot(1, 5, 4)\nplt.hist(quantized_data, bins=128)\nplt.title('quantized data using kl calibration')\nplt.subplot(1, 5, 5)\nplt.hist(dequantized_data, bins=2048)\nplt.title('dequantized data using kl calibration')\n\nplt.tight_layout()\nplt.savefig('show.png')\n</code></pre> <p>\u7531\u4e0a\u56fe\u53ef\u4ee5\u770b\u51fa\u57fa\u4e8eKL\u6563\u5ea6\u7684\u65b9\u6cd5\u4f1a\u4e22\u5f03\u6389\u540e\u9762\u6570\u91cf\u5360\u6bd4\u5f88\u5c11\u7684\u533a\u95f4\uff0c\u91c7\u7528\u4e00\u4e2a\u8f83\u5c0f\u7684scale\u8868\u793a\uff0c\u51cf\u5c0f\u91cf\u5316\u8bef\u5dee\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#activation","title":"\u4e5d. \u5bf9\u4e8e\u591a\u4e2aactivation\u503c\u7684\u9891\u7387\u76f4\u65b9\u56fe\u7684\u8fed\u4ee3\u6784\u9020\u65b9\u6848","text":"<p>\u5728\u6821\u51c6\u73af\u8282\uff0c\u6d4b\u8bd5\u6570\u636e\u4f1a\u5206\u6210\u591a\u4efd\u4f9d\u6b21\u8f93\u51fa\u5230\u6a21\u578b\u5f53\u4e2d\uff0c\u6a21\u578b\u7684\u6bcf\u4e00\u5c42\u8fdb\u800c\u4ea7\u751factivation\u503c\u3002\u90a3\u4e48\u5728\u6bcf\u6b21\u8fed\u4ee3\u540e\uff0c\u9891\u7387\u76f4\u65b9\u56fe\u5e94\u8be5\u5982\u4f55\u7d2f\u8ba1\u66f4\u65b0\u5462\uff1f</p> <p>\u53c2\u8003pytorch_quantization\u5b9e\u73b0\u5982\u4e0b\uff1a</p> <pre><code>            if self._calib_bin_edges is None and self._calib_hist is None:\n                # first time it uses num_bins to compute histogram.\n                self._calib_hist, self._calib_bin_edges = np.histogram(x_np, bins=self._num_bins)\n            else:\n                temp_amax = np.max(x_np)\n                if temp_amax &gt; self._calib_bin_edges[-1]:\n                    # increase the number of bins\n                    width = self._calib_bin_edges[1] - self._calib_bin_edges[0]\n                    # NOTE: np.arange may create an extra bin after the one containing temp_amax\n                    new_bin_edges = np.arange(self._calib_bin_edges[-1] + width, temp_amax + width, width)\n                    self._calib_bin_edges = np.hstack((self._calib_bin_edges, new_bin_edges))\n                hist, self._calib_bin_edges = np.histogram(x_np, bins=self._calib_bin_edges)\n                hist[:len(self._calib_hist)] += self._calib_hist\n                self._calib_hist = hist\n</code></pre> <p>\u7b2c\u4e00\u6b21\u65f6\u76f4\u63a5\u6784\u9020\u9891\u7387\u76f4\u65b9\u56fe\uff0c\u540e\u7eed\u8fd0\u884c\u65f6\u6b65\u9aa4\u5982\u4e0b</p> <ol> <li>\u8ba1\u7b97\u5f53\u524dactivation\u6700\u5927\u503c</li> <li>\u5982\u679c\u6700\u5927\u503c\u8d85\u8fc7\u4e86\u9891\u7387\u76f4\u65b9\u56fe\u533a\u95f4\u7684\u8868\u793a\u8303\u56f4\uff0c\u5219\u8d85\u8fc7\u90e8\u5206\u91cd\u65b0\u533a\u95f4\u6309\u7167\u539f\u6765\u7684\u5c0f\u533a\u95f4\u5bbd\u5ea6\u5411\u53f3\u6269\u5145</li> <li>\u6309\u7167\u65b0\u6784\u9020\u7684\u533a\u95f4\u7edf\u8ba1\u65b0\u7684\u9891\u7387</li> <li>\u5c06\u539f\u6765\u7edf\u8ba1\u7684\u9891\u7387\u52a0\u5230\u65b0\u7684\u9891\u7387\u76f4\u65b9\u56fe\u4e0a\u9762\u53bb</li> <li>\u4e22\u5f03\u539f\u9891\u7387\u76f4\u65b9\u56fe\uff0c\u91c7\u7528\u65b0\u7684</li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_9","title":"\u5341. \u603b\u7ed3","text":"<p>\u53bb\u5e74\u5c31\u5728\u601d\u8003\u8fd9\u4e2a\u95ee\u9898\uff0c\u76f4\u5230\u524d\u4e00\u6bb5\u65f6\u95f4\u624d\u7406\u89e3\u6574\u4e2a\u6d41\u7a0b\u4e3a\u4ec0\u4e48\u8fd9\u6837\u505a\u3002\u5e0c\u671b\u80fd\u7ed9\u8bfb\u8005\u4e00\u70b9\u542f\u53d1\uff0c\u6211\u4eec\u5728\u7528\u67d0\u9879\u6280\u672f\u7684\u65f6\u5019\uff0c\u4e0d\u80fd\u505c\u7559\u5728\u8868\u9762\uff0cknow why \u6bd4 know how\u66f4\u9ad8\u7ea7\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E5%AF%B9%E5%9F%BA%E4%BA%8EKL%E6%95%A3%E5%BA%A6%E7%A1%AE%E5%AE%9A%E9%87%8F%E5%8C%96%E5%8F%82%E6%95%B0%E6%96%B9%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E6%80%A7%E8%A7%A3%E8%AF%BB/#_10","title":"\u5341\u4e00. \u53c2\u8003\u94fe\u63a5","text":"<ul> <li>https://github.com/NVIDIA/TensorRT/blob/release/8.6/tools/pytorch-quantization/pytorch_quantization/calib/histogram.py</li> <li>https://zhuanlan.zhihu.com/p/72375164</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2021%E5%B9%B412%E6%9C%8816%E6%97%A5%2014%E6%97%B626%E5%88%8600%E7%A7%92/","title":"FasterCNNN+ROIAlign+FPN\u5728TensorRT\u4e0a\u7684\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848","text":"<p>Repo(\u6b22\u8fcestar): https://github.com/thb1314/tensorrt-onnx-fasterrcnn-fpn-roiailigin FasterRCNN\u4f5c\u4e3a\u7ecf\u5178\u7684two-staged detector\uff0c\u81f3\u4eca\u4e3a\u6b62\u5176\u7cbe\u5ea6\u914d\u5408FPN+ROIAlign\u4f9d\u7136SOTA\u3002 \u7136\u800cFasterRCNN\u5728TensorRT\u7684\u90e8\u7f72\u5374\u6ca1\u6709one-stage\u7684\u68c0\u6d4b\u5668\u90a3\u4e48\u5bb9\u6613\u3002\u56e0\u4e3aTensorRT\u8f93\u5165\u8f93\u51fa\u8981\u6c42shape\u662f\u786e\u5b9a\u503c\uff0c\u5c31\u7b97\u65b0\u7684\u7248\u672c\u652f\u6301\u52a8\u6001batch_size\uff0c\u4f46\u662f\u5728\u4e00\u5f00\u59cb\u4e5f\u8981\u786e\u5b9a\u6700\u5927\u8f93\u5165\u7684batch_size\uff0c\u4e2d\u95f4\u7684\u7b97\u5b50\u662f\u4e0d\u5141\u8bb8\u8fd0\u884c\u65f6\u66f4\u6539\u7ef4\u5ea6\u7684\u3002 \u8fd9\u6210\u4e3aFasterRCNN+FPN+ROIAlign\u5728TensorRT\u90e8\u7f72\u7684\u96be\u70b9\uff0c\u56e0\u4e3arpn\u7684\u8f93\u51fa\u9700\u8981\u7ecf\u8fc7nms+roialign\uff0c\u5c3d\u7ba1nms\u548croialign\u53ef\u4ee5\u901a\u8fc7plugin\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\uff0c\u4f46\u662fnms\u7684\u8f93\u51fa\u662f\u4e0d\u56fa\u5b9a\u7684\u3002 \u6b64\u5916\uff0c\u5728\u8ba1\u7b97roialign\u8ba1\u7b97\u65f6\uff0c\u5e94\u8be5\u91c7\u7528fpn\u54ea\u4e2a\u8f93\u51fa\u5c42\u7684feature\u662f\u6839\u636erpn\u8f93\u51fa\u7684bbox\u6765\u8ba1\u7b97\u7684\uff0connx\u5bf9\u4e8e\u8fd9\u91cc\u7684\u8ba1\u7b97\u6b65\u9aa4\u7528\u8ba1\u7b97\u56fe\u7684\u8868\u793a\u5f15\u5165\u4e86\u5927\u91cf\u7684\u5224\u65ad\u7b97\u5b50\uff0c\u8fd9\u5728TensorRT\u7684onnx\u89e3\u6790\u5668\u4e2d\u662f\u4e0d\u652f\u6301\u7684\u3002 \u672c\u9879\u76ee\u91c7\u7528<code>torchvision.models.detection.fasterrcnn_resnet50_fpn</code>\u4e3a\u5f85\u90e8\u7f72\u6a21\u578b\uff0c\u7740\u624b\u89e3\u51b3\u90e8\u7f72\u4e2d\u4ea7\u751f\u7684\u4e00\u4e9b\u95ee\u9898\u3002 \u4e3b\u8981\u601d\u8def\uff1a\u5c06rpn\u90e8\u5206\u548c\u68c0\u6d4b\u5934\u5206\u5f00\uff0c\u5206\u6210\u4e24\u4e2a\u6a21\u578b\u3002rpn\u90e8\u5206\u91c7\u7528onnx\u89e3\u6790\uff0cnms+roialigin\u90e8\u5206\u4f7f\u7528\u539f\u751fcuda\u6765\u505a\u3002\u5904\u7406\u540e\u7684feature\u9001\u5165header\u90e8\u5206\uff0c\u7136\u540e\u518d\u4e00\u6b21\u7ecf\u8fc7cuda\u5b9e\u73b0\u7684nms\u5f97\u5230\u6700\u7ec8\u7ed3\u679c\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2021%E5%B9%B412%E6%9C%8816%E6%97%A5%2014%E6%97%B626%E5%88%8600%E7%A7%92/#onnx","title":"ONNX\u751f\u6210\u6b65\u9aa4","text":"<p>\u4ee3\u7801\u89c1repo\u4e0b\u7684model\u548ctest</p> <ol> <li>\u5c06FasterRCNN\u4e2d\u7684rpn\u548cheader\u90e8\u5206\u5265\u79bb\u5f00\uff0c\u4ecetorchvision\u4e2d\u79fb\u690d</li> <li>\u5206\u522b\u751f\u6210rpn\u548cheader\u90e8\u5206\u7684onnx\u6587\u4ef6</li> <li>\u6574\u7406rpn\u548cheader\u7684\u8f93\u5165\u4e0e\u8f93\u51fa\uff0crpn\u7684\u8f93\u5165\u4e3a\u56fe\u50cf\uff0c\u8f93\u51fa\u4e3atopk\u540e\u7684bbox\u548cfpn\u5404\u5c42\u7684\u8f93\u51fa\u3002header\u7684\u8f93\u5165\u4e3aroialign\u540e\u7684feature\u548cbbox\uff0c\u8f93\u51fa\u4e3anms\u524d\u7684\u6700\u7ec8\u7684bbox\u548cscore</li> </ol> <p>\u4e0a\u9762\u6b65\u9aa4\u6d89\u53ca\u5230\u8ba1\u7b97\u56fe\u7684\u4fee\u5efa\uff0c\u8fc7\u7a0b\u8f83\u4e3a\u7e41\u7410\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2021%E5%B9%B412%E6%9C%8816%E6%97%A5%2014%E6%97%B626%E5%88%8600%E7%A7%92/#tensorrt","title":"TensorRT\u5b9e\u73b0\u90e8\u5206","text":"<p>tensorRT\u90e8\u5206\u9700\u8981\u5b8c\u6210\u54ea\u4e9b\u4e8b\uff1f</p> <ol> <li>\u5bf9\u8f93\u5165\u8fdb\u884c\u9884\u5904\u7406</li> <li>\u5bf9rpn\u7684\u8f93\u51fa\u8fdb\u884cnms\u5904\u7406\uff0c\u4ee5\u53ca\u6c42\u53d6roi_align\u540e\u7684feature\uff0c\u8fd9\u91cc\u6d89\u53ca\u5230\u5bf9\u6bcf\u4e00\u4e2abbox\u5e94\u8be5\u5728\u54ea\u4e00\u5c42fpn\u8f93\u51fafeature\u4e0a\u8fdb\u884c\u8ba1\u7b97roialign</li> <li>\u521b\u9020header\u7684\u8f93\u5165\uff0c\u5c06nms\u540e\u7684bbox\u548croi_align\u8ba1\u7b97\u540e\u7684feature\u9001\u5165header\u90e8\u5206</li> <li>\u5bf9header\u7684\u8f93\u51fa\u8fdb\u884cnms\u5904\u7406</li> </ol> <p>roi_align\u5982\u4f55\u5b9e\u73b0\uff1f</p> <ol> <li>\u79fb\u690donnxruntime\u7684cuda\u5b9e\u73b0\u4ee3\u7801\uff08\u9a8c\u8bc1\u5bfc\u51faonnx\u7684\u65f6\u5019\uff0c\u5df2\u7ecf\u8bc1\u660eonnxruntime\u5b9e\u73b0\u7684\u6b63\u786e\u6027\uff09</li> <li>\u770b\u539f\u7248\u8bba\u6587\u548ctorchvision\u7684\u5b9e\u73b0\u8ba1\u7b97fpn_level</li> <li>\u5c06\u4ee5\u4e0a\u4e24\u70b9\u7ed3\u5408\uff0c\u5bf9\u4e0d\u540cfpn_level\u52a8\u6001\u9009\u62e9\u4e0d\u540cfeature\u8fdb\u884croi_align\u8ba1\u7b97</li> </ol> <p>\u4ee5\u4e0a\u9700\u6c42\u7684\u5b9e\u73b0\u53ef\u4ee5\u5728<code>tensorrt_code/application/src/application/app_fasterrcnn</code>\u4e2d\u53ef\u4ee5\u627e\u5230 \u4ed3\u5e93\u4ee3\u7801\u6301\u7eed\u66f4\u65b0\u4e2d\uff0c\u5982\u679c\u6709\u95ee\u9898\u53ef\u4ee5\u5728\u672c\u6587\u4e0b\u9762\u7559\u8a00\uff0c\u4e5f\u53ef\u4ee5\u5728\u4ed3\u5e93issue\u533a\u63d0\u51fa\u95ee\u9898\uff0c\u5982\u679c\u53ef\u4ee5\u52a8\u52a8\u5c0f\u624b\u7ed9\u4e2astar\uff0c\u6211\u5c06\u4e0d\u80dc\u611f\u6fc0\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8806%E6%97%A5%2022%E6%97%B621%E5%88%8616%E7%A7%92/","title":"\u751f\u4ea7\u8005\u6d88\u8d39\u8005\u6a21\u5f0f\u5728\u591abatch\u63a8\u7406\u4e0b\u7684\u5e94\u7528(\u5ef6\u65f6\u961f\u5217)","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8806%E6%97%A5%2022%E6%97%B621%E5%88%8616%E7%A7%92/#_1","title":"\u9700\u6c42","text":"<p>\u672c\u6587\u4ee3\u7801\u6846\u67b6\u53c2\u8003\u81ea trtpy: https://zhuanlan.zhihu.com/p/462980738 \u521b\u5efa\u4e00\u79cd\u751f\u4ea7\u8005\u6d88\u8d39\u8005\u6a21\u5f0f\uff0c\u5b9e\u73b0\u591a\u7ebf\u7a0b\u8d44\u6e90\u5904\u7406\uff0c\u52a0\u901f\u6a21\u578b\u63a8\u7406\u3002 \u9700\u8981\u6ee1\u8db3\u4e00\u4e0b\u51e0\u70b9\uff1a</p> <ol> <li>\u751f\u4ea7\u8005\u751f\u4ea7\u63d0\u4ea4\u8d44\u6e90\uff0c\u6d88\u8d39\u8005\u8d1f\u8d23\u5904\u7406\uff0c\u5e76\u5c06\u5904\u7406\u7ed3\u679c\u8fd4\u56de\u7ed9\u751f\u4ea7\u8005\u3002</li> <li>\u8d44\u6e90\u961f\u5217\u4e0d\u662f\u6709\u9650\u7684\uff0c\u56e0\u4e3a\u663e\u5b58\u662f\u6709\u9650\u7684\u3002</li> <li>\u4e3a\u4e86\u591abatch\u52a0\u901f\uff0c\u5141\u8bb8\u751f\u4ea7\u8005\u751f\u4ea7\u8d44\u6e90\u95f4\u9694\u5728\u4e00\u5b9a\u8303\u56f4\u5185\uff0c\u6bd4\u598250ms\u5185\u7684\u8d44\u6e90\u90fd\u53ef\u4ee5\u653e\u5230\u4e00\u4e2abatch\u5f53\u7ed9\u6d88\u8d39\u8005\u5904\u7406</li> <li>\u4fdd\u8bc1\u8d44\u6e90\u54ea\u91cc\u5206\u914d\u54ea\u91cc\u91ca\u653e\uff0c\u54ea\u91cc\u4f7f\u7528\uff0c\u8fd9\u6837\u53ef\u4ee5\u4f7f\u5f97\u7a0b\u5e8f\u8db3\u591f\u7b80\u5355\u3002</li> <li>\u63a5\u53e3\u6a21\u5f0f\u4fdd\u8bc1RAII\uff0c\u4e0d\u66b4\u9732\u5185\u90e8\u63a5\u53e3\u3002</li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8806%E6%97%A5%2022%E6%97%B621%E5%88%8616%E7%A7%92/#_2","title":"\u8bbe\u8ba1\u5206\u6790","text":"<ol> <li>\u751f\u4ea7\u8005\u6d88\u8d39\u8005\u7ecf\u5178\u6846\u67b6-\u9700\u8981\u4e00\u4e2a\u7ebf\u7a0b\u5b89\u5168\u7684\u961f\u5217\u6765\u50a8\u5b58\u8d44\u6e90\uff0c\u9700\u8981\u4f7f\u7528<code>promise</code>\u548c<code>future</code>\u6765\u5b8c\u6210\u5bf9\u7ed3\u679c\u7684\u8fd4\u56de\u3002</li> <li>\u9700\u8981\u5bf9\u961f\u5217\u7684\u5927\u5c0f\u52a0\u4ee5\u63a7\u5236\uff0c\u5e76\u4e14\u66b4\u9732\u63a7\u5236\u5927\u5c0f\u7684\u63a5\u53e3</li> <li>\u9700\u8981\u8bbe\u7f6e\u4e00\u79cd\u5ef6\u65f6\u673a\u5236\uff0c\u6765\u63a7\u5236\u6d88\u8d39\u8005\u7ebf\u7a0b\u5728\u6536\u96c6\u8d44\u6e90\u65f6\u53ef\u4ee5\u7b49\u5f85\u4e00\u6bb5\u65f6\u95f4\u7528\u4e8e\u5224\u65ad\u540e\u7eed\u8fd8\u6709\u6ca1\u6709\u6570\u636e\u4f20\u5165\uff0c\u6b64\u65f6\u53ef\u4ee5\u4f7f\u7528<code>condition_variable</code>\u7684<code>wait_for</code>\u51fd\u6570\u3002</li> <li>\u8d44\u6e90\u7684\u5206\u914d\u548c\u91ca\u653e\u90fd\u653e\u5230\u6d88\u8d39\u8005\u7ebf\u7a0b\u4e2d\uff0c\u4e2d\u95f4\u7ed3\u679c\u7684\u6d88\u606f\u4f20\u9012\u53ef\u4ee5\u91c7\u7528\u4f7f\u7528<code>promise</code>\u548c<code>future</code>\u3002</li> <li>\u5728C++\u4e2d\uff0c\u4e00\u822c\u91c7\u7528\u62bd\u8c61\u7c7b\u6765\u4ee3\u66ff\u63a5\u53e3\uff0c\u518d\u8bbe\u7f6e\u4e00\u4e2a\u6784\u9020\u65b9\u6cd5\u901a\u8fc7\u591a\u6001\u5b8c\u6210\u5c01\u88c5\u3002</li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8806%E6%97%A5%2022%E6%97%B621%E5%88%8616%E7%A7%92/#_3","title":"\u4ee3\u7801\u6a21\u62df\u5b9e\u73b0","text":"<ol> <li>\u6587\u4ef6 <code>Infer.hpp</code>, \u63a5\u53e3\u58f0\u660e\u6587\u4ef6</li> </ol> <pre><code>#ifndef INFER_HPP\n#define INFER_HPP\n#include &lt;memory&gt;\n#include &lt;string&gt;\n#include &lt;map&gt;\n#include &lt;future&gt;\nnamespace Infer {\nusing Tensor = std::string;\nusing RET_TYPE = std::map&lt;std::string, Tensor&gt;;\nclass InferInterface {\n public:\n  // pic_tensor \u8868\u793a\u8f93\u5165\u7ed9\u751f\u4ea7\u8005\u7684tensor, timeout \u8868\u793a\u8d85\u65f6\u65f6\u95f4\n  // wait_timeout \u8868\u793a\u5f53\u961f\u5217\u6ee1\u4e86\u7684\u60c5\u51b5\u4e0b\uff0c\u613f\u610f\u6700\u591a\u7b49\u5f85 wait_timeout ms \u6765\u7b49\u5f85\n  virtual std::shared_future&lt;RET_TYPE&gt; forward(const Tensor&amp; pic_tensor, int wait_timeout = 10) = 0;\n  virtual void set_timeout(const int timeout) = 0;\n  virtual void set_max_queue_num(const int max_queue_num) = 0;\n  virtual ~InferInterface() {}\n  explicit InferInterface() {}\n protected:\n  InferInterface(const InferInterface&amp;) = delete;\n  InferInterface(InferInterface&amp;&amp;) = delete;\n  InferInterface&amp; operator=(const InferInterface&amp;) = delete;\n};\nstd::shared_ptr&lt;InferInterface&gt; create_infer(const std::string&amp; filepath, int max_bactch_size);\n}\n#endif // INFER_HPP\n</code></pre> <ol> <li>\u6587\u4ef6<code>Infer.cpp</code>\uff0c\u5206\u6790\u9700\u6c42\u4e2d\u7684\u5177\u4f53\u5b9e\u73b0</li> </ol> <pre><code>#include &lt;iostream&gt;\n#include &lt;thread&gt;\n#include &lt;future&gt;\n#include &lt;queue&gt;\n#include &lt;map&gt;\n#include \"infer.hpp\"\nnamespace Infer {\nusing std::string;\nusing std::thread;\nusing std::promise;\nusing std::future;\nusing std::map;\nusing std::queue;\nusing std::atomic;\nusing std::mutex;\nclass InferImpl: public InferInterface {\n protected:\n  // \u5b9a\u4e49\u961f\u5217\u4e2d\u5355\u4e2a\u4efb\u52a1\u7ed3\u679c\n  using RET_RPOMISE_PTR = std::shared_ptr&lt;promise&lt;RET_TYPE&gt;&gt;;\n  struct Job {\n   public:\n    // \u8f93\u5165\u56fe\u50cf\u77e9\u9635\n    Tensor pic;\n    // \u5bf9\u8f93\u5165\u56fe\u50cf\u77e9\u9635\u5904\u7406\u540e\u8fd4\u56de\u7684\u7ed3\u679c\n    RET_RPOMISE_PTR ret_promise;\n  };\n  // \u8fd9\u91cc\u5047\u8bbe\u662f\u6253\u5f00\u6587\u4ef6\u540e\u7684\u4e0a\u4e0b\u6587\n  string context_;\n  thread thread_;\n  queue&lt;Job&gt; queue_;\n  atomic&lt;bool&gt; running_;\n  mutex lock_;\n  atomic&lt;int&gt; max_batchsize_;\n  atomic&lt;int&gt; timeout_;\n  atomic&lt;int&gt; max_queue_num_;\n  std::condition_variable cond_var_;\n  std::condition_variable cond_queue_overflow_;\n public:\n  explicit InferImpl() {\n    running_ = false;\n    max_batchsize_ = 1;\n    timeout_ = 0;\n    max_queue_num_ = 5;\n  }\n  bool load_model(const string&amp; filepath) {\n    promise&lt;bool&gt; init_promise;\n    thread_ = thread(&amp;InferImpl::worker, this, filepath, std::ref(init_promise));\n    running_ = true;\n    return init_promise.get_future().get();\n  }\n  inline int max_batchsize() const {return max_batchsize_;}\n  bool set_max_batchsize(const int max_batchsize) {\n    if (max_batchsize &lt; 1)\n      return false;\n    this-&gt;max_batchsize_ = max_batchsize;\n    return true;\n  }\n  void set_timeout(const int timeout) {\n    timeout_ = timeout;\n  }\n  void set_max_queue_num(const int max_queue_num) {\n    max_queue_num_ = max_queue_num;\n  }\n  virtual std::shared_future&lt;RET_TYPE&gt; forward(const Tensor&amp; pic_tensor, int wait_timeout) override {\n    // \u7ed9\u961f\u5217\u63d0\u4ea4\u8f93\u5165\u5e76\u5c06\u5904\u7406\u7ed3\u679c\u8fd4\u56de\n    Job job;\n    job.pic = pic_tensor;\n    job.ret_promise = RET_RPOMISE_PTR(new promise&lt;RET_TYPE&gt;());\n    {\n      std::unique_lock&lt;mutex&gt; l(lock_);\n      if (queue_.size() &gt;= max_queue_num_) {\n        if (0 == wait_timeout) {\n          throw std::runtime_error(\"exhausted resource\");\n        }\n        cond_queue_overflow_.wait_for(l, std::chrono::milliseconds(wait_timeout), [&amp;]() {\n          return queue_.size() &lt; max_queue_num_;\n        });\n      }\n      if (queue_.size() &gt;= max_queue_num_)\n        throw std::runtime_error(\"exhausted resource\");\n      // \u6b64\u5904\u4e0d\u53ef\u4ee5\u65e0\u9650\u63d0\u4ea4\n      queue_.push(job);\n    }\n    cond_var_.notify_one();\n    return job.ret_promise-&gt;get_future();\n  }\n  ~InferImpl() override {\n    running_ = false;\n    cond_var_.notify_one();\n    if (thread_.joinable())\n      thread_.join();\n  }\n protected:\n  void worker(const string&amp; filepath, promise&lt;bool&gt;&amp; init_promise) {\n    // \u521d\u59cb\u5316\u6a21\u578b\u4e0a\u4e0b\u6587\n    context_ = filepath;\n    // \u5047\u8bbe\u6b64\u5904\u4e3a\u6a21\u578b\u52a0\u8f7d\u5931\u8d25\n    if (context_.empty()) {\n      context_ = filepath;\n      init_promise.set_value(false);\n      return;\n    }\n    // \u82e5\u5e72\u521d\u59cb\u5316\u4e0a\u4e0b\u6587\u4ee3\u7801\n    // \u4e0a\u4e0b\u6587\u521d\u59cb\u5316\u6210\u529f\n    init_promise.set_value(true);\n    // \u68c0\u67e5\u8d44\u6e90\u961f\u5217\u4e2d\u662f\u5426\u6709\u4efb\u52a1\n    std::vector&lt;Job&gt; jobs;\n    // \u6b64\u5904\u7528\u4e8e\u6a21\u62df\n    int batch_id = 0;\n    while (running_) {\n      {\n        std::unique_lock&lt;mutex&gt; l(lock_);\n        cond_var_.wait(l, [&amp;]() {\n          // return true \u8868\u793a \u9000\u51fa\u7b49\u5f85\n          return !queue_.empty() || !running_;\n        });\n        if (!running_)\n          break;\n        // \u8868\u793a\u5f53\u524d\u7ebf\u7a0b\u7b49\u5f85\u7684\u6700\u957f\u65f6\u95f4\n        if (0 != timeout_) {\n          cond_var_.wait_for(l, std::chrono::milliseconds(timeout_), [&amp;]() {\n            return queue_.size() &gt;= max_batchsize_;\n          });\n        }\n        for (int i = 0; !queue_.empty() &amp;&amp; i &lt; max_batchsize_; ++i) {\n          jobs.emplace_back(queue_.front());\n          queue_.pop();\n        }\n      }\n      // job inference \u6b64\u5904\u521d\u59cbjobs\u6240\u6709\u6570\u636e \u8fd9\u91cc\u6a21\u62df\u4e00\u4e0b\n      int size = jobs.size();\n      for (auto&amp; job : jobs) {\n        auto bbox = job.pic + \"_handled\";\n        RET_TYPE handled_result;\n        handled_result[\"bbox\"] = bbox;\n        job.ret_promise-&gt;set_value(handled_result);\n      }\n      jobs.clear();\n      std::this_thread::sleep_for(std::chrono::milliseconds(100 * size));\n      std::printf(\"batch_id = %d, job size=%d \n\", batch_id, size);\n      // \u901a\u77e5\u751f\u4ea7\u8005 \u6d88\u8d39\u8005\u8fd9\u8fb9\u5df2\u6d88\u8d39\u4e00\u6b21\n      cond_queue_overflow_.notify_one();\n      ++batch_id;\n    }\n    // \u9500\u6bc1\u7533\u8bf7\u7684\u8d44\u6e90\n    context_.clear();\n    std::cout &lt;&lt; \"context_ has cleared\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Workder done!\" &lt;&lt; std::endl;\n  }\n};\nstd::shared_ptr&lt;InferInterface&gt; create_infer(const std::string&amp; filepath, int max_bactch_size) {\n  auto infer_ptr = new InferImpl();\n  infer_ptr-&gt;set_max_batchsize(max_bactch_size);\n  if (!infer_ptr-&gt;load_model(filepath)) {\n    delete infer_ptr;\n    return nullptr;\n  }\n  return std::shared_ptr&lt;InferInterface&gt;(infer_ptr);\n}\n} // namespace Infer END\n</code></pre> <ol> <li>\u6587\u4ef6<code>main.cpp</code> \u6d4b\u8bd5\u529f\u80fd</li> </ol> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include \"infer.hpp\"\nusing std::cout;\nusing std::endl;\nusing std::cerr;\nusing RET_FUTRUE = std::shared_future&lt;Infer::RET_TYPE&gt;;\nint main() {\n  std::shared_ptr&lt;Infer::InferInterface&gt; infer = Infer::create_infer(\"/xxx/some.engine\", 5);\n  if (infer == nullptr) {\n    cerr &lt;&lt; \"create infer engine error\" &lt;&lt; endl;\n    return -1;\n  }\n  // \u5141\u8bb8\u6700\u591a\u7b49\u5f855ms\u5ef6\u8fdf\u6536\u96c6\u4e00\u7ec4\u6570\u636e\n  infer-&gt;set_timeout(5);\n  // \u8bbe\u7f6e\u961f\u5217\u4e2d\u5143\u7d20\u7684\u6700\u5927\u4e2a\u6570\n  infer-&gt;set_max_queue_num(10);\n  cout &lt;&lt; \"create infer engine success\" &lt;&lt; endl;\n  std::vector&lt;RET_FUTRUE&gt; shared_ptrs;\n  char buffer[100];\n  for (int i = 0; i &lt; 24; ++i) {\n    sprintf(buffer, \"%d.tensor\", i);\n    // 1000 \u8868\u793a\u5728\u961f\u5217\u6ee1\u7684\u60c5\u51b5\u4e0b \u751f\u4ea7\u8005\u613f\u610f\u7b49\u5f851000ms\uff0c\u8d85\u65f6\u4f1a\u629b\u51fa\u5f02\u5e38\n    shared_ptrs.push_back(infer-&gt;forward(buffer, 1000));\n  }\n  for (auto&amp; shared_ptr : shared_ptrs) {\n    shared_ptr.get();\n  }\n  return 0;\n}\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8806%E6%97%A5%2022%E6%97%B621%E5%88%8616%E7%A7%92/#_4","title":"\u603b\u7ed3","text":"<p>\u4e00\u76f4\u60f3\u7740\u5982\u4f55\u4f18\u96c5\u7684\u6765\u53bb\u5229\u7528\u591a\u7ebf\u7a0b\u52a0\u901f\u6a21\u578b\u7684\u63a8\u7406\uff0ctrtpy\u7ed9\u4e86\u6211\u7b54\u6848\u3002\u56de\u8fc7\u5934\u5728\u770b\u81ea\u5df1\u66fe\u7ecf\u7684\u5b9e\u73b0\uff0c\u53d1\u73b0\u4e00\u4e2a\u597d\u7684\u63a5\u53e3\u8bbe\u8ba1\u6bd4\u5bf9\u63a5\u53e3\u7684\u5177\u4f53\u5b9e\u73b0\u66f4\u4e3a\u91cd\u8981\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/","title":"pytorch\u5bfc\u51faonnx\u7684\u539f\u5219-\u4ee5SwinTransformer\u548cDETR\u5728trt8.0.3.4\u90e8\u7f72\u4e3a\u4f8b","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#_1","title":"\u4e00\u3001\u524d\u8a00","text":"<p>pytorch\u5bfc\u51faonnx\u662f\u901a\u8fc7\u8ffd\u8e2aforward\u51fd\u6570\u6784\u5efa\u7684\u8ba1\u7b97\u56fe\u6765\u5b9e\u73b0\u7684\uff0c\u7136\u800c\u8fd9\u79cd\u6784\u5efa\u7684\u65b9\u5f0f\u5f80\u5f80\u4f1a\u7531\u4e8e\u6a21\u578b\u7684\u8bbe\u8ba1\u8005\u6ca1\u6709\u8003\u8651\u5bfc\u51fa\u90e8\u7f72\u65f6\u7684\u4fbf\u6377\u6027\u4ece\u800c\u751f\u6210\u7684onnx\u4e2d\u7b97\u5b50\u6bd4\u8f83\u5197\u4f59\uff0c\u6bd4\u5982<code>x[x&gt; 0.5] = 0</code>\u8fd9\u79cdinplace\u64cd\u4f5c\u5c31\u4f1a\u751f\u6210onnx\u7684<code>scatter</code>\u7b97\u5b50\uff0c\u8fd9\u4e2a\u7b97\u5b50\u662f\u4e0d\u88abtensorrt\u652f\u6301\u7684\u3002\u5c3d\u7ba1\u53ef\u4ee5\u91c7\u7528plugin\u65b9\u5f0f\u6765\u5b9e\u73b0\uff0c\u4f46\u5176\u5e76\u4e0d\u662f\u4e00\u4e2a\u8f83\u4e3a\u6709\u597d\u7684\u7b97\u6cd5\u3002<code>x[x &gt; 0.5] = 0</code>\u53ef\u4ee5\u8f6c\u6362\u4e3a<code>y = x * (x &gt; 0.5).to(torch.float32)</code>\u8fd9\u79cd\u5f62\u5f0f\u6765\u907f\u514dinplace\u64cd\u4f5c\u3002\u6b64\u5916\u53d6shape\u64cd\u4f5c\u4e00\u822c\u7528\u4e8e\u52a8\u6001shape\uff0c\u8fd9\u79cd\u64cd\u4f5c\u5728\u90e8\u7f72\u6846\u67b6\u4e2d\u4e5f\u662f\u5197\u4f59\u7684\u5e94\u8be5\u53bb\u6389\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5927\u90e8\u5206\u6a21\u578b\u9664\u4e86batch size\u53ef\u53d8\u4ee5\u5916\uff0c\u5176\u4f59\u7ef4\u5ea6\u8f93\u5165\u90fd\u662f\u56fa\u5b9a\u7684\uff0c\u4ece\u800c\u5bf9\u4e8e\u4e00\u822c\u7684\u53d6shape\u64cd\u4f5c\u90fd\u662f\u53ef\u4ee5\u76f4\u63a5\u7531\u5e38\u91cf\u8ba1\u7b97\u5f97\u5230\uff0c\u4ece\u800c\u8ba1\u7b97\u5f97\u5230\u7684shape\u5b9e\u9645\u4e0a\u53ef\u4ee5\u56fa\u5316\u4e3a\u4e00\u4e2a\u5e38\u91cf\u3002\u4e0b\u9762\u6839\u636etrtpy\u4f5c\u8005\u63d0\u51fa\u7684\u5efa\u8bae\uff0c\u7ed9\u51fa\u5bfc\u51faonnx\u65f6\u5e94\u9075\u5b88\u7684\u539f\u5219\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#_2","title":"\u4e8c\u3001\u539f\u5219","text":"<ol> <li>\u5bf9\u4e8e\u4efb\u4f55\u7528\u5230shape\u3001size\u8fd4\u56de\u503c\u7684\u53c2\u6570\u65f6\uff0c\u4f8b\u5982\uff1a<code>tensor.view(tensor.size(0), -1)</code>\uff0c<code>B,C,H,W = x.shape</code> \u8fd9\u7c7b\u64cd\u4f5c\uff0c\u907f\u514d\u76f4\u63a5\u4f7f\u7528tensor.size\u7684\u8fd4\u56de\u503c\uff0c\u800c\u662f\u52a0\u4e0aint\u8f6c\u6362\uff0c<code>tensor.view(int(tensor.size(0)), -1)</code>, <code>B,C,H,W = map(int, x.shape)</code>\uff0c\u65ad\u5f00\u8ddf\u8e2a\u3002</li> <li>\u5bf9\u4e8enn.Upsample\u6216nn.functional.interpolate\u51fd\u6570\uff0c\u4e00\u822c\u4f7f\u7528scale_factor\u6307\u5b9a\u500d\u7387\uff0c\u800c\u4e0d\u662f\u4f7f\u7528size\u53c2\u6570\u6307\u5b9a\u5927\u5c0f\u3002\u5982\u679c\u6e90\u7801\u4e2d\u5c31\u662f\u63d2\u503c\u4e3a\u56fa\u5b9a\u5927\u5c0f\uff0c\u5219\u8be5\u6761\u5ffd\u7565\u3002</li> <li>\u5bf9\u4e8ereshape\u3001view\u64cd\u4f5c\u65f6\uff0c-1\u7684\u6307\u5b9a\u8bf7\u653e\u5230batch\u7ef4\u5ea6\u3002\u5176\u4ed6\u7ef4\u5ea6\u8ba1\u7b97\u51fa\u6765\u5373\u53ef\u3002batch\u7ef4\u5ea6\u7981\u6b62\u6307\u5b9a\u4e3a\u5927\u4e8e-1\u7684\u660e\u786e\u6570\u5b57\u3002\u5982\u679c\u662f\u4e00\u7ef4\uff0c\u90a3\u4e48\u76f4\u63a5\u6307\u5b9a\u4e3a-1\u5c31\u597d\u3002</li> <li>torch.onnx.export\u6307\u5b9adynamic_axes\u53c2\u6570\uff0c\u5e76\u4e14\u53ea\u6307\u5b9abatch\u7ef4\u5ea6\uff0c\u7981\u6b62\u5176\u4ed6\u52a8\u6001</li> <li>\u4f7f\u7528opset_version=11\uff0c\u4e0d\u8981\u4f4e\u4e8e11</li> <li>\u907f\u514d\u4f7f\u7528inplace\u64cd\u4f5c\uff0c\u4f8b\u5982<code>y[\u2026, 0:2] = y[\u2026, 0:2] * 2 - 0.5</code>\uff0c\u53ef\u4ee5\u91c7\u7528\u5982\u4e0b\u4ee3\u7801\u4ee3\u66ff <code>tmp = y[\u2026, 0:2] * 2 - 0.5; y = torch.cat((y[..., 2:], tmp), dim = -1)</code></li> <li>\u5c3d\u91cf\u5c11\u7684\u51fa\u73b05\u4e2a\u7ef4\u5ea6\uff0c\u4f8b\u5982ShuffleNet Module\uff0c\u53ef\u4ee5\u8003\u8651\u5408\u5e76wh\u907f\u514d\u51fa\u73b05\u7ef4</li> <li>\u5c3d\u91cf\u628a\u8ba9\u540e\u5904\u7406\u90e8\u5206\u5728onnx\u6a21\u578b\u4e2d\u5b9e\u73b0\uff0c\u964d\u4f4e\u540e\u5904\u7406\u590d\u6742\u5ea6\u3002\u6bd4\u5982\u5728\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u4e2d\u6700\u7ec8\u8f93\u51fa\u8bbe\u7f6e\u4e3axywh\u6216\u8005xyxy\uff0c\u800c\u4e0d\u662f\u4e00\u4e2a\u4e2d\u95f4\u7ed3\u679c\u3002</li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#_3","title":"\u4e09\u3001\u5e38\u89c1\u95ee\u9898\u65b9\u6cd5","text":"<ol> <li>onnx\u7684\u4fee\u6539</li> </ol> <p>\u4f7f\u7528python\u4e2d<code>onnx</code>\u5e93\u6216\u8005TensorRT\u643a\u5e26\u7684\u66f4\u4e3a\u65b9\u4fbf\u7684<code>onnx_graphsurgeon</code></p> <pre><code># \u5b89\u88c5onnx\npip install onnx\n# \u5b89\u88c5onnx_graphsurgeon https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon\npython3 -m pip install onnx_graphsurgeon --index-url https://pypi.ngc.nvidia.com\n</code></pre> <p>\u5177\u4f53\u4fee\u6539\u9700\u8981\u53bb\u5b98\u7f51\u67e5\u770b\u76f8\u5173\u6848\u4f8b\uff0c\u8fd9\u91cc\u4e0d\u518d\u8d58\u8ff0\u3002\u6b64\u5916\uff0connx\u7684\u672c\u8d28\u65f6protobuf\u5e8f\u5217\u5316\u540e\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u6240\u4ee5\u5176\u7ed3\u6784\u9075\u5faa<code>.proto</code>\u5b9a\u4e49\u7684\u6587\u4ef6\uff0c\u5982\u679c\u662f\u4f7f\u7528<code>onnx</code>\u5e93\u4fee\u6539\u65f6\u9700\u8981\u7262\u8bb0\u8fd9\u4e00\u70b9\u3002</p> <ol> <li>onnx\u7684\u7b80\u5316</li> </ol> <p><code>onnxsim</code>\u53ef\u4ee5\u7b80\u5316onnx graph\u4e2d\u4e00\u4e9b\u5e38\u91cf\u7684\u6298\u53e0\u8fd0\u7b97\uff0c\u5177\u4f53\u89c1\u5b98\u65b9github https://github.com/daquexian/onnx-simplifier \u3002 \u5373\u4f7f\u5728\u4f7f\u7528\u4e86\u4ee5\u4e0a\u539f\u5219\u4ee5\u540e\uff0c\u8fd8\u662f\u65e0\u6cd5\u907f\u514d\u751f\u6210\u4e00\u4e9b\u5197\u4f59\u7684\u5e38\u91cf\u8fd0\u7b97\u3002\u6bd4\u5982<code>d = a + b - c</code></p> <p>\u8fd9\u91cca,b,c\u90fd\u662f\u5e38\u91cf\u4e14\u53ea\u6709\u5728\u8ba1\u7b97d\u7684\u65f6\u5019\u7528\u5230\uff0c\u90a3\u4e48onnx\u8ba1\u7b97\u56fe\u4e2d\u53ea\u9700\u8981\u8868\u793ad\u5373\u53ef\uff0c\u4f46\u662ftorch\u7684api\u8fd8\u505a\u4e0d\u5230\u8fd9\u4e00\u70b9\u3002</p> <ol> <li>\u52a8\u6001shape\u7684\u95ee\u9898</li> </ol> <p>TensorRT\u662f\u652f\u6301\u5404\u4e2a\u7ef4\u5ea6\u7684\u52a8\u6001shape\u7684\uff0c\u4e0d\u5c40\u9650\u4e8e\u52a8\u6001\u7684batchsize\uff0c\u5176\u5141\u8bb8\u7528\u6237\u8bbe\u5b9a\u591a\u7ec4\u7ef4\u5ea6\u4f9bTensorRT\u7ed3\u6784\u4f18\u5316\u5668\u6765\u9009\u62e9\uff0c\u4f46\u662f\u5728\u9009\u62e9\u6700\u4f18\u7ed3\u6784\u7684\u65f6\u5019\u9700\u8981\u9884\u5148\u6307\u5b9a\u4e00\u4e2a\u56fa\u5b9a\u7ef4\u5ea6\u3002\u6b64\u5916\u52a8\u6001shape\u5bf9\u4e8e\u4e00\u822c\u7f51\u7edc\u800c\u8a00\uff0c\u4ec5\u4ec5\u662fbatch size\u53ef\u53d8\uff0c\u5176\u4f59\u6a21\u578b\u8f93\u5165\u7684\u957f\u548c\u5bbd\u4e00\u822c\u662f\u56fa\u5b9a\u7684\uff0c\u56e0\u6b64\u4e00\u822c\u60c5\u51b5\u4e0b\u53ea\u8003\u8651\u52a8\u6001batch size\u7684\u95ee\u9898\uff0c\u4e5f\u5c31\u662f\u539f\u52193\u3002</p> <ol> <li>\u83b7\u53d6onnx\u4e2d\u95f4\u8f93\u5165</li> </ol> <p>onnxruntime\u662f\u53ef\u4ee5\u83b7\u5f97\u6a21\u578b\u4e2d\u95f4\u5c42\u7ed3\u679c\u7684\uff0c\u5177\u4f53\u65b9\u5f0f\u8fd8\u8bf7\u8bfb\u8005\u641c\u7d22\u4e00\u4e0b\u3002\u672c\u6587\u7ed9\u51fa\u4e00\u79cd\u66f4\u4e3a\u4f18\u96c5\u7684\u65b9\u5f0f\uff0c\u5373\u91c7\u7528TensorRT\u9644\u5e26\u7684<code>polygraphy</code>\uff0c\u5177\u4f53\u7f51\u5740 https://github.com/NVIDIA/TensorRT/tree/master/tools/Polygraphy \u4e0b\u6587\u5728DETR\u6848\u4f8b\u4e2d\u5c06\u7ed9\u51fa\u5982\u4f55\u91c7\u7528<code>polygraphy</code>\u5b9a\u4f4d\u54ea\u4e2a\u4e2d\u95f4\u5c42\u51fa\u73b0\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\uff0c\u4e5f\u5c31\u662f<code>onnxruntime</code>\u7ed3\u679c\u4e0e<code>tensorrt</code>\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#1-swintransformertensorrt","title":"\u56db\u3001\u6848\u4f8b1-SwinTransformer\u5728TensorRT\u4e0a\u7684\u90e8\u7f72","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#41","title":"4.1 \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd","text":"<p>\u672c\u6587\u91c7\u7528\u57fa\u4e8epytorch\u7684<code>timm</code>\u5e93\u6765\u52a0\u8f7d\u5206\u7c7b\u6a21\u578b\u548c\u9884\u8bad\u7ec3\u6743\u91cd\uff0c\u91c7\u7528<code>pip install timm</code>\u5b89\u88c5\uff0c\u4f5c\u8005\u5728\u505a\u672c\u6b21\u5b9e\u9a8c\u65f6<code>timm</code>\u7248\u672c\u4e3a<code>0.5.4</code>\u3002 \u91c7\u7528\u5982\u4e0b\u4ee3\u7801\u8bb0\u8f7d\u6a21\u578b</p> <pre><code>import timm\nimport torch\nimport os\nswin_transformer_model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n</code></pre> <p>\u5982\u679c\u4e0b\u8f7d\u901f\u5ea6\u8f83\u6162\uff0c\u8bf7\u6253\u5f00log\u4e2d\u7684\u4e0b\u8f7d\u7f51\u5740\u91c7\u7528\u6d4f\u89c8\u5668\u4e0b\u8f7d\u597d\u4ee5\u540e\uff0c\u518d\u653e\u5230\u7ed9\u51fa\u7684<code>cache</code>\u6587\u4ef6\u5939\u4e2d\u3002 \u4ee5\u4e0a\u4ee3\u7801\u5373\u5b8c\u6210\u4e86\u6a21\u578b\u7684\u9884\u52a0\u8f7d\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#42","title":"4.2 \u9a8c\u8bc1\u5206\u7c7b\u6a21\u578b\u7cbe\u5ea6","text":"<pre><code>valdir = 'YourPath/ImageNet/val'\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\nval_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256, 3),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),batch_size=128, shuffle=False, num_workers=12, pin_memory=True)\nimport tqdm\ndef test(model, device, test_loader):\n    old_training_state = model.training\n    model.eval()\n    test_loss = 0\n    correct = 0\n    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n    for data, target in tqdm.tqdm(test_loader):\n        data, target = data.to(device), target.to(device)\n        with torch.no_grad():\n            output = model(data)\n        test_loss += lossLayer(output, target).item()\n        pred = output.argmax(dim=1, keepdim=True)\n        correct += pred.eq(target.view_as(pred)).sum().item()\n    test_loss /= len(test_loader.dataset)\n    model.train(old_training_state)\n    print('\nTest set: Average loss: {:.4f}, Accuracy: {:.3f}%\n'.format(\n        test_loss, 100. * correct / len(test_loader.dataset)\n\n    ))\ndevice = torch.device('cuda')\nswin_transformer_model.to(device)\n# Swin-B 85.2 22kto1k\ntest(swin_transformer_model, device, val_loader)\n</code></pre> <p>\u7ecf\u8fc7\u6d4b\u8bd5\uff0c\u4e0e\u539f\u8bba\u6587\u4e2d\u7ed9\u51fa\u7cbe\u5ea6\u4ec5\u5b58\u5728\u7ec6\u5fae\u5dee\u5f02\uff0c\u5dee\u4e860.1\u4e2a\u70b9\uff0c\u4e3b\u8981\u662f\u8f93\u5165\u56fe\u50cf\u63d2\u503c\u65b9\u5f0f\u5e26\u6765\u7684\uff0c\u8fd9\u4e0d\u662f\u672c\u6587\u91cd\u70b9\u6545\u4e0d\u518d\u4fee\u6539\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#43","title":"4.3 \u521d\u6b65\u5bfc\u51fa","text":"<pre><code>dummpy_input = torch.rand(1,3,224,224)\nswin_transformer_model.to('cpu')\nif not os.path.exists('swin-b-22kto1l.onnx'):\n    torch.onnx.export(swin_transformer_model, (dummpy_input, ), 'swin-b-22kto1l.onnx',\n                    input_names=['images',],\n                    output_names=['output'],\n                    dynamic_axes={\n                        'images': {\n                            0:'batch',\n                        },\n                        'output':{\n                            0:'batch',\n                        }\n                    },\n                    opset_version=11,\n                    verbose = True)\n</code></pre> <p>\u7531\u4e8e\u8bbe\u7f6e\u4e86<code>verbose = True</code>\uff0c\u4ee5\u4e0a\u4ee3\u7801\u4f1a\u6253\u5370\u51fa\u5f88\u957f\u7684log\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#44","title":"4.4 \u4fee\u6539\u6a21\u578b\u4ee3\u7801","text":"<p>\u6309\u7167\u5173\u952e\u8bcd<code>onnx::Shape</code>\u6765\u641c\u7d22shape\u64cd\u4f5c\u7684\u4ee3\u7801\u4f4d\u7f6e\uff0c\u627e\u5230\u4ee5\u540e\u6309\u7167\u539f\u52191\uff0c3\u4fee\u6539\u4ee3\u7801\u3002 \u5728<code>${PYENV}/lib/python3.9/site-packages/timm/models/layers/patch_embed.py</code>\uff0c\u4fee\u6539<code>PatchEmbed</code>\u7684<code>forward</code>\u51fd\u6570\uff0c\u4e3b\u8981\u662f\u628a<code>flatten</code>\u8f6c\u6362\u4e3a<code>view(-1, ...)</code>\u3002\u3001 ${PYENV}\u8868\u793apython\u73af\u5883\u6240\u5728\u76ee\u5f55 \u539f\u7248\u4e3a\uff08\u4e0b\u6587\u4e0d\u518d\u5c55\u793a\u539f\u7248\uff09</p> <pre><code>def forward(self, x):\n        B, C, H, W = map(int, x.shape)\n        _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n        _assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\")\n        x = self.proj(x)\n        if self.flatten:\n            x = x.flatten(2).transpose(1, 2)  # BCHW -&gt; BNC\n        x = self.norm(x)\n        return x\n</code></pre> <p>\u4fee\u6539\u4e3a</p> <pre><code>def forward(self, x):\n        B, C, H, W = map(int,x.shape)\n        _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n        _assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\")\n        x = self.proj(x)\n        if self.flatten:\n            _, newC, newH, newW = map(int, x.shape)\n            x = x.view(-1, newC, newH * newW).transpose(1, 2)  # BCHW -&gt; BNC\n        x = self.norm(x)\n        return x\n</code></pre> <p>\u5269\u4e0bshape\u64cd\u4f5c\u57fa\u672c\u90fd\u5728<code>${PYENV}/lib/python3.9/site-packages/timm/models/models/swin_transformer.py</code>\uff0c\u5148\u4ee5\u5173\u952e\u8bcd<code>.shape</code>\u5728\u8be5\u6587\u4ef6\u4e2d\u641c\u7d22\uff0c\u4fee\u6539\u5b8c\u6bd5\u540e\u518d\u770b\u5269\u4f59 <code>window_partition</code>\u548c<code>window_reverse</code>\u4fee\u6539\u5982\u4e0b</p> <pre><code>def window_partition(x, window_size: int):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = map(int, x.shape)\n    x = x.view(-1, H // window_size, window_size, W // window_size, window_size, C)\n    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n    return windows\n@register_notrace_function  # reason: int argument is a Proxy\ndef window_reverse(windows, window_size: int, H: int, W: int):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    C = int(windows.numel() // B // window_size // window_size // (H // window_size * W // window_size))\n    x = windows.view(-1, H // window_size, W // window_size, window_size, window_size, C)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x\n</code></pre> <p><code>WindowAttention</code>\u7c7b\u7684<code>forward</code>\u51fd\u6570\u4fee\u6539\u4e3a</p> <pre><code>def forward(self, x, mask: Optional[torch.Tensor] = None):\n        \"\"\"\n        Args:\n            x: input features with shape of (num_windows*B, N, C)\n            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n        \"\"\"\n        B_, N, C = map(int,x.shape)\n        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv.unbind(0)  # make torchscript happy (cannot use tensor as tuple)\n        q = q * self.scale\n        attn = (q @ k.transpose(-2, -1))\n        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n        attn = attn + relative_position_bias.unsqueeze(0)\n        if mask is not None:\n            nW = int(mask.shape[0])\n            attn = attn.view(-1, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n            attn = attn.view(-1, self.num_heads, N, N)\n            attn = self.softmax(attn)\n        else:\n            attn = self.softmax(attn)\n        attn = self.attn_drop(attn)\n        x = (attn @ v).transpose(1, 2)\n        last_dim = int(x.numel() // B_ // N)\n        x = x.reshape(-1, N, last_dim)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n</code></pre> <p><code>SwinTransformerBlock</code>\u7684<code>forward</code>\u51fd\u6570\u4fee\u6539\u5982\u4e0b:</p> <pre><code>def forward(self, x):\n        H, W = self.input_resolution\n        B, L, C = map(int, x.shape)\n        _assert(L == H * W, \"input feature has wrong size\")\n        shortcut = x\n        x = self.norm1(x)\n        x = x.view(-1, H, W, C)\n        # cyclic shift\n        if self.shift_size &gt; 0:\n            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n        else:\n            shifted_x = x\n        # partition windows\n        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n        # W-MSA/SW-MSA\n        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n        # merge windows\n        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n        # reverse cyclic shift\n        if self.shift_size &gt; 0:\n            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n        else:\n            x = shifted_x\n        x = x.view(-1, H * W, C)\n        # FFN\n        x = shortcut + self.drop_path(x)\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n        return x\n</code></pre> <p><code>PatchMerging</code>\u7684<code>forward</code>\u51fd\u6570\u4fee\u6539\u5982\u4e0b\uff1a</p> <pre><code>def forward(self, x):\n        \"\"\"\n        x: B, H*W, C\n        \"\"\"\n        H, W = self.input_resolution\n        B, L, C = map(int, x.shape)\n        _assert(L == H * W, \"input feature has wrong size\")\n        _assert(H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\")\n        x = x.view(B, H, W, C)\n        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n        x = x.view(-1, H // 2 * W // 2, 4 * C)  # B H/2*W/2 4*C\n        x = self.norm(x)\n        x = self.reduction(x)\n        return x\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#45-onnx","title":"4.5 \u91cd\u65b0\u751f\u6210onnx\u5e76\u68c0\u67e5","text":"<ol> <li>\u5982\u679c\u662f<code>.py</code>\u5c31\u91cd\u65b0\u6267\u884c<code>python xxx.py</code>\uff0c\u5982\u679c\u662f<code>jupyter notebook</code>\uff0c\u5219\u9700\u8981\u91cd\u542f\u5185\u6838\u3002</li> <li><code>pip install netron</code>\u5b89\u88c5<code>netron</code></li> <li>\u8fd0\u884c<code>netron swin-b-22kto1l.onnx</code>\u67e5\u770b\u751f\u6210\u7684onnx\uff0c\u67e5\u770b\u6a21\u578b\u6574\u4f53\u7b80\u6d01\u6027\uff08\u4e3b\u89c2\uff09\u3002</li> </ol> <p>\u7ecf\u8fc7\u67e5\u770bonnx\u7ed3\u6784\uff0c\u53d1\u73b0\u4fee\u6539\u7684onnx\u7ed3\u6784\u8f83\u4e3a\u7b80\u6d01\uff0c\u4e14\u652f\u6301batch size\u7684\u52a8\u6001shape\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#46-tensorrt","title":"4.6 \u5728TensorRT\u4e0a\u9a8c\u8bc1","text":"<p>\u8fd9\u91cc\u4f7f\u7528tensorRT\u7684\u5c01\u88c5\u7248\u672c<code>trtpy</code>\uff0c\u4e3b\u8981\u89e3\u51b3\u7248\u672c\u9694\u79bb\u95ee\u9898\u548c\u5b89\u88c5\u7e41\u7410\u95ee\u9898\u3002 \u5b89\u88c5\u548c\u4f7f\u7528\u8be6\u60c5\u8bf7\u67e5\u770bhttps://zhuanlan.zhihu.com/p/462980738</p> <pre><code>import trtpy\nimport numpy as np\ndef replace_suffix(path_name, new_extname = '.trtmodel'):\n    return os.path.splitext(path_name)[0] + new_extname\nonnx_filepath = 'swin-b-22kto1l.onnx'\nengine_file = replace_suffix(onnx_filepath)\nif not os.path.exists(engine_file):\n    trtpy.compile_onnx_to_file(128, onnx_filepath, engine_file, max_workspace_size=1 &lt;&lt; 30) # 1 &lt;&lt; 30 \u8868\u793a 1GiB\nengine = trtpy.load(engine_file)\nengine.print()\ndef test_trt(engine, model, device, test_loader):\n    old_training_state = model.training\n    model.eval()\n    test_loss = 0\n    correct = 0\n    delta_max = 0\n    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n    for data, target in tqdm.tqdm(test_loader):\n        data, target = data.to(device), target.to(device)\n        with torch.no_grad():\n            output = model(data)\n        output_engine = engine(data)\n        delta_max = max(delta_max, torch.abs(output_engine - output).max().item())\n\n        test_loss += lossLayer(output, target).item()\n        pred = output.argmax(dim=1, keepdim=True)\n        correct += pred.eq(target.view_as(pred)).sum().item()\n    print('delta_max:', delta_max)\n    test_loss /= len(test_loader.dataset)\n    model.train(old_training_state)\n    print('\nTest set: Average loss: {:.4f}, Accuracy: {:.3f}%\n'.format(\n        test_loss, 100. * correct / len(test_loader.dataset)\n\n    ))\nswin_transformer_model.to(device)\ntest_trt(engine, swin_transformer_model, device, val_loader)\n</code></pre> <p>\u6700\u540e\u8f93\u51fa</p> <pre><code>delta_max: 0.0006237030029296875\nTest set: Average loss: 0.6448, Accuracy: 85.126%\n</code></pre> <p>\u4ee5\u4e0a\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b0\u5bfc\u51fa\u7684onnx\u652f\u6301\u52a8\u6001batch size\uff0c\u5e76\u4e14TensorRT\u4e0etorch\u751f\u6210\u7ed3\u679c\u8bef\u5dee\u5f88\u5c0f\uff0c abs diff \u53ef\u4ee5\u63a7\u5236\u57280.0006\u4ee5\u5185\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#47","title":"4.7 \u5c0f\u7ed3","text":"<p>\u901a\u8fc7\u5bf9SwinTransformer\u6a21\u578b\u4ee3\u7801\u7684\u4fee\u6539\uff0c\u4f7f\u5f97onnx\u5bfc\u51fa\u66f4\u4e3a\u7b80\u6d01\u3002\u56e0\u4e3a\u8be5\u6a21\u578b\u8f83\u4e3a\u7b80\u5355\uff0c\u5728\u5bfc\u51fa\u65f6\u5e76\u6ca1\u6709\u4f7f\u7528<code>onnxsim</code>\u7b80\u5316\u6a21\u578b\uff0c\u4e0b\u4e00\u7ae0\u5bf9<code>DETR</code>\u7684\u5bfc\u51fa\u5c06\u4f1a\u770b\u5230\u6240\u6709\u5de5\u5177\u7684\u7efc\u5408\u8fd0\u7528\u8fdb\u884cDebug\u3002 \u6b64\u5916\uff0cTransformer\u5728CV\u9886\u57df\u5df2\u7ecf\u53ef\u4ee5\u5f88\u65b9\u4fbf\u7684\u843d\u5730\u4e86\uff0c\u5e76\u4e14\u662f\u652f\u6301\u52a8\u6001batchsize\u7684\u3002\u4e2a\u4eba\u7684\u76f4\u89c2\u611f\u53d7\u65f6\u8f83\u4e3a\u90e8\u7f72\u65f6\u91c7\u7528SwinTransformer\u5360\u7528\u663e\u5b58\u6bd4\u8f83\u5927\uff0c\u4e0d\u8fc7<code>85.2%</code>\u7684\u7cbe\u5ea6\u4e5f\u7b97\u6027\u4ef7\u6bd4\u8f83\u9ad8\u7684\u6a21\u578b\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#2-detrtensorrt","title":"\u4e94\u3001\u6848\u4f8b2-DETR\u5728TensorRT\u4e0a\u7684\u90e8\u7f72","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#51","title":"5.1 \u4e0b\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u5e76\u9a8c\u8bc1\u6a21\u578b\u6548\u679c","text":"<p>\u8fd9\u91cc\u91c7\u7528\u96c6\u6210\u7684<code>mmdetection</code>\u5e93\u4e2d\u7684DETR\u3002github\u5730\u5740\u4e3ahttps://github.com/open-mmlab/mmdetection \u4e3a\u4e86\u65b9\u4fbf\u4fee\u6539\u4ee3\u7801\uff0c<code>mmdetection</code>\u9700\u8981\u91c7\u7528clone\u4ed3\u5e93\uff0c<code>python setup.py develop</code>\u65b9\u5f0f\u5b89\u88c5\uff0c\u5373</p> <pre><code>git clone https://github.com/open-mmlab/mmdetection.git\ncd mmdetection\npip install -r requirements/build.txt\npip install -v -e .  # or \"python setup.py develop\"\n</code></pre> <ol> <li>\u5728\u6b64\u4e4b\u524d\u8bfb\u8005\u8fd8\u8bf7\u9605\u8bfb MMDetection\u5b89\u88c5\u6307\u5357 \u4e86\u89e3\u5168\u90e8\u5b89\u88c5\u6b65\u9aa4\u3002</li> <li>\u4ece https://github.com/open-mmlab/mmdetection/tree/master/configs/detr \u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u5e76\u8bb0\u5f55path\u5907\u7528\u3002</li> <li>\u5b89\u88c5onnxsim\uff0cpolygraphy\uff0connxruntime\u5e93</li> </ol> <p>\u4fee\u6539<code>mmdetection/tools/deployment/pytorch2onnx.py</code>\uff0c\u8ba9\u5176\u652f\u6301\u518d<code>skip-postprocess</code>\u6761\u4ef6\u4e0b\u652f\u6301<code>onnxsim</code> \u5728\u5224\u65ad\u8bed\u53e5\u90a3\u91cc\u52a0\u4e0a\u5982\u4e0b\u4ee3\u7801</p> <pre><code>    if skip_postprocess:\n        warnings.warn('Not all models support export onnx without post '\n                      'process, especially two stage detectors!')\n        model.forward = model.forward_dummy\n        torch.onnx.export(\n            model,\n            one_img,\n            output_file,\n            input_names=['input'],\n            export_params=True,\n            keep_initializers_as_inputs=True,\n            do_constant_folding=True,\n            verbose=show,\n            opset_version=opset_version)\n        print(f'Successfully exported ONNX model without '\n              f'post process: {output_file}')\n        # \u6dfb\u52a0\u7684\u4ee3\u7801 \u5f00\u59cb\n        # get the custom op path\n        ort_custom_op_path = ''\n        try:\n            from mmcv.ops import get_onnxruntime_op_path\n            ort_custom_op_path = get_onnxruntime_op_path()\n        except (ImportError, ModuleNotFoundError):\n            warnings.warn('If input model has custom op from mmcv, \\\\\n                you may have to build mmcv with ONNXRuntime from source.')\n        ort_custom_op_path = ort_custom_op_path if len(ort_custom_op_path) &gt; 0 else None\n        if do_simplify:\n            import onnxsim\n            from mmdet import digit_version\n            min_required_version = '0.3.0'\n            assert digit_version(onnxsim.__version__) &gt;= digit_version(\n                min_required_version\n            ), f'Requires to install onnx-simplify&gt;={min_required_version}'\n            input_dic = {'input': img_list[0].detach().cpu().numpy()}\n            model_opt, check_ok = onnxsim.simplify(\n                output_file,\n                input_data=input_dic,\n                custom_lib=ort_custom_op_path,\n                dynamic_input_shape=dynamic_export)\n            if check_ok:\n                onnx.save(model_opt, output_file)\n                print(f'Successfully simplified ONNX model: {output_file}')\n            else:\n                warnings.warn('Failed to simplify ONNX model.')\n            print(f'Successfully exported ONNX model: {output_file}')\n            # \u6dfb\u52a0\u7684\u4ee3\u7801\u7ed3\u675f\n        return\n</code></pre> <p>\u65b0\u5efa\u4e00\u4e2abash\u811a\u672c<code>export_detr_onnx.sh</code></p> <pre><code>#!/bin/bash\npython tools/deployment/pytorch2onnx.py configs/detr/detr_r50_8x2_150e_coco.py detr_r50_8x2_150e_coco_20201130_194835-2c4b8974.pth --skip-postprocess --show --simplify\n</code></pre> <p>\u6267\u884c\u5982\u4e0b\u6307\u4ee4\uff1a</p> <pre><code>bash export_detr_onnx.sh &amp;&gt; export_log.txt\n</code></pre> <p>\u901a\u8fc7\u4ee5\u4e0a\u6b65\u9aa4\u5373\u53ef\u5f97\u5230\u4e00\u4e2a\u7cbe\u7b80\u7248\u7684onnx\uff0c\u6b64\u5904\u5e76\u6ca1\u6709\u4fee\u6539\u4efb\u4f55\u6a21\u578b\u4ee3\u7801\uff0c\u56e0\u4e3a\u4fee\u6539\u6a21\u578b\u4ee3\u7801\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u5904\u7406inplace\u64cd\u4f5c\u548c\u5b9e\u73b0\u52a8\u6001batchsize\uff0c\u5728mmdetection\u4e2dDETR\uff0c\u5e76\u6ca1\u6709inplace\u64cd\u4f5c\uff0c\u4e14\u52a8\u6001batchsize\u64cd\u4f5c\u5b9e\u73b0\u8d77\u6765\u5f88\u96be\uff0c\u4e0b\u9762\u4f1a\u7ed9\u51fa\u89e3\u91ca\u3002 \u4f7f\u7528netron\u53ef\u89c6\u5316onnx\u540e\u53d1\u73b0\u5f88\u591a\u5197\u4f59\u7b97\u5b50\uff0c\u8fd9\u91cc\u9700\u8981\u4f7f\u7528<code>onnx_graphsurgeon</code>\u6e05\u7406\u4e00\u4e0b\u3002</p> <pre><code>import onnx_graphsurgeon as gs\nimport onnx\nimport numpy as np\ndef cleanOnnx():\n    onnx_save_path = \"tmp.onnx\"\n    graph = gs.import_onnx(onnx.load(onnx_save_path))\n    graph.cleanup()\n    onnx_save_path = \"tmp_new.onnx\"\n    onnx.save(gs.export_onnx(graph), onnx_save_path)\ncleanOnnx()\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#52-batchsize","title":"5.2 \u52a8\u6001batchsize\u5b9e\u73b0\u5f88\u96be","text":"<p> \u5982\u4e0a\u56fe\u4e3a\u751f\u6210\u7684onnx\uff0c\u5b9e\u9645\u4e0a\u8fd9\u4e2aonnx\u5df2\u7ecf\u53ef\u4ee5onnxruntime\u4e2d\u8fd0\u884c\u4e86\u3002\u4f46\u662fbatch size\u8bbe\u7f6e\u4e3a\u52a8\u6001\u7684\u5374\u5f88\u96be\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u540e\u7eed\u7684\u64cd\u4f5c\u4e0d\u80fd\u786e\u5b9a\u54ea\u4e2a\u7ef4\u5ea6\u8bbe\u7f6e\u4e3a-1\u3002 Reshape\u64cd\u4f5c\u4e2d\u5982\u679c\u662f\u52a8\u6001\u7ef4\u5ea6\uff0c\u7ed9\u5b9a\u7684shape\u4e2d\u8981\u6709\u4e00\u4e2a\u503c\u4e3a-1\uff0c\u4f46\u662f\u5982\u4e0a\u56fe\u6240\u793a\uff0cReshape+Tranpose\u64cd\u4f5c\u4ee5\u540e\uff0c\u6253\u4e71\u4e86batch size\u6240\u5728\u7684\u7ef4\u5ea6\uff0c\u540e\u7eed\u7684reshape\u64cd\u4f5c\u80af\u5b9a\u53ef\u4ee5\u4fee\u6539\uff0c\u4f46\u662f\u54ea\u4e2a\u7ef4\u5ea6\u4e3a-1\u4e0d\u592a\u597d\u8bbe\u5b9a\uff0c\u8fd9\u4e2a\u7559\u5230\u540e\u7eed\u518d\u6765\u63a2\u7d22\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#53","title":"5.3 \u52a0\u4e0a\u540e\u7eed\u4f4d\u7f6e\u4fe1\u606f\u89e3\u7801\u8fc7\u7a0b","text":"<p>\u5728\u524d\u9762\u5c0f\u8282\u5bfc\u51fa\u7684onnx\u4e2d\u7531\u4e8e<code>skip-postprocess</code>\u7684\u5b58\u5728\uff0c\u5e76\u6ca1\u6709\u5bf9\u4e2d\u95f4\u8f93\u51fa\u8fdb\u884c\u89e3\u7801\uff0c\u8fd9\u91cc\u901a\u8fc7\u4fee\u6539\u68c0\u6d4b\u5934\u7684<code>forward</code>\u51fd\u6570\u52a0\u4e0a\u5b83\uff0c\u627e\u5230<code>mmdetection/mmdet/models/dense_heads/detr_head.py</code>\u4e2d<code>DETRHead</code>\u7c7b\u7684<code>forward</code>\u65b9\u6cd5\uff0c \u4fee\u6539\u5982\u4e0b\uff1a</p> <pre><code>    def forward(self, feats, img_metas):\n        \"\"\"Forward function.\n        Args:\n            feats (tuple[Tensor]): Features from the upstream network, each is\n                a 4D-tensor.\n            img_metas (list[dict]): List of image information.\n        Returns:\n            tuple[list[Tensor], list[Tensor]]: Outputs for all scale levels.\n                - all_cls_scores_list (list[Tensor]): Classification scores \\\\\n\n                    for each scale level. Each is a 4D-tensor with shape \\\\\n                    [nb_dec, bs, num_query, cls_out_channels]. Note \\\\\n                    `cls_out_channels` should includes background.\n                - all_bbox_preds_list (list[Tensor]): Sigmoid regression \\\\\n\n                    outputs for each scale level. Each is a 4D-tensor with \\\\\n                    normalized coordinate format (cx, cy, w, h) and shape \\\\\n                    [nb_dec, bs, num_query, 4].\n        \"\"\"\n        num_levels = len(feats)\n        img_metas_list = [img_metas for _ in range(num_levels)]\n        # return multi_apply(self.forward_single, feats, img_metas_list)\n        all_cls_scores_list, all_bbox_preds_list = multi_apply(self.forward_single, feats, img_metas_list)\n        image_metas_for_onnx = img_metas_list[0:1][0]\n        image_metas_for_onnx[0]['img_shape_for_onnx'] = torch.as_tensor(img_metas[0]['img_shape'])[:2]\n        return self.onnx_export(all_cls_scores_list, all_bbox_preds_list, image_metas_for_onnx)\n</code></pre> <p><code>Line24-Line28</code>\u662f\u65b0\u589e\u7684\uff0c\u7528\u4e8e\u89e3\u7801\u4e2d\u95f4\u4fe1\u606f\uff0c\u76f4\u63a5\u8f93\u51fa\u5750\u6807\u4fe1\u606f\u548c\u5206\u7c7b\u4fe1\u606f\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#54-onnxruntime","title":"5.4 \u4f7f\u7528onnxruntime\u9a8c\u8bc1","text":"<ol> <li>\u6d4b\u8bd5\u56fe\u7247\u5982\u4e0b\uff1a</li> </ol> <p> \u8bfb\u8005\u53ef\u4ee5\u53f3\u952e\u5b58\u4e3a<code>car.jpg</code></p> <ol> <li>\u5206\u6790\u6a21\u578bconfig\u6587\u4ef6\uff0c\u5f97\u5230\u6570\u636e\u9884\u5904\u7406\u6b65\u9aa4</li> <li>\u7ed9\u51faonnxruntime\u9a8c\u8bc1\u4ee3\u7801</li> </ol> <pre><code>import onnxruntime as rt\nimport cv2\ndef get_onnx_runner(onnx_filepath):\n    sess = rt.InferenceSession(onnx_filepath)\n    input_names = [item.name for item in sess.get_inputs()]\n    label_names = [item.name for item in sess.get_outputs()]\n    def runner(input_tensors):\n        nonlocal label_names\n        nonlocal input_names\n        pred_onnx = sess.run(label_names, dict(zip(input_names, input_tensors)))\n        return dict(zip(label_names,pred_onnx))\n    return runner\ndef _normalize(img, mean, std):\n    img = img.astype(np.float32) / 255\n    mean = np.array(mean, dtype=np.float32).reshape(1, 1, 3) / 255\n    std = np.array(std, dtype=np.float32).reshape(1, 1, 3) / 255\n    img = (img - mean) / std\n\n    return img\ndef preprocess(img):\n    img = cv2.resize(img, dsize=(1216,800))\n    mean,std = [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]\n    img = _normalize(img, mean, std)\n    img = np.transpose(img, axes=[2, 0, 1])\n    img = np.expand_dims(img, 0)\n    return img\nrunner = get_onnx_runner(\"./tmp_new.onnx\")\nori_image = cv2.imread('../car.jpg')\nimg = cv2.cvtColor(ori_image, cv2.COLOR_BGR2RGB)\nimg = preprocess(img)\nouts = runner([img, ])\nprint(outs.keys())\n# det_bboxes[x1,y1,x2,y2,scores], det_labels[]\ndet_bboxes, scores = outs['3288'][:, :, :4], outs['3288'][:, :, 4:]\ndet_labels = outs['3209']\ndet_bboxes = np.round(det_bboxes).astype(np.int32)\nfrom torchvision.ops import nms as torch_nms\nimport torch\ndet_bboxes = det_bboxes[0]\ndet_labels = det_labels[0]\nscores = scores[0]\nscores = scores[:, 0]\ndef nms(ori_dets):\n    tmp_arr = np.array(ori_dets, dtype=np.float32)\n    dets, score = tmp_arr[:,:4], tmp_arr[:,4]\n    dets_tensor = torch.as_tensor(dets)\n    score_tensor = torch.as_tensor(score)\n    keep_index = torch_nms(dets_tensor, score_tensor, 0.4)\n    new_dets = [ori_dets[index] for index in keep_index]\n    return new_dets\ndef decode_infer(scores, det_bboxes, det_labels, score_threshold):\n    ret_dict = dict()\n    max_scores = scores\n    nonzero_index  = np.nonzero(max_scores &gt; score_threshold)[0].tolist()\n    if nonzero_index:\n        bbox_pred = det_bboxes[nonzero_index, :]\n        score_indexes = max_scores[nonzero_index]\n        score_indexes = score_indexes[..., None].astype(np.float32)\n        label_indexes = det_labels[nonzero_index]\n        print(label_indexes)\n        label_indexes = label_indexes[..., None].astype(np.float32)\n        max_label_indexes = label_indexes[:, 0]\n        bbox = np.concatenate([bbox_pred, score_indexes, label_indexes], axis = -1)\n        for i,index in enumerate(max_label_indexes):\n            ret_list = ret_dict.setdefault(index, list())\n            ret_list.append(bbox[i])\n    for k,v in ret_dict.items():\n        ret_dict[k] = nms(v)\n    return ret_dict\nret_dict = decode_infer(scores, det_bboxes, det_labels, 0.5)\nlabels = (\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\",\n            \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n            \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n            \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n            \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n            \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n            \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n            \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n            \"hair drier\", \"toothbrush\")\ncolor_list = (\n        (216 , 82 , 24),\n        (236 ,176 , 31),\n        (125 , 46 ,141),\n        (118 ,171 , 47),\n        ( 76 ,189 ,237),\n        (238 , 19 , 46),\n        ( 76 , 76 , 76),\n        (153 ,153 ,153),\n        (255 ,  0 ,  0),\n        (255 ,127 ,  0),\n        (190 ,190 ,  0),\n        (  0 ,255 ,  0),\n        (  0 ,  0 ,255),\n        (170 ,  0 ,255),\n        ( 84 , 84 ,  0),\n        ( 84 ,170 ,  0),\n        ( 84 ,255 ,  0),\n        (170 , 84 ,  0),\n        (170 ,170 ,  0),\n        (170 ,255 ,  0),\n        (255 , 84 ,  0),\n        (255 ,170 ,  0),\n        (255 ,255 ,  0),\n        (  0 , 84 ,127),\n        (  0 ,170 ,127),\n        (  0 ,255 ,127),\n        ( 84 ,  0 ,127),\n        ( 84 , 84 ,127),\n        ( 84 ,170 ,127),\n        ( 84 ,255 ,127),\n        (170 ,  0 ,127),\n        (170 , 84 ,127),\n        (170 ,170 ,127),\n        (170 ,255 ,127),\n        (255 ,  0 ,127),\n        (255 , 84 ,127),\n        (255 ,170 ,127),\n        (255 ,255 ,127),\n        (  0 , 84 ,255),\n        (  0 ,170 ,255),\n        (  0 ,255 ,255),\n        ( 84 ,  0 ,255),\n        ( 84 , 84 ,255),\n        ( 84 ,170 ,255),\n        ( 84 ,255 ,255),\n        (170 ,  0 ,255),\n        (170 , 84 ,255),\n        (170 ,170 ,255),\n        (170 ,255 ,255),\n        (255 ,  0 ,255),\n        (255 , 84 ,255),\n        (255 ,170 ,255),\n        ( 42 ,  0 ,  0),\n        ( 84 ,  0 ,  0),\n        (127 ,  0 ,  0),\n        (170 ,  0 ,  0),\n        (212 ,  0 ,  0),\n        (255 ,  0 ,  0),\n        (  0 , 42 ,  0),\n        (  0 , 84 ,  0),\n        (  0 ,127 ,  0),\n        (  0 ,170 ,  0),\n        (  0 ,212 ,  0),\n        (  0 ,255 ,  0),\n        (  0 ,  0 , 42),\n        (  0 ,  0 , 84),\n        (  0 ,  0 ,127),\n        (  0 ,  0 ,170),\n        (  0 ,  0 ,212),\n        (  0 ,  0 ,255),\n        (  0 ,  0 ,  0),\n        ( 36 , 36 , 36),\n        ( 72 , 72 , 72),\n        (109 ,109 ,109),\n        (145 ,145 ,145),\n        (182 ,182 ,182),\n        (218 ,218 ,218),\n        (  0 ,113 ,188),\n        ( 80 ,182 ,188),\n        (127 ,127 ,  0),\n    )\nframe = np.copy(ori_image)\nheight = img.shape[2]\nwidth = img.shape[3]\nfor v in ret_dict.values():\n    for left, top, right, bottom, score, label_index in v:\n        label_index = int(label_index)\n        new_left = int(left / width * frame.shape[1])\n        new_top = int(top / height * frame.shape[0])\n        new_right = int(right / width * frame.shape[1])\n        new_bottom = int(bottom / height * frame.shape[0])\n        cv2.rectangle(frame, (new_left, new_top), (new_right, new_bottom), color = color_list[label_index])\n        # \u5199\u5b57\n        ret, baseline = cv2.getTextSize(labels[label_index], cv2.FONT_HERSHEY_SIMPLEX, 0.8, 1)\n        cv2.rectangle(frame, (new_left, new_top - ret[1] - baseline),\n\n                    (new_left + ret[0], new_top), color_list[label_index], -1)\n        cv2.putText(frame, labels[label_index], (new_left, new_top - baseline),\n\n                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)\nimport matplotlib.pyplot as plt\nh,w = frame.shape[:2]\nplt.figure(figsize=(w / 50, h / 50))\nplt.imshow(frame[..., ::-1])\nplt.show()\n</code></pre> <p>\u6700\u7ec8\u6548\u679c\u5982\u4e0b\u56fe\uff1a </p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#55-tensorrt","title":"5.5 TensorRT\u4e0a\u9a8c\u8bc1","text":"<p>\u8fd9\u91cc\u672c\u6587\u7ee7\u7eed\u91c7\u7528trtpy\uff0c\u6ce8\u610f\u7531\u4e8e\u672c\u6587\u7684\u4ee3\u7801\u65f6\u653e\u5728\u4e00\u4e2a<code>jupyter notebook</code>\u4e2d\uff0c\u6240\u4ee5\u590d\u7528\u4e86\u4e0a\u4e00\u5c0f\u8282\u7684\u53d8\u91cf\u3002 <code>det_labels, det_bboxes_with_scores</code>\u8fd9\u4e24\u4e2a\u987a\u5e8f\u53ef\u80fd\u4f1a\u53cd\uff0c\u8bfb\u8005\u9700\u8981\u81ea\u884c\u8c03\u6362\u3002</p> <pre><code>import trtpy\nimport numpy as np\nimport os\ndef replace_suffix(path_name, new_extname = '.trtmodel'):\n    return os.path.splitext(path_name)[0] + new_extname\nonnx_filepath = 'tmp_new.onnx'\nengine_file = replace_suffix(onnx_filepath)\ntrtpy.compile_onnx_to_file(1, onnx_filepath, engine_file, max_workspace_size=1 &lt;&lt; 30)\nengine = trtpy.load(engine_file)\nengine.print()\ndata = torch.as_tensor(img).to(torch.float32).cuda()\noutput_engine = engine(data)\nprint(output_engine)\ndet_labels, det_bboxes_with_scores = output_engine\ndet_bboxes, scores = det_bboxes_with_scores[:, :, :4], det_bboxes_with_scores[:, :, 4:]\ndet_bboxes = det_bboxes[0].round().to(torch.int32)\ndet_labels = det_labels[0].round().to(torch.int32)\nscores = scores[0]\nscores = scores[:, 0]\nret_dict_trt = decode_infer(scores.cpu().numpy(), det_bboxes.cpu().numpy(), det_labels.cpu().numpy(), 0.5)\nframe = np.copy(ori_image)\nheight = img.shape[2]\nwidth = img.shape[3]\nfor v in ret_dict_trt.values():\n    for left, top, right, bottom, score, label_index in v:\n        label_index = int(label_index)\n        new_left = int(left / width * frame.shape[1])\n        new_top = int(top / height * frame.shape[0])\n        new_right = int(right / width * frame.shape[1])\n        new_bottom = int(bottom / height * frame.shape[0])\n        cv2.rectangle(frame, (new_left, new_top), (new_right, new_bottom), color = color_list[label_index])\n        ret, baseline = cv2.getTextSize(labels[label_index], cv2.FONT_HERSHEY_SIMPLEX, 0.8, 1)\n        cv2.rectangle(frame, (new_left, new_top - ret[1] - baseline),\n\n                    (new_left + ret[0], new_top), color_list[label_index], -1)\n        cv2.putText(frame, labels[label_index], (new_left, new_top - baseline),\n\n                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)\nh,w = frame.shape[:2]\nplt.figure(figsize=(w / 50, h / 50))\nplt.imshow(frame[..., ::-1])\nplt.show()\n</code></pre> <p><code>print(output_engine)</code>\u8f93\u51fa\u51680\uff0c\u4f1a\u8ba9\u4eba\u5f88\u5934\u75bc\uff0c\u6000\u7591\u662f\u4e0d\u662f\u54ea\u4e00\u6b65\u641e\u9519\u4e86\u3002\u8fd9\u4e2a\u65f6\u5019\u5c31\u9700\u8981\u8f93\u51fa\u6bcf\u4e00\u5c42\u7684\u4e2d\u95f4\u7ed3\u679c\u6253\u5370\u4e86\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#56","title":"5.6 \u8c03\u8bd5\u6a21\u578b\u4e2d\u95f4\u7ed3\u679c","text":"<p>\u7531\u4e8eonnxruntime\u8f93\u51fa\u7ed3\u679c\u65f6\u6b63\u786e\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u6709\u7406\u7531\u76f8\u4fe1\u5176\u4e2d\u95f4\u7ed3\u679c\u4e5f\u662f\u6b63\u786e\u7684\u3002\u8fdb\u800c\u53ef\u4ee5\u8f6c\u6362\u4e3aTensorRT\u4e0eonnxruntime\u4e2d\u95f4\u5c42\u4e0d\u4e00\u81f4\u95ee\u9898\u3002 \u6b64\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u501f\u52a9<code>polygraphy</code>\u5de5\u5177\u6765\u5b8c\u6210\u5bf9\u4e2d\u95f4\u5c42\u8f93\u51fa\u7684\u6821\u5bf9\u3002 <code>polygraphy</code>\u5b89\u88c5\u547d\u4ee4\uff0c<code>polygraphy</code>\u4f5c\u8005\u5b89\u88c5\u7684\u7248\u672c\u4e3a<code>0.35.2</code></p> <pre><code>python -m pip install colored polygraphy --extra-index-url https://pypi.ngc.nvidia.com\n</code></pre> <p>\u5c06\u5982\u4e0b\u4ee3\u7801\u5b58\u4e3a<code>debug_detr.sh</code></p> <pre><code>polygraphy run tmp_new.onnx --onnxrt --onnx-outputs mark all --save-results=onnx_out.json\npolygraphy run tmp_new.onnx --trt --validate --trt-outputs mark all --save-results=trt_out.json\n</code></pre> <p>\u8fd0\u884c\u65f6\u4f60\u4f1a\u53d1\u73b0\u62a5\u9519\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u865a\u62df\u73af\u5883\u5e76\u6ca1\u6709\u5b89\u88c5\u539f\u7248\u7684TensorRT\uff0c\u9700\u8981\u505a\u4e00\u5b9a\u4fee\u6539\u3002\u9519\u8bef\u5982\u4e0b</p> <pre><code>[!] Module: 'tensorrt' is required but could not be imported.\n    You can try setting POLYGRAPHY_AUTOINSTALL_DEPS=1 in your environment variables to allow Polygraphy to automatically install missing modules.\n    Note that this may cause existing modules to be overwritten - hence, it may be desirable to use a Python virtual environment or container.\n</code></pre> <p>\u6253\u5f00<code>${PYENV}/lib/python3.9/site-packages/polygraphy/mod/importer.py</code>\uff0c\u627e\u5230<code>lazy_import</code>\u51fd\u6570\uff0c\u5728\u7b2c\u4e00\u53e5assert\u8bed\u53e5\u4e0b\u9762 \u52a0\u4e0a\u8fd9\u53e5\u8bdd</p> <pre><code>if name == \"tensorrt\":\n        name = \"trtpy.tensorrt\"\n</code></pre> <p>\u6b64\u5916\u8fd8\u53ef\u80fd\u78b0\u5230\u8bf4tensorrt\u6ca1\u6709<code>__version__</code>\uff0c\u8fd9\u4e2a\u65f6\u5019\u9700\u8981\u4fee\u6539trtpy\u4e2d\u7684<code>tensorrt</code>\u3002 \u627e\u5230<code>${PYENV}/lib/python3.9/site-packages/trtpy/tensorrt/__init__.py</code> \u641c\u7d22<code>__version__</code>\u8be5\u884c\u7136\u540e\u53bb\u6389\u6ce8\u91ca\u3002 \u7ecf\u8fc7\u4ee5\u4e0a\u8fc7\u7a0b\uff0c\u91cd\u65b0\u6267\u884c\u4e0a\u9762\u7684\u751f\u6210\u811a\u672c\u5f97\u5230\u4e24\u4e2ajson\u6587\u4ef6\uff0c\u91c7\u7528\u5982\u4e0b\u4ee3\u7801\u6bd4\u8f83\u4e2d\u95f4\u7ed3\u679c</p> <pre><code>import numpy as np\nfrom polygraphy.json import load_json\ninfo_onnx = load_json('onnx_out.json')\n# print(info_onnx)\ninfo_trt = load_json('trt_out.json')\n# print(info)\nrunners_trt = list(info_trt.keys())\nrunners_onnx = list(info_onnx.keys())\nprint('onnx:', len(info_onnx.__getitem__(runners_onnx[0])[0]))\nprint('tensorrt:', len(info_trt.__getitem__(runners_trt[0])[0]))\noutputs_trt = info_trt['lst'][0][1][0]['outputs']\noutputs_onnx = info_onnx['lst'][0][1][0]['outputs']\nfor layer in outputs_onnx:\n    if layer in outputs_trt:    # \u53ea\u5206\u6790\u76f8\u540c\u540d\u79f0\u7684\u8282\u70b9\u8f93\u51fa\n        value_onnx = outputs_onnx[layer]['values']\n        value_trt = outputs_trt[layer]['values']\n        try:\n            np.testing.assert_allclose(value_onnx, value_trt, 0.001, 0.001)\n        except Exception as e:\n            print('-' * 20)\n            print(layer, value_onnx.shape, value_trt.shape)\n            print(e)\n</code></pre> <p>\u7ecf\u8fc7\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u4f1a\u8f93\u51fa\u5f88\u591a\u4e0d\u4e00\u81f4\u7684\u4e2d\u95f4\u5c42\uff0c\u7ecf\u8fc7\u4f5c\u8005\u7684\u641c\u7d22\u5f15\u64ce\u5927\u6cd5\u548c\u7ecf\u9a8c\uff0c\u9996\u5148\u5b9a\u4f4d\u5230Gather\u7b97\u5b50\uff0c\u53ef\u80fd\u662fTensorRT\u7684Gather\u7b97\u5b50\u4e0d\u652f\u6301\u8d1f\u503c\u7d22\u5f15\uff0c\u56e0\u6b64\u4fee\u6539cleanOnnx\u51fd\u6570\u4fee\u6539\u539f\u6765\u7684onnx\u3002\u81f3\u4e8e\u4e3a\u4ec0\u4e48\u662f5\uff0c\u56e0\u4e3a\u4e4b\u524d\u7684\u5f62\u72b6\u662f<code>6x?x?x?x</code>\uff0c6-1 = 5.</p> <pre><code>import onnx_graphsurgeon as gs\nimport onnx\nimport numpy as np\ndef cleanOnnx():\n    onnx_save_path = \"tmp.onnx\"\n    graph = gs.import_onnx(onnx.load(onnx_save_path))\n    for node in graph.nodes:\n        if node.name.startswith('Gather'):\n            indices = node.inputs[1]\n            if isinstance(indices, gs.Constant):\n                print(node.name)\n                print(indices.values)\n            # \u53bb\u6389\u8d1f\u7d22\u5f15\n            if isinstance(indices, gs.Constant) and indices.values == -1:\n                    node.inputs[1].values = np.int64(5)\n            if isinstance(indices, gs.Constant):\n                print(indices.values)\n    graph.cleanup()\n    onnx_save_path = \"tmp_new.onnx\"\n    onnx.save(gs.export_onnx(graph), onnx_save_path)\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#57-trtpybug","title":"5.7 trtpy\u7684\u5c0fbug","text":"<p>\u7ecf\u8fc7\u4e0a\u9762\u7684\u4fee\u6539\uff0ctensorRT\u77e9\u5f62\u6846\u8f93\u51fa\u6b63\u5e38\u4e86\uff0c\u4f46\u662f\u5206\u7c7b\u7ed3\u679c\u5168\u4e3a0\uff0c\u539f\u56e0\u5728\u4e8etrtpy\u5c06\u8f93\u51fa\u7684int32\u7c7b\u578b\u6309\u7167float32\u89e3\u6790\u4e86\uff0c\u4ece\u800c\u9020\u6210\u89e3\u7801\u9519\u8bef\u3002\u4e00\u4e2a\u8ba8\u5de7\u7684\u65b9\u6cd5\u662f\u5728<code>mmdetection/mmdet/models/dense_heads/detr_head.py</code>\u4e2d<code>DETRHead</code>\u7c7b\u7684<code>onnx_export</code>\u65b9\u6cd5\u7684\u8fd4\u56de\u503c\u52a0\u4e0a\u7c7b\u578b\u8f6c\u6362\uff0c\u5373\u5c06<code>return det_bboxes, det_labels</code>\u4fee\u6539\u4e3a<code>return det_bboxes, det_labels.to(torch.float32)</code>\uff0c\u7136\u540e\u91cd\u65b0\u751f\u6210<code>tmp.onnx</code>\u548c<code>tmp_new.onnx</code>\uff0c\u4f7f\u7528\u539f\u751ftensorRT\u7684\u7528\u6237\u53ef\u4ee5\u81ea\u884c\u5ffd\u7565\u8fd9\u4e00\u70b9\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#_4","title":"\u516d\u3001\u603b\u7ed3","text":"<p>\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86onnx\u5bfc\u51fa\u7684\u539f\u5219\u548c\u5177\u4f53\u8c03\u8bd5\u6280\u5de7\uff0c\u5e0c\u671b\u80fd\u7ed9\u9047\u5230\u76f8\u4f3c\u9519\u8bef\u7684\u8bfb\u8005\u7ed9\u4ee5\u542f\u53d1\u3002\u4f5c\u8005\u4f1a\u7ee7\u7eed\u7814\u7a76DETR\u7684\u52a8\u6001batch size\u95ee\u9898\uff0c\u6b22\u8fce\u6709\u5174\u8da3\u7684\u5c0f\u4f19\u4f34\u4e00\u8d77\u8ba8\u8bba\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B404%E6%9C%8811%E6%97%A5%2023%E6%97%B612%E5%88%8655%E7%A7%92/#_5","title":"\u4e03\u3001\u53c2\u8003\u94fe\u63a5","text":"<ul> <li>https://zhuanlan.zhihu.com/p/436017991</li> <li>https://github.com/DataXujing/TensorRT-DETR</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/","title":"\u8ba1\u7b97\u56fe\u7684\u4f18\u5316-\u4ee5onnx\u8868\u793a\u5f62\u5f0f\u4e3a\u4f8b","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#_1","title":"\u4e00\u3001\u5f15\u8a00","text":"<p>\u6a21\u578b\u8bad\u7ec3\u597d\u4ee5\u540e\u5fc5\u7136\u6d89\u53ca\u5230\u90e8\u7f72\u5230\u5404\u79cd\u786c\u4ef6\u5e73\u53f0\uff0c\u9488\u5bf9\u8ba1\u7b97\u56fe\u7684\u4f18\u5316\u4e0d\u53ef\u4ee5\u5355\u5355\u4f9d\u8d56\u4e8e\u6240\u5728\u786c\u4ef6\u90e8\u7f72\u5de5\u5177\u7684\u4f18\u5316\u7b56\u7565\uff0c\u8fd9\u91cc\u9762\u4ecd\u7136\u9700\u8981\u4e00\u4e9b\u4eba\u529b\u6765\u53bb\u5220\u51cf\u5408\u5e76\u4e00\u4e9b\u7b97\u5b50\u3002 \u5728\u4fee\u6539\u8ba1\u7b97\u56fe\u65f6\uff0c\u6709\u4e24\u79cd\u65b9\u5f0f\u3002\u7b2c\u4e00\u4e2a\u662f\u4ece\u6e90\u5934\u63a7\u5236\uff0c\u5373\u5bf9\u5bfc\u51fa\u65f6\u63cf\u8ff0\u6a21\u578b\u7684\u6e90\u7801\uff08\u5982pytorch\u6216\u8005tensorflow\uff09\u8fdb\u884c\u66f4\u6539\u3002\u7b2c\u4e8c\u4e2a\u662f\u5bf9\u5bfc\u51fa\u7684\u683c\u5f0f\uff08\u5982onnx\uff0cpb\u7b49\uff09\u8fdb\u884c\u66f4\u6539\u3002 \u4e2a\u4eba\u6bd4\u8f83\u504f\u597d\u5927\u90e8\u5206\u7528\u7b2c\u4e00\u79cd\uff0c\u7136\u540e\u5bf9\u4e8e\u66f4\u4e3a\u7cbe\u7ec6\u7684\u8c03\u6574\u91c7\u7528\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u3002\u4f46\u662f\u5bf9\u4e8e\u4e00\u4e2a\u6210\u719f\u7684\u56e2\u961f\u6765\u8bf4\uff0c\u7b2c\u4e00\u79cd\u5f80\u5f80\u4f9d\u8d56\u4e8e\u6a21\u578b\u5f00\u53d1\u4eba\u5458\uff0c\u7b2c\u4e8c\u4e2a\u5de5\u4f5c\u5f80\u5f80\u5206\u914d\u7ed9\u6a21\u578b\u90e8\u7f72\u4eba\u5458\u3002\u9488\u5bf9\u8ba1\u7b97\u56fe\u7684\u4f18\u5316\u5f80\u5f80\u662f\u4ea4\u7ed9\u90e8\u7f72\u4eba\u5458\u53bb\u505a\uff0c\u6240\u4ee5\u7b2c\u4e8c\u79cd\u65b9\u5f0f\u5bf9\u4e8e\u6a21\u578b\u90e8\u7f72\u4eba\u5458\u6765\u8bf4\u5e94\u7528\u7684\u6bd4\u8f83\u591a\uff08\u56e0\u4e3a\u5176\u53ea\u80fd\u5f97\u5230\u4e00\u4e2aonnx\uff09\u3002 onnx\u683c\u5f0f\u9010\u6e10\u53d8\u6210\u4e00\u79cd\u901a\u7528\u7684\u89c4\u8303\u6765\u53bb\u8868\u793a\u8ba1\u7b97\u56fe\uff0c\u5c3d\u7ba1\u6709\u4e9b\u5f00\u53d1\u4eba\u5458\u4e0d\u559c\u6b22\u5176\u5728\u7b97\u5b50\u8868\u793a\u4e0a\u7684\u4e0d\u8db3\uff0c\u4f46\u662f\u4e0d\u53ef\u5426\u8ba4\u7684\u662f\u901a\u4e00\u5316\u7684\u8868\u793a\u89c4\u8303\u4f1a\u8ba9\u6574\u4e2a\u884c\u4e1a\u53d1\u5c55\u5f97\u66f4\u597d\uff0c\u76ee\u524d\u5927\u90e8\u5206\u6a21\u578b\u90e8\u7f72\u6846\u67b6\u90fd\u652f\u6301\u5bf9onnx\u7684\u89e3\u6790\uff0c\u6240\u4ee5\u672c\u6587\u4e5f\u91c7\u7528\u8be5\u683c\u5f0f\u6765\u8bf4\u660e\u5bf9\u4e8e\u8ba1\u7b97\u56fe\u7684\u5316\u7b80\u3002</p> <p>\u5bf9\u4e8eonnx \u6240\u652f\u6301\u7684\u7b97\u5b50\u53c2\u89c1 ONNX Operators\u6587\u6863</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#_2","title":"\u4e8c\u3001\u57fa\u672c\u6d41\u7a0b","text":"<ol> <li>\u786e\u5b9a\u6a21\u578b\u8f93\u5165\u8f93\u51fa\uff0c\u5220\u9664\u4e0d\u9700\u8981\u7684\u8f93\u5165\uff08\u8bbe\u7f6e\u4e3a\u56fa\u5b9a\u8f93\u5165\uff09\u548c\u8f93\u51fa</li> <li>\u786e\u5b9a\u8f93\u5165\u8f93\u51fa\u7ef4\u5ea6\u4ee5\u53ca\u54ea\u4e9b\u7ef4\u5ea6\u662f\u53ef\u53d8\u7684</li> <li>\u5bf9\u8ba1\u7b97\u56fe\u4e2d\u5197\u4f59\u903b\u8f91\u8ba1\u7b97\u548c\u4ee3\u6570\u8fd0\u884c\u8fdb\u884c\u5220\u51cf\uff0c\u5148\u8fdb\u884c\u7b80\u5355\u7684\u90e8\u5206\uff0c\u518d\u5206\u6790\u590d\u6742\u7684\u90e8\u5206\u3002</li> <li>\u6e05\u7406\u8ba1\u7b97\u56fe\u5197\u4f59\u90e8\u5206</li> </ol> <p>\u5173\u952e\u5de5\u5177\uff1aonnx_graphsurgeon https://github.com/NVIDIA/TensorRT/tree/main/tools/onnx-graphsurgeon \u82f1\u4f1f\u8fbe\u51fa\u7684onnx\u7f16\u8f91\u5de5\u5177\uff0c\u72ec\u7acb\u7248\u672c\uff0c\u4e0d\u5c40\u9650\u4e8etensorrt\u90e8\u7f72\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#21","title":"2.1 \u9759\u6001\u7ef4\u5ea6\u8f93\u5165","text":"<p>\u5bf9\u4e8e\u9759\u6001shape\u7684\u8f93\u5165\uff0c\u4e00\u822c\u53ef\u4ee5\u91c7\u7528<code>onnx-simplifier</code>\u8fc7\u4e00\u904d\u5c31\u53ef\u4ee5\u5f97\u5230\u4e0d\u9519\u7684\u6548\u679c\u3002\u6211\u4eec\u53ef\u4ee5\u5728\u4f7f\u7528<code>onnx-simplifier</code>\u4ee5\u540e\u518d\u53bb\u89c2\u5bdf\u4e0bonnx\u4e2d\u8ba1\u7b97\u56fe\u7684\u8868\u793a\u60c5\u51b5\uff0c\u91c7\u7528\u4e0b\u6587\u4e2d\u7684\u5316\u7b80\u6280\u5de7\u8fdb\u884c\u5316\u7b80\u3002</p> <p><code>onnx-simplifier</code>: https://github.com/daquexian/onnx-simplifier</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#22","title":"2.2 \u52a8\u6001\u7ef4\u5ea6\u8f93\u5165","text":"<p>\u5bf9\u4e8e\u52a8\u6001\u7ef4\u5ea6\u8f93\u5165\uff0c<code>onnx-simplifier</code>\u53ef\u4ee5\u505a\u7684\u5fae\u4e4e\u5176\u5fae\u3002\u53ea\u80fd\u9760\u4eba\u5de5\u53bb\u5316\u7b80\uff0c\u6216\u8bb8\u968f\u7740\u7248\u672c\u7684\u5347\u7ea7<code>onnx-simplifier</code>\u5728\u8fd9\u4e00\u65b9\u9762\u53ef\u4ee5\u505a\u7684\u597d\u4e00\u4e9b\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#_3","title":"\u4e09\u3001\u57fa\u672c\u903b\u8f91\u5316\u7b80","text":"<ol> <li>Less + Not = GreaterOrEqual     \u5bf9\u5e94\u5904\u7406\u903b\u8f91\u4ee3\u7801     <pre><code>graph = gs.import_onnx(onnx.load(onnx_save_path))\nfor node in graph.nodes:\n    if node.op == \"Less\":\n        next_node = node.o()\n        if next_node.op == \"GreaterOrEqual\":\n            node.op = \"Less\"\n            node.name = node.name.replace(\"GreaterOrEqual\", \"Less\")\n</code></pre></li> <li> <p>not ((not A) or (not B) or C) = A and B and not C   \u8fd9\u91cc\u6307\u7684\u662fNot\u7b97\u5b50\u548cOr\u7b97\u5b50</p> </li> <li> <p>bool -&gt; Cast(to int32) + Equal( == 0) = bool -&gt; Not   \u5e03\u5c14\u503c\u5f3a\u5236\u8f6c\u6362\u4e3aint32\uff0c\u7136\u540e\u5224\u65ad\u503c\u662f\u5426\u4e3a0\uff0c\u7b49\u4ef7\u4e8e\u5bf9\u8be5\u5e03\u5c14\u503c\u53d6\u975e\u3002</p> </li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#_4","title":"\u56db\u3001\u57fa\u672c\u4ee3\u6570\u5316\u7b80","text":"<ol> <li> <p>MatMul + Add + Mul = MatMul + Add    \u8bbe <code>y = Mul(Add(MatMul(x, A), B), C)</code>\uff0c \u5373y = C(Ax+B) \u53ef\u4ee5\u5316\u7b80\u4e3a <code>y = ACx+BC</code>   \u8fd9\u91cc\u9700\u8981\u5904\u7406\u7684\u662f\u77e9\u9635\u5e7f\u64ad\u7684\u5173\u7cfb\u3002   \u7c7b\u4f3c\u7684\u4f8b\u5b50\u8fd8\u6709<code>Add(MatMul, MatMul) + Div</code> \u53ef\u4ee5\u5c06Div\u7684\u53c2\u6570\u5206\u914d\u5230\u4e24\u4e2aMatMul\u4e2d\uff0c\u8fd9\u4e00\u70b9\u5728<code>Attention</code>\u4e2d\u8f83\u4e3a\u5e38\u89c1\uff0c\u5c3d\u7ba1<code>Attention</code>\u6709\u66f4\u597d\u7684\u4f18\u5316\u65b9\u5f0f\u3002 </p> </li> <li> <p>MatMul + Add + (Add\u3001Add) = MatMul + Add + Add   \u8bbe <code>y1 = Add(MatMul(Add(x, A), B), C1)</code> \u548c <code>y2 = Add(MatMul(Add(x, A), B), C2)</code>\uff0c\u53ef\u4ee5\u5316\u7b80\u4e3a<code>y1 = MatMul(Add(x, A), B + C1)</code> \u548c <code>y2 = Add(MatMul(Add(x, A), B + C1), C2 - C1)</code>\u3002 </p> </li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#_5","title":"\u4e94\u3001\u5176\u4f59\u7b97\u5b50\u7684\u57fa\u672c\u5316\u7b80","text":"<ol> <li> <p>\u53bb\u6389Shape\u7b97\u5b50      \u8fd9\u91cc\u7684\u53d6Shape\u64cd\u4f5c\uff0c\u7136\u540e\u53d6index=2\u7684\u60c5\u51b5\uff0c\u8fd9\u91cc\u7684\u53d6Shape\u4ee5\u53ca\u540e\u9762\u7684Gather\u90fd\u53ef\u4ee5\u53bb\u6389\u3002\u5177\u4f53\u64cd\u4f5c\u53ef\u4ee5\u91c7\u7528<code>onnx_graphsurgeon</code>\u4fee\u6539Gather\u7684\u8f93\u5165\uff0c\u7136\u540e\u91c7\u7528<code>onnx-simplifier</code>\u6267\u884c\u4e0b\u5316\u7b80\u64cd\u4f5c\u3002     \u5f53\u7136\u4e5f\u53ef\u4ee5\u904d\u5386Gather\u6240\u6709\u7684\u8f93\u51fa\uff0c\u586b\u5145\"256\"\u8fd9\u4e2a\u5e38\u91cf\u3002</p> <pre><code>import onnx\nfrom onnxsim import simplify\nfor node in model_gs.nodes:\n    if node.name == \"Gather_63\":\n        node.inputs[0] = gs.Constant(\"Gather_63_input_0\", values=np.int64([1,10,64]))\n    elif node.name == \"Shape_61\":\n        node.outputs.clear()\nmodel_gs.cleanup().toposort()\nmodel = gs.export_onnx(model_gs)\nmodel_simp, check = simplify(\n    model,\n    check_n = 0,\n    perform_optimization = True,\n    skip_fuse_bn = False,\n    skip_shape_inference=False,\n    input_data = {\n        'input': np.random.randn(4,16,256).astype(np.float32),\n    },\n    dynamic_input_shape = True,\n)\n</code></pre> </li> <li> <p>\u8fde\u7eedSlice\u7684\u5316\u7b80      \u5982\u4e0a\u56fe\uff0c\u4e24\u4e2aSlice\u64cd\u4f5c\u5bf9\u5e94numpy\u7684\u64cd\u4f5c\u5206\u522b\u4e3a<code>x[:,:,0:-2:2,...]</code>\u3001<code>x[:,:,0:-2:2,...]</code>\uff0c\u5373\u5bf9\u6570\u636e\u7684\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u4e24\u6b21\u76f8\u540c\u95f4\u9694\u4e0b\u91c7\u6837\u3002     \u5728numpy\u4e0a\u4e0a\u8ff0\u4e24\u4e2a\u8fde\u7eed\u64cd\u4f5c\u53ef\u4ee5\u8f6c\u6362\u4e3a<code>x[:,:,0:-4:4,...]</code>\u3002</p> </li> <li> <p>Tile\u540e\u79fb     Tile\u540e\u79fb\u539f\u5219\u5373\u5c06\u5f20\u91cf\u6cbf\u7740\u67d0\u4e00\u7ef4\u590d\u5236\u7684\u64cd\u4f5c\u5c3d\u53ef\u80fd\u5f97\u540e\u79fb\uff0c\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u8282\u7701\u8ba1\u7b97\u91cf\u3002     \u6bd4\u5982 <code>x-&gt;Tile-&gt;Mul-&gt;Add-&gt;y</code> \u53ef\u4ee5\u8f6c\u6362\u4e3a <code>x-&gt;Mul-&gt;Add-&gt;Tile-&gt;y</code>\u3002     \u4e5f\u6709\u53ef\u80fd\u5b58\u5728\u591a\u4e2ay\u5bf9\u5e94\u4e00\u4e2ax\u8ba1\u7b97\u7684\u60c5\u51b5\uff0c\u8fd9\u65f6\u5c31\u9700\u8981\u5c06\u524d\u9762\u7684Tile\u5220\u9664\uff0c\u7136\u540e\u518d\u591a\u4e2ay\u7684\u524d\u9762\u6dfb\u52a0Tile\u3002\u540e\u79fb\u662f\u6709\u6761\u4ef6\u7684\uff0c\u5f53\u5bf9\u4e8e\u5f20\u91cf\u7684\u8ba1\u7b97\u4e0d\u6d89\u53ca\u590d\u5236\u7ef4\u5ea6\u7684\u5dee\u5f02\u64cd\u4f5c\u65f6\u624d\u53ef\u4ee5\u5c06Tile\u540e\u79fb\u3002</p> </li> <li> <p>\u7b97\u5b50\u7684\u7b49\u4ef7\u66ff\u6362     \u5728\u6709\u4e9b\u60c5\u51b5\u4e0b\uff0c\u67d0\u4e9b\u7b97\u5b50\u53ef\u80fd\u4e0d\u88ab\u90e8\u7f72\u5e73\u53f0\u652f\u6301\uff0c\u4f46\u662f\u53ef\u4ee5\u66ff\u6362\u4e3a\u5df2\u77e5\u652f\u6301\u7684\u7b97\u5b50\u3002\u6bd4\u5982\u5728opencv\u7684dnn\u6a21\u5757\u4e2d\uff0c\u5982\u679c\u90e8\u7f72yolov5\uff0cFocus\u6a21\u5757\u4e2d\u7684slice\u7b97\u5b50\u5728\u4e00\u5f00\u59cb\u7684\u7248\u672c\u4e2d\u5e76\u4e0d\u652f\u6301\uff0cslice\u7684\u95f4\u9694\u91c7\u6837\u8fd0\u7b97\u5b9e\u9645\u4e0a\u53ef\u4ee5\u88ab depthwise \u5377\u79ef\u4ee3\u66ff\uff0c\u8fd9\u91cc\u7ed9\u51fa\u4e00\u79cd\u6bd4\u8f83\u7701\u4e8b\u7684\u89e3\u51b3\u65b9\u6848\u3002     \u9996\u5148\u5728pytorch\u4e0a\u9a8c\u8bc1\u7b49\u4ef7\u6027</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        # x: [1,3,xxx,xxx]\n        weight = torch.as_tensor([[1,0],[0,0]]).float().to(x.device).reshape(1,1,2,2)\n        weight = weight.repeat(3,1,1,1)\n        x1 = F.conv2d(x, weight=weight, bias=None, stride=2, groups=3)\n        weight = torch.as_tensor([[0,0],[1,0]]).float().to(x.device).reshape(1,1,2,2)\n        weight = weight.repeat(3,1,1,1)\n        x2 = F.conv2d(x, weight=weight, bias=None, stride=2, groups=3)\n        weight = torch.as_tensor([[0,1],[0,0]]).float().to(x.device).reshape(1,1,2,2)\n        weight = weight.repeat(3,1,1,1)\n        x3 = F.conv2d(x, weight=weight, bias=None, stride=2, groups=3)\n        weight = torch.as_tensor([[0,0],[0,1]]).float().to(x.device).reshape(1,1,2,2)\n        weight = weight.repeat(3,1,1,1)\n        x4 = F.conv2d(x, weight=weight, bias=None, stride=2, groups=3)\n        return torch.cat([x1, x2, x3, x4], dim=1)\nif __name__ == \"__main__\":\n    model = MyModel()\n    x = torch.rand(1, 3, 224, 224).float()\n    y = torch.cat([x[:,:,0::2,0::2], x[:,:, 1::2, 0::2], x[:,:,0::2,1::2], x[:,:,1::2,1::2]], dim=1)\n    model.eval()\n    out = model(x)\n    input_dummpy = torch.rand(1,3,224,224)\n    torch.onnx.export(model, input_dummpy, 'focus.onnx')\n</code></pre> <p>\u7136\u540e\u66ff\u6362\u539f\u6765\u7684onnx</p> <pre><code>import onnx_graphsurgeon as gs\nimport onnx\nimport numpy as np\ndef get_conv_node(onnx_filepath):\n    onnx_model = onnx.load(onnx_filepath)\n    model_gs = gs.import_onnx(onnx_model)\n    node_list = list()\n    for node in model_gs.nodes:\n        if node.op == \"Conv\":\n            node_list.append(node)\n    node_list.sort(key=lambda x:x.name)\n    return node_list\ndef replaceSliceNodes(onnx_filepath, conv_filepath):\n    conv_nodes = get_conv_node(conv_filepath)\n    onnx_model = onnx.load(onnx_filepath)\n    model_gs = gs.import_onnx(onnx_model)\n    slices_nodes = list()\n    for node in model_gs.nodes:\n        if len(node.inputs) &gt; 0 and node.inputs[0].name == \"input\":\n            slices_nodes.append(node)\n    input_var = slices_nodes[0].inputs[0]\n    next_slices_nodes = [item.o() for item in slices_nodes]\n    output_vars = [node.outputs[0] for node in next_slices_nodes]\n    # concat_node = next_slices_nodes[0].o()\n    output_vars.sort(key = lambda x: x.name)\n    # print(input_var.name)\n    for output_var, conv_node in zip(output_vars, conv_nodes):\n        conv_node.outputs[0] = output_var\n        conv_node.inputs[0] = input_var\n        const = conv_node.inputs[1].inputs[0].attrs['value']\n        name = conv_node.inputs[1].name\n        const.name = name\n        conv_node.inputs[1] = const\n        # print(.name)\n        model_gs.nodes.append(conv_node)\n    for item in next_slices_nodes:\n        item.outputs.clear()\n    for node in model_gs.nodes:\n        if node.name == \"Concat_153\":\n            resize_node = node.o()\n            node.outputs.clear()\n            resize_node.inputs[2] = gs.Constant(name = resize_node.inputs[2].name + \"_new\", values = np.array([1.0, 1.0, 4.0, 4.0], dtype=np.float32) )\n            resize_node.inputs.pop(-1)\n    model_gs.cleanup().toposort()\n    model = gs.export_onnx(model_gs)\n    onnx.checker.check_model(model)\n    onnx.save(model, 'rm_slice_'+onnx_filepath)\nreplaceSliceNodes('yolov5.onnx', 'focus.onnx')\n</code></pre> </li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#-","title":"\u516d\u3001\u9ad8\u9636\u90e8\u5206-\u590d\u6742\u8ba1\u7b97\u7684\u6a21\u578b\u4e0e\u5316\u7b80","text":"<p>\u9ad8\u9636\u90e8\u5206\u5b9e\u9645\u4e0a\u5f88\u96be\u8986\u76d6\u5b8c\u5168\uff0c\u4e2a\u4eba\u5fc3\u5f97\u5c31\u662f\u4eceonnxsim\u5316\u7b80\u7684\u9759\u6001\u8f93\u5165\u4e0b\u7684onnx\u83b7\u5f97\u7075\u611f\uff0c\u5bf9\u6bd4\u5316\u7b80\u524d\u540e\u7684\u4e0d\u540c\u3002</p> <ol> <li> <p>slice+matmul \u7684\u9884\u5148\u8ba1\u7b97</p> <p> \u5982\u4e0a\u56fe\u6240\u793a\uff0cSlice\u64cd\u4f5c\u4e2d\u8868\u793adata\u7684pos_embedding\u662f\u4e00\u4e2a\u5e38\u91cf\uff0c\u8fd9\u91cc\u64cd\u4f5c\u4e3a<code>pos_index-&gt;slice-&gt;matmul-&gt;y</code>\uff0c\u7531\u4e8eslice\u662f\u5bf9\u524d\u9762\u7684\u7ef4\u5ea6\u8fdb\u884cslice,\u5bf9\u4e8e<code>mxk @ kxn</code>\u7684\u8fd0\u7b97\uff0ck\u5e76\u6ca1\u6709\u906d\u5230\u7834\u574f\uff0c\u6240\u4ee5\u53ef\u4ee5\u5148\u5c06matmul\u9884\u7b97\u8ba1\u7b97\u51fa\u6765\uff0c\u7136\u540e\u5728\u8fdb\u884cslice\uff0c\u5373\u8f6c\u6362\u4e3a<code>pos_index-&gt;slice-&gt;y</code>\u3002</p> </li> <li> <p>key_padding_mask \u90e8\u5206\u7684\u5904\u7406</p> <p> \u5bf9Shape\u8fdb\u884c\u7684Slice\u64cd\u4f5c\u662f\u53d6\u5f97\u6700\u540e\u4e00\u7ef4\uff0c\u6700\u540e\u4e00\u7ef4\u662f\u9759\u6001\u7684\uff0c\u8fd9\u91cc\u5047\u8bbe\u4e3a63\u3002\u90a3\u4e48concat\u8f93\u51fa\u4e3a<code>[63,63]</code>,Reshape\u7684\u8f93\u51fa\u4e5f\u4e3a<code>[63,63]</code>\uff0c<code>ConstantOfShape</code>\u7684\u7684value\u5c5e\u6027\u4e3a1\uff0c\u8f93\u51fa\u4e3a\u5f62\u72b6\u4e3a<code>[2]</code>\u7684\u5168\u4e3a1\u7684Tensor\uff0c<code>Mul</code>\u7684\u8f93\u51fa\u4e3a\u5f62\u72b6\u4e3a<code>[2]</code>\u7684\u5168\u4e3a-1\u7684Tensor\uff0cEqual\u7684\u8f93\u51fa\u5fc5\u7136\u4e3a\u5f62\u72b6\u4e3a<code>[2]</code>\u7684\u5168\u4e3aFalse\u7684Tensor\u3002Where\u7684\u8f93\u51fa\u4e3aReshape\u7684\u8f93\u51fa\u5373<code>[63,63]</code>\uff0cCast+Range\u7684\u8f93\u51fa\u4e3a<code>np.range(0,63)</code>\u7684\u8f93\u51fa\uff0c\u5373<code>[0...62]</code>,Expand\u7684\u8f93\u51fa\u4e3a\u5f62\u72b6\u4e3a<code>[63,63]</code>\u4e14\u6bcf\u884c\u4e3a<code>[0...62]</code>\u7684Tensor\u3002Unsqueeze\u7684\u8f93\u51fa\u4e3a<code>[63,1]</code>\u7684Tensor\uff0c\u6bcf\u5217\u5143\u7d20\u4f9d\u6b21\u4e3a<code>[0...62]</code>\uff0cLessOrEqual\u8f93\u51fa\u4e3a<code>[63,63]</code>\u7684Tensor\uff0c\u683c\u5f0f\u4e3a</p> <pre><code>[\n[True, False,..., False],\n[True, True, ..., False],\n...\n[True, True, ..., True]\n]\n</code></pre> <p>Unsqueeze\u7684\u8f93\u51fa\u4e3a1x63x63\u7684Tensor\u3002\u6240\u4ee5\u76f4\u5230Unsqueeze\u8f93\u51fa\u90fd\u662f\u9759\u6001\u53ef\u4ee5\u88ab\u8ba1\u7b97\u51fa\u6765\u7684\uff0c\u8fd9\u91cc\u53ef\u4ee5\u66ff\u6362\u4e3a\u5e38\u91cf\uff0c\u753b\u51fa\u7684\u77e9\u5f62\u8ba1\u7b97\u56fe\u90fd\u53ef\u4ee5\u5220\u6389\u3002</p> </li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#_6","title":"\u4e03\u3001\u9762\u5411\u7279\u5b9a\u786c\u4ef6\u4e0a\u7684\u4f18\u5316","text":"<p>\u8fd9\u91cc\u4ee5NV GPU\u90e8\u7f72TensorRT\u4e3a\u4f8b</p> <ol> <li> <p>\u4e8c\u7ef4\u77e9\u9635\u4e58\u6cd5\u52a0\u901f</p> <p>\u5982<code>x-&gt;MatMul-&gt;Add-&gt;y</code>\uff0c\u5982\u679cx\u662f\u4e09\u7ef4\u7684\uff0c\u53ef\u4ee5\u5148\u5c06<code>x</code> reshape\u4e3a[-1, E1]\uff0c\u7136\u540e\u8fdb\u884c\u8ba1\u7b97\uff0c\u6700\u540e\u5f97\u5230\u7684y,\u518dreshape\u4e3a[B,S,E2]\uff0c\u8fd9\u91cc\u9700\u8981\u8bb0\u5f55\u4e0bx\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u6216\u8005\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\uff08\u5982\u679c\u524d\u4e24\u4e2a\u7ef4\u5ea6\u6709\u5df2\u77e5\u7684\u5c31\u4e0d\u9700\u8981\uff09\u7ed9reshape\u8282\u70b9\u4f7f\u7528\uff0c\u6bd4\u5982reshape\u7684\u4e2d\u586b\u5145\u7684shape\u4e3a[B,-1, E2]\u3002\u5176\u4e2dE2\u662f\u5df2\u77e5\u7684\uff0cB\u662f\u4ecex\u7684<code>Shape-&gt;Gather[0]-&gt;Unsquueze-&gt;Concat</code>\u7ec4\u5408\u800c\u6765\u3002 \u8fd9\u6837\u53ef\u4ee5\u5e26\u6765\u52a0\u901f\u7684\u539f\u56e0\u662f\uff0c\u4e8c\u7ef4\u77e9\u9635\u4e58\u76f8\u6bd4\u4e8e\u9ad8\u7ef4\u77e9\u9635\u4e58\u5728trt\u5185\u90e8\u5b9e\u73b0\u65f6\u53ef\u4f9b\u9009\u62e9\u7684\u7b97\u6cd5\u66f4\u591a\uff0c\u52a0\u901f\u6548\u679c\u66f4\u660e\u663e\u3002</p> </li> <li> <p>\u5171\u4eabshape</p> <p>\u5982\u679connx\u7684\u8f93\u5165\u6709\u4e24\u4e2a<code>x1\uff0cx2</code>\uff0c<code>x1</code>\u7684shape\u4e3a<code>[B,S,E]</code>\uff0c<code>x2</code>\u7684shape\u4e3a<code>[B]</code>\uff0c\u90a3\u4e48\u518d\u5f15\u7528<code>x2</code>\u7684B\u65f6\u6700\u597d\u5c06\u5176\u66ff\u6362\u4e3a<code>x1</code>\u7684B\uff0c\u8fd9\u6837\u53ef\u4ee5\u8868\u793ax2\u7684B\u4e8ex1\u7684B\u76f8\u540c\u3002</p> </li> <li> <p>\u5e38\u89c1\u90e8\u5206plugin\u7684\u5b9e\u73b0</p> <p>plugin\u5e38\u7528\u4e8e\u4e00\u4e9b\u96f6\u788e\u7b97\u5b50\u7684\u6574\u5408\uff0c\u6bd4\u5982attn\u3002\u73b0\u5728trt\u7684\u7b97\u5b50\u878d\u5408\u5df2\u7ecf\u505a\u7684\u5f88\u597d\uff0c\u5b9e\u73b0plugin\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u52a0\u901f\uff0c\u4f46\u662f\u60f3\u8d85\u8fc7trt\u7684\u5b9e\u73b0\u7edd\u975e\u6613\u4e8b\u3002plugin\u4f1a\u7834\u574f\u7b97\u5b50\u7684\u878d\u5408\uff0c\u6240\u4ee5plugin\u5b9e\u73b0\u524d\u540e\u8981\u5bf9\u6bd4\u662f\u5426\u5e26\u6765\u4e86\u4f18\u5316\u6548\u679c\u3002\u6b64\u5916\u5bf9\u4e8e\u663e\u5b58\u7684\u590d\u7528\u5bf9\u4e8eplugin\u6765\u8bf4\u662f\u4e00\u4e2a\u4f18\u52bf\uff0c\u8fd9\u4e2a\u5728plugin\u5185\u90e8\u662f\u53ef\u63a7\u7684\uff0c\u4e5f\u662fplugin\u53ef\u4ee5\u8d77\u5230\u52a0\u901f\u6548\u679c\u7684\u539f\u56e0\u4e4b\u4e00\u3002\u540e\u9762\u7684\u6587\u7ae0\u5c06\u9010\u6b65\u4ecb\u7ecdplugin\u7684\u7f16\u5199\u4e8e\u5b9e\u73b0\u3002</p> </li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B405%E6%9C%8828%E6%97%A5%2017%E6%97%B623%E5%88%8651%E7%A7%92/#_7","title":"\u516b\u3001\u603b\u7ed3","text":"<p>\u8ba1\u7b97\u56fe\u7684\u4f18\u5316\u5185\u5bb9\u4e0d\u5c40\u9650\u4e8e\u8ba1\u7b97\u56fe\u7684\u5316\u7b80\uff0c\u9488\u5bf9\u7279\u5b9a\u5e73\u53f0\u4e0b\u7684\u4f18\u5316\u540c\u6837\u4e0d\u53ef\u4ee5\u5ffd\u7565\uff0c\u540c\u65f6\u7b97\u5b50\u4e4b\u95f4\u7684\u53ef\u66ff\u4ee3\u6027\u53ef\u4ee5\u4e3a\u4e3a\u89e3\u51b3\u7b97\u5b50\u4e0d\u652f\u6301\u7684\u95ee\u9898\u63d0\u4f9b\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5728\u5316\u7b80\u8ba1\u7b97\u56fe\u65f6\uff0c\u4e00\u5b9a\u662f\u6309\u7167\u5148\u7b80\u5355\u540e\u590d\u6742\u7684\u529e\u6cd5\u4e00\u6b65\u6b65\u5206\u6790\uff0c\u5c3d\u53ef\u80fd\u7684\u53bb\u5220\u9664\u5197\u4f59\u3002\u6b64\u5916\u5bf9\u7167\u9759\u6001\u8f93\u5165\u4e0bonnxsim\u7684\u5316\u7b80\u53ef\u4ee5\u5e26\u6765\u4e00\u4e9b\u601d\u8def\u3002\u96f6\u788e\u7b97\u5b50\u6574\u5408\u4e3aplugin\u4e5f\u662f\u5f88\u91cd\u8981\u7684\u4f18\u5316\u624b\u6bb5\uff0c\u8fd9\u5bf9cuda\u6216\u8005mpi\u7b49\u4f7f\u7528\u5e76\u7ebf\u7f16\u7a0b\u7684\u80fd\u529b\u6709\u4e86\u4e00\u5b9a\u7684\u8981\u6c42\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/","title":"TensorRT Plugin\u7684\u5b9e\u73b0\u3001\u8c03\u8bd5\u4e0e\u9a8c\u8bc1\uff1a\u4ee5\u5b9e\u73b0Layernorm\u4e3a\u4f8b","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#plugin","title":"\u4e00\u3001Plugin\u662f\u4ec0\u4e48","text":"<p>TensorRT\u7684Plugin\u76f4\u8bd1\u5e94\u8be5\u4e3a\u63d2\u4ef6\uff0c\u671b\u6587\u751f\u4e49\u7684\u89e3\u91ca\u662f\u63d2\u5165\u5230\u4f5c\u4e3a\u4e00\u4e2a\u8ba1\u7b97\u8282\u70b9\u63d2\u5165\u5230TensorRT\u6784\u9020\u7684\u8ba1\u7b97\u56fe\u4e2d\uff0c\u6240\u4ee5Plugin\u672c\u8d28\u4e0a\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u8ba1\u7b97\u8282\u70b9\uff0c\u4f1a\u4ee5\u52a8\u6001\u94fe\u63a5\u5e93\u7684\u5f62\u5f0f\u63d2\u5165\u5230\u7f51\u7edc\u6a21\u578b\u4e2d\u5b9e\u73b0\u67d0\u4e9b\u7b97\u5b50\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#plugin_1","title":"\u4e8c\u3001\u4ec0\u4e48\u65f6\u5019\u9700\u8981Plugin","text":"<p>\u4e3a\u4e86\u5b9e\u73b0\u4ee5\u4e0b\u51e0\u79cd\u9700\u6c42\u65f6\uff1a</p> <ul> <li>\u5b9e\u73b0TensorRT\u539f\u751f\u4e0d\u652f\u6301\u7684\u5c42\u6216\u8005\u7ed3\u6784</li> <li>\u66ff\u6362TensorRT\u539f\u672c\u5b9e\u73b0\u6027\u80fd\u4e0d\u591f\u597d\u7684\u5c42\u6216\u8005\u7ed3\u6784</li> <li>\u624b\u52a8\u5408\u5e76\u6ca1\u6709\u81ea\u52a8\u878d\u5408\u7684\u5c42\u6216\u8005\u7ed3\u6784</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#plugin_2","title":"\u4e09\u3001Plugin\u7684\u7279\u70b9","text":"<ul> <li>\u81ea\u5b9a\u4e49cuda kerkel\uff0c\u529f\u80fd\u548c\u6027\u80fd\u5b9e\u73b0\u5b8c\u5168\u81ea\u5b9a\u4e49</li> <li>Plugin\u5b9e\u73b0\u7684\u7b97\u5b50\u4e0d\u53ef\u4ee5\u4e0e\u5176\u4ed6Layer\u4e4b\u95f4\u878d\u5408\uff0c\u5982\u679cPlugin\u8986\u76d6\u7684\u7ed3\u6784\u4e2d\u6709\u53c2\u4e0e\u7b97\u5b50\u878d\u5408\u7684\u7ed3\u6784\uff0c\u90a3\u4e48\u6b64\u5904\u7b97\u5b50\u878d\u5408\u4f1a\u88ab\u7834\u574f\u3002</li> <li>Plugin\u8282\u70b9\u524d\u540e\u53ef\u80fd\u4f1a\u63d2\u5165reformatting\u8282\u70b9\uff0c\u589e\u52a0\u5f00\u9500\u3002</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#onnxtensorrt-plugin","title":"\u56db\u3001onnx\u8ba1\u7b97\u8282\u70b9\u4e0eTensorRT Plugin\u4e4b\u95f4\u7684\u8054\u7cfb","text":"<p>\u6e90\u7801\u5730\u5740\uff1a https://github.com/onnx/onnx-tensorrt/blob/main/builtin_op_importers.cpp#L4881</p> <pre><code>// Any ops that are not supported will attempt to import as plugins.\nDEFINE_BUILTIN_OP_IMPORTER(FallbackPluginImporter)\n{\n    OnnxAttrs attrs(node, ctx);\n    const std::string pluginName{node.op_type()};\n    const std::string pluginVersion{attrs.get&lt;std::string&gt;(\"plugin_version\", \"1\")};\n    const std::string pluginNamespace{attrs.get&lt;std::string&gt;(\"plugin_namespace\", \"\")};\n    LOG_INFO(\"Searching for plugin: \" &lt;&lt; pluginName &lt;&lt; \", plugin_version: \" &lt;&lt; pluginVersion &lt;&lt; \", plugin_namespace: \" &lt;&lt; pluginNamespace);\n    nvinfer1::IPluginCreator* creator = importPluginCreator(pluginName, pluginVersion, pluginNamespace);\n    ASSERT(creator &amp;&amp; \"Plugin not found, are the plugin name, version, and namespace correct?\", ErrorCode::kUNSUPPORTED_NODE);\n    const nvinfer1::PluginFieldCollection* fieldNames = creator-&gt;getFieldNames();\n    // Field data needs to be type erased, we use fieldData for temporary allocations.\n    string_map&lt;std::vector&lt;uint8_t&gt;&gt; fieldData{};\n    std::vector&lt;nvinfer1::PluginField&gt; fields = loadFields(fieldData, attrs, fieldNames, ctx);\n    const auto plugin = createPlugin(getNodeName(node), creator, fields);\n    ASSERT(plugin &amp;&amp; \"Could not create plugin\", ErrorCode::kUNSUPPORTED_NODE);\n    std::vector&lt;nvinfer1::ITensor*&gt; pluginInputs{};\n    for (auto&amp; input : inputs)\n    {\n        pluginInputs.emplace_back(&amp;convertToTensor(input, ctx));\n    }\n    LOG_INFO(\"Successfully created plugin: \" &lt;&lt; pluginName);\n    auto* layer = ctx-&gt;network()-&gt;addPluginV2(pluginInputs.data(), pluginInputs.size(), *plugin);\n    ctx-&gt;registerLayer(layer, getNodeName(node));\n    RETURN_ALL_OUTPUTS(layer);\n}\n</code></pre> <p>\u901a\u8fc7\u770b<code>onnx-parser</code>\u7684\u6e90\u7801\u53ef\u77e5\uff0c\u5bf9\u4e8e\u4e00\u4e2aonnx\u4e2d\u7684\u8ba1\u7b97\u8282\u70b9\uff0c\u5f53\u89e3\u6790\u5668\u4e2d\u5176\u4ed6\u7684\u89e3\u6790\u89c4\u5219\u90fd\u4e0d\u6ee1\u8db3\u65f6\u4f1a\u8f6c\u5411\u4f7f\u7528TensorRT Plugin\u6784\u9020\uff0connx\u4e2d\u8ba1\u7b97\u8282\u70b9\u7684\u53c2\u6570\u4f1a\u6210\u4e3aTensorRT Plugin\u4e2d\u6784\u9020\u65f6\u7684\u4f20\u53c2\u3002\u6309\u7167\u6e90\u7801\u91cc\u9762\u7684\u8981\u6c42\uff0c\u5047\u8bbe\u6211\u4eec\u60f3\u5bf9\u4e00\u4e2aonnx\u8ba1\u7b97\u8282\u70b9\u7f16\u5199Plugin\uff0c\u90a3\u4e48Plugin\u7684\u540d\u5b57\u5c31\u8981\u4e0eonnx\u8ba1\u7b97\u8282\u70b9\u7684\u540d\u5b57\u76f8\u540c\uff0c\u4e14\u7248\u672c\u4e3a<code>\"1\"</code>\u3002</p> <p>\u4f7f\u7528\u6280\u5de7\uff1a \u5047\u8bbe\u6211\u4eec\u60f3\u878d\u5408onnx\u4e2d\u4e00\u4e9b\u8282\u70b9\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982LayerNorm\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u5bf9Layernorm\u7275\u626f\u7684\u8282\u70b9\u7684\u53c2\u6570\u6536\u96c6\u8d77\u6765\uff0c\u7136\u540e\u5220\u9664\u8fd9\u4e9b\u8282\u70b9\uff0c\u7528\u65b0\u7684\u540d\u5b57\u4e3a\u201cLayernorm\u201d\u7684\u8282\u70b9\u6765\u66ff\u6362\u8fd9\u4e9b\u8282\u70b9\uff0c\u63a5\u7740\u5199TensorRT Plugin\uff0c\u540d\u5b57\u4e3a\u201cLayernorm\u201d\uff0c\u6765\u5b9e\u73b0\u4e0a\u8ff0\u7684\u878d\u5408\u64cd\u4f5c\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#plugin_3","title":"\u4e94\u3001Plugin\u7684\u5b9e\u73b0\u6d41\u7a0b","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#51-plugin","title":"5.1 Plugin\u7684\u79cd\u7c7b","text":"<p>\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5b9e\u73b0Plugin\u57fa\u7c7b\u5b9a\u4e49\u597d\u7684\u63a5\u53e3\uff08\u865a\u51fd\u6570\uff09\u6765\u81ea\u5b9a\u4e49Plugin\u3002 \u6839\u636e\u7ee7\u627f\u57fa\u7c7b\u7684\u79cd\u7c7b\uff0c\u53ef\u4ee5\u5c06Plugin\u7684\u79cd\u7c7b\u5206\u4e3a\u4e09\u79cd</p> Introduced in TensorRT version? Mixed I/O formats/types Dynamic shapes? Supports implicit/explicit batch mode? IPluginV2Ext 5.1 Limited No Both implicit and explicit batch modes IPluginV2IOExt 6.0.1 General No Both implicit and explicit batch modes IPluginV2DynamicExt 6.0.1 General Yes Explicit batch mode only <p>\u4e0a\u9762\u7684\u8868\u683c\u6284\u5f55\u81ea\u5b98\u65b9\u6587\u6863\uff0c\u4f5c\u8005\u5199\u8fd9\u7bc7\u6587\u7ae0\u65f6\uff0cTensorRT\u7248\u672c\u5df2\u7ecf\u5347\u52308.4\uff0c\u6240\u4ee5Plugin\u7684\u5b9e\u73b0\u901a\u5e38\u5c31\u662f\u7ee7\u627f\u8868\u683c\u4e2d\u6700\u540e\u4e00\u884c\u7684<code>IPluginV2DynamicExt</code>\u7c7b\uff0c\u4e5f\u5c31\u662f\u53ef\u4ee5\u5b9e\u73b0\u52a8\u6001shape\u7684\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#52-plugin","title":"5.2 Plugin\u7684\u5b9a\u4e49\u5b9e\u73b0\u76f8\u5173\u63a5\u53e3","text":"<p>Plugin\u7684\u5b9e\u73b0\u6b65\u9aa4\uff1a</p> <ol> <li>\u7ee7\u627f<code>IPluginV2DynamicExt</code>\u7c7b\u5b9e\u73b0\u4e00\u4e2a\u65b0\u7684Plugin\u7c7b</li> <li>\u7ee7\u627f<code>IPluginCreator</code>\u7c7b\u5b9e\u73b0\u4e00\u4e2aPluginCreator\u7c7b</li> <li>\u5b9e\u73b0\u7528\u4e8e\u8ba1\u7b97\u7684CUDA C++ kernel</li> <li>\u5c06Plugin\u7f16\u8bd1\u4e3a\u52a8\u6001\u94fe\u63a5\u5e93.so</li> <li>c++/python\u4ee3\u7801\u4e2d\u52a0\u8f7dso\u6587\u4ef6</li> </ol> <p>Plugin\u6784\u5efa\u671f\u548c\u8fd0\u884c\u671f\u8981\u6267\u884c\u7684\u4ea4\u4e92(\u4e0b\u9762\u6240\u8ff0\u529f\u80fd\u5747\u53cd\u6620\u5728IPluginV2DynamicExt\u7684\u63a5\u53e3\u5b9a\u4e49\u4e0a) - \u6784\u5efa\u671f</p> <pre><code>* \u7528\u6237\u6216\u8005\u89e3\u6790\u5668\u9700\u8981\u5411Plugin\u4f20\u9012\u6784\u9020\u53c2\u6570\u548c\u6743\u91cd\n* Plugin\u9700\u8981\u62a5\u544a\u5176\u652f\u6301\u7684\u8f93\u5165\u8f93\u51fa\u5f20\u91cf\u4fe1\u606f\uff08\u5305\u62ec\u7c7b\u578b\uff0c\u5f62\u72b6\u3001\u6570\u91cf\u3001\u6570\u636e\u5206\u5e03\u7b49\uff09\n* Plugin\u9700\u8981\u62a5\u544a\u6240\u9700\u7684workspace\u5927\u5c0f\n* TensorRT\u4f1a\u5c1d\u8bd5\u6240\u6709\u5141\u8bb8\u7684\u7ec4\u5408\uff0c\u7136\u540e\u9009\u62e9\u6027\u80fd\u6700\u4f73\u7684\u7ec4\u5408\uff08\u53ef\u80fd\u4f1a\u5728Plugin\u524d\u540e\u63d2\u5165reformat\u8282\u70b9\uff09\n* Plugin\u8981\u5b9e\u73b0\u5e8f\u5217\u5316\u548c\u53cd\u5e8f\u5217\u5316\u63a5\u53e3\n</code></pre> <ul> <li> <p>\u8fd0\u884c\u671f</p> <ul> <li> <p>TensorRT\u4e3aPlugin\u63d0\u4f9b\u8f93\u5165\u8f93\u51fa\u5f20\u91cf\u7684\u6240\u6709\u4fe1\u606f\uff0cworkspace\u5730\u5740\u8fd8\u6709cuda stream \u6ce8\u610f\uff1a\u4e0d\u8981\u5728\u8fd0\u884c\u671f<code>enqueue</code>\u51fd\u6570\u91cc\u9762\u4f7f\u7528<code>cudaMalloc</code>\u7b49\u8017\u65f6\u7684\u51fd\u6570 Plugin\u9700\u8981\u5b9e\u73b0\u7684\u5173\u952eAPI</p> </li> <li> <p>getOutputDimensions \u6839\u636e\u8f93\u5165\u5f20\u91cf\u5f62\u72b6\uff0c\u5411 TensorRT \u62a5\u544a\u6bcf\u4e2a\u8f93\u51fa\u5f20\u91cf\u7684\u5f62\u72b6</p> </li> <li> <p>supportsFormatCombination \u5411TensorRT\u62a5\u544a\u652f\u6301\u7684\u6570\u636e\u7c7b\u578b\u548c\u6570\u636e\u6392\u5e03 Plugin \u53ef\u4ee5\u540c\u65f6\u652f\u6301\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff08DataType\uff09\u548c\u6570\u636e\u6392\u5e03\uff08LayerOut\uff09\u7684\u8f93\u5165\u8f93\u51fa\u5f20\u91cf\u7ec4\u5408 TensorRT \u6df1\u5ea6\u4f18\u5148\u904d\u5386\u5404\u4e2a\u8f93\u5165\u5f20\u91cf\u7d22\u5f15\uff0c\u5c1d\u8bd5\u5404\u79cd\u7ec4\u5408\uff0c\u8be5\u51fd\u6570\u8fd4\u56de\u201cPlugin \u662f\u5426\u652f\u6301\u5f53\u524d\u5c1d\u8bd5\u7684\u7ec4\u5408\u201d \u4fdd\u8bc1\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c \u591a\u5b9e\u73b0\u4e00\u4e9b format \u7684\u7ec4\u5408\uff0c \u6d88\u9664 TenosrRT \u81ea\u52a8\u63d2\u5165 reformat \u8282\u70b9\u7684\u5f00\u9500</p> </li> <li> <p>configurePlugin \u5728\u63a8\u7406\u524d\u5c06\u8c03\u7528\u8be5\u6210\u5458\u51fd\u6570 Dynamic Shape \u6a21\u5f0f\u4e2d\uff0c\u6bcf\u5f53\u8f93\u5165\u6570\u636e\u5f62\u72b6\u53d1\u751f\u53d8\u5316\uff08\u8c03\u7528 context.set_binding_shape\uff09\u65f6\uff0c\u8be5\u6210\u5458\u51fd\u6570\u88ab\u8c03\u7528 \u6784\u5efa\u671f\u8c03\u7528\u65f6 in/out \u5f20\u91cf\u5f62\u72b6\u4e2d\u542b\u6709 -1 \u8fd0\u884c\u671f\u8c03\u7528\u65f6 in/out \u5f20\u91cf\u5f62\u72b6\u4e3a\u771f\u5b9e\u7ed1\u5b9a\u7684\u5f62\u72b6</p> </li> <li> <p>getWorkspaceSize \u5411 TensorRT \u62a5\u544a\u4e2d\u95f4\u8ba1\u7b97\u7ed3\u679c\u7684\u5b58\u50a8\u7a7a\u95f4 workspace\u663e\u5b58\u7533\u8bf7\u548c\u91ca\u653e\u7531 TensorRT \u7ba1\u7406</p> </li> <li> <p>enqueue \u8c03\u7528 CUDA C++ kernel \u8ba1\u7b97\u7684\u5730\u65b9 \u53ef\u4ee5\u6839\u636e\u8f93\u5165\u5f20\u91cf\u7684\u4e0d\u540c\u5f62\u72b6\u3001\u6570\u636e\u7c7b\u578b\u7b49\u6761\u4ef6\u9009\u62e9\u4e0d\u540c kernel \u6267\u884c\u8ba1\u7b97 \u4e0d\u8981\u5728 enqueue \u4e2d\u4f7f\u7528 cudaMalloc* \u7b49\u51fd\u6570</p> </li> </ul> </li> <li> <p>\u8d44\u6e90\u7ba1\u7406\u7c7b</p> <ul> <li>initialize\uff08engine \u521b\u5efa\u65f6\u88ab\u8c03\u7528\uff0c\u7528\u4e8e\u521d\u59cb\u5316 Plugin \u5c42\uff09  </li> <li>terminate (engine \u9500\u6bc1\u65f6\u88ab\u8c03\u7528\uff0c\u7528\u4e8e\u91ca\u653e initialize \u51fd\u6570\u7533\u8bf7\u7684\u8d44\u6e90)  </li> <li>clone\uff08\u521b\u5efa\u591a\u4e2a context \uff0c\u53ef\u4ee5\u4e0e\u6e90\u5bf9\u8c61\u5171\u4eab\u672c engine \u7684\u8d44\u6e90\uff09  </li> <li>attachToContext\uff08\u7533\u8bf7\u4f7f\u7528 context \u72ec\u5360\u7684 cudnn \u6216 cublas \u8d44\u6e90\uff09  </li> <li>detachFromContext\uff08\u9500\u6bc1 context \u72ec\u5360\u7684 cudnn \u6216 cublas \u8d44\u6e90\uff09  </li> <li>destroy\uff08\u5f53 context/engine \u9500\u6bc1\u65f6\u88ab\u8c03\u7528\uff09</li> </ul> </li> <li> <p>\u5e8f\u5217\u5316\u53cd\u5e8f\u5217\u5316</p> <ul> <li> <p>\u5e8f\u5217\u5316\uff08Plugin \u8d1f\u8d23\uff09</p> <ul> <li>getSerializationSize\uff08\u62a5\u544a\u5e8f\u5217\u5316\u9700\u8981\u7684\u7a7a\u95f4\u5927\u5c0f\uff0c\u5355\u4f4d Byte\uff09</li> <li> <p>serialize\uff08\u5c06Plugin \u6570\u636e\u5e8f\u5217\u5316\u5230\u7ed9\u5b9a\u7684 buffer \u4e2d\uff09</p> <ul> <li>\u53cd\u5e8f\u5217\u5316\uff08PluginCreator \u8d1f\u8d23\uff09</li> </ul> </li> <li> <p>deserializePlugin\uff08\u628a\u5e8f\u5217\u5316\u7684 buffer \u4f20\u7ed9 Plugin \u7684\u6784\u9020\u51fd\u6570\uff09</p> </li> <li>Plugin \u6784\u9020\u51fd\u6570\uff08\u4ece buffer \u4e2d\u8bfb\u53d6\u6570\u636e\u5e76\u5b8c\u6210 Plugin \u6784\u9020\uff09</li> </ul> </li> </ul> </li> </ul> <p>PluginCreator\u7684\u5173\u952eAPI</p> <ul> <li>createPlugin\uff08\u4f9d\u7167\u4f20\u5165\u53c2\u6570\u8c03\u7528 Plugin \u6784\u9020\u51fd\u6570\uff09</li> <li>\u6ce8\u518c PluginCreator</li> </ul> <p>REGISTER_TENSORRT_PLUGIN(xxxPluginCreator);</p> <ul> <li>Version \u548c namespace \u76f8\u5173</li> <li>\u5e8f\u5217\u5316\u65f6 TensorRT \u4f1a\u5c06 Plugin \u7684\u540d\u5b57\uff08Name\uff09\u3001\u7c7b\u578b\uff08Type\uff09\u3001\u7248\u672c\u53f7\uff08Version\uff09\u3001\u547d\u540d\u7a7a\u95f4\uff08Namespace\uff09\u4fe1\u606f\u5199\u5165 engine</li> <li>\u901a\u5e38\u4e0d\u7528\u4fee\u6539</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#53-plugin","title":"5.3 Plugin\u7684\u529f\u80fd\u5b9e\u73b0\u6280\u5de7","text":"<ul> <li>\u5148\u4fdd\u8bc1\u539f\u751f\u8ba1\u7b97\u7684\u6b63\u786e\u6027</li> <li>\u5c1d\u8bd5\u91c7\u7528\u6216\u8005\u57fa\u4e8e\u81ea\u5e26Plugin\u4fee\u6539</li> <li>\u5c1d\u8bd5\u91c7\u7528\u5176\u4ed6\u6846\u67b6\u7684cuda\u5b9e\u73b0</li> <li>\u91c7\u7528cublas\u548ccudnn\u81ea\u884c\u5b9e\u73b0</li> <li>\u91c7\u7528\u539f\u751fcuda\u81ea\u884c\u7f16\u5199</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#layernormplugin","title":"\u516d\u3001LayerNorm\u7684\u539f\u7406\u4e0ePlugin\u7684\u5b9e\u73b0","text":"<p>\u5f00\u6e90\u5730\u5740: https://github.com/thb1314/tensorrt-layernorm-plugin \u7248\u672c\u8981\u6c42: TensorRT8.x</p> <p>\u4f5c\u8005\u5b9e\u73b0\u7684Layernorm\u63d2\u4ef6\u6027\u80fd\u662f\u6709\u4fdd\u8bc1\u7684\uff0ccuba\u90e8\u5206\u79fb\u690d\u7684oneflow\u7684\u5b98\u65b9\u5b9e\u73b0\u3002  </p> <p>https://github.com/Oneflow-Inc/oneflow/blob/master/oneflow/core/cuda/layer_norm.cuh  </p> <p>\u79fb\u690d\u6280\u5de7\uff1a\u6839\u636ecuh\u51fd\u6570\u540d\u5b57\u5728github\u4ed3\u5e93\u4e2d\u641c\u7d22\u5177\u4f53\u7528\u4f8b\uff0c\u7136\u540e\u5199\u4e00\u4e2a\u9002\u914d\u5668\u51fd\u6570\u6216\u8005\u76f4\u63a5\u4fee\u6539\u539f\u51fd\u6570\u63a5\u53e3\u6765\u6ee1\u8db3\u81ea\u5df1\u7684\u4f7f\u7528\u3002 Layernorm\u7684\u539f\u7406 \u8fd9\u91cc\u4ec5\u7ed9\u51faLayernorm\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u4e3a\u4ec0\u4e48\u9700\u8981Layernorm\u8bf7\u81ea\u884c\u641c\u7d22\u3002 torch\u4f2a\u4ee3\u7801\uff1a</p> <pre><code># x shape: [B, S, E]\n# B\u4ee3\u8868 batch size\uff0c S \u4ee3\u8868 Sequence length E\u4ee3\u8868Embedding dim length\ngamma = nn.Parameter(torch.ones(E))\nbeta = nn.Parameter(torch.zeros(E))\nmean = x.mean(-1, keepdim=True) # mean: [bsz, max_len, 1]\nstd = x.std(-1, keepdim=True) # std: [bsz, max_len, 1]\n# \u6ce8\u610f\u8fd9\u91cc\u4e5f\u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u53d1\u751f\u4e86\u5e7f\u64ad\nlayernorm_output =  gamma * (x - mean) / (std + self.eps) + beta\n</code></pre> <p>\u62d3\u5c55 1. \u5982\u679c\u662f\u5e94\u7528\u5728CV\u9886\u57df\uff0cx\u7684shape\u4e3a[B,C,H,W]\u7684\u662f\u65f6\u5019\u5e94\u8be5\u5bf9\u8c01\u8fdb\u884c\u5f52\u4e00\u5316\u548c\u6c42mean\u5462\uff1f 2. torch\u81ea\u5e26\u7684nn.LayerNorm\u600e\u4e48\u9002\u914d\u8fd9\u79cd\u60c5\u51b5\u5462\uff1f \u5728\u63d2\u4ef6\u7684enqueue\u51fd\u6570\uff0c\u505a\u4e86\u5982\u4e0b\u7c7b\u578b\u5224\u65ad\uff0c\u4e5f\u5c31\u662f\u5f53\u524d\u7684LayerNorm Plugin fp32/fp16\u90fd\u662f\u652f\u6301\u7684\u3002</p> <pre><code>int LayerNormalizationPlugin::enqueue(const nvinfer1::PluginTensorDesc* inputDesc,\n    const nvinfer1::PluginTensorDesc* outputDesc, const void* const* inputs, void* const* outputs, void* workspace,\n    cudaStream_t stream) noexcept\n{\n    // Get the input dimensions\n    nvinfer1::Dims input_dims = inputDesc[0].dims;\n    int batchSize = input_dims.d[0];\n    int nbChannels = input_dims.d[1];\n    bool use_fp16 = inputDesc[0].type == DataType::kHALF;\n    bool use_fp32 = inputDesc[0].type == DataType::kFLOAT;\n    mChannelVolume = std::accumulate(input_dims.d + 2, input_dims.d + inputDesc[0].dims.nbDims, 1, std::multiplies&lt;int&gt;());\n    int need_size = batchSize * nbChannels;\n    if(mean_len &lt; need_size) {\n        if(mean != nullptr) {\n            cudaFree(mean);\n            mean = nullptr;\n        }\n        mean_len = need_size;\n        cudaMalloc(&amp;mean, mean_len * sizeof(float));\n    }\n    if(inv_variance_len &lt; need_size) {\n        if(inv_variance != nullptr) {\n            cudaFree(inv_variance);\n            inv_variance = nullptr;\n        }\n        inv_variance_len = need_size;\n        cudaMalloc(&amp;inv_variance, inv_variance_len * sizeof(float));\n    }\n    if(use_fp16) {\n        LayerNormForwardGpu(stream, batchSize * nbChannels, mChannelVolume,\n                        mEpsilon, reinterpret_cast&lt;const __half*&gt;(inputs[0]), reinterpret_cast&lt;const __half*&gt;(inputs[1]),\n                        reinterpret_cast&lt;const __half*&gt;(inputs[2]), reinterpret_cast&lt;__half*&gt;(outputs[0]), mean,\n                        inv_variance);\n    } else if(use_fp32) {\n        LayerNormForwardGpu(stream, batchSize * nbChannels, mChannelVolume,\n                        mEpsilon, reinterpret_cast&lt;const float*&gt;(inputs[0]), reinterpret_cast&lt;const float*&gt;(inputs[1]),\n                        reinterpret_cast&lt;const float*&gt;(inputs[2]), reinterpret_cast&lt;float*&gt;(outputs[0]),mean,\n                        inv_variance);\n    } else {\n        printf(\"unsupported type!\");\n    }\n    return 0;\n}\n</code></pre> <p>\u8fd9\u91cc\u5148\u5224\u65ad\u8f93\u5165\u6570\u636e\u7684\u7c7b\u578b\uff0c\u518d\u51b3\u5b9a\u91c7\u7528\u90a3\u4e2a\u7c7b\u578b\u7684\u8ba1\u7b97\u51fd\u6570\uff0c\u540e\u7eed\u6587\u7ae0\u4e3a\u8bb2\u4e00\u4e0bint8\u7684\u5b9e\u73b0\u4e0e\u8ba1\u7b97\u3002 \u8bfb\u8005\u53ef\u80fd\u4f1a\u56f0\u60d1\u4e3a\u4ec0\u4e48\u8fd9\u91cc<code>enqueue</code>\u51fd\u6570\u5185\u90e8\u6709<code>cudaMalloc</code>\u51fd\u6570\uff0c\u524d\u9762\u4e0d\u662f\u8bf4\u4e0d\u80fd\u7528\u4e48\uff0c\u8fd9\u91cc\u7684\u903b\u8f91\u5728<code>configurePlugin</code>\u903b\u8f91\u4e5f\u6709\u5b9e\u73b0\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u6309\u9700\u52a8\u6001\u7533\u8bf7mean\u548cstd\u7684\u663e\u5b58\u3002\u6309\u7406\u8bf4\u8fd9\u91cc\u7684if\u5224\u65ad\u662f\u8fdb\u4e0d\u53bb\u7684\uff0c\u8fd9\u4e48\u5199\u662f\u4e3a\u4e86\u5b89\u5168\u4e00\u4e9b\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#plugindebug","title":"\u4e03\u3001Plugin\u7684Debug\u6280\u5de7","text":"<p>\u5982\u679c\u8bfb\u8005\u7531\u4ed4\u7ec6\u9605\u8bfb\u6e90\u7801\u7684\u8bdd\uff0c\u53ef\u4ee5\u53d1\u73b0\u91cc\u9762\u7684trt_tensor\u76f8\u5173\u7684\u7c7b\u4e0e\u63d2\u4ef6\u7f16\u5199\u6ca1\u4ec0\u4e48\u5173\u8054\uff0c\u653e\u5728\u8fd9\u91cc\u662f\u4e3a\u4e86\u540e\u7eed\u7684\u8c03\u8bd5\u3002 \u8c03\u8bd5\u7684\u4e3b\u8981\u64cd\u4f5c\u5c31\u662f\u83b7\u53d6\u4e2d\u95f4\u7ed3\u679c\u5e76\u4fdd\u5b58\u7136\u540e\u91c7\u7528\u5176\u4ed6\u65b9\u5f0f\u9a8c\u8bc1\u3002</p> <ol> <li>enqueue\u51fd\u6570\u4e2d\u95f4\u7ed3\u679c\u8c03\u8bd5\u4f7f\u7528cnpy\u4fdd\u5b58\u4e3anpz\u6587\u4ef6</li> <li>\u5355\u4e2acuda kernel\u7684\u8c03\u8bd5\u5efa\u8bae\u53e6\u5916\u8d77\u4e00\u4e2a\u65b0\u9879\u76ee\uff0c\u4eff\u7167cublas\u9879\u76ee</li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#layernorm","title":"\u516b\u3001LayerNorm\u7684\u9a8c\u8bc1","text":"<p>LayerNorm\u7684\u9a8c\u8bc1\u53ef\u4ee5\u91c7\u7528TensorRT python\u7684API\u6765\u9a8c\u8bc1\u3002 \u8f93\u5165\u8f93\u51fa\u7531numpy tensor\u5b9a\u4e49\uff0c\u5177\u4f53\u51fd\u6570\u5b9e\u73b0\u4e5f\u53ef\u4ee5\u901a\u8fc7numpy\u6765\u6a21\u62df\uff0c\u7136\u540e\u5bf9\u6bd4tensorRT\u7684\u8f93\u51fa\u7ed3\u679c\u548cnumpy\u7684\u8f93\u51fa\u7ed3\u679c\u3002 \u4ee3\u7801</p> <pre><code>import os\nimport ctypes\nimport numpy as np\n# cuda: https://nvidia.github.io/cuda-python/\nfrom cuda import cudart\nimport tensorrt as trt\nimport torch\nsoFile = \"./layernorm_plugin.so\"\nepsilon = 1.0e-2\nnp.random.seed(97)\ndef printArrayInfo(x, description=\"\"):\n    print('%s: %s\n  Mean=%.5e,SumAbs=%.5e,Var=%.5e,Max=%.5f,Min=%.5f,SAD=%.5e' % (\n        description, str(x.shape), np.mean(x), np.sum(abs(x)), np.var(x), np.max(x), np.min(x), np.sum(np.abs(np.diff(x.reshape(-1))))))\n    print(\"\\t\", x.reshape(-1)[:10])\ndef check(a, b, weak=False):\n    if weak:\n        res = np.all(np.abs(a - b) &lt; epsilon)\n\n    else:\n        res = np.all(a == b)\n    diff0 = np.max(np.abs(a - b))\n\n    diff1 = np.max(np.abs(a - b) / (np.abs(b) + epsilon))\n\n    print(\"check:\", res, \"maxAbsDiff:\", diff0, \"maxRelDiff:\", diff1)\ndef getLayerNormalizationPlugin():\n    for c in trt.get_plugin_registry().plugin_creator_list:\n        if c.name == 'LayerNormalizationPlugin':\n            parameterList = []\n            parameterList.append(trt.PluginField(\n                \"eps\", np.float32(1e-5), trt.PluginFieldType.FLOAT32))\n            return c.create_plugin(c.name, trt.PluginFieldCollection(parameterList))\n    return None\nuse_fp16 = True\ndef run():\n    trtFile = \"./layernorm-plugin.plan\"\n    logger = trt.Logger(trt.Logger.ERROR)\n    trt.init_libnvinfer_plugins(logger, '')\n    ctypes.cdll.LoadLibrary(soFile)\n    if os.path.isfile(trtFile):\n        with open(trtFile, 'rb') as f:\n            engine = trt.Runtime(logger).deserialize_cuda_engine(f.read())\n        if engine is None:\n            print(\"Failed loading engine!\")\n            return\n        print(\"Succeeded loading engine!\")\n    else:\n        builder = trt.Builder(logger)\n        network = builder.create_network(\n            1 &lt;&lt; int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n        profile = builder.create_optimization_profile()\n        config = builder.create_builder_config()\n        config.max_workspace_size = 6 &lt;&lt; 30\n        if builder.platform_has_fast_fp16 and use_fp16:\n            config.set_flag(trt.BuilderFlag.FP16)\n            config.set_flag(trt.BuilderFlag.STRICT_TYPES)\n        if use_fp16:\n            inputT0 = network.add_input(\n                'x', trt.DataType.HALF, [-1 for i in range(3)])\n            weight = network.add_input('weight', trt.DataType.HALF, [-1])\n            bias = network.add_input('bias', trt.DataType.HALF, [-1])\n        else:\n            inputT0 = network.add_input(\n                'x', trt.DataType.FLOAT, [-1 for i in range(3)])\n            weight = network.add_input('weight', trt.DataType.FLOAT, [-1])\n            bias = network.add_input('bias', trt.DataType.FLOAT, [-1])\n        profile.set_shape(inputT0.name, [1, 1, 1], [8, 63, 256], [64, 63, 256])\n        profile.set_shape(weight.name, [1, ], [8, ], [64, ])\n        profile.set_shape(bias.name, [1, ], [8, ], [64, ])\n        config.add_optimization_profile(profile)\n        pluginLayer = network.add_plugin_v2(\n            [inputT0, weight, bias], getLayerNormalizationPlugin())\n        # pluginLayer.\n        network.mark_output(pluginLayer.get_output(0))\n        if use_fp16:\n            pluginLayer.precision = trt.float16\n            pluginLayer.set_output_type(0, trt.float16)\n            network.get_output(0).dtype = trt.float16\n        print('type', network.get_output(0).dtype)\n        engineString = builder.build_serialized_network(network, config)\n        if engineString is None:\n            print(\"Failed building engine!\")\n            return\n        print(\"Succeeded building engine!\")\n        with open(trtFile, 'wb') as f:\n            f.write(engineString)\n        engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n    context = engine.create_execution_context()\n    shape = (2, 32, 10)\n    context.set_binding_shape(0, shape)\n    context.set_binding_shape(1, [shape[-1]])\n    context.set_binding_shape(2, [shape[-1]])\n    _, stream = cudart.cudaStreamCreate()\n    nInput = np.sum([engine.binding_is_input(i) for i in range(engine.num_bindings)])\n    nOutput = engine.num_bindings - nInput\n\n    bufferH = []\n    data_type = np.float16 if use_fp16 else np.float32\n    data = np.random.rand(np.prod(shape)).astype(data_type).reshape(shape) * 200 - 100\n\n    print(\"min, max:\", data.min(), data.max())\n    weight_data = np.ones((shape[-1], ), dtype=data_type)\n    bias_data = np.zeros((shape[-1], ), dtype=data_type)\n    bufferH.append(data)\n    bufferH.append(weight_data)\n    bufferH.append(bias_data)\n    print('nOutput:', nOutput)\n    for i in range(nOutput):\n        print('context.get_binding_shape(nInput + i)',\n              context.get_binding_shape(nInput + i))\n        bufferH.append(np.empty(context.get_binding_shape(\n            nInput + i), dtype=trt.nptype(engine.get_binding_dtype(nInput + i))))\n    bufferD = []\n    for i in range(engine.num_bindings):\n        bufferD.append(cudart.cudaMallocAsync(bufferH[i].nbytes, stream)[1])\n    for i in range(nInput):\n        cudart.cudaMemcpyAsync(bufferD[i], np.ascontiguousarray(\n            bufferH[i].reshape(-1)).ctypes.data, bufferH[i].nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n    context.execute_async_v2(bufferD, stream)\n    for i in range(nOutput):\n        cudart.cudaMemcpyAsync(bufferH[nInput + i].ctypes.data, bufferD[nInput + i],\n                               bufferH[nInput + i].nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n    cudart.cudaStreamSynchronize(stream)\n    mean = np.mean(bufferH[0], axis=-1, keepdims=True)\n    std = np.sqrt((np.mean((bufferH[0] - mean) ** 2, axis=-1, keepdims=True) + 1e-5))\n\n    a = (bufferH[0] - mean) / std\n\n    weight = bufferH[1]\n    bias = bufferH[2]\n    a = weight.reshape(1, 1, -1) * a + bias.reshape(1, 1, -1)\n    print(\"bufferH[-1].dtype: \", bufferH[-1].dtype)\n    print('diff abs max', np.abs(a - bufferH[-1].astype(data_type)).max())\n\n    t = torch.as_tensor(bufferH[0])\n    cudart.cudaStreamDestroy(stream)\n    for buffer in bufferD:\n        cudart.cudaFree(buffer)\nif __name__ == '__main__':\n    os.system('rm ./layernorm-plugin.plan')\n    np.set_printoptions(precision=3, linewidth=100, suppress=True)\n    run()\n    print(\"test finish!\")\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/2022%E5%B9%B408%E6%9C%8802%E6%97%A5%2023%E6%97%B628%E5%88%8628%E7%A7%92/#_1","title":"\u4e5d\u3001\u603b\u7ed3","text":"<p>TensorRT Plugin\u7684\u5b9e\u73b0\u4e0d\u7b97\u5f88\u590d\u6742\uff0c\u63a5\u53e3\u5b9a\u4e49\u4e5f\u5f88\u6e05\u6670\u3002\u672c\u6587\u8be6\u7ec6\u4ecb\u7ecd\u4e86TensorRT Plugin\u7684\u57fa\u7840\u4f7f\u7528\u548c\u5b9e\u73b0\uff0c\u5b66\u6d77\u65e0\u6daf\uff0c\u4f5c\u8005\u4f1a\u7ee7\u7eed\u5b66\u4e60\u4e3a\u8bfb\u8005\u5206\u4eab\u66f4\u591a\u5173\u4e8ePlugin\u7684\u9ad8\u7ea7\u7528\u6cd5\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/","title":"\u5bf9\u5355\u673a\u591a\u5361AI\u6a21\u578b\u63a8\u7406\u573a\u666f\u4e0b\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u95ee\u9898\u7684\u601d\u8003","text":"<p>\u672c\u6587\u5199\u4e8e2023-01-14</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#_1","title":"\u4e00 \u5199\u5728\u524d\u9762","text":"<p>\u51fa\u5dee\u5c06\u8fd1\u4e00\u4e2a\u6708\uff0c\u89d2\u8272\u4ece\u8bc4\u59d4\u5230\u5b66\u5458\uff0c\u8fd9\u662f\u5f53\u524d\u8fd9\u4efd\u5de5\u4f5c\u5e26\u7ed9\u6211\u7684\u9b54\u5e7b\u7ecf\u5386\uff08\u6342\u8138\u7b11\uff09\u3002\u51fa\u5dee\u7684\u8fc7\u7a0b\u4e2d\u611f\u67d3\u4e86\u5965\u5bc6\u514b\u620e\uff0c\u5e78\u8fd0\u7684\u662f\u6ca1\u6709\u53d1\u9ad8\u70e7\uff0c\u6d41\u4e86\u4e94\u5929\u6e05\u9f3b\u6d95\u548c\u9f3b\u585e\uff0c\u66f4\u591a\u7684\u662f\u5fc3\u7406\u4e0a\u7684\u538b\u529b\uff0c\u662f\u5bf9\u4e8e\u672a\u77e5\u7684\u6050\u60e7\u548c\u5bb6\u4eba\u7684\u62c5\u5fe7\uff0c\u4e0d\u8fc7\u4e5f\u5df2\u7ecf\u6162\u6162\u5316\u89e3\u4e86\u3002\u4e2a\u4eba\u89c9\u5f97\u66f4\u591a\u7684\u8981\u517b\u6210\u957f\u671f\u9632\u75ab\u4e0b\u7684\u4e60\u60ef\uff0c\u6234\u597dN95\u5c11\u53bb\u4eba\u591a\u5730\u65b9\uff0c\u53ca\u65f6\u6d88\u6bd2\u3002\u597d\u957f\u65f6\u95f4\u6ca1\u5403\u6c34\u997a\u4e86\uff0c\u56de\u6765\u540e\u7b2c\u4e00\u5929\u4e00\u4e2a\u997a\u5b50\u4e00\u53e3\u849c\uff0c\u4e00\u987f\u5403\u4e8636\u4e2a\uff0c\u771f\u7684\u592a\u9999\u4e86\uff0c\u987f\u65f6\u611f\u53f9\u5e74\u8f7b\u771f\u597d\u3002</p> <p>\u4e0d\u8bf4\u5e9f\u8bdd\u4e86\uff0c\u5173\u4e8e\u5355\u673a\u591a\u5361AI\u6a21\u578b\u63a8\u7406\u573a\u666f\u4e0b\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u662f\u4e1a\u52a1\u62bd\u8c61\u51fa\u6765\u7684\u95ee\u9898\uff0c\u672c\u6587\u5c06\u9488\u5bf9\u8fd9\u7c7b\u5171\u6027\u95ee\u9898\u7684\u4e0d\u540c\u60c5\u51b5\u8fdb\u884c\u8ba8\u8bba\uff0c\u601d\u8003\u4e0d\u540c\u7684\u89e3\u51b3\u65b9\u6848\u4e0b\u7684\u4f18\u52a3\u3002</p> <p>\u672c\u6587\u6d89\u53ca\u5230\u7684\u5b8c\u6574\u4ee3\u7801\u5728\uff1a https://github.com/thb1314/mutual_share_memory_with_priority_queue</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#_2","title":"\u4e8c \u62bd\u8c61\u95ee\u9898","text":"<p>\u9996\u5148\u5bf9\u201d\u5355\u673a\u591a\u5361AI\u6a21\u578b\u63a8\u7406\u573a\u666f\u4e0b\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\"\u8fd9\u4e00\u53e5\u8bdd\u8fdb\u884c\u62c6\u89e3</p> <p>\u5355\u673a\u591a\u5361: \u5728\u4e00\u4e2a\u4e3b\u677f\u4e0a\uff0c\u5b58\u5728\u591a\u5f20\u8ba1\u7b97\u5361\uff08gpu\u3001npu\u7b49\uff09\uff0c\u591a\u5f20\u8ba1\u7b97\u5361\u4e4b\u95f4\u53ef\u4ee5\u901a\u4fe1\uff0c\u8ba1\u7b97\u5361\u4e0e\u4e3b\u63a7\u82af\u7247\uff08cpu\uff09\u4e4b\u95f4\u53ef\u4ee5\u901a\u4fe1</p> <p>AI\u6a21\u578b\u63a8\u7406: \u4eba\u5de5\u667a\u80fd\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u8fd9\u91cc\u7279\u6307\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff08\u5373\u5927\u91cf\u7684\u77e9\u9635\u4e58\u6cd5\uff09</p> <p>\u8ba1\u7b97\u8d44\u6e90: \u8ba1\u7b97\u8d44\u6e90\u6307\u7684\u662f\u591a\u5f20\u8ba1\u7b97\u5361\u5171\u540c\u63d0\u4f9b\u7684\u7b97\u529b\uff0c\u4e5f\u5c31\u662f\u5176\u63d0\u4f9b\u7684\u8ba1\u7b97\u80fd\u529b\u548c\u5b58\u50a8\u80fd\u529b\u5171\u540c\u7ec4\u6210\u7684\u4e1c\u897f\u3002</p> <p>\u5206\u914d\uff1a\u6beb\u65e0\u7591\u95ee\u6307\u7684\u662f\u4e0a\u8ff0\u8ba1\u7b97\u8d44\u6e90\u7684\u5212\u5206\u95ee\u9898\uff0c\u5f52\u6839\u7ed3\u5e95\u5c31\u662f\u5f53\u6709\u4e00\u4e2a\u6a21\u578b\u63a8\u7406\u4efb\u52a1\u521b\u5efa\u65f6\u5e94\u8be5\u91c7\u7528\u4e0a\u8ff0\u5355\u673a\u591a\u5361\u4e2d\u91c7\u7528\u54ea\u5f20\u5361\u7684\u95ee\u9898\u3002</p> <p>\u62d3\u5c55\uff1a \u8bf4\u660e\u767d\u4e86\u5355\u673a\u591a\u5361\u4e0a\u7684\u95ee\u9898\uff0c\u90a3\u4e48\u591a\u673a\u591a\u5361\u5c31\u663e\u800c\u6613\u89c1\u4e86\uff0c\u65e0\u975e\u5c31\u662f\u4e00\u4e2a\u4e3b\u677f\u6362\u6210\u4e86\u591a\u4e2a\u4e3b\u677f\uff0c\u5148\u89e3\u51b3\u5355\u673a\u591a\u5361\u7684\u95ee\u9898\u540e\uff0c\u518d\u89e3\u51b3\u591a\u673a\u4e4b\u95f4\u7684\u901a\u8baf\u95ee\u9898\u5373\u53ef\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#_3","title":"\u4e09 \u89e3\u51b3\u65b9\u6848","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#31","title":"3.1 \u7b97\u6cd5\u5c42\u9762","text":"<p>\u5bf9\u4e8e\u4e0a\u8ff0\u95ee\u9898\uff0c\u5b9e\u9645\u4e0a\u53ef\u4ee5\u7b49\u4ef7\u4e3a\u5982\u4e0b\u95ee\u9898\uff1a</p> <p>\u5df2\u77e5\uff1a  N\u5f20\u5361\uff0c\u5355\u5f20\u5361\u7684\u5b58\u50a8\u5bb9\u91cf\u4e3aM\uff0c\u8ba1\u7b97\u80fd\u529b\u4e3aP * X\u4e2a\u4efb\u52a1\uff1a\u6bcf\u4e2a\u4efb\u52a1\u9700\u8981\u6d88\u8017\u5b58\u50a8\u5bb9\u91cf \\(M_i\\) \u548c\u8ba1\u7b97\u80fd\u529b \\(P_i\\) \uff0c\u6d88\u8017\u65f6\u95f4 \\(T_i\\) \uff08 \\(i\\in[1,X]\\) \uff09  \u76ee\u6807\uff1a\u6784\u9020\u4e00\u4e2a\u4efb\u52a1\u8868\uff0c\u6bcf\u6b21\u53ef\u4ee5\u8dd11\u4e2a\u6216\u591a\u4e2a\u4efb\u52a1\uff0c\u4f7f\u5f97\u603b\u4f53\u4ee3\u4ef7\u51fd\u6570\u6700\u5c0f\u3002\u4ee3\u4ef7\u51fd\u6570\u6bd4\u5982\u53ef\u4ee5\u662f\u63a8\u7406\u65f6\u95f4 \u8ba8\u8bba\uff1a 1. \u5f53X\u7684\u503c\u5df2\u77e5\u65f6\uff0c\u5373\u5c06X\u4e2a\u4efb\u52a1\u5206\u6279\u6b21\u5b89\u6392\u5230N\u5f20\u5361\uff0c\u6bcf\u6b21\u5b89\u6392\u7684\u4efb\u52a1\u4e2a\u6570\u4e0d\u9650\u5236\uff08\u53d7\u5b58\u50a8\u5bb9\u91cf\u548c\u8ba1\u7b97\u80fd\u529b\u9650\u5236\uff09\uff0c\u5b89\u6392\u591a\u5c11\u6b21\u4e0d\u9650\u5236\uff0c\u76ee\u6807\u662f\u603b\u4f53\u4ee3\u4ef7\u51fd\u6570\u6700\u5c0f\u3002\u6bd4\u5982\u603b\u4f53\u4ee3\u4ef7\u51fd\u6570\u4e3a\u603b\u4f53\u6d88\u8017\u65f6\u95f4\uff0c\u90a3\u4e48\u6b64\u7c7b\u6700\u4f18\u5316\u95ee\u9898\u6216\u8005\u8bf4\u662f\u5206\u914d\u95ee\u9898\u3002 2. \u5f53X\u7684\u503c\u672a\u77e5\u65f6\uff0c\u6b64\u65f6X\u5e94\u8be5\u662f\u65e0\u7a77\u5927\u7684\u60c5\u51b5\uff0c\u7c7b\u4f3c\u4e8e\u7528\u6237\u70b9\u51fb\u6216\u8005\u8bf7\u6c42\u7684\u4e8b\u4ef6\uff0c\u6bcf\u9694\u4e00\u6bb5\u65f6\u95f4\u5c31\u4f1a\u6709\u4e00\u4e2a\u4efb\u52a1\uff0c\u7b49\u5f85\u65f6\u95f4\u672a\u77e5\u3002  </p> <p>\u9488\u5bf9\u7b2c\u4e00\u4e2a\u95ee\u9898\u6211\u6682\u65f6\u6ca1\u6709\u627e\u5230\u6bd4\u8f83\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e0d\u8fc7\u6b64\u7c7b\u95ee\u9898\u662f\u6211\u5047\u8c61\u7684\uff0c\u73b0\u5b9e\u4e2dX\u7684\u503c\u66f4\u591a\u662f\u672a\u77e5\u7684\uff0c\u6bd4\u5982\u5728\u4e00\u4e2aAPP\u4e2d\u8c03\u7528\u7aef\u4fa7\u63a8\u7406\u4eba\u7269\uff0c\u7528\u6237\u4e00\u5171\u8c03\u7528\u4e86\u591a\u5c11\u6b21\u4ec0\u4e48\u65f6\u5019\u8c03\u7528\u90fd\u662f\u672a\u77e5\u7684\u3002</p> <p>\u4e0b\u9762\u8bf4\u4e00\u4e0b\u7b2c\u4e8c\u4e2a\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff1a</p> <p>\u8003\u8651\u5230\u4efb\u52a1\u7684\u65f6\u6548\u6027\uff0c\u5b9e\u9645\u4e0a\u5c40\u90e8\u6700\u4f18\u65b9\u6848\u662f\u9488\u5bf9\u6bcf\u6b21\u7684\u5b89\u6392\u7684\u4efb\u52a1\u90fd\u4f7f\u5f97\u5f53\u524d\u4ee3\u4ef7\u51fd\u6570\u8ba1\u7b97\u7684\u6700\u5c0f\u3002\u6709\u4eba\u6216\u8bb8\u4f1a\u8003\u8651\u5c40\u90e8\u6700\u4f18\u5e76\u4e0d\u4ee3\u8868\u5168\u5c40\u6700\u4f18\uff0c\u662f\u8fd9\u6837\u7684\uff0c\u4f46\u662f\u4e0b\u4e00\u4e2a\u4efb\u52a1\u7684\u5230\u6765\u65f6\u95f4\u662f\u672a\u77e5\u7684\uff0c\u8fd9\u4e5f\u5c31\u610f\u5473\u7740\u7b49\u5f85\u65f6\u95f4\u662f\u6ca1\u529e\u6cd5\u4fdd\u8bc1\u7684\uff0c\u5047\u8bbe\u53ef\u4ee5\u5c06\u5f53\u524d\u4efb\u52a1\u548c\u4e0b\u4e00\u4e2a\u4efb\u52a1\u5408\u5e76\uff0c\u90a3\u4e48\u968f\u4e4b\u800c\u6765\u589e\u52a0\u7684\u7b49\u5f85\u65f6\u95f4\u7edf\u8ba1\u8fdb\u53bb\u540e\u53c8\u8be5\u5982\u4f55\u53d6\u820d\u5462\uff1f</p> <p>\u6211\u4eec\u603b\u662f\u5e0c\u671b\u6211\u4eec\u505a\u7684\u9009\u62e9\u662f\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u53ef\u7531\u4e8e\u7b49\u5f85\u65f6\u95f4\u7684\u5b58\u5728\u6211\u4eec\u6ca1\u529e\u6cd5\u53bb\u5224\u65ad\u662f\u5426\u662f\u6700\u4f18\u89e3\uff0c\u53ea\u80fd\u8ba9\u5176\u53d1\u751f\u7136\u540e\u518d\u53bb\u89c2\u5bdf\uff0c\u53ef\u90a3\u6837\u5bf9\u4e8e\u5df2\u7ecf\u53d1\u751f\u5bf9\u7684\u7ed3\u679c\u6beb\u65e0\u610f\u4e49\uff0c\u4eba\u751f\u6216\u8bb8\u4ea6\u662f\u5982\u6b64\uff0c\u6211\u4eec\u603b\u662f\u4ece\u4e00\u4e2a\u5c40\u90e8\u6700\u4f18\u89e3\u9009\u62e9\u5230\u4e0b\u4e00\u4e2a\u5c40\u90e8\u6700\u4f18\u89e3\u3002</p> <p>\u5f53\u7136\u6211\u4eec\u4e5f\u5141\u8bb8\u7b49\u5f85\u65f6\u95f4\u7684\u5b58\u5728\uff0c\u8bbe\u7f6e\u4e00\u4e2a\u6700\u5927\u7b49\u5f85\u65f6\u95f4\uff0c\u8d85\u65f6\u540e\u624d\u4e0d\u7b49\uff0c\u6bd4\u5982\u6211\u5728 \u751f\u4ea7\u8005\u6d88\u8d39\u8005\u6a21\u5f0f\u5728\u591abatch\u63a8\u7406\u4e0b\u7684\u5e94\u7528(\u5ef6\u65f6\u961f\u5217) \u4e2d\u7684\u5b9e\u73b0\u91cc\u9762\u5c31\u5b58\u5728\u4e00\u4e2a\u6700\u5927\u7b49\u5f85\u65f6\u95f4\uff0c\u5982\u679c\u4e0d\u8d85\u8fc7\u5c31\u653e\u5165\u5f53\u524d\u7684\u63a8\u7406batch\u4e2d\uff0c\u5982\u679c\u8d85\u8fc7\u4e86\u5c31\u4e0d\u7b49\u4e86\uff0c\u653e\u5230\u4e0b\u4e2abatch\u4e2d\u3002</p> <p>\u65e0\u8bba\u7b49\u5f85\u8fd8\u662f\u4e0d\u7b49\u5f85\u90fd\u9700\u8981\u6839\u636e\u573a\u666f\u5b9e\u9645\u6d4b\u8bd5\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#32","title":"3.2 \u901a\u8baf\u5c42\u9762","text":"<p>\u9488\u5bf9\u5355\u673a\u591a\u5361\u573a\u666f\uff0c\u627f\u62c5\u63a8\u7406\u8bf7\u6c42\u7684\u6709\u53ef\u80fd\u662f\u8fdb\u7a0b\u3001\u7ebf\u7a0b\u3001\u534f\u7a0b\u6216\u8005\u662f\u591a\u4e2a\u865a\u62df\u673a\u3001docker\u5bb9\u5668\u7b49\uff0c\u672c\u6587\u5c06\u5176\u5b9a\u4e49\u4e3a\u201c\u8fd0\u884c\u4f53\u201d\uff0c\u6839\u636e\u662f\u5426\u5728\u540c\u4e00\u4e2a\u64cd\u4f5c\u7cfb\u7edf\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u5206\u4e3a\u4e24\u7c7b\uff0c\u5373\u662f\u5426\u53ef\u4ee5\u5171\u7528\u4e00\u4e2a\u64cd\u4f5c\u7cfb\u7edf\u5185\u6838\u3002</p> <p>\u8fd9\u91cc\u9700\u8981\u8bf4\u660e\u7684\u662f\uff0c\u4e0d\u540c\u5185\u5b58\u7684\u65b9\u6cd5\u81ea\u7136\u4e5f\u53ef\u4ee5\u7528\u4e8e\u540c\u4e00\u4e2a\u5185\u6838\uff0c\u53ea\u4e0d\u8fc7\u540c\u4e00\u4e2a\u5185\u6838\u5f53\u4e2d\u6709\u66f4\u9002\u5408\u7684\u529e\u6cd5\u3002</p> <p>\u540c\u7406\uff0c\u540c\u4e00\u4e2a\u5185\u6838\u5f53\u4e2d\uff0c\u8fdb\u7a0b\u4e4b\u95f4\u7684\u901a\u4fe1\u65b9\u5f0f\u81ea\u7136\u4e5f\u53ef\u4ee5\u7528\u4e8e\u7ebf\u7a0b\u548c\u534f\u7a0b\uff08\u7ebf\u7a0b\u548c\u534f\u7a0b\u4e0d\u5b58\u5728\u901a\u4fe1\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u7684\u662f\u540c\u6b65\u95ee\u9898\uff09\uff0c\u53ea\u4e0d\u8fc7\u540e\u8005\u6709\u81ea\u5df1\u66f4\u597d\u7684\u540c\u6b65\u65b9\u5f0f\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#321","title":"3.2.1 \u540c\u4e00\u4e2a\u5185\u6838","text":"<p>\u5728\u540c\u4e00\u4e2a\u5185\u6838\u7684\u6709\u540c\u4e00\u4e2a\u64cd\u4f5c\u7cfb\u7edf\u5185\u90e8\u7684\u8fdb\u7a0b\u3001\u7ebf\u7a0b\u3001\u534f\u7a0b\uff0c\u4e0b\u9762\u5206\u5f00\u8fdb\u884c\u8ba8\u8bba\u3002</p> <p>\u8fdb\u7a0b\u4e4b\u95f4\u901a\u4fe1\uff1a</p> <ul> <li>\u975eIPC\uff08Inter-Process Communication\uff09\u901a\u4fe1</li> <li>\u7ba1\u9053\uff1a\u534a\u53cc\u5de5\u901a\u4fe1\uff0c\u4e00\u6761\u7ba1\u9053\u53ea\u80fd\u4e00\u4e2a\u8fdb\u7a0b\u5199\uff0c\u4e00\u4e2a\u8fdb\u7a0b\u8bfb\uff0c\u4e14\u4e0d\u53ef\u4ee5\u7528\u65f6\u8bfb\u5199\u3002<ul> <li>\u533f\u540d\u7ba1\u9053\uff1a\u9002\u7528\u4e8e\u6709\u4eb2\u7f18\u5173\u7cfb\u7684\u8fdb\u7a0b\u4e4b\u95f4\u7684\u901a\u4fe1\uff08\u7236\u5b50\u8fdb\u7a0b\u3001\u5144\u5f1f\u8fdb\u7a0b\uff09</li> <li>\u547d\u540d\u7ba1\u9053\uff1a\u9002\u7528\u4e8e\u72ec\u7acb\u8fdb\u7a0b\u4e4b\u95f4\u901a\u4fe1</li> </ul> </li> <li>\u6587\u4ef6\u9501\uff1a\u4e3b\u8981\u5229\u7528IO\u64cd\u4f5c\u53ef\u4ee5\u505a\u6210\u4e92\u65a5\u8bbf\u95ee\u8fd9\u4e00\u7279\u6027</li> <li>\u4e92\u65a5\u9501\uff1a\u8fdb\u7a0b\u4e4b\u95f4\u7684\u4e92\u65a5\u9501\u5b58\u5728\u4e8e\u5185\u6838\u5f53\u4e2d\uff0c\u4e3b\u8981\u770b\u64cd\u4f5c\u7cfb\u7edf\u662f\u5426\u652f\u6301</li> <li>IPC\u901a\u4fe1\uff1a</li> <li>\u6d88\u606f\u961f\u5217\uff1a\u5c06\u6d88\u606f\u4f53\u4ee5\u961f\u5217\u5f62\u5f0f\u8fdb\u884c\u5c01\u88c5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u8fb9\u53d1\u9001\u8fb9\u63a5\u6536\u3002</li> <li>\u5171\u4eab\u5185\u5b58\uff1a\u5171\u4eab\u5185\u5b58\u7684\u673a\u5236\u662f\u4e0d\u540c\u8fdb\u7a0b\u62ff\u51fa\u4e00\u5757\u865a\u62df\u5185\u5b58\u7a7a\u95f4\uff0c\u6620\u5c04\u5230\u76f8\u540c\u7684\u7269\u7406\u5185\u5b58\u7a7a\u95f4</li> <li>\u4fe1\u53f7\uff1aWindows\u548cLinux\u4e2d\u90fd\u6709\uff0c\u7528\u4e8e\u54cd\u5e94\u5404\u79cd\u4e8b\u4ef6\uff0c\u4e5f\u53ef\u4ee5\u7528\u4e8e\u81ea\u5b9a\u4e49\u4e8b\u4ef6\u6bd4\u5982\u8fdb\u7a0b\u540c\u6b65</li> <li>\u4fe1\u53f7\u706f\uff1a\u5b9e\u73b0\u5171\u4eab\u8d44\u6e90\u7684\u4e92\u65a5\u8bbf\u95ee\u4e0e\u8fdb\u7a0b\u95f4\u7684\u540c\u6b65\u64cd\u4f5c</li> </ul> <p>Note: \u5728Linux/Unix\u7cfb\u7edf\u4e2d\uff0cIPC\u901a\u4fe1\u6709\u4e24\u5957API\uff1a * System-V IPC \u63a5\u53e3\uff1a\u6765\u81ea\u8f83\u65e9\u7684Unix\u64cd\u4f5c\u7cfb\u7edf\uff0c\u662fUnix\u4f17\u591a\u5206\u652f\u4e2d\u7684\u4e00\u5458\uff0c\u4ed6\u6709\u5f88\u591a\u7ecf\u5178\u7684\u7528\u4f8b\uff0c\u4f8b\u5982 \u201dSysV \u521d\u59cb\u5316\u811a\u672c\u201c (/etc/init.d) * Posix IPC \u63a5\u53e3\uff1a\u5219\u662f\u6765\u81eaIEEE\u6240\u5f00\u53d1\u7684\u4e00\u7c07\u6807\u51c6\uff0c\u57fa\u4e8eUnix\u7684\u7ecf\u9a8c\u548c\u5b9e\u8df5\u6240\u5b9e\u73b0\u7684\u4e00\u5806\u8c03\u7528\u670d\u52a1\u63a5\u53e3\uff0c\u81f4\u529b\u4e8e\u5728\u591a\u79cd\u64cd\u4f5c\u7cfb\u7edf\u4e4b\u95f4\u6e90\u4ee3\u7801\u7ea7\u522b\u79fb\u690d\u3002 Posix IPC\u548cSystem-V IPC\u90fd\u662f\u5e94\u7528\u4e8e\u7cfb\u7edf\u7ea7\u7684\u63a5\u53e3\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u591a\u8fdb\u7a0b\u95f4\u901a\u4fe1\uff0c\u4e5f\u9002\u7528\u4e8e\u591a\u7ebf\u7a0b\u95f4\u901a\u4fe1\u3002Posix\u76f8\u5bf9\u4e8eSystem-V\u53ef\u4ee5\u8bf4\u662f\u6bd4\u8f83\u65b0\u7684\u6807\u51c6\uff0c\u8bed\u6cd5\u76f8\u5bf9\u7b80\u5355\u3002</p> <p>\u7ebf\u7a0b\u4e4b\u95f4\u540c\u6b65\u65b9\u6cd5\uff1a</p> <p>\u9996\u5148\u9700\u8981\u8bf4\u660e\u7684\u662f\uff0c\u540c\u4e00\u4e2a\u8fdb\u7a0b\u5185\u90e8\u7684\u7ebf\u7a0b\u95f4\u5168\u5c40\u8d44\u6e90\u662f\u5171\u4eab\u7684\uff0c\u4e0d\u5b58\u5728\u901a\u4fe1\u95ee\u9898\uff0c\u66f4\u591a\u7684\u662f\u5bf9\u5171\u4eab\u8d44\u6e90\u7684\u4fdd\u62a4\u95ee\u9898\u3002</p> <ul> <li>\u4e92\u65a5\u91cf mutex (windows/linux\u90fd\u6709)</li> <li>\u6761\u4ef6\u53d8\u91cf condition_variable\uff08\u53ef\u4ee5\u770b\u505a\u8ba1\u6570\u4e3a1\u7684\u4fe1\u53f7\u91cf\uff0c linux\u7279\u6709\uff09</li> <li>\u4fe1\u53f7\u91cf semaphore (linux/windows\u90fd\u6709)</li> <li>\u4e34\u754c\u533a critical section (windows\u7279\u6709)</li> <li>\u4e8b\u4ef6 event</li> </ul> <p>\u534f\u7a0b\u4e4b\u95f4\u540c\u6b65\u65b9\u6cd5\uff1a</p> <p>\u534f\u7a0b\u4e3b\u8981\u662f\u9488\u5bf9\u5f02\u6b65IO\u6765\u505a\u7684\uff0c\u9700\u8981\u540c\u6b65\u7684\u60c5\u51b5\u4e0d\u591a\uff0c\u4f46\u662f\u4e5f\u662f\u5b58\u5728\u7684\uff0c\u6bd4\u5982\u5728python\u534f\u7a0b\u4e2d\uff0c\u91c7\u7528asyncio\u4e2d\u7684Lock\u548cEvent\u90fd\u662f\u53ef\u4ee5\u505a\u5230\u540c\u6b65\u7684\uff0c\u8fd9\u4e00\u70b9\u4e0e\u7ebf\u7a0b\u5927\u540c\u5c0f\u5f02\uff0c\u4e0d\u8fc7\u9700\u8981\u65f6\u523b\u7262\u8bb0\u7684\u662f\uff0c\u534f\u7a0b\u4e2d\u7684\u4ee3\u7801\u4e00\u5b9a\u5728cpu\u7684\u5355\u4e2a\u6838\u5fc3\u4e0a\uff0c\u4e14\u5728\u540c\u4e00\u4e2a\u7ebf\u7a0b\u4e2d\uff0c\u53ea\u662f\u5207\u5206\u65f6\u95f4\u5206\u6bb5\u8fd0\u884c\u800c\u5df2\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#322","title":"3.2.2 \u4e0d\u540c\u5185\u6838","text":"<p>\u4e0d\u540c\u5185\u6838\u4e4b\u95f4\uff0c\u5305\u62ec\uff08\u4e0d\u540cdocker\u5bb9\u5668\uff0c\u4e0d\u540c\u865a\u62df\u673a\uff0c\u4e0d\u540c\u7269\u7406\u673a\uff09\u7f51\u7edc\u901a\u4fe1\u81ea\u7136\u662f\u9996\u9009\uff0c\u8c08\u5230\u7f51\u7edc\u81ea\u7136\u79bb\u4e0d\u5f00Socket\uff0c\u901a\u8fc7Socket\u6211\u4eec\u53ef\u4ee5\u521b\u5efa\u673a\u5668\u4e4b\u95f4\u7684tcp\u548cudp\u8fde\u63a5\uff0c\u9488\u5bf9\u5171\u4eab\u8d44\u6e90\u6211\u4eec\u53ef\u4ee5\u4fdd\u5b58\u5728\u67d0\u4e00\u53f0\u4e3b\u673a\u6216\u8005\u96c6\u7fa4\u4e2d\u7684\u6570\u636e\u5e93\u6216\u8005redis\u4e2d\uff0c\u901a\u8fc7\u6570\u636e\u5e93\u7684\u4e8b\u52a1\u64cd\u4f5c\u6216\u8005redis\u4e2d\u7684\u540c\u6b65\u9501\u673a\u5236\u6765\u4fdd\u8bc1\u8d44\u6e90\u7684\u4e92\u65a5\u8bbf\u95ee\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#_4","title":"\u56db \u5177\u4f53\u5b9e\u73b0\u6848\u4f8b","text":"<p>\u573a\u666f\uff1a\u5355\u673a\u591a\u5361\u540c\u4e00\u4e2a\u5185\u6838\uff0c\u6bcf\u4e2a\u63a8\u7406\u4efb\u52a1\u6d88\u8017\u7684\u663e\u5b58\u548c\u8ba1\u7b97\u8d44\u6e90\u76f8\u540c\uff0c\u6709\u591a\u5c11\u4e2a\u63a8\u7406\u4efb\u52a1\u672a\u77e5\uff0c\u201c\u8fd0\u884c\u4f53\u201d\u662f\u72ec\u7acb\u8fdb\u7a0b\uff0c\u6bd4\u5982apache\u4e2d\u7684prefork\u6a21\u5f0f\uff0c\u4e00\u6b21\u6027\u5f00\u591a\u4e2a\u8fdb\u7a0b\u6765\u5b9e\u73b0\u5e76\u53d1\u5904\u7406\uff0c\u5c3d\u7ba1\u6bcf\u4e2a\u8fdb\u7a0b\u662f\u5144\u5f1f\u5173\u7cfb\uff0c\u4f46\u662f\u5bf9\u5176\u91c7\u7528\u7ba1\u9053\u65b9\u5f0f\u662f\u8d39\u529b\u4e0d\u8ba8\u597d\u7684\uff0c\u6240\u4ee5\u672c\u6587\u7ed9\u51fa\u4e00\u79cd\u5171\u4eab\u5185\u5b58+\u8fdb\u7a0b\u95f4\u4e92\u65a5\u9501\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\u5171\u4eab\u8d44\u6e90\u7684\u4e92\u65a5\u8bbf\u95ee\u3002</p> <p>\u4f5c\u8005\u76ee\u7684\u662f\u4e3a\u4e86\u7ed9\u4e00\u4e2apython web\u670d\u52a1\u6765\u63d0\u4f9b\u63a5\u53e3\uff0cweb\u670d\u52a1\u901a\u5e38\u8fd0\u884c\u5728linux\u673a\u5668\u4e0a\uff0c\u6240\u4ee5\u4f5c\u8005\u91c7\u7528<code>System-V IPC</code>\u63a5\u53e3\u6765\u64cd\u4f5c\u5171\u4eab\u5185\u5b58\u3002\u91c7\u7528C++\u8c03\u7528linux\u5e94\u7528\u5c42API\uff0c\u5c01\u88c5\u6210C++ class\u6765\u7ba1\u7406\u5171\u4eab\u5185\u5b58\u7684\u8bfb\u5199\u4e0e\u91ca\u653e\uff0c\u7136\u540e\u91c7\u7528pybind11\u7ed9python\u63d0\u4f9b\u63a5\u53e3\u3002\u4e0b\u9762\u9700\u8981\u7406\u6e05\u4ee5\u4e0b\u51e0\u4e2a\u95ee\u9898\uff1a</p> <ol> <li>\u5171\u4eab\u5185\u5b58\u4ec0\u4e48\u65f6\u5019\u521b\u5efa\u4ec0\u4e48\u65f6\u5019\u6253\u5f00\u5df2\u5b58\u5728\uff1f    \u5982\u679c\u5df2\u5b58\u5728\u5c31\u9009\u62e9\u6253\u5f00\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5c31\u521b\u5efa\uff0c\u8fd9\u91cc\u8981\u505a\u4e00\u4e2a\u5224\u65ad\uff08\u521b\u5efa\u62a5\u9519\u5c31\u8bf4\u660e\u5df2\u7ecf\u5b58\u5728\uff09</li> <li>\u5171\u4eab\u5185\u5b58\u4ec0\u4e48\u65f6\u5019\u91ca\u653e\uff1f    \u4f7f\u7528\u7684\u8fdb\u7a0b\u6570\u5c0f\u4e8e\u7b49\u4e8e1\uff0c\u4e14\u5f53\u524d\u8fdb\u7a0b\u4e2d\u7684\u5171\u4eab\u5185\u5b58\u7ba1\u7406\u5bf9\u8c61\u4ec5\u5269\u4e0b\u4e00\u4e2a\u7684\u65f6\u5019\u5c31\u91ca\u653e\u3002\u6240\u4ee5\u5728\u5171\u4eab\u5185\u5b58\u91cc\u9762\u5f00\u8f9f\u4e00\u5c0f\u5757\u533a\u95f4\u7528\u4e8e\u8bb0\u5f55\u5f53\u524d\u8fdb\u7a0b\u4e2d\u7684\u5bf9\u8c61\u4e2a\u6570\uff0c\u5e76\u5728\u62f7\u8d1d\u6784\u9020\u4e2d\u7ef4\u62a4\u8be5\u4e2a\u6570\uff0c\u5728\u6790\u6784\u51fd\u6570\u4e2d\u52a0\u4ee5\u5224\u65ad\u3002</li> <li>\u5982\u4f55\u4fdd\u8bc1\u8ba1\u7b97\u8d44\u6e90\u7684\u5747\u5300\u5206\u914d\u5462\uff1f    \u8fd9\u91cc\u7684\u8ba1\u7b97\u8d44\u6e90\u53ef\u4ee5\u89c6\u4e3a\u5361\u7684id\u53f7\uff0c\u91c7\u7528\u4f18\u5148\u961f\u5217\u7684\u5f62\u5f0f\uff0c\u5148\u4ece\u4f18\u5148\u961f\u5217\u4e2d\u53d6\u51fa\uff0c\u518d\u5c06\u9700\u8981\u5224\u65ad\u7684\u503c\u4f18\u5148\u7ea7\u964d\u4f4e\u518d\u653e\u56de\u961f\u5217\u4e2d\u7528\u4e8e\u4e0b\u6b21\u8c03\u7528</li> <li>\u5982\u4f55\u4fdd\u8bc1\u5bf9\u8d44\u6e90\u7684\u4e92\u65a5\u8bbf\u95ee\u5462\uff1f    \u53ef\u4ee5\u5c06mutex\u521b\u5efa\u5728\u5171\u4eab\u5185\u5b58\u4e2d\uff0c\u751f\u547d\u5468\u671f\u8ddf\u5171\u4eab\u5185\u5b58\u4e00\u6837\uff0c\u521b\u5efa\u5171\u4eab\u5185\u5b58\u7684\u65f6\u5019\u521b\u5efamutex</li> <li>\u5982\u4f55\u5bf9\u5171\u4eab\u5185\u5b58\u8fdb\u884c\u521d\u59cb\u5316\uff1f    \u5982\u679c\u5171\u4eab\u5185\u5b58\u5df2\u7ecf\u5b58\u5728\u5c31\u4e0d\u9700\u8981\u521d\u59cb\u5316\uff0c\u4e0d\u5b58\u5728\u9700\u8981\u521b\u5efa\u7684\u65f6\u5019\u521d\u59cb\u5316\u6765\u4fdd\u8bc1\u4ec5\u521d\u59cb\u5316\u4e00\u6b21\u3002</li> <li>\u5982\u4f55\u9002\u914d\u591a\u79cd\u6570\u636e\uff1f    \u91c7\u7528STL\u6a21\u677f\u7f16\u7a0b\u601d\u60f3\uff0c\u521b\u5efa\u4e00\u4e2a\u4f18\u5148\u961f\u5217\u6a21\u677f\u7c7b\uff0c\u5c06\u6570\u636e\u7c7b\u578b\u548c\u6570\u636e\u7c7b\u578b\u6bd4\u8f83\u51fd\u6570\u505a\u6210\u6a21\u677f\u4e2d\u7684typename\u7528\u4e8e\u9002\u914d\u81ea\u5b9a\u4e49\u6570\u636e</li> <li>\u5982\u4f55\u5bf9python\u7528\u6237\u5f00\u653e\u63a5\u53e3\uff1f    \u91c7\u7528pybind11\u5c01\u88c5\u4e00\u4e2a\u5e26lock\u7684\u5171\u4eab\u5185\u5b58\u4f18\u5148\u961f\u5217\u7c7b\uff0c\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u5c06c++\u7684\u4e00\u4e9b\u7684\u63a5\u53e3\u66b4\u9732\u7ed9python</li> </ol> <p>\u7c7b\u4e4b\u95f4\u5173\u7cfb</p> <pre><code>MutualSharedMemory: \u7528\u4e8e\u5bf9\u5e26\u6709\u52a0\u9501\u529f\u80fd\u7684\u5171\u4eab\u5185\u5b58\u7684\u7ba1\u7406\uff08\u4e5f\u53ef\u4ee5\u7ee7\u7eed\u62bd\u8c61\u4e00\u4e2a\u4ec5\u9488\u5bf9\u5171\u4eab\u5185\u5b58\u7684\u7ba1\u7406\u7c7b\uff0c\u8fd9\u91cc\u7b80\u5316\uff09\nMutualShmemWithPriorityQueue: \u7ee7\u627fMutualSharedMemory\uff0c\u5728\u4e0a\u8ff0\u529f\u80fd\u57fa\u7840\u4e0a\u5728\u5171\u4eab\u5185\u5b58\u5185\u90e8\u7ef4\u62a4\u4e00\u4e2a\u4f18\u5148\u961f\u5217\nMutualShmemPriorityIndexedQueue: \u7ee7\u627fMutualShmemWithPriorityQueue\uff0c\u53ef\u4ee5\u770b\u505aMutualShmemWithPriorityQueue\u7684\u4e00\u79cd\u6a21\u677f\u7279\u5316\u4e0e\u6269\u5c55\uff0c\u7d22\u5f15\u5806\u7ba1\u7406\u7c7b\uff0c\u4e5f\u662fpybind11\u4e2d\u7684\u9002\u914d\u7c7b\u578b\uff0c\u5176\u5927\u90e8\u5206api\u90fd\u5bf9pybind11\u66b4\u9732\u3002\n</code></pre> <p>\u4ee3\u7801\u8fd9\u91cc\u5c31\u4e0d\u8d34\u51fa\u4e86\uff0c\u6ca1\u6709\u57fa\u7840\u77e5\u8bc6\u7684\u8bfb\u8005\u53ef\u4ee5\u770b\u4e00\u4e0blinux\u4e2d\u5171\u4eab\u5185\u5b58\u7684\u64cd\u4f5c\uff0c\u7136\u540e\u518d\u53bb\u67e5\u770b\u6e90\u4ee3\u7801\u3002</p> <p>\u6e90\u7801\u5730\u5740\uff1a</p> <p>https://github.com/thb1314/mutual_share_memory_with_priority_queue</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#_5","title":"\u4e94 \u603b\u7ed3","text":"<p>2023-01-08\u56de\u5230\u897f\u5b89\uff0c\u6b64\u7bc7\u6587\u7ae0\u5373\u662f\u6211\u8def\u4e0a\u7684\u788e\u788e\u5ff5\uff0c\u4e5f\u662f\u51fa\u5dee\u8fd9\u6bb5\u65f6\u95f4\u5bf9\u8be5\u95ee\u9898\u7684\u601d\u8003\u7684\u4e00\u4e2a\u603b\u7ed3\u3002\u4e00\u5468\u8fc7\u53bb\uff0c\u672c\u6587\u7684\u76f8\u5173\u4ee3\u7801\u548c\u6587\u7ae0\u7ec8\u4e8e\u5199\u5b8c\u4e86\uff0c\u4e5f\u7b97\u662f\u5bf9\u81ea\u5df1\u6709\u6240\u4ea4\u4ee3\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/20230114%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/#_6","title":"\u516d \u53c2\u8003\u6587\u732e","text":"<ol> <li>https://blog.csdn.net/woyimibayi/article/details/80096275</li> </ol>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/","title":"\u57fa\u4e8emmdet\u7684maskrcnn\u5728TensorRT\u4e0a\u7684\u7aef\u5230\u7aef\u90e8\u7f72\u4e0e\u7cbe\u5ea6\u5bf9\u9f50","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#_1","title":"\u96f6. \u524d\u8a00","text":"<p>\u4e00\u76f4\u60f3\u5bf9\u53bb\u5e74\u505a\u7684<code>FasterRCNN+ROIAlign+FPN</code>\u5728TensorRT\u4e0a\u7684\u90e8\u7f72\u505a\u4e2a\u5347\u7ea7\uff0c\u4e4b\u524d\u7684\u7248\u672c\u5305\u542b\u5982\u4e0b\u7f3a\u70b9\uff1a 1. \u8bad\u7ec3\u4ee3\u7801\u9700\u8981\u81ea\u5df1\u7f16\u5199 2. \u4ec5\u652f\u6301batch size = 1\u7684\u63a8\u7406 3. \u6a21\u578b\u5c06onnx\u5207\u6210\u4e24\u90e8\u5206\u6765\u5b9e\u73b0\uff08RPN+ROIHead\u4e24\u90e8\u5206\uff09\uff0c\u4e2d\u95f4\u91c7\u7528\u4e86\u90e8\u5206cuda\u5b9e\u73b0ROIAlign\u548cROIHead\u7684NMS\uff0c\u6ca1\u6709\u505a\u5230\u7aef\u5230\u7aef\u7684\u90e8\u7f72 4. \u7528\u4e8enms\u91c7\u7528TensorRTPro\u4e2d\u7684nms\uff0cTensorRT\u63a8\u7406\u7ed3\u679c\u6ca1\u6709\u4e0ePytorch\u5bf9\u9f50 5. \u6ca1\u6709FP16\u652f\u6301</p> <p>\u9488\u5bf9\u5982\u4e0a\u7f3a\u70b9\uff0c\u7b14\u8005\u51b3\u5b9a\u57fa\u4e8emmdet\u6765\u7ed9\u8bfb\u8005\u5c55\u793a\u5982\u4f55\u4e00\u6b65\u6b65\u5c06\u4e0a\u9762\u7684\u7f3a\u70b9\u7ed9\u89e3\u51b3\u6389\u3002\u9996\u5148\uff0c\u91c7\u7528mmdet\u540e\u8bad\u7ec3\u4ee3\u7801\u5c31\u5b8c\u5168\u4ea4\u7ed9\u4e86\u8be5\u6846\u67b6\u3002\u5176\u6b21mmcv\u4e2d\u5305\u542b\u4e30\u5bcc\u7684TensorRT\u63d2\u4ef6\uff0c\u8fd9\u6837\u53ef\u4ee5\u89e3\u51b3\u7cbe\u5ea6\u5bf9\u9f50\u7684\u95ee\u9898\u548c\u7aef\u5230\u7aef\u90e8\u7f72\u7684\u95ee\u9898\u3002\u518d\u8005\uff0c\u52a8\u6001batch\u7684\u652f\u6301\u95ee\u9898\u4e5f\u5df2\u7ecf\u901a\u8fc7mmdet\u4e2d\u7684\u90e8\u7f72\u7ecf\u9a8c\u5f97\u5230\u89e3\u51b3\u3002\u6700\u540e\uff0cFP16\u7684\u652f\u6301\u7b14\u8005\u8017\u8d39\u4e86\u4e00\u4e9b\u65f6\u95f4\u6765\u5b9a\u4f4d\u8bef\u5dee\u5c42\uff0c\u6210\u529f\u89e3\u51b3\u4e86FP16\u8f93\u51fa\u4e2d\u542b\u6709<code>nan</code>\u7684\u95ee\u9898\u3002</p> <p>\u672c\u6587\u6240\u6709\u6e90\u7801\u90fd\u5728\uff1a https://github.com/thb1314/maskrcnn-tensorrt</p> <p>\u540c\u65f6\uff0c\u672c\u6587\u5bf9\u5e94\u7684\u89c6\u9891\u6559\u7a0b\u4e5f\u653e\u8fdb\u4e86B\u7ad9\uff0c\u70b9\u6b64\u94fe\u63a5\u8fdb\u884c\u89c2\u770b</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#mmdetmaskrcnn","title":"\u4e00. mmdet\u4e2d\u7684MaskRCNN\u6a21\u578b\u7ed3\u6784","text":"<p>\u4e3a\u4ec0\u4e48\u4f1a\u6709\u8fd9\u4e00\u7ae0\u5462\uff1f\u663e\u7136\u662f\u60f3\u5f3a\u8c03\u4e0bmmdet\u4e2d\u7684MaskRCNN\u6a21\u578b\u7ed3\u6784\u4e0e\u8bba\u6587\u4e2dMaskRCNN\u63cf\u8ff0\u7684\u4e0d\u4e00\u6837\u3002</p> <p>MaskRCNN\u5e38\u89c4\u7ed3\u6784\u56fe\u5982\u4e0b\u56fe\u6240\u793a\uff1a  </p> <p>\u5176\u7ec4\u6210\u90e8\u5206\u4e3a <code>FasterRCNN + FPN + ROIAlign + FCN</code>\u3002\u5148\u8bf4\u4e00\u4e0b\u4e0a\u56fe\u4e2d\u4e0d\u4e25\u8c28\u7684\u70b9\uff0cRPN\u90e8\u5206\u8f93\u51fa\u4e0d\u5e94\u8be5\u662fsoftmax\uff08\u5f53\u524dsoftmax\u4e5f\u53ef\u4ee5\u505a\u4e8c\u5206\u7c7b\uff09\uff0csigmoid\u66f4\u4e3a\u9002\u5408\uff0cRPN\u7684\u4f5c\u7528\u5c31\u662f\u5224\u65ad\u5f53\u524d\u9884\u6d4b\u662f\u5426\u662f\u7269\u4f53\u3002RPN\u4ea7\u751f\u7684<code>proposals</code>\u9001\u5165<code>RoIAlign</code>\u540e\u8f93\u51fa\u56fa\u5b9a\u5927\u5c0f\u7684feature map\uff0c\u8f93\u5165\u7ed9\u540e\u7eed\u7684<code>RoIHead</code>\u3002</p> <p>\u63a5\u4e0b\u6765\u5c31\u662f\u91cd\u70b9\u4e86\uff0c\u5e38\u89c4\u7684MaskRCNN\u4e2d\u7684<code>RoIHead</code>\u4e2d\u5206\u5272map\u7684\u9884\u6d4b\u548c\u6846\u7684\u9884\u6d4b\u662f\u5e76\u884c\u8fdb\u884c\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u8fd9\u4e24\u4e2a\u662f\u4e24\u4e2a\u5e76\u884c\u7684\u5206\u652f(\u8fd9\u4e24\u4e2a\u5206\u652f\u5206\u522b\u4e3aFCN+BoxHead)\u3002 \u4f46\u662f\uff0c\u5728mmdet\u7684\u5b9e\u73b0\u4e2d\uff0c\u5bf9\u6846\u7684\u9884\u6d4b\u8fc7\u7a0b\u548c\u5bf9\u5206\u5272map\u7684\u9884\u6d4b\u8fc7\u7a0b\u662f\u4e32\u8054\u5173\u7cfb\uff0c\u4e5f\u5c31\u662f<code>RoIAlign</code>\u63d0\u53d6\u7684RPN\u751f\u6210\u7684\u7c97\u7cd9\u6846\u7684\u4fe1\u606f\u5bf9\u5e94\u7684<code>feature map</code>\u751f\u6210\u4fee\u6b63\u7684\u66f4\u4e3a\u7cbe\u51c6\u7684\u6846\u9884\u6d4b\u548c\u7ec6\u7c92\u5ea6\u7684\u5206\u7c7b\u9884\u6d4b\uff0c\u7136\u540e\u518d\u5c06\u8be5\u4fee\u6b63\u7684\u6846\u9884\u6d4b\u548cFPN\u8f93\u51fa\u7684\u7279\u5f81\u9001\u5165<code>RoIAlign</code>\uff08\u6ce8\u610f\u8fd9\u662f\u7b2c\u4e8c\u4e2a\u54e6\uff0c\u524d\u9762\u7684\u7528\u4e8e\u751f\u6210\u6846\u4e86\uff09\u751f\u6210<code>feature map</code>\uff0c\u6700\u540e\u5229\u7528\u4e0a\u8ff0\u7684<code>feature map</code>\u9001\u5165FCN\u5206\u5272mask\u9884\u6d4b\u3002</p> <p>\u8fd9\u5728mmdet\u4e2d<code>StandardRoIHead</code>\u4ee3\u7801\u4e2d\u4e5f\u6709\u4f53\u73b0\uff08\u8bfb\u8005\u53ef\u4ee5\u641c\u7d22<code>class StandardRoIHead</code>\u6765\u89c2\u5bdf\uff09\uff0c\u4e0b\u9762\u7ed9\u51fa\u5173\u952e\u4ee3\u7801\uff1a</p> <pre><code>def onnx_export(self, x, proposals, img_metas, rescale=False):\n    \"\"\"Test without augmentation.\"\"\"\n    assert self.with_bbox, 'Bbox head must be implemented.'\n    det_bboxes, det_labels = self.bbox_onnx_export(\n        x, img_metas, proposals, self.test_cfg, rescale=rescale)\n\n    if not self.with_mask:\n        return det_bboxes, det_labels\n    else:\n        segm_results = self.mask_onnx_export(\n            x, img_metas, det_bboxes, det_labels, rescale=rescale)\n        return det_bboxes, det_labels, segm_results\n</code></pre> <p>\u5982\u4e0a\u9762\u51fd\u6570\u6240\u793a\uff0c<code>x</code>\u8868\u793aFPN\u8f93\u51fa\u7684\u7279\u5f81\uff0c<code>onnx_export</code>\u51fd\u6570\u4e2d\u7684\u6d41\u7a0b\u5c31\u662f\u5148\u68c0\u6d4b\u51fa<code>det_bboxes</code>\u548c<code>det_labels</code>\uff0c\u7136\u540e\u518d\u68c0\u6d4b\u51fa<code>segm_results</code>\u3002\u5728<code>mask_onnx_export</code>\u4e2d\u4f1a\u8c03\u7528<code>_mask_forward</code>, \u53ef\u4ee5\u770b\u5230\u5982\u4e0b\u64cd\u4f5c\uff0c\u6b64\u5904\u53ca\u8bc1\u660e\u4e86\u4e0a\u9762\u8bf4\u7684\u4e32\u8054\u5173\u7cfb\uff0c<code>mask_roi_extractor</code>\u5c31\u662f<code>RoIAlign</code>\u3002</p> <pre><code>def _mask_forward(self, x, rois=None, pos_inds=None, bbox_feats=None):\n    \"\"\"Mask head forward function used in both training and testing.\"\"\"\n    assert ((rois is not None) ^\n            (pos_inds is not None and bbox_feats is not None))\n    if rois is not None:\n        mask_feats = self.mask_roi_extractor(\n            x[:self.mask_roi_extractor.num_inputs], rois)\n        if self.with_shared_head:\n            mask_feats = self.shared_head(mask_feats)\n    else:\n        assert bbox_feats is not None\n        mask_feats = bbox_feats[pos_inds]\n\n    mask_pred = self.mask_head(mask_feats)\n    mask_results = dict(mask_pred=mask_pred, mask_feats=mask_feats)\n    return mask_results\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#_2","title":"\u4e8c. \u73af\u5883\u5b89\u88c5","text":"<p>\u672c\u6587\u5b9e\u9a8c\u7684\u786c\u4ef6\u548c\u64cd\u4f5c\u7cfb\u7edf\u73af\u5883\u5982\u4e0b\uff1a</p> <ul> <li>NVIDIA GPU 2080Ti</li> <li>Ubuntu 22.04.1 LTS</li> <li>NVIDIA GPU Driver Version: 515.65.01</li> </ul>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#21-tensorrt","title":"2.1 TensorRT\u5b89\u88c5","text":"<p>\u7b14\u8005\u91c7\u7528\u7684TensorRT\u7248\u672c\u4e3a<code>8.4.1.5</code>\uff0ccuda\u7248\u672c\u4e3a<code>10.2</code>\uff0ccudnn\u7248\u672c\u4e3a<code>8.5.0</code>\u3002cuda\u548ccudnn\u7684\u5b89\u88c5\u8fd8\u8bf7\u81ea\u884c\u767e\u5ea6\uff0c\u4e0d\u5728\u672c\u6b21\u6559\u7a0b\u7684\u5185\u5bb9\u8303\u56f4\u4ee5\u5185\u3002\u539f\u5219\u4e0a\uff0c\u8bfb\u8005\u7684TensorRT\u7248\u672c\u53ea\u9700\u8981\u8ddf\u6211\u4fdd\u6301\u4e00\u81f4\u5373\u53ef\uff0ccuda\u548ccudnn\u7684\u7248\u672c\u7684\u53ef\u4ee5\u653e\u5bbd\u9650\u5236\u3002</p> <p>TensorRT\u7684C++\u7248\u672c\u5b89\u88c5\u540e\uff0c\u8fd8\u8bf7\u8bfb\u8005\u5b89\u88c5python\u7684\u5305\uff0cwhl\u5c31\u5728<code>xxx/TensorRT-8.4.1.5/python</code>\u4e0b\u9762\u3002</p> <p>\u6b64\u5916\uff0c\u8fd8\u9700\u8981\u5b89\u88c5pycuda\uff0c\u8bfb\u8005\u65b0\u5efa\u597dconda\u6216\u8005virtualenv\u7684\u865a\u62df\u73af\u5883\u540e\u91c7\u7528<code>pip install pycuda==2022.1</code>\u5b89\u88c5\u5373\u53ef\uff08cuda10.2\u4eb2\u6d4b\u53ef\u7528\uff09</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#22","title":"2.2 \u7f16\u8bd1\u5de5\u5177\u7684\u964d\u7ea7","text":"<p>\u7531\u4e8ecuda10.2\u5bf9gcc/g++\u7248\u672c\u8981\u6c42\u4e3a5.0-8.0\u7248\u672c\uff0c\u6240\u4ee5\u8fd8\u8bf7\u8bfb\u8005\u81ea\u884c\u5b89\u88c5\u672c\u7248\u672c\u7684\u5de5\u5177\uff0c\u5982\u679c\u89c9\u5f97\u81ea\u5df1\u7684linux\u7cfb\u7edf\u5e93\u4e0d\u662f\u5f88\u65b9\u4fbf\u53ef\u4ee5\u91c7\u7528docker\u7684\u65b9\u5f0f\u89e3\u51b3\u3002</p> <p>\u5982\u679c\u8bfb\u8005cuda\u7684\u7248\u672c\u4e0d\u662f10.2\uff0c\u8bf7\u81ea\u884c\u89e3\u51b3gcc/g++\u7248\u672c\u9650\u5236\u95ee\u9898\uff0c\u540e\u9762\u80fd\u4fdd\u8bc1maskrcnn\u6240\u9700\u8981\u7684TensorRT\u76f8\u5173\u63d2\u4ef6\u5373\u53ef\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#23-mmdet","title":"2.3 mmdet\u7684\u5b89\u88c5","text":"<p>\u65b0\u5efa\u865a\u62df\u73af\u5883</p> <pre><code>conda create -n mmdet_test python=3.7\nconda activate mmdet_test\n</code></pre> <p>\u5b89\u88c5pytorch\uff0c\u6309\u7167\u81ea\u5df1\u5b9e\u9645\u60c5\u51b5\u6765\u5b89\u88c5\uff0c\u4e0d\u63a8\u8350\u4f7f\u7528conda\u5b89\u88c5<code>cudatookit</code>\uff0c\u56e0\u4e3a\u4f1a\u5b58\u5728\u81ea\u8eabcuda cudnn\u5e93\u4e0econda\u4e2d\u7684\u5e93\u7248\u672c\u51b2\u7a81\u7684\u95ee\u9898\uff0c\u53ea\u7528torch\u95ee\u9898\u4e0d\u5927\uff0c\u4f46\u662f\u5982\u679c\u662f\u4f7f\u7528TensorRT\u53ef\u80fd\u4f1a\u51fa\u95ee\u9898\u3002</p> <pre><code>pip install typing_extensions==4.5.0\n</code></pre> <pre><code># CUDA 10.2\npip install torch==1.12.1+cu102 torchvision==0.13.1+cu102 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu102\n</code></pre> <p>\u5b89\u88c5onnxruntime\u7684lib\u5e93</p> <pre><code># \u5207\u6362\u5230\u4ee3\u7801\u76ee\u5f55\nwget https://github.com/microsoft/onnxruntime/releases/download/v1.12.1/onnxruntime-linux-x64-1.12.1.tgz\ntar -zxvf onnxruntime-linux-x64-1.12.1.tgz\ncd onnxruntime-linux-x64-1.12.1\nexport ONNXRUNTIME_DIR=$(pwd)\nexport LD_LIBRARY_PATH=$ONNXRUNTIME_DIR/lib:$LD_LIBRARY_PATH\n</code></pre> <pre><code>pip install onnx==1.11.0\npip install onnxruntime==1.12.1\npip install onnxsim==0.4.8\n</code></pre> <p>mmcv\u548cmmdetection\u5b89\u88c5</p> <pre><code>pip install mmengine==0.5.0\npip install openmim==0.3.5\npip install chardet==5.1.0\n# \u5b89\u88c5mmcv\ngit clone -b v1.7.1 --single-branch https://github.com/open-mmlab/mmcv.git mmcv\ncd mmcv\n# \u7f16\u8bd1\u5b89\u88c5mmcv\u76f8\u5173onnxruntime\u7b97\u5b50\nMMCV_WITH_OPS=1 MMCV_WITH_ORT=1 python setup.py develop\ncd ..\ngit clone -b 'v2.27.0' --single-branch https://github.com/open-mmlab/mmdetection.git mmdetection\ncd mmdetection\npip install -v -e .\n# \u5b89\u88c5 protobuf\npip install protobuf==3.20.0\n</code></pre> <p>\u4fee\u6539mmdet\u9002\u914dmaskrcnn\u7684onnx\u7684\u5bfc\u51fa\uff0c\u5efa\u8bae\u8fd9\u4e00\u6b65\u5148\u4e0d\u8981\u6267\u884c\uff0c\u5982\u679c\u662f\u4e3a\u4e86\u7acb\u5373\u4f7f\u7528\u770b\u6548\u679c\u7684\u8bfb\u8005\u53ef\u4ee5\u8fd9\u4e48\u505a\u3002\u540e\u9762\u672c\u6587\u4f1a\u4e00\u6b65\u6b65\u7684\u5c55\u793a\u539f\u7248\u7684mmdet\u4e2d\u7684MaskRCNN\u6709\u4ec0\u4e48\u95ee\u9898\uff0c\u5e76\u544a\u77e5\u4f5c\u8005\u662f\u600e\u4e48\u4e00\u6b65\u6b65\u89e3\u51b3\u5b83\u7684\u3002</p> <pre><code>cp patch/mmdet/* mmdetection/mmdet/ -rf\n</code></pre> <p>Note\uff1a \u6bcf\u6b21\u5f00\u673a\u6216\u8005\u6253\u5f00\u91cd\u65b0\u6253\u5f00\u547d\u4ee4\u884c\u65f6\uff0c\u5728shell\u73af\u5883\u4e2d\u90fd\u9700\u8981\u91cd\u65b0\u5c06onnxruntime lib\u76ee\u5f55\u52a0\u5165\u5230<code>LB_LIBRARY_PATH</code>\u4e2d\u3002\u8bfb\u8005\u4e5f\u53ef\u4ee5\u5728~/.bashrc\u5bf9<code>LB_LIBRARY_PATH</code>\u505a\u6c38\u4e45\u66f4\u6539\uff0c\u539f\u7406\u90fd\u662f\u4e00\u6837\u7684\u3002 \u8fd9\u91cc\u7ed9\u51fa\u6dfb\u52a0\u547d\u4ee4\uff1a</p> <pre><code>cd onnxruntime-linux-x64-1.12.1\nexport ONNXRUNTIME_DIR=$(pwd)\nexport LD_LIBRARY_PATH=$ONNXRUNTIME_DIR/lib:$LD_LIBRARY_PATH\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#pytorch-api","title":"\u4e09. \u4e0b\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u5e76\u91c7\u7528Pytorch API\u63a8\u7406","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#31-min","title":"3.1 \u91c7\u7528min\u4e0b\u8f7d\u914d\u7f6e\u6587\u4ef6\u548c\u9884\u8bad\u7ec3\u6a21\u578b","text":"<p>\u6211\u4eec\u90fd\u77e5\u9053\uff0cmmdet\u4e2d\u6a21\u578b\u7684\u7ed3\u6784\u548c\u8bad\u7ec3\u548c\u63a8\u7406\u65b9\u5f0f\u7684\u5b9a\u4e49\u91c7\u7528<code>xxx.py</code>\u6765\u914d\u7f6e\uff0c\u91c7\u7528\u5982\u4e0b\u6307\u4ee4\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5bf9\u5e94\u7684config\u914d\u7f6e\u6587\u4ef6</p> <pre><code>cd scripts\nmkdir -p models/mask-rcnn\nmim download mmdet --config mask_rcnn_r50_fpn_2x_coco --dest models/mask-rcnn\ncd models/mask-rcnn\nmkdir config\nmv mask_rcnn_r50_fpn_2x_coco.py ./config\nmkdir pretrained_model\nmv *.pth pretrained_model\ncd ../../../\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#32-pytorch-api","title":"3.2 \u91c7\u7528Pytorch API\u8fdb\u884c\u63a8\u7406\u5e76\u8fdb\u884c\u53ef\u89c6\u5316","text":"<p>mmdet\u4e2d\u7684\u6a21\u578b\u90fd\u6709\u53ef\u89c6\u5316\u63a8\u7406\u7ed3\u679c\u7684\u529f\u80fd\uff0c<code>model.show_result</code>\u7b80\u5355\u4e00\u53e5api\u53ef\u5c06\u63a8\u7406\u7ed3\u679c\u8fdb\u884c\u53ef\u89c6\u5316\u3002 \u9996\u5148\u8c03\u7528<code>init_detector</code>\u6784\u5efa\u6a21\u578b\uff0c\u5e76\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u8f7d\uff0c\u7136\u540e\u8c03\u7528<code>inference_detector</code>\u5c06\u56fe\u7247\u9001\u5165\u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff0c\u6700\u540e\u8c03\u7528<code>model.show_result</code>\u8fdb\u884c\u53ef\u89c6\u5316\u3002</p> <p>\u4ee3\u7801\u5982\u4e0b\uff08\u5bf9\u5e94\u8def\u5f84<code>scripts/codes/001infer_maskrcnn_mmdet_api.py</code>\uff09\uff1a</p> <pre><code>from mmdet.apis import init_detector, inference_detector\nimport os\nimport glob\nimport mmdet\n\n\ndirpath = os.path.dirname\npath_join = os.path.join\nBASE_DIR = path_join(dirpath(dirpath(os.path.realpath(__file__))), 'models', 'mask-rcnn')\nMMDET_DIR = dirpath(dirpath(mmdet.__file__))\nprint('BASE_DIR', BASE_DIR)\nprint('MMDET_DIR', MMDET_DIR)\n\nconfig_file = path_join(BASE_DIR, 'config', 'mask_rcnn_r50_fpn_2x_coco.py')\ncheckpoint_file = path_join(BASE_DIR, 'pretrained_model', 'mask_rcnn_r50_fpn_2x_coco_*.pth')\ncheckpoint_file = glob.glob(checkpoint_file)[0]\n\nmodel = init_detector(config_file, checkpoint_file, device='cpu')\njpg_image_path = path_join(MMDET_DIR,  'demo', 'demo.jpg')\ndet_result = inference_detector(model, jpg_image_path)\n\nbasename_woext, ext = os.path.splitext(os.path.basename(jpg_image_path))\nresult_pred_path = path_join('../results', basename_woext + '_result' + ext)\nos.makedirs(dirpath(result_pred_path), exist_ok=True)\n\nmodel.show_result(jpg_image_path, det_result, out_file=result_pred_path)\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#maskrcnnonnxonnxruntimeonnx","title":"\u56db. \u5bfc\u51famaskrcnn\u7684onnx\u5e76\u91c7\u7528onnxruntime\u6267\u884connx","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#41-onnx","title":"4.1 \u521d\u6b65\u5bfc\u51faonnx","text":"<p>\u4f5c\u8005\u53c2\u7167<code>mmdetection/tools/deployment/pytorch2onnx.py</code>\u6587\u4ef6\uff0c\u4fee\u6539\u5176\u4e2d\u7684<code>pytorch2onnx</code>\u51fd\u6570\uff0c\u76f4\u63a5\u91c7\u7528\u4ee3\u7801\u65b9\u5f0f\u6784\u5efa\u5bfc\u51fa\u529f\u80fd\uff0c\u5173\u952e\u4ee3\u7801\u5982\u4e0b\uff08\u5b8c\u6574\u4ee3\u7801\u8def\u5f84\u5728<code>scripts/codes/002export_onnx.py</code>\uff09\uff1a</p> <pre><code>import os\nimport glob\nimport mmdet\n\n\ndirpath = os.path.dirname\npath_join = os.path.join\nBASE_DIR = path_join(dirpath(dirpath(os.path.realpath(__file__))), 'models', 'mask-rcnn')\nMMDET_DIR = dirpath(dirpath(mmdet.__file__))\nprint('BASE_DIR', BASE_DIR)\nprint('MMDET_DIR', MMDET_DIR)\n\nconfig_file = path_join(BASE_DIR, 'config', 'mask_rcnn_r50_fpn_2x_coco.py')\ncheckpoint_file = path_join(BASE_DIR, 'pretrained_model', 'mask_rcnn_r50_fpn_2x_coco_*.pth')\ncheckpoint_file = glob.glob(checkpoint_file)[0]\n\nopset_version = 11\ntry:\n    from mmcv.onnx.symbolic import register_extra_symbolics\nexcept ModuleNotFoundError:\n    raise NotImplementedError('please update mmcv to version&gt;=v1.0.4')\nregister_extra_symbolics(opset_version)\n\ncfg = Config.fromfile(config_file)\nimg_scale = [800, 1216]\ninput_shape = (1, 3, img_scale[0], img_scale[1])\n\n\n# build the model and load checkpoint\nmodel = build_model_from_cfg(config_file, checkpoint_file)\njpg_image_path = path_join(MMDET_DIR,  'demo', 'demo.jpg')\nnormalize_cfg = parse_normalize_cfg(cfg.test_pipeline)\nbasename_woext, ext = os.path.splitext(os.path.basename(config_file))\n\n# convert model to onnx file\npytorch2onnx(\n    model,\n    jpg_image_path,\n    input_shape,\n    normalize_cfg,\n    opset_version=opset_version,\n    show=True,\n    output_file=basename_woext+'.onnx',\n    verify=True,\n    test_img=None,\n    do_simplify=True,\n    dynamic_export=False,\n    skip_postprocess=False,\n    force_write=True)\n</code></pre> <p>\u6267\u884c<code>scripts/codes/002export_onnx.py</code>\u540e\uff0c\u9996\u5148\u4f1a\u9047\u5230</p> <pre><code>RuntimeError: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: numpy.ndarray\n</code></pre> <p>\u539f\u56e0\uff1a \u4ee3\u7801\u4e2d<code>one_meta</code>\u5b57\u5178\u4e2d\u7684<code>scale_factor</code>\u662f\u4e00\u4e2anp.ndarray\uff0c\u8fd9\u4e2a\u5728torch.jit\u65f6\u88ab\u8ffd\u8e2a\u5230\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5bf9<code>preprocess_example_input</code>\u51fd\u6570\u6700\u540e\u7684\u8fd4\u56de\u503c\u52a0\u4ee5\u6539\u9020\u5373\u53ef\u3002</p> <p>\u5bf9<code>mmdetection/mmdet/core/export/pytorch2onnx.py</code>\u6587\u4ef6<code>Line 148</code>\u4fee\u6539\u5982\u4e0b:</p> <pre><code>one_meta = {\n        'img_shape': (H, W, C),\n        'ori_shape': (H, W, C),\n        'pad_shape': (H, W, C),\n        'filename': '&lt;demo&gt;.png',\n        'scale_factor': np.ones(4, dtype=np.float32).tolist(),\n        'flip': False,\n        'show_img': torch.as_tensor(show_img),\n        'flip_direction': None\n    }\n</code></pre> <p>\u5bf9\u4e0a\u9762\u8fdb\u884c\u66f4\u6539\u540e\uff0c<code>mmdet/models/roi_heads/test_mixins.py</code>\u4e2d<code>simple_test_mask</code>\u4f1a\u62a5\u9519\uff0c\u8fd9\u91cc\u9700\u8981\u9002\u914d\u4e00\u4e0b\u3002</p> <pre><code># \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/roi_heads/test_mixins.py mmdetection/mmdet/models/roi_heads/test_mixins.py\n# \u53ef\u4ee5\u770b\u5230\u4ec5\u4ec5\u662f\u5c06`torch.from_numpy`\u6539\u6210\u4e86`torch.as_tensor`\ncp patch/mmdet/models/roi_heads/test_mixins.py mmdetection/mmdet/models/roi_heads/test_mixins.py -rf\n</code></pre> <p>\u7136\u540e\u4f1a\u78b0\u5230mmcv\u4e2d\u7684<code>imread</code>\u51fd\u6570\uff0c\u5728203\u884c\u4e0b\u9762\u6dfb\u52a0\u5982\u4e0b\u903b\u8f91\uff1a</p> <pre><code>elif isinstance(img_or_path, torch.Tensor):\n    return img_or_path.detach().cpu().numpy()\n</code></pre> <p><code>torch</code>\u7684\u5bfc\u5165\u52a0\u5165\u5230<code>mmcv/mmcv/image/io.py</code>\u6587\u4ef6\u524d\u9762</p> <p>\u6700\u7ec8\u6211\u4eec\u7ec8\u4e8e\u5bfc\u51fa\u4e86maskrcnn\u7684onnx\uff0c\u5e76\u4e14\u91c7\u7528onnxruntime\u4e0epytorch\u5206\u522b\u8fdb\u884c\u63a8\u7406\uff0c\u6700\u540e\u5c34\u5c2c\u7684\u53d1\u73b0\u8fd9\u4e24\u8005\u7ed3\u679c\u5e76\u6ca1\u6709\u5bf9\u9f50\uff0c\u8fd9\u662f\u4e3a\u4f55\u5462\uff1f\u4e0b\u4e00\u5c0f\u8282\u7ed9\u8bfb\u8005\u8bf4\u660e\u6211\u4eec\u662f\u5982\u679c\u5b9a\u4f4d\u8fd9\u4e2abug\u7684\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#42-onnxpytorch","title":"4.2 \u89e3\u51b3onnx\u4e0epytorch\u8f93\u51fa\u7ed3\u679c\u4e0d\u4e00\u81f4\u7684\u95ee\u9898","text":"<p>\u5df2\u77e5torch\u548connxruntime\u8fd9\u4e24\u79cd\u6846\u67b6\u76f8\u540c\u6a21\u578b\u9488\u5bf9\u76f8\u540c\u8f93\u5165\u6700\u7ec8\u8f93\u51fa\u4e0d\u4e00\u81f4\uff0c\u6211\u4eec\u9700\u8981\u7684\u662f\u5236\u4f5c\u5b9a\u4f4d\u7cbe\u5ea6\u4e0d\u4e00\u81f4\u7684\u5de5\u5177\u3002\u7b80\u5355\u5206\u6790\u5c31\u662f\u4e2d\u95f4\u7ed3\u679c\u7684\u4e0d\u4e00\u81f4\u5bfc\u81f4\u4e86\u6700\u7ec8\u7ed3\u679c\u7684\u4e0d\u4e00\u81f4\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u53ef\u4ee5\u5f97\u5230\u4e2d\u95f4\u7ed3\u679c\u7684\u5de5\u5177\u3002</p> <p>\u9488\u5bf9Pytorch\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u5176\u5404\u4e2a<code>nn.Module</code>\u7ec4\u4ef6\u4e2d\u7684forward\u51fd\u6570\u91cc\u9762\u63d2\u5165\u5982\u4e0b\u8bed\u53e5\u5c06\u4e2d\u95f4\u7ed3\u679c\u4fdd\u5b58\uff08\u5f53\u7136\u4e5f\u53ef\u4ee5\u5199hook\uff0c\u4e0d\u8fc7\u6ca1\u5fc5\u8981\uff09\uff1a</p> <pre><code>def forward(self, x)\n    x = children_module1(x)\n    torch.save({'x':x}, 'xxx.pkl')\n    # ...\n</code></pre> <p>\u5373\u8c03\u7528<code>torch.save</code>\u6765\u8c03\u7528\u5b9e\u73b0\u5bf9\u4e2d\u95f4\u7ed3\u679c\u7684\u5e8f\u5217\u5316\u4ee5\u53ca\u79bb\u7ebf\u5b58\u50a8\u3002</p> <p>\u9488\u5bf9ONNX\u5b58\u50a8\u683c\u5f0f\uff0c\u9996\u5148\u9700\u8981\u5c06\u9700\u8981\u6355\u83b7\u7684\u7ed3\u70b9\u7684\u540d\u5b57\u627e\u5230\uff0c\u8fd9\u4e9b\u540d\u5b57\u5b58\u5728\u4e8e<code>onnx.model.graph.node</code>\u7684<code>input</code>\u548c<code>output</code>\u5217\u8868\u5f53\u4e2d\uff0c\u4f60\u53ef\u4ee5\u7528<code>onnx</code>\u904d\u5386onnx\u6a21\u578b\uff0c\u7136\u540e\u5f97\u5230\u67d0\u7c7b\u7b97\u5b50\u7684\u8f93\u51fa\uff0c\u5e76\u5c06\u5176\u52a0\u5165\u5230<code>onnx.model.output</code>\u4e2d\u3002\u5177\u4f53\u4ee3\u7801\u5982\u4e0b\uff08\u53c2\u8003<code>patch/mmdet/core/export/model_wrappers.py</code>\uff09\uff1a</p> <pre><code>onnx_model = onnx.load(onnx_file)\nori_output = copy.deepcopy(onnx_model.graph.output)\n# \u8f93\u51fa\u6a21\u578b\u6bcf\u5c42\u7684\u8f93\u51fa\nfor node in onnx_model.graph.node:\n    # \u52a0\u9650\u5236\u6761\u4ef6 \u83b7\u53d6\u6ee1\u8db3\u5982\u4e0b\u6761\u4ef6\u7684node\u7684\u8f93\u51fa\n    if not (node.op_type in ['NonMaxSuppression', 'Concat', 'TopK', 'Sigmoid', 'Mul'] or \\\n        node.name in ['Reshape_1686', 'onnx::Mul_2265'] or node.output[0] in ['onnx::Mul_2265', \\\n        'onnx::Reshape_2348', 'onnx::Gather_2347', 'onnx::Gather_2337']):\n        continue\n\n    for output in node.output:\n        if output not in ori_output:\n            onnx_model.graph.output.extend([onnx.ValueInfoProto(name=output)])\nsess = ort.InferenceSession(onnx_model.SerializeToString(), session_options)\n</code></pre> <p>\u7136\u540e\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u62ff\u5230\u6700\u7ec8\u8f93\u51fa\u7684dict\uff0c\u901a\u8fc7\u89c2\u5bdf\u8f93\u51faonnx\u4e0etorch\u8282\u70b9\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u901a\u8fc7\u4e8c\u5206\u6cd5\u5b9a\u4f4d\u51fa\u54ea\u4e2a\u8f93\u51fa\u4e0d\u4e00\u6837\u3002\u5f53\u7136\u8fd9\u4e2a\u8fc7\u7a0b\u5f88\u8f9b\u82e6\u3002</p> <p>\u8fd8\u6709\u4e00\u4e2a\u5c0f\u6280\u5de7\uff0c\u9664\u4e86\u81ea\u5df1\u63a8\u65adtorch\u4e2dforward\u8fd0\u7b97\u548connx\u7b97\u5b50\u4e4b\u95f4\u5173\u7cfb\u4e4b\u5916\uff0c\u8fd8\u53ef\u4ee5\u91c7\u7528\u5728\u5bfc\u51faonnx\u65f6\uff0c\u5c06<code>verbose</code>\u53c2\u6570\u8bbe\u7f6e\u4e3a<code>True</code>\u7684\u65b9\u5f0f\u6765\u8bb0\u5f55onnx\u7b97\u5b50\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u8fd9\u6837onnx\u7b97\u5b50\u4e2d<code>description</code>\u5c5e\u6027\u4e2d\u5c31\u8bb0\u5f55\u4e86\u6574\u4e2a\u8fc7\u7a0b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u4f5c\u8005\u6b63\u662f\u901a\u8fc7\u5982\u4e0a\u9014\u5f84\uff0c\u4e00\u6b65\u6b65\u5b9a\u4f4d\u5230\u662fRPN\u6a21\u578b\u7684NMS\u8f93\u51fa\u4e0d\u4e00\u81f4\uff0c\u4e3a\u4ec0\u4e48\u4e0d\u4e00\u81f4\u5462\uff1f</p> <p>\u8fd9\u662f\u56e0\u4e3a\u7531\u4e8eFPN\u7684\u5b58\u5728\uff0cRPN\u63a8\u7406\u5728NMS\u9636\u6bb5\u662f\u9700\u8981\u5bf9FPN\u4e2d\u6bcf\u4e2astage\u7684\u8f93\u51fa\u5355\u72ec\u6267\u884cNMS\u540e\u5904\u7406\u7684\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5c31\u7c7b\u4f3c\u4e8e\u628a\u6bcf\u4e2astage\u7684\u8f93\u51fa\u770b\u505a\u4e0d\u540c\u7c7b\u522b\uff0c\u91c7\u7528\u7c7b\u95f4NMS\u505a\u540e\u5904\u7406\u3002</p> <p>\u4f46\u662f\uff0c\u5728\u5bfc\u51faonnx\u7684\u8fc7\u7a0b\u4e2d\uff0cmmdet\u7b80\u5316\u4e86\u8be5\u6b65\u9aa4\uff0c\u5373\u628a\u6240\u6709\u7684\u6846\u90fd\u5f53\u505a\u540c\u4e00\u4e2astage\u8f93\u51fa\u7684\u6765\u770b\u5230\uff0c\u4ece\u800c\u5bfc\u81f4onnxruntime\u4e0etorch\u7684\u4e0d\u4e00\u81f4\u3002\u8ffd\u6eaf\u6e90\u7801\u8fc7\u7a0b\u5982\u4e0b\uff1a</p> <ol> <li>\u9996\u5148\u4ececonfig\u6587\u4ef6\u4e2d\u627e\u5230RPN\u4e2dHead\u90e8\u5206\uff0cHead\u90e8\u5206\u624d\u5305\u542bNMS\uff0c\u6b64\u65f6\u6211\u4eec\u627e\u5230<code>RPNHead</code>\u7c7b</li> <li>\u4f7f\u7528<code>class RPNHead</code>\u5173\u952e\u8bcd\u627e\u5230\uff08\u7b14\u8005\u4f7f\u7528\u7684\u662fVSCode\u7684\u5168\u6587\u641c\u7d22\u529f\u80fd\uff09<code>mmdetection/mmdet/models/dense_heads/rpn_head.py</code>\u6587\u4ef6\uff08\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5728netron\u4e2d\u67e5\u770b\u5bfc\u51fa\u7684onnx\u6a21\u578b\u4e2d\u7684<code>NonMaxSuppression</code>\u7b97\u5b50\u7136\u540e\u627e\u5230\u4f4d\u7f6e<code>mmdetection/mmdet/models/dense_heads/rpn_head.py(264)</code>\uff09\u3002</li> <li>\u5b9a\u4f4d\u5230\u5bfc\u51fa\u7684\u51fd\u6570\u4e3a<code>add_dummy_nms_for_onnx</code></li> <li>\u6b64\u65f6\u4f60\u4f1a\u770b\u5230mmdet\u5b98\u65b9\u7ed9\u7684\u6ce8\u91ca\uff0c\u8fd9\u5c31\u662f\u6839\u56e0\u6240\u5728</li> </ol> <pre><code># Different from the normal forward doing NMS level by level,\n   # we do NMS across all levels when exporting ONNX.\n</code></pre> <p>\u90a3\u4e48\u5982\u4f55\u89e3\u51b3\u5462\uff1f</p> <p>\u5982\u679c\u8bfb\u8005\u9605\u8bfb\u8fc7torchvision\u4e2d<code>batched_nms</code>\u7684\u5b9e\u73b0\uff0c\u4f60\u4e00\u5b9a\u5c31\u4f1a\u77e5\u9053\u9488\u5bf9\u7c7b\u95f4\u548c\u4e0d\u540cbatch\u7684nms\u662f\u600e\u4e48\u8f6c\u6362\u4e3a\u7c7b\u5185\u7684nms\u7684\u3002 \u53c2\u8003\u4ee3\u7801\u94fe\u63a5\uff1ahttps://github.com/pytorch/vision/blob/505cd6957711af790211896d32b40291bea1bc21/torchvision/ops/boxes.py#L39 </p> <p>\u8fd9\u91cc\u5f15\u7528\u4ee3\u7801\u4e2d\u5173\u952e\u7684\u4e00\u6bb5\u6ce8\u91ca\u6765\u8bf4\u660e\u601d\u8def\uff1a</p> <pre><code># strategy: in order to perform NMS independently per class.\n# we add an offset to all the boxes. The offset is dependent\n# only on the class idx, and is large enough so that boxes\n# from different classes do not overlap\n</code></pre> <p>\u540c\u65f6mmcv\u4e2d\u4e5f\u7ed9\u51fa\u76f8\u5e94<code>batch_nms</code>\u7684\u5b9e\u73b0\uff0c\u4f4d\u7f6e\u5728<code>mmcv/mmcv/ops/nms.py</code> Line 264\u3002</p> <p>\u6211\u4eec\u6839\u636e\u5982\u4e0a\u601d\u8def\u901a\u8fc7\u4fee\u6539<code>RPNHead</code>\u4e2d\u7684<code>onnx_export</code>\u51fd\u6570\u4ee5\u53cammdet\u4e2d\u7684<code>add_dummy_nms_for_onnx</code>\u51fd\u6570\uff0c\u4e3a\u5176\u589e\u52a0\u652f\u6301\u7c7b\u95f4nms\u7684\u529f\u80fd\u3002</p> <p>\u9996\u5148\uff0c\u9488\u5bf9\u6bcf\u4e2alevel\u7684box\uff0c\u6211\u4eec\u9700\u8981\u7ed9\u4ed6\u4eec\u4e00\u4e2a\u6807\u8bb0\uff0c\u8868\u793a\u4ed6\u4eec\u5c5e\u4e8e\u54ea\u4e2astage\u8f93\u51fa\u7684\u3002\u4ee3\u7801\u5982\u4e0b</p> <pre><code>ids_list = []\nnms_pre_tensor = torch.tensor(cfg.get('nms_pre', -1), device=cls_scores[0].device, dtype=torch.long)\nfor i in range(num_levels):\n    c, h, w = list(map(int, cls_scores[i].shape[1:4]))\n    cur_lvl_length = torch.as_tensor(c * h * w, dtype=torch.long, device=cls_scores[0].device)\n    topk = get_k_for_topk(nms_pre_tensor, cur_lvl_length)\n    if topk &gt; 0 and topk != int(cur_lvl_length):\n        cur_lvl_length = topk\n    # \u6700\u5173\u952e\u4e00\u6b65\uff0c\u7ed9\u6bcf\u4e2a\u5c42\u7ea7\u6253\u4e0a\u6807\u7b7e\n    ids_list.append(torch.full((1, cur_lvl_length, 1), fill_value = i, dtype=torch.long, device=cls_scores[0].device))\n# [1, num_boxes, 1] \nidxs = torch.cat(ids_list, dim=1)\n</code></pre> <p>\u63a5\u7740\uff0c\u6211\u4eec\u5c06<code>idxs</code>\u4f20\u5165<code>add_dummy_nms_for_onnx</code>\uff0c\u4fee\u6539<code>add_dummy_nms_for_onnx</code>\u53bb\u9002\u914d\u8be5\u7c7b\u4fe1\u606f\u3002 \u9996\u5148\u6211\u4eec\u9700\u8981\u5bf9\u4e4b\u524d\u7684\u65b9\u5f0f\u505a\u517c\u5bb9\uff0c\u5f53idxs\u5b58\u5728\u65f6\u518d\u505a\u5904\u7406</p> <pre><code>boxes_for_nms = boxes\nif idxs is not None:\n    # [b,1,1]\n    max_coordinate, _ = boxes.max(dim=1, keepdim=True)\n    max_coordinate, _ = max_coordinate.max(dim=2, keepdim=True)\n    # [b,N,1]\n    offsets = idxs.to(boxes) * (max_coordinate + torch.tensor(1).to(boxes))\n    boxes_for_nms = boxes + offsets.view(1, num_box, 1)\n</code></pre> <p>\u4ee5\u4e0a\u5c31\u662f\u5173\u952e\u9002\u914d\u4ee3\u7801\uff0c\u903b\u8f91\u5b8c\u5168\u501f\u9274<code>batched_nms</code>\u7684\u5b9e\u73b0\uff0c\u81f3\u4e8e\u4e0d\u540cbatch\u4e4b\u95f4\u7684nms\u903b\u8f91\uff0c\u8fd9\u91cconnx\u7684<code>NonMaxSuppression</code>\u672c\u8eab\u5c31\u652f\u6301\uff0c\u6240\u4ee5\u5c31\u4e0d\u9700\u8981\u518d\u8003\u8651\u3002</p> <p>\u91c7\u7528\u5982\u4e0b\u65b9\u5f0f\u66ff\u6362\u4ee3\u7801\uff0c\u89e3\u51b3\u7cbe\u5ea6\u5bf9\u9f50\u95ee\u9898</p> <pre><code># \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/dense_heads/rpn_head.py mmdetection/mmdet/models/dense_heads/rpn_head.py\ncp patch/mmdet/models/dense_heads/rpn_head.py mmdetection/mmdet/models/dense_heads/rpn_head.py -rf\n\n# \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/core/export/onnx_helper.py mmdetection/mmdet/core/export/onnx_helper.py\ncp patch/mmdet/core/export/onnx_helper.py mmdetection/mmdet/core/export/onnx_helper.py -rf\n</code></pre> <p>\u6267\u884c\u5b8c\u4e0a\u9762\u4ee3\u7801\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230<code>onnxruntime</code>\u548c<code>torch</code>\u7684\u7ed3\u679c\u8fd8\u662f\u4e0d\u4e00\u6837\uff1f\u5565\u60c5\u51b5\u5462\uff1f</p> <p>\u4e0d\u8981\u7070\u5fc3\uff0c\u5b9e\u9645\u4e0a\u4ed4\u7ec6\u9605\u8bfb<code>ONNXRuntimeDetector</code>\u6e90\u7801\u4e4b\u540e\uff0c\u4f60\u4f1a\u53d1\u73b0\u540e\u5904\u7406\u8fd8\u662f\u6709\u4e9b\u4e0d\u4e00\u6837\uff0c\u6bd4\u5982\u6ca1\u6709<code>ONNXRuntimeDetector</code>\u6ca1\u6709\u5bf9nms\u4e2d\u7684\u65e0\u6548\u6846\u8fdb\u884c\u8fc7\u6ee4\uff0c\u8fd9\u4e2a\u65f6\u5019\u9700\u8981\u6211\u4eec\u6539\u6e90\u7801\u52a0\u4e0a\u6b64\u7c7b\u903b\u8f91\uff08\u5728<code>mmdetection/mmdet/core/export/model_wrappers.py</code>\u4e0a\uff09</p> <pre><code>for i in range(batch_size):\n    dets, labels = batch_dets[i], batch_labels[i]\n    det_mask = np.sum(dets, axis=-1) &gt;= 1e-3\n    dets = dets[det_mask]\n    labels = labels[det_mask]\n</code></pre> <p>\u4e0b\u9762\u7ed9\u51fa\u547d\u4ee4</p> <pre><code># \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/core/export/model_wrappers.py mmdetection/mmdet/core/export/model_wrappers.py\ncp patch/mmdet/core/export/model_wrappers.py mmdetection/mmdet/core/export/model_wrappers.py -rf\n</code></pre> <p>\u6700\u540e\u91cd\u65b0\u8fd0\u884c<code>002export_onnx.py</code>\uff0c\u7ed3\u679c\u7ec8\u4e8e\u5b8c\u5168\u4e00\u81f4\uff0c\u6b64\u65f6\u6211\u4eec\u53ef\u4ee5\u957f\u547c\u4e00\u53e3\u6c14\u653e\u677e\u4e00\u4e0b\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#tensorrtmaskrcnn","title":"\u4e94. \u91c7\u7528TensorRT\u63a8\u7406MaskRCNN","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#51","title":"5.1 \u5206\u6790\u7f3a\u5c11\u54ea\u4e9b\u7b97\u5b50\u4ee5\u53ca\u76f8\u5e94\u63d2\u4ef6\u7f16\u8bd1","text":"<p>\u4e0b\u9762\u662f\u4e00\u4efdTensorRT\u5b98\u65b9\u53d1\u5e03\u7684\u652f\u6301\u7684\u7b97\u5b50\u7684\u6e05\u5355\uff1a</p> <p>ONNX-TensorRT Operators\u6587\u6863</p> <p>\u6211\u4eec\u53ef\u4ee5\u770b\u5230<code>ROIAlign</code>\u548c<code>gridmask</code>\u7b97\u5b50\u5728TensorRT\u4e2d\u662f\u4e0d\u652f\u6301\u7684\uff08NonMaxSuppression\u5728TRT8.4\u5df2\u7ecf\u652f\u6301\uff09\uff0c\u90a3\u4e48\u78b0\u5230\u4e0d\u652f\u6301\u7684\u53c8\u8be5\u600e\u4e48\u529e\u5462\uff1f</p> <p>\u5148\u91c7\u7528\u76f4\u63a5\u8f6cengine\u7684\u65b9\u5f0f\u770b\u4e00\u4e0b\u4f1a\u62a5\u4ec0\u4e48\u9519\u8bef\uff1a</p> <pre><code>trtexec --onnx=../results/mask_rcnn_r50_fpn_2x_coco.onnx \\\n        --saveEngine=../results/mask_rcnn_r50_fpn_2x_coco.onnx.engine \\\n        --workspace=10240\n</code></pre> <p>\u7ed3\u679c</p> <pre><code>input: \"rois.3\"\noutput: \"onnx::Mul_2534\"\nname: \"MMCVRoiAlign_1931\"\nop_type: \"MMCVRoiAlign\"\n</code></pre> <p>\u4f1a\u62a5\u4e0a\u8ff0\u7b97\u5b50\u627e\u4e0d\u5230\uff0c\u8fd9\u91cc\u6211\u4eec\u53ef\u4ee5\u5199\u63d2\u4ef6\u652f\u6301\u5b83\uff0c\u5728\u53bb\u5e74\u7684\u65f6\u5019\u8fd9\u91cc\u7684cuda\u90e8\u5206\u6211\u8fd8\u662f\u6284\u7684onnxruntime\u7684GPU\u5b9e\u73b0\uff0c\u5e76\u4e14\u6ca1\u6709\u7528\u5230\u63d2\u4ef6\u5b9e\u73b0\uff0c\u800c\u662f\u91c7\u7528\u7eafcuda\u7684\u65b9\u5f0f\u3002  </p> <p>\u5e78\u8fd0\u7684\u662fMMCV\u9664\u4e86\u7ed9\u6211\u4eec\u63d0\u4f9b\u4e86onnxruntime\u7684\u81ea\u5b9a\u4e49\u7b97\u5b50\u7684\u5b9e\u73b0\uff0c\u4e5f\u7ed9\u6211\u4eec\u63d0\u4f9b\u4e86TensorRT\u4e0d\u652f\u6301\u7b97\u5b50\u7684\u63d2\u4ef6\u5b9e\u73b0\uff0c\u5177\u4f53\u4f4d\u7f6e\u5728<code>mmcv/mmcv/ops/csrc/tensorrt</code> \u3002\u7531\u4e8e\u5176\u63d0\u4f9b\u7684\u63d2\u4ef6\u9002\u914d\u7684\u7248\u672c\u4e3aTRT7.x\u7684\uff0c\u6211\u4eec\u9700\u8981\u7b80\u5355\u4fee\u6539\u9002\u914d\u4e0b\uff0c\u4f5c\u8005\u5df2\u7ecf\u5c06\u662f\u914d\u597d\u7684\u7248\u672c\u653e\u5728\u4e86<code>scripts/relaventTensorRTPlugin</code>\u4e2d\u3002</p> <p>\u8fd9\u91cc\u6211\u4eec\u5148\u7f16\u8bd1\u4e00\u4e0b<code>MMCVRoiAlign</code>\u63d2\u4ef6\uff0c\u770b\u770b\u8fd8\u7f3a\u5c11\u4ec0\u4e48\u3002</p> <p>\u8fd9\u91cc\u8bfb\u8005\u8981\u6ce8\u610f\u66f4\u6539Makefile\u91cc\u9762\u7684<code>SM</code>\uff0c\u8ba9\u5176\u9002\u914d\u81ea\u5df1\u7684GPU\u3002</p> <pre><code>trtexec --onnx=../results/mask_rcnn_r50_fpn_2x_coco.onnx \\\n        --saveEngine=../results/mask_rcnn_r50_fpn_2x_coco.onnx.engine \\\n        --workspace=10240 \\\n        --plugins=\"../relaventTensorRTPlugin/build/MMCVRoiAlign.so\"\n</code></pre> <p>\u62a5\u5982\u4e0b\u9519\u8bef\uff1a</p> <pre><code>input: \"grid\"\noutput: \"onnx::Gather_3387\"\nname: \"grid_sampler_2715\"\nop_type: \"grid_sampler\"\n</code></pre> <p>\u76f8\u4f3c\u539f\u7406\uff0c\u6211\u4eec\u5230<code>grid_sampler</code>\u4e0b\u9762\u53bb\u7f16\u8bd1\u751f\u6210\u5bf9\u5e94\u63d2\u4ef6\uff0c\u7136\u540e\u6267\u884c\uff1a</p> <pre><code>trtexec --onnx=../results/mask_rcnn_r50_fpn_2x_coco.onnx \\\n        --saveEngine=../results/mask_rcnn_r50_fpn_2x_coco.engine \\\n        --workspace=10240 \\\n        --plugins=\"../relaventTensorRTPlugin/build/MMCVRoiAlign.so\" \\\n        --plugins=\"../relaventTensorRTPlugin/build/grid_sampler.so\"\n</code></pre> <p>\u81f3\u6b64\u6211\u4eec\u5c31\u751f\u6210\u4e86\u5bf9\u5e94\u7684trt\u7f16\u8bd1\u540e\u7684<code>engine</code>\u6587\u4ef6\uff0c\u81f3\u4e8e<code>NonMaxSuppression</code>\u548c<code>ScatterND</code>\u662f\u4e3a\u4e86\u9002\u914d\u4f4e\u7248\u672cTensorRT\u8bbe\u7f6e\u7684\uff0c\u91c7\u7528\u4f4e\u7248\u672cTensorRT\u7684\u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u63a2\u7d22\u3002 \u518d\u6b21\u611f\u8c22MMCV\u63d0\u4f9b\u8fd9\u4e48\u65b9\u4fbf\u7684TensorRT\u63d2\u4ef6\u7684\u5b9e\u73b0\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#52-tensorrt-fp32","title":"5.2 TensorRT FP32\u6a21\u578b\u7cbe\u5ea6\u5bf9\u9f50","text":"<p>\u5df2\u77e5onnxruntime\u4e0etorch\u9488\u5bf9\u76f8\u540c\u7684\u8f93\u5165\u53ef\u4ee5\u5f97\u5230\u76f8\u540c\u7684\u8f93\u51fa\uff0c\u90a3\u4e48\u5982\u679c\u9700\u8981\u505a\u5230\u7cbe\u5ea6\u5bf9\u9f50\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5bf9\u9f50onnxruntime\u4e0eTensorRT\u7684\u8f93\u51fa\u5373\u53ef\u3002</p> <p>\u9996\u5148\u6211\u4eec\u5148\u4fdd\u5b58\u4e0bonnxruntime\u7684\u8f93\u51fa\uff0c\u8fd0\u884c<code>scripts/codes/003run_on_onnx.py</code>\u5f97\u5230<code>onnx_output_dict.pkl</code>\u6587\u4ef6\uff0c\u91cc\u9762\u8bb0\u5f55\u4e86\u9488\u5bf9demo jpg\u5f97\u5230\u7684\u8f93\u51fa\uff0c\u53ef\u89c6\u5316\u7ed3\u679c\u5728<code>scripts/results/onnxruntime_result.png</code>\u3002</p> <p>\u7136\u540e\uff0c\u6211\u4eec\u8fd0\u884c<code>004run_on_tensorrt.py</code>\uff08\u6211\u4eec\u7684004\u4e5f\u652f\u6301build engine\uff09\uff0c\u7b49\u597d\u4e45\u7684\u6a21\u578b\u8f6c\u4e3aengine\u7684\u8fc7\u7a0b\u540e\uff0c\u6700\u7ec8\u4f1a\u5f97\u5230\u8f93\u51fa</p> <pre><code>key: labels, diff: 0\nkey: dets, diff: 0.000244140625\nkey: masks, diff: 0.0\n</code></pre> <p>\u8fd9\u4e2a\u65f6\u5019\u6709\u6ca1\u6709\u611f\u5230\u6210\u5c31\u611f\u7206\u68da\uff1f\u6211\u4eec\u514b\u670d\u4e86\u91cd\u91cd\u82e6\u96be\uff0c\u6700\u7ec8\u6210\u529f\u5c06onnx\u8f6c\u6362\u4e3aengine\uff0c\u5e76\u4e14\u5f97\u5230\u4e86\u4e0eonnx\u8fd0\u884c\u76f8\u540c\u7684\u7ed3\u679c\uff01</p> <p>\u7136\u800c\u8fd9\u4e0d\u662f\u7ec8\u70b9\uff0c\u4f18\u5316\u6c38\u65e0\u5c3d\u5934\uff0c\u4e0b\u9762\u6211\u4eec\u770b\u4e00\u4e0b\u52a8\u6001batch\u7684\u652f\u6301\u95ee\u9898\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#batch","title":"\u516d. \u52a8\u6001batch\u7684\u652f\u6301","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#61-batchonnx","title":"6.1 \u5bfc\u51fa\u52a8\u6001batch\u7684onnx","text":"<p>\u9996\u5148\u8981\u60f3\u83b7\u5f97\u652f\u6301\u52a8\u6001batch\u7684trt\u6a21\u578b\uff0c\u6211\u4eec\u9700\u8981\u5bfc\u51fa\u7684onnx\u672c\u8eab\u5c31\u652f\u6301\u52a8\u6001\u7ef4\u5ea6\u3002\u4e0b\u9762\u7ed9\u51fa\u4e4b\u524d\u6587\u7ae0\u4e2d\u53cd\u590d\u5f3a\u8c03\u7684\u5bfc\u51fa\u539f\u5219\uff1a</p> <ol> <li>\u5bf9\u4e8e\u4efb\u4f55\u7528\u5230shape\u3001size\u8fd4\u56de\u503c\u7684\u53c2\u6570\u65f6\uff0c\u4f8b\u5982\uff1a<code>tensor.view(tensor.size(0), -1)</code>\uff0c<code>B,C,H,W = x.shape</code> \u8fd9\u7c7b\u64cd\u4f5c\uff0c\u907f\u514d\u76f4\u63a5\u4f7f\u7528tensor.size\u7684\u8fd4\u56de\u503c\uff0c\u800c\u662f\u52a0\u4e0aint\u8f6c\u6362\uff0c<code>tensor.view(int(tensor.size(0)), -1)</code>, <code>B,C,H,W = map(int, x.shape)</code>\uff0c\u65ad\u5f00\u8ddf\u8e2a\u3002</li> <li>\u5bf9\u4e8enn.Upsample\u6216nn.functional.interpolate\u51fd\u6570\uff0c\u4e00\u822c\u4f7f\u7528scale_factor\u6307\u5b9a\u500d\u7387\uff0c\u800c\u4e0d\u662f\u4f7f\u7528size\u53c2\u6570\u6307\u5b9a\u5927\u5c0f\u3002\u5982\u679c\u6e90\u7801\u4e2d\u5c31\u662f\u63d2\u503c\u4e3a\u56fa\u5b9a\u5927\u5c0f\uff0c\u5219\u8be5\u6761\u5ffd\u7565\u3002</li> <li>\u5bf9\u4e8ereshape\u3001view\u64cd\u4f5c\u65f6\uff0c-1\u7684\u6307\u5b9a\u8bf7\u653e\u5230batch\u7ef4\u5ea6\u3002\u5176\u4ed6\u7ef4\u5ea6\u8ba1\u7b97\u51fa\u6765\u5373\u53ef\u3002batch\u7ef4\u5ea6\u7981\u6b62\u6307\u5b9a\u4e3a\u5927\u4e8e-1\u7684\u660e\u786e\u6570\u5b57\u3002\u5982\u679c\u662f\u4e00\u7ef4\uff0c\u90a3\u4e48\u76f4\u63a5\u6307\u5b9a\u4e3a-1\u5c31\u597d\u3002</li> <li>torch.onnx.export\u6307\u5b9adynamic_axes\u53c2\u6570\uff0c\u5e76\u4e14\u53ea\u6307\u5b9abatch\u7ef4\u5ea6\uff0c\u7981\u6b62\u5176\u4ed6\u52a8\u6001</li> <li>\u4f7f\u7528opset_version=11\uff0c\u4e0d\u8981\u4f4e\u4e8e11</li> <li>\u907f\u514d\u4f7f\u7528inplace\u64cd\u4f5c\uff0c\u4f8b\u5982<code>y[\u2026, 0:2] = y[\u2026, 0:2] * 2 - 0.5</code>\uff0c\u53ef\u4ee5\u91c7\u7528\u5982\u4e0b\u4ee3\u7801\u4ee3\u66ff <code>tmp = y[\u2026, 0:2] * 2 - 0.5; y = torch.cat((y[..., 2:], tmp), dim = -1)</code></li> <li>\u5c3d\u91cf\u5c11\u7684\u51fa\u73b05\u4e2a\u7ef4\u5ea6\uff0c\u4f8b\u5982ShuffleNet Module\uff0c\u53ef\u4ee5\u8003\u8651\u5408\u5e76wh\u907f\u514d\u51fa\u73b05\u7ef4</li> <li>\u5c3d\u91cf\u628a\u8ba9\u540e\u5904\u7406\u90e8\u5206\u5728onnx\u6a21\u578b\u4e2d\u5b9e\u73b0\uff0c\u964d\u4f4e\u540e\u5904\u7406\u590d\u6742\u5ea6\u3002\u6bd4\u5982\u5728\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u4e2d\u6700\u7ec8\u8f93\u51fa\u8bbe\u7f6e\u4e3axywh\u6216\u8005xyxy\uff0c\u800c\u4e0d\u662f\u4e00\u4e2a\u4e2d\u95f4\u7ed3\u679c\u3002</li> </ol> <p>\u63a5\u7740\u6309\u7167\u4ee5\u4e0a\u539f\u5219\u4fee\u6539\u4ee3\u7801\uff0c\u4fee\u6539\u5982\u4e0b\uff1a</p> <pre><code># \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/core/bbox/coder/delta_xywh_bbox_coder.py mmdetection/mmdet/core/bbox/coder/delta_xywh_bbox_coder.py\ncp patch/mmdet/core/bbox/coder/delta_xywh_bbox_coder.py mmdetection/mmdet/core/bbox/coder/delta_xywh_bbox_coder.py -rf\n\n# \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/dense_heads/base_dense_head.py mmdetection/mmdet/models/dense_heads/base_dense_head.py\n\ncp patch/mmdet/models/dense_heads/base_dense_head.py mmdetection/mmdet/models/dense_heads/base_dense_head.py -rf\n\n# \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/detectors/two_stage.py mmdetection/mmdet/models/detectors/two_stage.py \ncp patch/mmdet/models/detectors/two_stage.py mmdetection/mmdet/models/detectors/two_stage.py  -rf\n\n# \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/roi_heads/standard_roi_head.py mmdetection/mmdet/models/roi_heads/standard_roi_head.py \ncp patch/mmdet/models/roi_heads/standard_roi_head.py mmdetection/mmdet/models/roi_heads/standard_roi_head.py -rf\n\n# \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py mmdetection/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py\ncp patch/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py mmdetection/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py -rf\n\n\n# \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py\ncp patch/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py -rf\n\n# \u8bfb\u8005\u53ef\u4ee5\u81ea\u884c\u67e5\u770b\u505a\u4e86\u54ea\u4e9b\u66f4\u6539\ndiff patch/mmdet/models/roi_heads/standard_roi_head.py mmdetection/mmdet/models/roi_heads/standard_roi_head.py\ncp patch/mmdet/models/roi_heads/standard_roi_head.py mmdetection/mmdet/models/roi_heads/standard_roi_head.py -rf\n</code></pre> <p>\u5b9e\u9645\u4e0a\u6709\u4e9b\u6587\u4ef6\u7684\u4fee\u6539\u8fd8\u662f\u6bd4\u8f83\u5173\u952e\u7684\uff0c\u6bd4\u5982<code>two_stage.py</code>\uff0c\u5bf9\u6b64\u6587\u4ef6\u7684\u4fee\u6539\u662f\u4e3a\u4e86\u6ee1\u8db3<code>ROIAlign</code>\u7b97\u5b50\u5bf9\u77e9\u5f62\u6709\u6548\u6027\u7684\u8981\u6c42\u3002\u8fd9\u5728\u5bfc\u51fa\u9759\u6001onnx\u65f6\u95ee\u9898\u53ef\u80fd\u6ca1\u6709\u66b4\u9732\u51fa\u6765\uff0c\u4f46\u662f\u5728\u5bfc\u51fa\u52a8\u6001batch\u7684onnx\u65f6\u95ee\u9898\u5c31\u663e\u73b0\u51fa\u6765\u4e86\u3002</p> <p>\u6700\u540e\u8fd0\u884c<code>scripts/codes/005export_onnx_with_dynamic_shape.py</code>\uff0c\u6210\u529f\u5bfc\u51fa\u652f\u6301\u52a8\u6001batch\u7684onnx\u3002</p> <p></p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#62-tensorrtbatch","title":"6.2 TensorRT\u6a21\u578b\u52a8\u6001batch\u7684\u6d4b\u8bd5","text":"<p>\u5e9f\u8bdd\u4e0d\u591a\u8bf4\uff0c\u914d\u7f6e\u597d<code>max_batch_size</code>\uff0c\u76f4\u63a5\u8f6c\u4e3atrt\u7684\u6a21\u578b\u5e8f\u5217\u5316\u6587\u4ef6\u3002\u7136\u540e\u8fd0\u884c<code>scripts/codes/006run_on_tensorrt_dynamic_shape.py</code></p> <p>\u8f93\u51fa\uff1a</p> <pre><code>key: labels, shape: (2, 100), diff: 0\nkey: dets, shape: (2, 100, 5), diff: 0.000244140625\nkey: masks, shape: (2, 100, 800, 1216), diff: 0.0\n</code></pre> <p>Nice\uff01</p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u518d\u8fdb\u4e00\u6b65\uff0c\u770b\u4e00\u4e0bFP16\u80fd\u5426\u5b9e\u73b0\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#fp16-nan","title":"\u4e03. FP16 NAN\u95ee\u9898\u7684\u89e3\u51b3","text":""},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#71-fp16-tensorrt-engine","title":"7.1 \u521d\u6b65\u5c1d\u8bd5\u8f6c\u6362fp16 TensorRT engine","text":"<p>\u6211\u4eec\u5c06<code>scripts/codes/006run_on_tensorrt_dynamic_shape.py</code>\u590d\u5236\u4e00\u4efd\uff0ccopy\u4e3a<code>007run_on_tensorrt_dynamic_shape_fp16.py</code>\uff0c\u7136\u540e\u5c06Line171\u884c\u7684<code>enable_fp16</code>\u8bbe\u7f6e\u4e3a<code>True</code>\u3002</p> <p>\u8fd9\u4e2a\u65f6\u5019\u6211\u4eec\u53d1\u73b0</p> <pre><code>key: labels, shape: (2, 100), diff: 56\nkey: dets, shape: (2, 100, 5), diff: nan\nkey: masks, shape: (2, 100, 800, 1216), diff: 1.0\n</code></pre>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#72-nan","title":"7.2 \u5b9a\u4f4dNAN\u51fa\u73b0\u5c42","text":"<p>dets\u51fa\u73b0\u4e86NAN\uff0c\u90a3\u4e48\u54ea\u4e9b\u5c42\u4f1a\u51fa\u8f93\u51faNAN\u5462\uff1f\u8fd9\u4e2a\u9700\u8981\u6211\u4eec\u53bb\u83b7\u5f97TensorRT\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\u3002\u6211\u4eec\u53ef\u4ee5\u91c7\u7528<code>polygraphy</code>\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5df1\u5199\u76f8\u5173\u4ee3\u7801\u3002\u672c\u8d28\u90fd\u662f\u4e00\u6837\uff0c<code>polygraphy</code>\u6700\u540e\u4e5f\u662f\u901a\u8fc7\u4fee\u6539tensorRT network\u7684\u4ee3\u7801\u6765\u5b8c\u6210\u7684\u3002</p> <p>\u7531\u4e8eTensorRT\u4e0d\u80fd\u8f93\u51faint8\u548cbool\u7c7b\u578b\u7684\u53d8\u91cf\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u83b7\u53d6\u5230\u5176\u4ed6\u7684\u53ef\u4ee5\u5bfc\u51fa\u7684\u4e2d\u95f4\u5c42\u53d8\u91cf\u7684\u540d\u5b57\u3002\u8be6\u60c5\u4e0b\u9762\u7684\u4ee3\u7801\u3002</p> <p>\u4e0b\u9762\u6211\u4eec\u6211\u4eec\u4fee\u6539<code>build_engine</code>\u51fd\u6570\uff0c\u901a\u8fc7\u4fee\u6539<code>network</code>\u6765\u83b7\u53d6\u4e2d\u95f4\u8f93\u51fa</p> <pre><code>def build_engine(onnx_file_path, enable_fp16=False, max_batch_size=1, max_workspace_size=10, write_engine=True):\n    # \u901a\u8fc7\u52a0\u8f7donnx\u6587\u4ef6\uff0c\u6784\u5efaengine\n    # :param onnx_file_path: onnx\u6587\u4ef6\u8def\u5f84\n    # :return: engine\n\n    onnx_path = os.path.realpath(onnx_file_path) \n    engine_file_path = \".\".join(onnx_path.split('.')[:-1] + ['engine' if not enable_fp16 else 'fp16.engine'])\n    print('engine_file_path', engine_file_path)\n    G_LOGGER = trt.Logger(trt.Logger.INFO)\n    if os.path.exists(engine_file_path):\n        with open(engine_file_path, 'rb') as f, trt.Runtime(G_LOGGER) as runtime:\n            engine = runtime.deserialize_cuda_engine(f.read())\n        return engine, engine_file_path\n    explicit_batch = 1 &lt;&lt; (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    with trt.Builder(G_LOGGER) as builder, builder.create_network(explicit_batch) as network, \\\n            trt.OnnxParser(network, G_LOGGER) as parser:\n\n        config = builder.create_builder_config()\n        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, GiB(max_workspace_size))\n        if enable_fp16:\n            config.set_flag(trt.BuilderFlag.FP16)\n        print('Loading ONNX file from path {} ...'.format(onnx_file_path))\n        with open(onnx_file_path, 'rb') as model:\n            print('Beginning ONNX file parsing')\n            if not parser.parse(model.read()):\n                for error in range(parser.num_errors):\n                    print(parser.get_error(error))\n                return None, None\n        print('Completed parsing of ONNX file')\n        print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n        # \u91cd\u70b9\n        profile = builder.create_optimization_profile()\n        profile.set_shape(\"input\", (1, 3, 800, 1216), (max_batch_size, 3, 800, 1216), (max_batch_size, 3, 800, 1216))\n        config.add_optimization_profile(profile)\n\n        output_layer_names = set()\n        cnt = 0\n        if enable_fp16 and builder.platform_has_fast_fp16:\n            for i in range(network.num_layers):\n\n                layer = network.get_layer(i)\n                layer_type = layer.type\n\n                if layer_type in (trt.LayerType.SHAPE, trt.LayerType.SLICE,\n                                  trt.LayerType.IDENTITY, \n                                  trt.LayerType.SHUFFLE, trt.LayerType.RESIZE):\n                    print(f'{layer.name} passed 1')\n                    continue\n\n                layer_output_precision = layer.get_output(0).dtype\n                print(f'layer_name: {layer.name}, layer_output_precision: {layer_output_precision}')\n\n                if layer_output_precision in (trt.int32, trt.int8, trt.bool):\n                    print(f'{layer.name} passed 2')\n                    continue\n\n                if layer.name in output_layer_names:\n                    continue\n                output_layer_names.add(layer.name)\n\n                print(f'layer {layer.name} set fp32 precision mode')\n\n                cnt += 1\n                if 180 &lt; cnt &lt; 300:\n                    network.mark_output(layer.get_output(0))\n        serialized_engine = builder.build_serialized_network(network, config)\n        if not serialized_engine:\n            return None, None\n        print(\"Completed creating Engine\")\n        # \u4fdd\u5b58engine\u6587\u4ef6\n        if write_engine:\n            with open(engine_file_path, \"wb\") as f:\n                f.write(serialized_engine)\n        with trt.Runtime(G_LOGGER) as runtime:\n            engine = runtime.deserialize_cuda_engine(serialized_engine)\n        return engine, engine_file_path\n</code></pre> <p>\u6211\u4eec\u5206\u522b\u83b7\u53d6\u4e2d\u95f4\u5c42\u7684\u67d0\u4e00\u6bb5\u8f93\u51fa\uff0c\u53d1\u73b0\u4f1a\u5f97\u5230\u5982\u4e0b\u9519\u8bef\uff1a</p> <pre><code>[E] 10: [optimizer.cpp::computeCosts::3628] Error Code 10: Internal Error (Could not find any implementation for node {ForeignNode[onnx::Range_3318...Unsqueeze_690]}.)\n</code></pre> <p>\u6728\u6709\u529e\u6cd5\u4e86\uff0c\u8fd9\u7c7b\u7684\u95ee\u9898\u57fa\u672c\u65e0\u89e3\uff0c\u9664\u975e\u52a0\u5927\u663e\u5b58\u3002</p> <p>\u7531\u4e8e\u53ea\u6709\u8fd9\u4e00\u5f202080Ti\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u597d\u53e6\u8f9f\u8e4a\u5f84\u3002</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#73-fp16","title":"7.3 FP16\u89e3\u51b3\u65b9\u6848","text":"<p>\u4e0a\u4e00\u5c0f\u8282\uff0c\u6211\u4eec\u901a\u8fc7\u8c03\u7528<code>network.mark_output(layer.get_output(0))</code>\u6765\u83b7\u53d6\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\uff0c\u53d1\u73b0\u8fd9\u6837\u884c\u4e0d\u901a\u3002\u90a3\u4e48\u8fd8\u6709\u5176\u4ed6\u89e3\u51b3\u65b9\u6848\u5417\uff1f</p> <p>\u663e\u7136\u662f\u6709\u7684\uff0c\u6211\u4eec\u5df2\u77e5FP32\u63a8\u7406\u662f\u597d\u7684\uff0c\u90a3\u4e48\u662f\u4e0d\u662f\u53ef\u4ee5\u628a\u6d89\u53ca\u8fd0\u7b97\u548c\u5185\u5b58\u64cd\u4f5c\u76f8\u5173\u7684\u5c42\u5168\u90fd\u6539\u4e3a<code>FP32</code>\u5462\uff1f</p> <p>\u7531\u6b64\uff0c\u6211\u4eec\u7ee7\u7eed\u4fee\u6539<code>build_engine</code>\u51fd\u6570\uff0c\u4e0d\u9700\u8981\u518d\u83b7\u53d6\u4e2d\u95f4\u8f93\u51fa\uff0c\u800c\u662f\u628a\u5df2\u77e5\u7684\u53ef\u4ee5\u8bbe\u7f6e\u4e3aFP32\u8fd0\u7b97\u7684\u7b97\u5b50\u90fd\u8bbe\u7f6e\u4e3a<code>FP32</code>\uff0c\u4ee3\u7801\u5982\u4e0b\uff08\u9700\u8981\u501f\u52a9<code>onnx-graphsurgeon</code>\uff09\uff1a</p> <p>onnx-graphsurgeon \u5b89\u88c5\u6307\u5357\uff1a <code>python3 -m pip install onnx_graphsurgeon --index-url https://pypi.ngc.nvidia.com</code></p> <pre><code>import onnx_graphsurgeon as gs\nimport onnx\ndef build_engine(onnx_file_path, enable_fp16=False, max_batch_size=2, max_workspace_size=10, write_engine=True):\n    graph = gs.import_onnx(onnx.load(onnx_file_path))\n    precision_name_list = list()\n\n    for node in graph.nodes:\n        if node.op in [ 'Concat', 'Conv', 'Add', 'Sub', 'Mul', 'Exp', 'Sqrt', 'Log']:\n            output = node.outputs[0]\n            if output.dtype == np.float32:\n                precision_name_list.append(node.name)\n\n    # exit(0)\n    # \u901a\u8fc7\u52a0\u8f7donnx\u6587\u4ef6\uff0c\u6784\u5efaengine\n    # :param onnx_file_path: onnx\u6587\u4ef6\u8def\u5f84\n    # :return: engine\n    onnx_path = os.path.realpath(onnx_file_path) \n    engine_file_path = \".\".join(onnx_path.split('.')[:-1] + ['engine' if not enable_fp16 else 'fp16.engine'])\n    print('engine_file_path', engine_file_path)\n    G_LOGGER = trt.Logger(trt.Logger.WARNING)\n    if os.path.exists(engine_file_path):\n        with open(engine_file_path, 'rb') as f, trt.Runtime(G_LOGGER) as runtime:\n            engine = runtime.deserialize_cuda_engine(f.read())\n        return engine, engine_file_path\n    explicit_batch = 1 &lt;&lt; (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    with trt.Builder(G_LOGGER) as builder, builder.create_network(explicit_batch) as network, \\\n            trt.OnnxParser(network, G_LOGGER) as parser:\n\n        config = builder.create_builder_config()\n        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, GiB(max_workspace_size))\n        if enable_fp16 and builder.platform_has_fast_fp16:\n            config.set_flag(trt.BuilderFlag.FP16)\n            config.set_flag(trt.BuilderFlag.STRICT_TYPES)\n        print('Loading ONNX file from path {} ...'.format(onnx_file_path))\n\n\n        with open(onnx_file_path, 'rb') as model:\n            print('Beginning ONNX file parsing')\n            if not parser.parse(model.read()):\n                for error in range(parser.num_errors):\n                    print(parser.get_error(error))\n                return None, None\n        print('Completed parsing of ONNX file')\n        print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n        # \u91cd\u70b9\n        profile = builder.create_optimization_profile()\n        profile.set_shape(\"input\", (1, 3, 800, 1216), (max_batch_size, 3, 800, 1216), (max_batch_size, 3, 800, 1216))\n        config.add_optimization_profile(profile)\n\n        if enable_fp16 and builder.platform_has_fast_fp16:\n            for i in range(network.num_layers):\n\n                layer = network.get_layer(i)\n\n                layer_type = layer.type\n\n                if layer_type in (trt.LayerType.SHAPE, trt.LayerType.SLICE,\n                                  trt.LayerType.IDENTITY,\n                                  trt.LayerType.SHUFFLE, trt.LayerType.RESIZE):\n                    print(f'{layer.name} passed 1')\n                    continue\n\n                layer_output_precision = layer.get_output(0).dtype\n                print(f'layer_name: {layer.name}, layer_output_precision: {layer_output_precision}')\n\n                if layer_output_precision in (trt.int32, trt.int8, trt.bool):\n                    print(f'{layer.name} passed 2')\n                    continue\n\n\n                if layer.name in precision_name_list:\n                    print(f'layer {layer.name} set fp32 precision mode')\n                    # layer.precision = trt.float32\n                    layer.set_output_type(0, trt.float32)\n                    layer.precision = trt.float32\n\n        serialized_engine = builder.build_serialized_network(network, config)\n        if not serialized_engine:\n            return None, None\n        print(\"Completed creating Engine\")\n        # \u4fdd\u5b58engine\u6587\u4ef6\n        if write_engine:\n            with open(engine_file_path, \"wb\") as f:\n                f.write(serialized_engine)\n        with trt.Runtime(G_LOGGER) as runtime:\n            engine = runtime.deserialize_cuda_engine(serialized_engine)\n        return engine, engine_file_path\n</code></pre> <p>\u4e8b\u5b9e\u8bc1\u660e\u4e0a\u9762\u7684\u65b9\u6cd5\u786e\u5b9e\u53ef\u884c\uff0c\u53ef\u662f\u901f\u5ea6\u53d8\u6162\u4e86\u554a\uff0c\u6bd5\u7adf\u5927\u90e8\u5206\u8fd0\u7b97\u90fd\u662f<code>FP32</code>\uff0c\u6211\u4eec\u9700\u8981\u7684\u662fFP16\u7684\u6a21\u578b\u3002 \u5173\u952e\u8bed\u53e5\u5982\u4e0b\uff1a</p> <pre><code>[ 'Concat', 'Conv', 'Add', 'Sub', 'Mul', 'Exp', 'Sqrt', 'Log']\n</code></pre> <p>\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5c1d\u8bd5\u5220\u9664\u8fd9\u4e2a\u5217\u8868\u4e2d\u7b97\u5b50\u7c7b\u578b\uff0c\u76f4\u5230\u6700\u540e\u4e00\u6b21\u4e0d\u51fa\u73b0NAN\u4e3a\u6b62\u3002 \u6700\u540e\u6211\u4eec\u5f97\u5230\u5982\u4e0b\u7ed3\u679c\uff1a</p> <pre><code>[ 'Concat', 'Add', ]\n</code></pre> <p>\u5b9e\u9645\u4e0a\u8fd8\u80fd\u4e0d\u80fd\u518d\u518d\u4f18\u5316\u5462\uff1f\u6211\u4eec\u53ef\u4ee5\u7740\u773c\u4e8e\u7ee7\u7eed\u9650\u5236Add\u7c7b\u578b\u548cConcat\u7c7b\u578b\u7684\u7b97\u5b50\u8303\u56f4\u7ee7\u7eed\u4f18\u5316\u3002\u4f18\u5316\u6c38\u65e0\u6b62\u5883\uff01</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/maskrcnn-tensorrt/#_3","title":"\u516b. \u603b\u7ed3","text":"<p>\u672c\u9879\u76ee\u662f\u5bf9\u53bb\u5e74<code>FasterRCNN+ROIAlign+FPN</code>\u9879\u76ee\u7684\u5347\u7ea7\uff0c\u52a0\u5165\u4e86\u8bad\u7ec3\u3001\u52a8\u6001batch\u3001FP16\u7b49\u529f\u80fd\uff0c\u4ece\u529f\u80fd\u5168\u9762\u6027\u8003\u8651\u53ef\u4ee5\u8bf4\u5f88\u9f50\u5168\u4e86\u3002</p> <p>\u5728\u505a\u672c\u9879\u76ee\u7684\u65f6\u5019\uff0c\u6211\u89e3\u51b3\u4e86\u4e00\u4e2a\u53c8\u4e00\u4e2a\u7684\u95ee\u9898\uff0c\u6700\u7ec8\u5f97\u5230\u81ea\u5df1\u60f3\u8981\u7684\u7ed3\u679c\u3002\u6587\u7ae0\u4e2d\u7565\u53bb\u4e86\u4e00\u90e8\u5206\u63a2\u7d22\u7684\u8fc7\u7a0b\uff0c\u8bfb\u8005\u53ef\u4ee5\u901a\u8fc7\u5bf9\u6bd4\u6e90\u7801\u7684\u65b9\u5f0f\u6765\u89c2\u5bdf\u4e3a\u4ec0\u4e48\u8981\u8fd9\u6837\u4fee\u6539\u3002</p> <p>\u5ba1\u89c6\u4e00\u5e74\u540e\u7684\u6211\uff0c\u62e5\u6709\u66f4\u5bbd\u7684\u6280\u672f\u89c6\u91ce\uff0c\u66f4\u591a\u7684\u6280\u672f\u9009\u62e9\uff0c\u4e5f\u7b97\u662f\u4e00\u79cd\u8fdb\u6b65\u5427\u3002</p> <p>\u5145\u6ee1\u672a\u77e5\u76842023\uff0c\u4e00\u5207\u90fd\u4f1a\u53d8\u5f97\u66f4\u597d\u5427\uff01</p>"},{"location":"%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/mmyolo_tensorrt/","title":"Yolo\u7cfb\u5217\u6a21\u578b\u7684\u90e8\u7f72\u3001\u7cbe\u5ea6\u5bf9\u9f50\u4e0eint8\u91cf\u5316\u52a0\u901f","text":"<p>\u672c\u6587\u5199\u4e8e2023-11-02\u665a \u82e5\u9700\u8f6c\u8f7d\u8bf7\u8054\u7cfb haibintian@foxmail.com</p> <p>\u5927\u5bb6\u597d\uff0c\u6211\u662f\u6d77\u6ee8\u3002\u5199\u8fd9\u7bc7\u6587\u7ae0\u7684\u76ee\u7684\u662f\u4e3a\u5ba3\u4f20\u6211\u572823\u5e74\u521d\u5230\u73b0\u5728\u5b8c\u6210\u7684\u4e00\u9879\u5de5\u4f5c---Yolo\u7cfb\u5217\u6a21\u578b\u5728TensorRT\u4e0a\u7684\u90e8\u7f72\u4e0e\u91cf\u5316\u52a0\u901f\uff0c\u76ee\u524d\u4ee5\u901a\u8fc7\u89c6\u9891\u7684\u5f62\u5f0f\u5728B\u7ad9\u53d1\u5e03\uff08\u4e0d\u6536\u8d39\uff0c\u53ea\u56fe\u4e00\u4e2a\u4e00\u5251\u4e09\u8fde\uff09\u3002</p> <p>\u9ebb\u96c0\u867d\u5c0f\u4f46\u4e94\u810f\u4ff1\u5168\uff0c\u672c\u9879\u76ee\u7cfb\u7edf\u4ecb\u7ecd\u4e86YOLO\u7cfb\u5217\u6a21\u578b\u5728TensorRT\u4e0a\u7684\u91cf\u5316\u65b9\u6848\uff0c\u5de5\u7a0b\u578b\u8f83\u5f3a\uff0c\u6211\u4eec\u7ed9\u51fa\u7684\u5de5\u5177\u53ef\u4ee5\u5b9e\u73b0\u4e0d\u540c\u91cf\u5316\u65b9\u6848\u5728Yolo\u7cfb\u5217\u6a21\u578b\u7684\u91cf\u5316\u90e8\u7f72\uff0c\u65e0\u8bba\u662f\u5de5\u7a0b\u5b9e\u8df5\u8fd8\u662f\u5b66\u672f\u5b9e\u9a8c\uff0c\u76f8\u4fe1\u90fd\u4f1a\u5bf9\u4f60\u5e26\u6765\u4e00\u5b9a\u7684\u5e2e\u52a9\u3002</p> <p>B\u7ad9\u5730\u5740\uff08\u6c42\u5173\u6ce8\u548c\u4e09\u8fde\uff09\uff1ahttps://www.bilibili.com/video/BV1Ds4y1k7yr/ Github\u5f00\u6e90\u5730\u5740\uff08\u6c42star\uff09\uff1ahttps://github.com/thb1314/mmyolo_tensorrt/ </p> <p>\u5f53\u65f6\u60f3\u505a\u8fd9\u4e2a\u7684\u76ee\u7684\u662f\u662f\u4e3a\u4e86\u603b\u7ed3\u4e00\u4e0b\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u91cf\u5316\u52a0\u901f\u5230\u5e95\u4f1a\u9047\u5230\u4ec0\u4e48\u5751\uff0c\u53ea\u662f\u6ca1\u60f3\u5230\u4e0d\u91cf\u5316\u5751\u90fd\u4f1a\u5f88\u591a\u3002</p> <p>\u6bd4\u5982\u5373\u4f7f\u662f\u4ee5FP32\u5f62\u5f0f\u63a8\u7406\uff0c\u7531\u4e8eTensorRT\u7b97\u5b50\u53c2\u6570\u7684\u4e00\u4e9b\u9650\u5236\u548cTRT\u548ctorch\u5185\u90e8\u5b9e\u73b0\u7684\u4e0d\u540c\uff0c\u5bfc\u81f4torch\u63a8\u7406\u7ed3\u679c\u4f1a\u548cTensorRT\u63a8\u7406\u7ed3\u679c\u5929\u7136\u7684\u4e0d\u7edf\u4e00\uff0c\u81f3\u4e8e\u4e3a\u4ec0\u4e48\u4e0d\u7edf\u4e00\u8fd9\u91cc\u5356\u4e2a\u5173\u5b50\u5927\u5bb6\u611f\u5174\u8da3\u53ef\u4ee5\u770b\u4e0b\u89c6\u9891\u3002</p> <p>\u4e0b\u9762\u8bf4\u4e00\u4e0b\u6211\u4eec\u8fd9\u4e2a\u9879\u76ee\u505a\u4e86\u54ea\u4e9b\u4e8b\u60c5  </p> <ol> <li>YOLO\u7cfb\u5217\u6a21\u578b\u5728tensorrt\u4e0a\u7684\u90e8\u7f72\u4e0e\u7cbe\u5ea6\u5bf9\u9f50   \u8be5\u9879\u76ee\u8be6\u7ec6\u4ecb\u7ecd\u4e86Yolo\u7cfb\u5217\u6a21\u578b\u5728TensorRT\u4e0a\u7684FP32\u7684\u7cbe\u5ea6\u90e8\u7f72\uff0c\u57fa\u4e8emmyolo\u6846\u67b6\u5bfc\u51fa\u5404\u79cdyolo\u6a21\u578b\u7684onnx\uff0c\u5728coco val\u6570\u636e\u96c6\u4e0a\u5bf9\u9f50torch\u7248\u672c\u4e0eTensorRT\u7248\u672c\u7684\u7cbe\u5ea6\u3002   \u5728\u6b64\u8fc7\u7a0b\u4e2d\u6211\u4eec\u53d1\u73b0\uff0c\u7531\u4e8eTopK\u7b97\u5b50\u9650\u5236\u548cNMS\u7b97\u5b50\u5b9e\u73b0\u4e0a\u7684\u4e0d\u540c\uff0c\u6211\u4eec\u65e0\u6cd5\u5b8c\u5168\u5bf9\u9f50torch\u548cyolo\u6a21\u578b\u7684\u7cbe\u5ea6\uff0c\u4e0d\u8fc7\u8fd9\u79cd\u98ce\u9669\u662f\u53ef\u89e3\u91ca\u4e14\u53ef\u63a7\u7684\u3002  </li> <li>\u8be6\u89e3TensorRT\u91cf\u5316\u7684\u4e09\u79cd\u5b9e\u73b0\u65b9\u5f0f   TensorRT\u91cf\u5316\u7684\u4e09\u79cd\u5b9e\u73b0\u65b9\u5f0f\u5305\u62ectrt7\u81ea\u5e26\u91cf\u5316\u3001dynamic range api\uff0ctrt8\u5f15\u5165\u7684QDQ\u7b97\u5b50\u3002   Dynamic range api\u4f1a\u5728\u91c7\u7528\u57fa\u4e8eMQbench\u6846\u67b6\u505aPTQ\u65f6\u8bb2\u89e3\u3002   TensorRT\u5f15\u5165\u7684QDQ\u7b97\u5b50\u65b9\u5f0f\u5728\u9488\u5bf9Yolo\u6a21\u578b\u7684PTQ\u548cQAT\u65b9\u5f0f\u65f6\u90fd\u6709\u8be6\u7ec6\u7684\u9610\u8ff0\uff0c\u5f53\u7136\u8fd9\u4e2a\u8fc7\u7a0b\u4e5f\u6ca1\u6709\u90a3\u4e48\u987a\u5229\u3002   \u5728\u57fa\u4e8ePytorchQuantization\u5bfc\u51fa\u7684\u542b\u6709QDQ\u8282\u70b9\u7684onnx\u65f6\uff0c\u6211\u4eec\u53d1\u73b0\u5c3d\u7ba1\u91cf\u5316\u7248\u672c\u7684torch\u6a21\u578b\u7cbe\u5ea6\u5f88\u9ad8\uff0c\u4f46\u662f\u5728TensorRT\u90e8\u7f72\u65f6\u7cbe\u5ea6\u5374\u5f88\u4f4e\uff0cTRT\u90e8\u7f72\u6536\u7cbe\u5ea6\u635f\u5931\u5f88\u4e25\u91cd\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u5176\u4ed6\u91cf\u5316\u5f62\u5f0f\u7684engine\u548c\u95ee\u9898engine\u8fdb\u884c\u5bf9\u6bd4\uff0c\u6211\u4eec\u53d1\u73b0\u662f\u4e00\u4e9b\u5c42\u7684int8\u91cf\u5316\u4f1a\u51fa\u95ee\u9898\uff0c\u7531\u6b64\u627e\u51fa\u95ee\u9898\u91cf\u5316\u8282\u70b9\u89e3\u51b3\u3002</li> <li>\u8be6\u89e3MQbench\u91cf\u5316\u5de5\u5177\u5305\u5728TensorRT\u4e0a\u7684\u5e94\u7528    \u6211\u4eec\u7814\u7a76\u4e86\u57fa\u4e8eMQbench\u6846\u67b6\u7684\u666e\u901aPTQ\u7b97\u6cd5\u548c\u5305\u62ecAdaround\u9ad8\u9636PTQ\u7b97\u6cd5\uff0c\u4e14\u542f\u53d1\u4e8eAdaround\u9ad8\u9636PTQ\u7b97\u6cd5\u3002    \u6211\u4eec\u5c06torch\u7248\u672c\u4e2d\u7684HistogramObserver\u5f15\u5165\u5230MQBench\u4e2d\uff0cactivation\u91c7\u7528HistogramObserver    weight\u91c7\u7528MinMaxObserver\uff0c\u5728PTQ\u8fc7\u7a0b\u4e2d\uff0cweight\u7684\u6821\u51c6\u524d\u5411\u4f20\u64ad\u4e00\u6b21\uff0cactivation\u7684\u6821\u51c6\u9700\u8981\u591a\u6b21    \u56e0\u6b64\u6211\u4eec\u5c06weight\u7684PTQ\u8fc7\u7a0b\u548cactivation\u7684PTQ\u8fc7\u7a0b\u5206\u5f00\u8fdb\u884c\uff0c\u52a0\u901fPTQ\u91cf\u5316\u3002     \u5b9e\u8df5\u8bc1\u660e\uff0c\u6211\u4eec\u91c7\u7528\u4e0a\u8ff0\u914d\u7f6e\u7684\u5206\u79bbPTQ\u91cf\u5316\u5728yolov8\u4e0a\u53ef\u4ee5\u53d6\u5f97\u57fa\u672c\u4e0d\u6389\u70b9\u7684int8\u91cf\u5316\u7cbe\u5ea6\u3002</li> <li>\u9488\u5bf9YoloV6\u8fd9\u79cd\u96be\u91cf\u5316\u6a21\u578b\uff0c\u5206\u522b\u91c7\u7528\u90e8\u5206\u91cf\u5316\u548cQAT\u6765\u5f25\u8865\u91cf\u5316\u7cbe\u5ea6\u635f\u5931   \u5728\u90e8\u5206\u91cf\u5316\u9636\u6bb5\uff0c\u6211\u4eec\u91c7\u7528\u91cf\u5316\u654f\u611f\u5c42\u5206\u6790\u6280\u672f\u6765\u5224\u65ad\u54ea\u4e9b\u5c42\u6700\u9700\u8981\u6062\u590d\u539f\u59cb\u7cbe\u5ea6\uff0c\u7ed9\u51fa\u5404\u79cdmetric\u7684\u91cf\u5316\u654f\u611f\u5c42\u5b9e\u73b0\u3002   \u5728QAT\u9636\u6bb5\uff0c\u4e0d\u540c\u4e8e\u539f\u59cbYolov6\u8bba\u6587\u4e2d\u84b8\u998f+RepOPT\u7684\u65b9\u5f0f\uff0c\u6211\u4eec\u76f4\u63a5\u91c7\u7528\u4e0a\u8ff0\u90e8\u5206\u91cf\u5316\u540e\u7684\u6a21\u578b\u505a\u51fa\u521d\u59cb\u6a21\u578b\u8fdb\u884cfinetune\uff0c\u7ed3\u679c\u53d1\u73b0finetune\u540e\u7684\u6a21\u578b\u4f9d\u7136\u53d6\u5f97\u4e0d\u9519\u6548\u679c\u3002</li> <li>\u9488\u5bf9\u65cb\u8f6c\u76ee\u6807\u68c0\u6d4b\uff0c\u6211\u4eec\u540c\u6837\u7ed9\u51fa\u4e00\u79cd\u7aef\u5230\u7aef\u65b9\u6848\uff0c\u6700\u540e\u7684\u8f93\u51fa\u5c31\u662fNMS\u540e\u7684\u7ed3\u679c\u3002    \u901a\u8fc7\u5c06TensorRT\u4e2d\u7684EfficientNMS Plugin\u548cmmcv\u4e2d\u65cb\u8f6c\u6846iou\u8ba1\u7b97\u7684cuda\u5b9e\u73b0\u76f8\u7ed3\u5408\uff0c\u7ed9\u51faEfficientNMS for rotated box\u7248\u672c\uff0c\u7ecf\u8fc7\u7b80\u5355\u9a8c\u8bc1\u6211\u4eec\u7684TRT\u7248\u672c\u4e0eTorch\u7248\u672c\u6a21\u578b\u8f93\u51fa\u57fa\u672c\u5bf9\u9f50\u3002</li> </ol> <p>\u4ee5\u4e0a\u5c31\u662f\u6211\u4eec\u8fd9\u4e2a\u9879\u76ee\u505a\u7684\u4e8b\u60c5\uff0c\u6b22\u8fce\u5404\u4f4d\u770b\u5b98\u5173\u6ce8b\u7ad9\u548c\u4e00\u5251\u4e09\u8fde\u3002\u540c\u65f6\uff0c\u5982\u679c\u5404\u4f4d\u6709\u66f4\u597d\u7684\u60f3\u6cd5\u4e5f\u6b22\u8fce\u7ed9\u6211\u4eec\u7684git\u4ed3\u5e93\u63d0PR\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/","title":"TOOD\u8bba\u6587\u548c\u6e90\u7801\u89e3\u8bfb\uff1a\u76ee\u6807\u68c0\u6d4b\u4e2d\u5b9a\u4f4d\u548c\u5206\u7c7b\u4efb\u52a1\u4e00\u81f4\u6027\u95ee\u9898","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#_1","title":"\u4e00\u3001\u524d\u8a00","text":"<p>\u8bba\u6587\u94fe\u63a5\uff1a https://arxiv.org/abs/2108.07755 \u4ee3\u7801\u94fe\u63a5\uff1ahttps://github.com/fcjian/TOOD</p> <p>TOOD\u8fd9\u7bc7\u6587\u7ae0\u51fa\u81eaICCV 2021 Oral\uff0c\u5168\u79f0\u4e3a\u201cTask-aligned One-stage Object Detection\u201d\uff0c</p> <p>Yolov8\u3001Yolov6\u3001PP-YOLOE\u3001PicoDet\u7b49\u6a21\u578b\u90fd\u9009\u62e9TOOD\u4f5c\u4e3a\u8bad\u7ec3\u65f6\u7684\u6807\u7b7e\u5206\u914d\u7b56\u7565\uff0c\u53ef\u89c1TOOD\u7684\u6709\u6548\u6027\u5f97\u5230\u4e86\u4f17\u591a\u5de5\u4f5c\u7684\u501f\u9274\u548c\u8ba4\u53ef\uff0c\u90a3\u4e48TOOD\u5230\u5e95\u89e3\u51b3\u4e86\u4ec0\u4e48\u95ee\u9898\u5462\uff1f\u4ee5\u53ca\u89e3\u51b3\u65b9\u6848\u662f\u4ec0\u4e48\uff1f\u672c\u6587\u5c31\u5e26\u8fd9\u8bfb\u8005\u6df1\u6316\u8bba\u6587\u4e0e\u5bf9\u5e94\u4ee3\u7801\uff0c\u4ee5\u901a\u4fd7\u6613\u61c2\u7684\u8bed\u8a00\u4e3a\u8bfb\u8005\u89e3\u8bfb\u4e0b\u8fd9\u7bc7\u8bba\u6587\uff0c\u5e76\u8c08\u4e00\u4e0b\u81ea\u5df1\u7684\u7406\u89e3\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#_2","title":"\u4e8c\u3001\u95ee\u9898\u5f15\u5165","text":"<p>\u76ee\u6807\u68c0\u6d4b\u65e8\u5728\u4ece\u56fe\u4e2d\u5b9a\u4f4d\u548c\u8bc6\u522b\u51fa\u611f\u5174\u8da3\u7684\u7269\u4f53\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\uff0c\u662fCV\u4e2d\u7684\u4e00\u9879\u57fa\u7840\u4efb\u52a1\u3002\u76ee\u6807\u68c0\u6d4b\u53ef\u4ee5\u770b\u505a\u4e00\u4e2a\u591a\u4efb\u52a1\u5b66\u4e60\u95ee\u9898\uff0c\u5206\u7c7b\u4efb\u52a1\u4e13\u6ce8\u4e8e\u76ee\u6807\u7684\u9002\u7528\u4e8e\u5206\u7c7b\u7684\u663e\u8457\u7279\u5f81\uff0c\u5b9a\u4f4d\u4efb\u52a1\u81f4\u529b\u4e8e\u7cbe\u786e\u5b9a\u4f4d\u7269\u4f53\u7684\u8fb9\u754c\u3002\u7531\u4e8e\u4e24\u79cd\u4efb\u52a1\u5b66\u4e60\u673a\u5236\u4e0d\u540c\uff0c\u4e24\u79cd\u4efb\u52a1\u5b66\u4e60\u5230\u7684\u7279\u5f81\u7a7a\u95f4\u5206\u5e03\u4e5f\u53ef\u80fd\u4e0d\u540c\uff0c\u5f53\u91c7\u7528\u4e24\u4e2a\u72ec\u7acb\u4efb\u52a1\u5206\u652f\u8fdb\u884c\u9884\u6d4b\u65f6\uff0c\u4f1a\u5bfc\u81f4\u4e00\u5b9a\u7a0b\u5ea6\u7684\u9519\u4f4d\u3002</p> <p></p> <p>\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u7b2c\u4e00\u884c\u8868\u793a\u4f7f\u7528ATSS(\u4e00\u79cd\u52a8\u6001\u6807\u7b7e\u5206\u914d\u7b56\u7565)\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c\uff0c\u4e0b\u9762\u4e00\u884c\u8868\u793aTOOD\u9884\u6d4b\u7684\u7ed3\u679c\u3002</p> <p>\u9ec4\u8272\u77e9\u5f62\u6846\u8868\u793aGT\uff0c\u4ece\u56fe\u4e2d\u7b2c\u4e00\u5217\u53ef\u4ee5\u770b\u51faGT\u7684\u5206\u7c7b\u7ed3\u679c\u4e3a\u9910\u684c\u3002\u4e24\u884c\u4e2d\u7b2c\u4e00\u5217\u7684\u7ea2\u8272\u77e9\u5f62\u6846\u90fd\u8868\u793a\u76f8\u5e94\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\uff0c\u7b2c\u4e00\u884c\u7b2c\u4e00\u5217\u4e2d\u7684\u7eff\u8272\u77e9\u5f62\u6846\u4e5f\u8868\u793aATSS\u7684\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679c\u3002\u7b2c\u4e8c\u884c\u7b2c\u4e00\u5217\u5176\u5b9e\u4e5f\u6709\u7eff\u8272\u6846\uff0c\u4f46\u662f\u4e0e\u7ea2\u8272\u6846\u91cd\u5408\uff0c\u6240\u4ee5\u6ca1\u6709\u5c55\u793a\u3002</p> <p>\u7b2c\u4e8c\u5217(Score)\u4e2d\u8868\u793a\u6a21\u578b\u5728GT\u533a\u57df\u5185\u9884\u6d4b\u4e3a\u9910\u684c\u7684\u6982\u7387\u5206\u5e03\uff0c\u8fd9\u91cc\u8be6\u7ec6\u89e3\u91ca\u4e00\u4e0b\uff0c\u5728\u4e00\u5f20\u56fe\u4e2d\u6bcf\u4e2a\u5750\u6807\u70b9\u90fd\u4f1a\u6709\u82e5\u5e72\u4e2a\u7f51\u683c(\u65e0\u8bba\u662f\u57fa\u4e8eanchor-box\u8fd8\u662fanchor-point)\uff0c\u7f51\u683c\u6240\u5bf9\u5e94\u7684\u7684\u5206\u7c7b\u6982\u7387\u8bb0\u4e3ap\uff0c\u7f51\u683c\u4e2d\u5fc3\u70b9\u8bb0\u4e3a(x,y)\uff0c\u90a3\u4e48\u6709S(x,y) = p\uff0c\u4ece\u800c\u5c31\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u4e8c\u7ef4\u5355\u901a\u9053\u77e9\u9635\uff0c\u5bf9\u8be5\u77e9\u9635\u8fdb\u884c\u53ef\u89c6\u5316\u5373\u53ef\u5f97\u5230\u4e0a\u8ff0\u6982\u7387\u5206\u5e03\u3002</p> <p>\u7b2c\u4e09\u5217(IoU)\u8868\u793a\u9884\u6d4b\u6846\u4e0eGT\u7684IOU\u5206\u5e03\uff0c\u5728\u4e00\u5f20\u56fe\u4e2d\u6bcf\u4e2a\u5750\u6807\u70b9\u90fd\u4f1a\u6709\u82e5\u5e72\u4e2a\u7f51\u683c\uff0c\u8fd9\u4e9b\u7f51\u683c\u4e00\u5b9a\u5bf9\u5e94\u4e00\u4e2a\u6216\u8005\u591a\u4e2aanchor(\u65e0\u8bba\u662f\u57fa\u4e8eanchor-box\u8fd8\u662fanchor-point)\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e00\u4e2a\u7f51\u683c\u5bf9\u5e94\u4e00\u4e2a\u6216\u8005\u591a\u4e2a\u9884\u6d4b\u6846\uff0c\u5c06\u8fd9\u4e9b\u9884\u6d4b\u6846\u4e0eGT\u8fdb\u884cIOU\u8ba1\u7b97\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u5373\u53ef\u7ed8\u5236\u51fa\u4e0a\u56fe\u7b2c\u4e09\u5217\u4e2d\u7684\u5206\u5e03\u3002</p> <p>TOOD\u5c06\u4e0a\u56fe\u4e2d\u8868\u73b0\u51fa\u7684\u95ee\u9898\u6982\u8ff0\u4e3a\u4e24\u70b9\uff1a</p> <ol> <li>\u5206\u7c7b\u4efb\u52a1\u4e0e\u5b9a\u4f4d\u4efb\u52a1\u4e4b\u95f4\u8fc7\u4e8e\u72ec\u7acb\u7f3a\u4e4f\u4ea4\u4e92\uff1a\u5e38\u89c1\u7684\u4e00\u9636\u6bb5\u68c0\u6d4b\u5668\u57fa\u672c\u90fd\u662f\u91c7\u7528\u53cc\u5206\u652f\u72ec\u7acb\u7ed3\u6784\u7684head\u6765\u5b9e\u73b0\u5b9a\u4f4d\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u8fd9\u6837\u4e00\u79cd\u53cc\u5206\u652f\u7ed3\u6784\u53ef\u80fd\u4f1a\u5bfc\u81f4\u9884\u6d4b\u548c\u5b9a\u4f4d\u7ed3\u679c\u7684\u4e0d\u4e00\u81f4\u3002\u6bd4\u5982\u4e0a\u56fe\u7b2c\u4e00\u884c\u7b2c\u4e00\u5217\u7684ATSS\u9884\u6d4b\u7ed3\u679c\uff0c\u9ec4\u8272\u6846\u8868\u793a\u9884\u6d4b\u4e3a\u201c\u9910\u684c\u201d\u7684\u6700\u4f73\u5339\u914d\u7ed3\u679c\uff08\u5206\u7c7b\u4e3a\u9910\u684c\uff09\uff0c\u4f46\u662f\u5176\u66f4\u9002\u5408\u4f5c\u4e3a\u201c\u62ab\u8428\u201d\u7684\u5b9a\u4f4d\uff08\u5b9a\u4f4d\u4e3a\u62ab\u8428\uff09\u3002</li> <li>\u4efb\u52a1\u65e0\u5173\u7684\u6837\u672c\u5206\u914d\u7b56\u7565\uff1a\u9996\u5148\u8981\u89e3\u91ca\u4e00\u4e0b\u4efb\u52a1\u65e0\u5173\u7684\u542b\u4e49\u8868\u793a\u6837\u672c\u7684\u5206\u914d\u6ca1\u6709\u8003\u8651\u5206\u7c7b\u548c\u5b9a\u4f4d\u7684\u7efc\u5408\u56e0\u7d20\u3002\u5927\u591a\u6570ahchor-free\u68c0\u6d4b\u5668\u91c7\u7528\u57fa\u4e8e\u51e0\u4f55\u5206\u5e03\u7684\u5206\u914d\u7b56\u7565\uff0c\u5373\u9009\u62e9\u4f4d\u4e8e\u7269\u4f53\u4e2d\u5fc3\u9644\u8fd1\u7684anchor-point\u7528\u4e8e\u56de\u5f52\u548c\u5b9a\u4f4d\u4efb\u52a1\u3002\u540c\u65f6anchor-based\u7684\u68c0\u6d4b\u5668\u4e00\u822c\u91c7\u7528\u8ba1\u7b97GT\u4e0eanchor-box\u7684IOU\u7684\u5f62\u5f0f\u5b9e\u73b0anchor-box\u8d1f\u8d23\u54ea\u4e2aGT\u7684\u9884\u6d4b\u3002\u4f46\u662f\u9002\u5408\u5b9a\u4f4d\u548c\u9002\u5408\u5206\u7c7b\u7684anchor\u5f80\u5f80\u4e0d\u4e00\u81f4\uff0c\u8fd9\u5c31\u5bfc\u81f4\u4e0a\u8ff0\u4e24\u79cd\u4e0e\u4efb\u52a1\u65e0\u5173\u7684\u6837\u672c\u5206\u914d\u7b56\u7565\u5f88\u96be\u53bb\u5f15\u5bfc\u6a21\u578b\u53bb\u5b66\u4e60\u51fa\u5b9a\u4f4d\u548c\u5206\u7c7b\u5f97\u5206\u4e00\u81f4\u9ad8\u7684\u9884\u6d4b\u6846\u3002\u4e0a\u56fe\u4e2d\u7b2c\u4e00\u884c\u4e2dScore\u5217\u4e0eIoU\u5217\u5c31\u8bf4\u660e\u4e86\u8be5\u95ee\u9898\u3002\u5728\u7b2c\u4e00\u884cResult\u5217\u4e2d\u7eff\u8272\u6846\u5373\u4e3aIOU\u5f97\u5206\u6700\u9ad8\u7684\u6846\uff0c\u4f46\u662f\u5176\u5206\u7c7b\u5f97\u5206\u8f83\u4f4e\uff0c\u6700\u7ec8\u4f1a\u88abNMS\u540e\u5904\u7406\u7b97\u6cd5\u8fc7\u6ee4\u6389\u3002</li> </ol>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#tood_1","title":"\u4e09\u3001TOOD\u7ed9\u51fa\u7684\u89e3\u51b3\u601d\u8def","text":"<p>TOOD\u9762\u5411\u4e0a\u8ff0\u95ee\u9898\uff0c\u5206\u522b\u7ed9\u51fa\u4e24\u4e2a\u89e3\u51b3\u65b9\u6848\uff1a</p> <ol> <li>\u8bbe\u8ba1\u4e00\u79cdHead\u7ed3\u6784\u589e\u5f3a\u4e24\u4e2a\u4efb\u52a1\u4e4b\u95f4\u7684\u7279\u5f81\u4ea4\u4e92</li> <li>\u8bbe\u8ba1\u4e00\u79cd\u4efb\u52a1\u5bf9\u9f50\u7684\u6807\u7b7e\u5206\u914d\u673a\u5236\uff0c\u7efc\u5408\u8003\u8651\u5206\u7c7b\u4e0e\u5b9a\u4f4d\u56e0\u7d20\uff0c\u5c1d\u8bd5\u5f15\u5bfc\u6a21\u578b\u7ed9\u51fa\u627e\u5230\u4e00\u4e2a\u5206\u7c7b\u548c\u5b9a\u4f4d\u5f97\u5206\u90fd\u8f83\u9ad8\u7684\u4f4d\u7f6e\u3002</li> </ol>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#31-headt-headtask-aligned-head","title":"3.1 \u4efb\u52a1\u5bf9\u9f50Head\uff1aT-Head(Task-aligned head)","text":"<p>TAL\u7684\u8bbe\u8ba1\u6709\u4e24\u4e2a\u76ee\u7684\uff1a</p> <ol> <li>\u589e\u5f3a\u5b9a\u4f4d\u4e8e\u5206\u7c7b\u4efb\u52a1\u4e4b\u95f4\u7684\u7279\u5f81\u4ea4\u4e92</li> <li>\u63d0\u5347\u68c0\u6d4b\u5668\u7684\u4efb\u52a1\u5bf9\u9f50\u5b66\u4e60\u80fd\u529b</li> </ol> <p>\u5e38\u89c4\u68c0\u6d4b\u5668Head\u5982\u4e0a\u56fe(a)\u6240\u793a\uff0c\u5206\u7c7b\u4efb\u52a1\u4e0e\u5b9a\u4f4d\u4efb\u52a1\u91c7\u7528\u4e24\u4e2a\u5e76\u884c\u72ec\u7acb\u5206\u652f\u5b8c\u6210\u3002T-Head\u7684\u6574\u4f53\u7ed3\u6784\u56fe\u5982\u56fe(b)\u6240\u793a\uff0c\u5176\u7531\u4e00\u4e2a\u7279\u5f81\u63d0\u53d6\u5668\u548c\u4e24\u4e2aTAP\uff08Task-aligned predictor\uff09\u7ec4\u6210\u3002TAP\u7ed3\u6784\u5982\u56fe\u00a9\u6240\u793a\uff0c\u4e00\u4f1a\u7ed9\u51fa\u5177\u4f53\u516c\u5f0f\u3002</p> <p>T-Head\u4e0e\u5e38\u89c4\u68c0\u6d4b\u4e0d\u540c\u7684\u662f\uff0c\u4e3a\u589e\u5f3a\u4e24\u7c7b\u4efb\u52a1\u4e4b\u95f4\u7684\u7279\u5f81\u4ea4\u4e92\uff0cT-Head\u91c7\u7528\u591a\u5c42\u4e32\u8054\u7684\u7684\u5377\u79ef\u5c42\u6765\u63d0\u53d6\u591a\u5c42\u7279\u5f81\u56fe\uff0c\u591a\u5c42\u7279\u5f81\u56fe\u5bf9\u5e94\u4e0d\u540c\u611f\u53d7\u91ce\u4fe1\u606f\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a\u5176\u4e2d \\(X^{fpn}\\) \u4e3aFPN\u5355\u5c42\u8f93\u51fa\u7684\u4fe1\u606f\uff0c \\(conv_k\\)  and  \\(\\delta\\)  \u5206\u522b\u8868\u793a k-th \u5377\u79ef\u5c42\u4e2aRelu\u6fc0\u6d3b\u51fd\u6570\u3002</p> <p></p> <p>N\u4e2a \\(X_{k}^{inter}\\) \u7279\u5f81\u5c06\u4f1a\u7ea7\u8054\u8d77\u6765\uff0c\u9001\u5165TAP\u4e2d\uff0c\u6700\u7ec8\u4ea7\u751f\u5206\u7c7b\u548c\u5b9a\u4f4d\u9884\u6d4b\u4fe1\u606f\u3002</p> <p>\u7531\u4e8e\u5b9a\u4f4d\u4e0e\u5206\u7c7b\u7684\u76ee\u6807\u4e0d\u540c\uff0c\u4e24\u7c7b\u4efb\u52a1\u5171\u7528\u4e00\u79cd\u7279\u5f81\u4e0d\u53ef\u907f\u514d\u4f1a\u5e26\u6765\u7279\u5f81\u51b2\u7a81\uff0c\u5404\u81ea\u5173\u6ce8\u7684\u7279\u5f81\u4e5f\u4e0d\u76f8\u540c\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5728\u8bba\u6587\u4e2d\u63d0\u51fa\u5bf9k\u4e2a \\(X_{k}^{inter}\\) \u7279\u5f81\u91c7\u7528Layer Attention\u7684\u65b9\u5f0f\u8fdb\u884c\u5904\u7406\uff0c\u8ba9\u6a21\u578b\u81ea\u52a8\u4e3a\u6bcf\u4e2aLayer\u5b66\u4e60\u5f97\u5230\u4e00\u79cd\u9002\u914d\u4e8e\u5f53\u524d\u4efb\u52a1\u7684\u6743\u91cd\u7cfb\u6570 \\(w_k\\) \uff08\u662f\u4e00\u4e2a\u6807\u91cf\uff09\uff0c\u7136\u540e\u5c06 \\(w_k\\) \u4e0e \\(X_{k}^{inter}\\) \u76f8\u4e58\u5f97\u5230 \\(X_k^{task}\\) \u3002\u5982\u56fe\u00a9\u6240\u793a\uff0c \\(\\omega\\) \u7531N\u4e2a \\(X_{k}^{inter}\\) \u5171\u540c\u8ba1\u7b97\u5f97\u5230\uff0c\u53ef\u4ee5\u6355\u83b7\u8de8\u5c42\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u5176\u4e2d \\(f_{c1}\\) \u4e0e \\(f_{c2}\\) \u8868\u793a\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c \\(\\sigma\\) \u4ee3\u8868sigmoid\u51fd\u6570\uff0c \\(x^{inter}\\) \u662f\u5bf9 \\(X^{inter}\\) \uff08N\u4e2a \\(X_{k}^{inter}\\) \u62fc\u63a5\uff09\u505a\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5f97\u5230\u3002</p> <p></p> <p></p> <p>\u6700\u540e\uff0c\u7531 \\(X^{task}\\) \uff08N\u4e2a \\(X_{k}^{task}\\) \u62fc\u63a5\uff09\u5f97\u5230 \\(Z^{task}\\) \uff0c\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a</p> <p></p> <p>\\(Z^{task}\\) \u7ecf\u8fc7sigmoid\u51fd\u6570\u8f6c\u6362\u4e3a\u5206\u7c7b\u9884\u6d4b\u56fe \\(P \\in R^{H \\times W \\times 80}\\) \u6216\u8005<code>distance-to-bbox</code>\u51fd\u6570\u8f6c\u6362\u4e3a \\(B \\in R^{H \\times W \\times 4}\\) \u3002</p> <p>\u9884\u6d4b\u5bf9\u9f50\u6b65\u9aa4\uff1a</p> <p>\u5982\u4e0a\u56fe\u4e2d\u56fe\u00a9\u6240\u793a\uff0cTOOD\u91c7\u7528\u8de8\u5c42\u4efb\u52a1\u4ea4\u4e92\u7279\u5f81 \\(X^{inter}\\) \u751f\u6210\u7279\u5f81\u56feM\u548cO\uff0c\u91c7\u7528\u8de8\u5c42\u7279\u5f81\u5b9e\u73b0\u5bf9P\u548cB\u7684\u8fdb\u4e00\u6b65\u77eb\u6b63\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a</p> <p></p> <p></p> <p></p> <p>\u5176\u4e2d\uff0c\u516c\u5f0f(5)\u4e2d\u7684\u4e58\u6cd5\u5c31\u662f\u5143\u7d20\u4e58\u6cd5\uff0c\u516c\u5f0f(6)\u7684\u516c\u5f0f\u53ef\u4ee5\u53c2\u8003\u53ef\u53d8\u6027\u5377\u79ef\u7684\u516c\u5f0f\uff0c\u4ee5B\u4e3a\u57fa\u7840O\u4e3a\u5750\u6807\u6765\u751f\u6210\u4e00\u4e2a\u65b0\u7684 \\(B^{align}\\) \uff0c\u5176\u4e2d\u65b0\u7684\u4f4d\u7f6e\u5750\u6807\u6bd4\u5982 \\(i + O(i, j, 2 \\times c)\\) \u662f\u4e00\u4e2a\u8fde\u7eed\u503c\uff0c\u91c7\u7528float\u8868\u793a\uff0c\u5bf9\u5e94\u8fde\u7eed\u503c\u4f4d\u7f6e\u7684\u503c\u91c7\u7528\u53cc\u63d2\u503c\u7b97\u6cd5\u8ba1\u7b97\u5f97\u5230\u3002\u516c\u5f0f(7)(8)\u8868\u793aM\u548cO\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u5176\u4e2d \\(M \\in \\text{R}^{H \\times W \\times 4}\\) \uff0c \\(O \\in \\text{R}^{H \\times W \\times 8}\\) \uff0c \\(M\\) \u53ef\u4ee5\u770b\u505a\u7a7a\u95f4\u4e2d\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u4efb\u52a1\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u7528\u4e8e\u8861\u91cf\u4e24\u7c7b\u4efb\u52a1\u7684\u4e00\u81f4\u6027\u3002</p> <p>\u8fd9\u91cc\u9700\u8981\u8bf4\u660e\u7684\u662f\uff0c\u5373\u4f7f\u6ca1\u6709TAL\uff0cT-Head\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cdHead\u4ee5\u5373\u63d2\u5373\u7528\u7684\u65b9\u5f0f\u7ed9\u5176\u4ed6\u6a21\u578b\u63d0\u4f9b\u4e00\u79cd\u5e26\u6709\u4efb\u52a1\u95f4\u4ea4\u4e92\u7279\u5f81\u7684Head\u3002</p> <p>\u4ee3\u7801\u89e3\u6790</p> <p>\u57fa\u4e8emmdet2.28.1\u7248\u672c</p> <p>https://github.com/open-mmlab/mmdetection/blob/v2.28.1/mmdet/models/dense_heads/tood_head.py</p> <p>\u53c2\u8003\u4ee3\u7801\uff0c\u8fd9\u91cc\u4e00\u6b65\u6b65\u62c6\u89e3\uff0c\u5148\u8bf4 \\(X^{inter}\\) \u7684\u751f\u6210\uff1a</p> <p>\u5377\u79ef\u5c42\u7684\u5b9a\u4e49\u5728Line145-160\uff0c\u5728<code>_init_layers</code>\u51fd\u6570\u91cc\u9762\uff1a</p> <pre><code>        self.inter_convs = nn.ModuleList()\n        for i in range(self.stacked_convs):\n            if i &lt; self.num_dcn:\n                conv_cfg = dict(type='DCNv2', deform_groups=4)\n            else:\n                conv_cfg = self.conv_cfg\n            chn = self.in_channels if i == 0 else self.feat_channels\n            self.inter_convs.append(\n                ConvModule(\n                    chn,\n                    self.feat_channels,\n                    3,\n                    stride=1,\n                    padding=1,\n                    conv_cfg=conv_cfg,\n                    norm_cfg=self.norm_cfg))\n</code></pre> <p>\u8fd9\u91cc<code>self.inter_convs</code>\u5373\u8868\u793a\u751f\u6210 \\(X^{inter}\\) \u6240\u7528\u5377\u79ef\u3002</p> <p>TAP\u6a21\u5757\u4e2d \\(Z^{task}\\) \u7684\u751f\u6210\u8fc7\u7a0b\u7531\u7c7b<code>TaskDecomposition</code>\u6765\u63cf\u8ff0\uff0c\u5bf9\u5e94Line162-169</p> <pre><code>self.cls_decomp = TaskDecomposition(self.feat_channels,\n                                    self.stacked_convs,\n                                    self.stacked_convs * 8,\n                                    self.conv_cfg, self.norm_cfg)\nself.reg_decomp = TaskDecomposition(self.feat_channels,\n                                    self.stacked_convs,\n                                    self.stacked_convs * 8,\n                                    self.conv_cfg, self.norm_cfg)\n</code></pre> <p>\u540e\u7eed\u7684 \\(P^{align}\\) \u4e0e \\(B^{align}\\) \u89c1\u4e0b\u9762\u7684\u4ee3\u7801\u548c\u6ce8\u91ca\uff08Line171-189\uff09\uff1a</p> <pre><code>        # \u751f\u6210P\u6240\u9700\u5377\u79ef\u5c42 \u5bf9\u5e94\u516c\u5f0f(4)\u4e2d\u7684 conv2\n        self.tood_cls = nn.Conv2d(\n            self.feat_channels,\n            self.num_base_priors * self.cls_out_channels,\n            3,\n            padding=1)\n        # \u751f\u6210B\u6240\u9700\u5377\u79ef\u5c42 \u5bf9\u5e94\u516c\u5f0f(4)\u4e2d\u7684 conv2\n        self.tood_reg = nn.Conv2d(\n            self.feat_channels, self.num_base_priors * 4, 3, padding=1)\n\n        # \u751f\u6210M\u6240\u9700\u5377\u79ef\u5c42\n        self.cls_prob_module = nn.Sequential(\n            nn.Conv2d(self.feat_channels * self.stacked_convs,\n                      self.feat_channels // 4, 1), nn.ReLU(inplace=True),\n            nn.Conv2d(self.feat_channels // 4, 1, 3, padding=1))\n\n        # \u751f\u6210O\u6240\u9700\u5377\u79ef\u5c42\n        self.reg_offset_module = nn.Sequential(\n            nn.Conv2d(self.feat_channels * self.stacked_convs,\n                      self.feat_channels // 4, 1), nn.ReLU(inplace=True),\n            nn.Conv2d(self.feat_channels // 4, 4 * 2, 3, padding=1))\n\n        # reg head \u6240\u9700\u53ef\u5b66\u4e60\u7684\u7f29\u653e\u7cfb\u6570\n        self.scales = nn.ModuleList(\n            [Scale(1.0) for _ in self.prior_generator.strides])\n</code></pre> <p>\u4e0b\u9762\u518d\u770b\u4e00\u4e0b<code>TaskDecomposition</code>\u505a\u4e86\u4ec0\u4e48\uff0c\u5bf9\u5e94Line17-86\uff0c\u6211\u5220\u51cf\u4e86\u4e00\u90e8\u5206</p> <pre><code>class TaskDecomposition(nn.Module):\n    \"\"\"Task decomposition module in task-aligned predictor of TOOD.\n    Args:\n        feat_channels (int): \u8868\u793aX_{k}^{inter}\u7684\u901a\u9053\u6570\n        stacked_convs (int): TOOD head\u4e2d\u516c\u5f0f(1)\u7684N\uff0c\u8868\u793a\u6709\u591a\u5c11\u4e2aX_{k}^{inter}\n        la_down_rate (int): Downsample rate of layer attention.\n        conv_cfg (dict): Config dict for convolution layer.\n        norm_cfg (dict): Config dict for normalization layer.\n    \"\"\"\n\n    def __init__(self,\n                 feat_channels,\n                 stacked_convs,\n                 la_down_rate=8,\n                 conv_cfg=None,\n                 norm_cfg=None):\n        super(TaskDecomposition, self).__init__()\n        # \u8868\u793aX_{k}^{inter}\u7684\u901a\u9053\u6570\n        self.feat_channels = feat_channels\n        # TOOD head\u4e2d\u516c\u5f0f(1)\u7684N\uff0c\u8868\u793a\u6709\u591a\u5c11\u4e2aX_{k}^{inter}\n        self.stacked_convs = stacked_convs\n        self.in_channels = self.feat_channels * self.stacked_convs\n        self.norm_cfg = norm_cfg\n        # \u5bf9\u5e94\u516c\u5f0f3\u4e2d\u7684\u4e24\u4e2afc\u5c42\u548c\u6fc0\u6d3b\u51fd\u6570\n        self.layer_attention = nn.Sequential(\n            nn.Conv2d(self.in_channels, self.in_channels // la_down_rate, 1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(\n                self.in_channels // la_down_rate,\n                self.stacked_convs,\n                1,\n                padding=0), nn.Sigmoid())\n\n        # \u5bf9\u5e94\u516c\u5f0f4\u4e2d\u7684conv1\n        self.reduction_conv = ConvModule(\n            self.in_channels,\n            self.feat_channels,\n            1,\n            stride=1,\n            padding=0,\n            conv_cfg=conv_cfg,\n            norm_cfg=norm_cfg,\n            bias=norm_cfg is None)\n\n    def forward(self, feat, avg_feat=None):\n        b, c, h, w = feat.shape\n        if avg_feat is None:\n            # \u5bf9\u5e94\u56feC\u4e2d\u7684GAP(global average pooling)\n            avg_feat = F.adaptive_avg_pool2d(feat, (1, 1))\n        # \u5bf9\u5e94\u516c\u5f0f3\u8ba1\u7b97\u8fc7\u7a0b\n        weight = self.layer_attention(avg_feat)\n\n        # \u8fd9\u91cc\u6e90\u7801\u4f5c\u8005\u4e3a\u4e86\u52a0\u901f\u8ba1\u7b97\u5c06 \u516c\u5f0f\u4e09\u4e2d\u7684\u7ed3\u679c omega \u4e0e conv1 \u4e2d\u7684\u6743\u91cd\u8fdb\u884c\u4e86\u5408\u5e76\n        # here we first compute the product between layer attention weight and\n        # conv weight, and then compute the convolution between new conv weight\n        # and feature map, in order to save memory and FLOPs.\n        conv_weight = weight.reshape(\n            b, 1, self.stacked_convs,\n            1) * self.reduction_conv.conv.weight.reshape(\n                1, self.feat_channels, self.stacked_convs, self.feat_channels)\n        conv_weight = conv_weight.reshape(b, self.feat_channels,\n                                          self.in_channels)\n        feat = feat.reshape(b, self.in_channels, h * w)\n        # 1x1 conv \u53ef\u4ee5\u770b\u6210\u5168\u8fde\u63a5\u5c42\uff0c\u5168\u8fde\u63a5\u5c42\u7684\u5b9e\u73b0\u5c31\u662f\u77e9\u9635\u4e58\u6cd5\uff0c\u8fd9\u91cc\u5373conv1\u7684\u8ba1\u7b97\n        feat = torch.bmm(conv_weight, feat).reshape(b, self.feat_channels, h,\n                                                    w)\n        if self.norm_cfg is not None:\n            feat = self.reduction_conv.norm(feat)\n        feat = self.reduction_conv.activate(feat)\n\n        return \n</code></pre> <p>\u8bfb\u8005\u53ef\u80fd\u4f1a\u7591\u60d1\uff0c<code>TaskDecomposition</code>\u7c7b\u4e2d\u4e3a\u4ec0\u4e48\u6ca1\u6709\u516c\u5f0f(4)\u4e2d\u7684conv2\u3002\u6211\u8ba4\u4e3aconv2\u662f\u7528\u6765\u505a\u8f6c\u6362\u7684\uff0c\u5373\u751f\u6210P\u6216\u8005B\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4 \\(Z^{task}\\) \u6cdb\u6307P\u6216\u8005B\u7684\u4e00\u79cd\uff0c\u516c\u5f0f(4)\u5c31\u5305\u542b\u4e86P\u548cB\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u8fd9\u4e5f\u89e3\u91ca\u4e86\u56fe\u00a9\u4e2d \\(Z^{task}(P/B)\\) \u4e2d\u62ec\u53f7\u7684\u542b\u4e49\uff0c\u8fd9\u91cc\u8bfb\u8005\u53ef\u4ee5\u770b\u4e00\u4e0b\u524d\u9762\u4ee3\u7801\u7684\u6ce8\u91ca\u3002</p> <p>\u89e3\u91ca\u6e05\u695a<code>TaskDecomposition</code>\u7c7b\u540e\uff0c\u6211\u4eec\u518d\u770b\u4e00\u4e0b\u6574\u4e2aT-Head\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u5bf9\u5e94\u4ee3\u7801Line210-282</p> <pre><code>    def forward(self, feats):\n        \"\"\"Forward features from the upstream network.\n        Args:\n            feats (tuple[Tensor]): Features from the upstream network, each is\n                a 4D-tensor. fpn\u8f93\u51fa\u7684\u7279\u5f81\n        Returns:\n            tuple: Usually a tuple of classification scores and bbox prediction\n                cls_scores (list[Tensor]): Classification scores for all scale\n                    levels, each is a 4D-tensor, the channels number is\n                    num_anchors * num_classes.\n                bbox_preds (list[Tensor]): Decoded box for all scale levels,\n                    each is a 4D-tensor, the channels number is\n                    num_anchors * 4. In [tl_x, tl_y, br_x, br_y] format.\n        \"\"\"\n        cls_scores = []\n        bbox_preds = []\n        # \u904d\u5386\u6240\u6709\u7684FPN\u8f93\u51famap\n        for idx, (x, scale, stride) in enumerate(\n                zip(feats, self.scales, self.prior_generator.strides)):\n            b, c, h, w = x.shape\n            # \u5f97\u5230anchor point \u6216\u8005 anchor box\n            anchor = self.prior_generator.single_level_grid_priors(\n                (h, w), idx, device=x.device)\n            anchor = torch.cat([anchor for _ in range(b)])\n            # extract task interactive features\n            inter_feats = []\n            # \u8ba1\u7b97\u5f97\u5230 X^{inter}_k\n            for inter_conv in self.inter_convs:\n                x = inter_conv(x)\n                inter_feats.append(x)\n            # concat \u5f97\u5230 X^{inter}\n            feat = torch.cat(inter_feats, 1)\n\n            # task decomposition\n            # TAP\u4e2dLayerAttention\u8fc7\u7a0b\n            avg_feat = F.adaptive_avg_pool2d(feat, (1, 1))\n            # \u5f97\u5230 \u516c\u5f0f4\u4e2dconv1\u7684\u8f93\u51fa \u7528\u4e8e\u5206\u7c7b\n            cls_feat = self.cls_decomp(feat, avg_feat)\n            # \u5f97\u5230 \u516c\u5f0f4\u4e2dconv1\u7684\u8f93\u51fa \u7528\u4e8e\u5b9a\u4f4d\n            reg_feat = self.reg_decomp(feat, avg_feat)\n\n\n            # cls prediction and alignment\n            # \u5bf9\u5e94\u516c\u5f0f4\u4e2dconv2 \n            cls_logits = self.tood_cls(cls_feat)\n            # \u751f\u6210M\n            cls_prob = self.cls_prob_module(feat)\n            # \u751f\u6210P^{align} = sqrt(sigmoid(M) x sigmoid(P))\n            # \u8fd9\u91cc\u5047\u8bbeM\u548cP\u8868\u793a\u672a\u63a5\u5165\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u7684\u7279\u5f81\n            cls_score = sigmoid_geometric_mean(cls_logits, cls_prob)\n\n            # reg prediction and alignment\n            if self.anchor_type == 'anchor_free':\n                # \u8ba1\u7b97\u4e2d\u5fc3\u70b9\u5230\u56db\u4e2a\u8fb9\u7684\u8ddd\u79bb \u5bf9\u5e94 FCOS\u8bba\u6587\u4e2d\u7684 lrtb\n                reg_dist = scale(self.tood_reg(reg_feat).exp()).float()\n                reg_dist = reg_dist.permute(0, 2, 3, 1).reshape(-1, 4)\n                # \u751f\u6210 B\n                # \u5bf9anchor\u8fdb\u884c\u5f52\u4e00\u5316 \u7136\u540e\u8f6c\u6362\u4e3a b, 4, h, w\n                reg_bbox = distance2bbox(\n                    self.anchor_center(anchor) / stride[0],\n                    reg_dist).reshape(b, h, w, 4).permute(0, 3, 1,\n                                                          2)  # (b, c, h, w)\n            elif self.anchor_type == 'anchor_based':\n                reg_dist = scale(self.tood_reg(reg_feat)).float()\n                reg_dist = reg_dist.permute(0, 2, 3, 1).reshape(-1, 4)\n                reg_bbox = self.bbox_coder.decode(anchor, reg_dist).reshape(\n                    b, h, w, 4).permute(0, 3, 1, 2) / stride[0]\n            else:\n                raise NotImplementedError(\n                    f'Unknown anchor type: {self.anchor_type}.'\n                    f'Please use `anchor_free` or `anchor_based`.')\n            # \u751f\u6210O\n            reg_offset = self.reg_offset_module(feat)\n            # \u751f\u6210B^{align}\uff0c\u8fd9\u91cc\u5373\u91c7\u7528\u53ef\u53d8\u6027\u5377\u79ef\u6765\u5b9e\u73b0\uff0cO\u5f53\u505a\u504f\u79fb\u5750\u6807\n            bbox_pred = self.deform_sampling(reg_bbox.contiguous(),\n                                             reg_offset.contiguous())\n\n            # \u7ecf\u8fc7\u53ef\u53d8\u6027\u5377\u79ef\u8ba1\u7b97\u540e\uff0c\u53ef\u80fd\u6709\u4e9b\u6846\u6709\u4e0d\u7b26\u5408\u77e9\u5f62\u6761\u4ef6, \u6c42GIOULoss\u65f6\u4f1a\u5bfc\u81f4\u5c0f\u4e8e0\n            # \u8fd9\u4e2a\u65f6\u5019\u8f6c\u800c\u7528\u539f\u6765\u7684 B \u6765\u4ee3\u66ff B^{align}\n            # After deform_sampling, some boxes will become invalid (The\n            # left-top point is at the right or bottom of the right-bottom\n            # point), which will make the GIoULoss negative.\n            invalid_bbox_idx = (bbox_pred[:, [0]] &gt; bbox_pred[:, [2]]) | \\\n                               (bbox_pred[:, [1]] &gt; bbox_pred[:, [3]])\n            invalid_bbox_idx = invalid_bbox_idx.expand_as(bbox_pred)\n            bbox_pred = torch.where(invalid_bbox_idx, reg_bbox, bbox_pred)\n\n            cls_scores.append(cls_score)\n            bbox_preds.append(bbox_pred)\n        return tuple(cls_scores), tuple(bbox_preds)\n</code></pre> <p>\u4e0b\u9762\u7ed9\u51fa\u7684\u6e90\u7801\uff0c\u6e90\u7801\u5730\u5740</p> <pre><code># \u4e3a\u4e86\u89e3\u51b3torch\u539f\u751f\u5b9e\u73b0\u4e24\u4e2asigmoid\u8fde\u7eed\u76f8\u4e58\u540e\u68af\u5ea6\u5bb9\u6613\u4e3aNone\u7684\u95ee\u9898\uff0c\u5316\u7b80\u4e86\u68af\u5ea6\u8ba1\u7b97\u8fc7\u7a0b\u7528\u4e8e\u7f13\u89e3\u8be5\u7c7b\u95ee\u9898\u3002\nclass SigmoidGeometricMean(Function):\n    \"\"\"Forward and backward function of geometric mean of two sigmoid\n    functions.\n    This implementation with analytical gradient function substitutes\n    the autograd function of (x.sigmoid() * y.sigmoid()).sqrt(). The\n    original implementation incurs none during gradient backprapagation\n    if both x and y are very small values.\n    \"\"\"\n\n    @staticmethod\n    def forward(ctx, x, y):\n        x_sigmoid = x.sigmoid()\n        y_sigmoid = y.sigmoid()\n        z = (x_sigmoid * y_sigmoid).sqrt()\n        ctx.save_for_backward(x_sigmoid, y_sigmoid, z)\n        return z\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        x_sigmoid, y_sigmoid, z = ctx.saved_tensors\n        grad_x = grad_output * z * (1 - x_sigmoid) / 2\n        grad_y = grad_output * z * (1 - y_sigmoid) / 2\n        return grad_x, grad_y\n\n\nsigmoid_geometric_mean = SigmoidGeometricMean.apply\n</code></pre> <p><code>distance2bbox</code>\u51fd\u6570</p> <pre><code>def distance2bbox(points, distance, max_shape=None):\n    \"\"\"Decode distance prediction to bounding box.\n\n    Args:\n        points (Tensor): Shape (B, N, 2) or (N, 2).\n        distance (Tensor): Distance from the given point to 4\n            boundaries (left, top, right, bottom). Shape (B, N, 4) or (N, 4)\n        max_shape (Sequence[int] or torch.Tensor or Sequence[\n            Sequence[int]],optional): Maximum bounds for boxes, specifies\n            (H, W, C) or (H, W). If priors shape is (B, N, 4), then\n            the max_shape should be a Sequence[Sequence[int]]\n            and the length of max_shape should also be B.\n\n    Returns:\n        Tensor: Boxes with shape (N, 4) or (B, N, 4)\n    \"\"\"\n    x1 = points[..., 0] - distance[..., 0]\n    y1 = points[..., 1] - distance[..., 1]\n    x2 = points[..., 0] + distance[..., 2]\n    y2 = points[..., 1] + distance[..., 3]\n\n    bboxes = torch.stack([x1, y1, x2, y2], -1)\n\n    # \u5c06 bboxes\u9650\u5236\u5728max_shape\n    if max_shape is not None:\n        if not isinstance(max_shape, torch.Tensor):\n            max_shape = x1.new_tensor(max_shape)\n        max_shape = max_shape[..., :2].type_as(x1)\n        if max_shape.ndim == 2:\n            assert bboxes.ndim == 3\n            assert max_shape.size(0) == bboxes.size(0)\n\n        min_xy = x1.new_tensor(0)\n        max_xy = torch.cat([max_shape, max_shape],\n                           dim=-1).flip(-1).unsqueeze(-2)\n        bboxes = torch.where(bboxes &lt; min_xy, min_xy, bboxes)\n        bboxes = torch.where(bboxes &gt; max_xy, max_xy, bboxes)\n\n    return bboxes\n</code></pre> <p>\u4ee5\u4e0a\u5c31\u662fT-Head\u7684\u6e90\u7801\u89e3\u6790\uff0cmmdet\u4e2d\u7684\u5b9e\u73b0\u4e0e\u539f\u6587\u76f8\u7b26\uff0c\u4e00\u4e9b\u5de5\u7a0b\u4e0a\u7684\u7ec6\u8282\u503c\u5f97\u6211\u4eec\u5b66\u4e60\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#32-taltask-alignment-learning","title":"3.2 \u4efb\u52a1\u5bf9\u9f50\u5b66\u4e60\u673a\u5236\uff1aTAL(Task alignment learning)","text":"<p>\u4e3a\u4e86\u8ba9T-Head\u80fd\u591f\u4efb\u52a1\u5bf9\u9f50\u7684\u9884\u6d4b\u6846\uff0cTOOD\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6837\u672c\u5206\u914d\u7b56\u7565\u548cLoss\uff0c\u5e76\u5c06\u5176\u547d\u540d\u4e3aTAL\uff08\u4efb\u52a1\u5bf9\u9f50\u5b66\u4e60\uff09\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#321","title":"3.2.1 \u4efb\u52a1\u5bf9\u9f50\u7684\u6837\u672c\u5206\u914d\u7b56\u7565","text":"<p>\u9996\u5148\u518d\u56de\u987e\u4e0bTOOD\u7684\u76ee\u6807\uff0cTOOD\u5e0c\u671b\u6a21\u578b\u7684\u9884\u6d4b\u6846\u5177\u6709\u5982\u4e0b\u7279\u5f81\uff1a</p> <ol> <li>\u5206\u7c7b\u5f97\u5206\u9ad8\u7684\u4e00\u5b9a\u5177\u6709\u6bd4\u8f83\u597d\u7684\u5b9a\u4f4d\u7cbe\u5ea6</li> <li>\u5b9a\u4f4d\u7cbe\u5ea6\u9ad8\u7684\u4e00\u5b9a\u5177\u6709\u6bd4\u8f83\u9ad8\u7684\u5206\u7c7b\u5f97\u5206</li> <li>\u53cd\u4e4b\uff0c\u5206\u7c7b\u5f97\u5206\u4f4e\u4f34\u968f\u7740\u5b9a\u4f4d\u7cbe\u5ea6\u4f4e</li> </ol> <p>\u8fd9\u6837\u624d\u53ef\u4ee5\u65b9\u4fbf\u88abnms\u540e\u5904\u7406\uff0c\u4f7f\u5f97\u5206\u7c7b\u9ad8\u4e14\u5b9a\u4f4d\u51c6\u786e\u7684\u6846\u4fdd\u7559\u4e0b\u6765\u3002</p> <p>\u6709\u4e86\u4ee5\u4e0a\u76ee\u6807\uff0cTOOD\u6839\u636e\u4e0a\u9762\u7684\u76ee\u6807\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u9f50\u5ea6\u91cf\u65b9\u5f0f\u6765\u660e\u786e\u6d4b\u91cfanchor level\u7684\u4efb\u52a1\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u8fd9\u79cd\u65b0\u7684\u5bf9\u9f50\u5ea6\u91cf\u7528\u4ee5\u6837\u672c\u5206\u914d\u4e0eLoss\u7684\u8bbe\u8ba1\u4e2d\u3002</p> <p>\u951a\u6846\u5bf9\u9f50\u5ea6\u91cf\uff1a</p> <p>\u8861\u91cf\u5206\u7c7b\u548c\u5b9a\u4f4d\u7684\u7cbe\u5ea6\u6807\u51c6\u7684\u5206\u522b\u662f\u9884\u6d4b\u6846\u5bf9\u5e94\u7684\u5206\u7c7bScore\u4ee5\u53ca\u5176\u4e0eGT\u4e4b\u95f4\u7684IOU\u3002</p> <p>\u8bb0 \\(s\\) \u4e3a\u5206\u7c7b\u5f97\u5206\uff08\u662f\u611f\u5174\u8da3\u7269\u4f53\u4e14\u5206\u7c7b\u4e3a\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u5f97\u5206\uff09\uff0c \\(\\mu\\) \u4e3aIoU\u503c\uff0c\u90a3\u4e48</p> \\[ t = s^{\\alpha} \\times \\mu^{\\beta} \\] <p>\\(\\alpha\\) \u548c \\(\\beta\\) \u4f5c\u4e3a\u4e00\u4e2a\u8d85\u53c2\u6570\u7528\u4e8e\u63a7\u5236\u4e24\u7c7b\u4efb\u52a1\u7684anchor\u5bf9\u9f50\u7a0b\u5ea6\u3002t\u503c\u53ef\u4ee5\u4f7f\u5f97\u7f51\u7edc\u4ece\u8054\u5408\u4f18\u5316\u7684\u89d2\u5ea6\u52a8\u6001\u5173\u6ce8\u4efb\u52a1\u5bf9\u9f50\u7684anchor\u3002</p> <p>\u6211\u8fd9\u91cc\u6709\u4e2a\u7591\u95ee\uff1aIoU\u7684\u597d\u7406\u89e3\uff0c\u4e3a\u4ec0\u4e48s\u53ef\u4ee5\u4f5c\u4e3a\u5206\u7c7b\u5f97\u5206\u7684\u8d28\u91cf\u8bc4\u4f30\u6807\u51c6\u5462\uff1f</p> <p>\u6709\u4e86t\u503c\u4ee5\u540e\uff0cTOOD\u5728anchor\u7b5b\u9009\u65f6\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u4efb\u52a1\u5bf9\u9f50\u7684anchor\uff08t\u503c\u6bd4\u8f83\u9ad8\u7684\uff09\uff0c\u5bf9\u4e8e\u5355\u4e2aGT\u6846\uff0c\u9009\u62e9m\u4e2at\u503c\u6700\u5927\u7684anchor\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u4f7f\u7528\u5269\u4f59\u7684anchor\u4f5c\u4e3a\u8d1f\u6837\u672c\uff0cm\u8fd9\u91cc\u662f\u4e00\u4e2a\u8d85\u53c2\u6570\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#322","title":"3.2.2 \u4efb\u52a1\u5bf9\u9f50\u635f\u5931","text":"<p>\u4e3a\u589e\u52a0\u5bf9\u9f50anchor\u7684\u5206\u7c7bScore\uff0c\u540c\u65f6\u964d\u4f4e\u672a\u5bf9\u9f50anchor\u7684\u5206\u7c7b\u5f97\u5206\uff08t\u503c\u8f83\u4f4e\u7684\uff09\uff0c\u4f5c\u8005\u91c7\u7528\u5f52\u4e00\u5316\u7684\\(\\hat t\\)\u6765\u4ee3\u66fft\u6765\u4f5c\u4e3a\u6b63\u6837\u672canchor\u7684\u5206\u7c7bScore\u5f97\u5206\uff0c\u5176\u4e2d\\(\\hat t\\)\u901a\u8fc7\u4e00\u4e0b\u4e24\u4e2a\u5c5e\u6027\u8fdb\u884c\u5f52\u4e00\u5316\uff1a</p> <ol> <li>\u786e\u4fdd\u56f0\u96be\u5b9e\u4f8b\u7684\u6709\u6548\u5b66\u4e60</li> <li>\u6839\u636e\u9884\u6d4b\u8fb9\u754c\u6846\u7684\u7cbe\u5ea6\u4fdd\u6301\u5b9e\u4f8b\u4e4b\u95f4\u7684\u6392\u540d</li> </ol> <p>\u56e0\u6b64\uff0cTOOD\u91c7\u7528\u6700\u5927\u6700\u5c0f\u503c\u5f52\u4e00\u5316\u6765\u8c03\u6574t\u5f97\u5230 \\(\\hat t\\) \uff0c\u6bcf\u4e2aGT\u6846\u7684\\(\\hat t\\)\u7684\u6700\u5927\u503c\u4e3a\u5176\u4e0eanchor\u7684\u6700\u5927IoU\u503c\uff0c\u5e76\u91c7\u7528Focus Loss\u8fdb\u884c\u5206\u7c7b\u7528\u4ee5\u51cf\u8f7b\u8bad\u7ec3\u671f\u95f4\u6b63\u8d1f\u6837\u672c\u7684\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u6b64\u65f6Loss\u5e94\u8be5\u5199\u4e3a\uff1a</p> <p></p> <p>\u7531\u826f\u597d\u5bf9\u9f50\u7684anchor\uff08\u5177\u6709\u8f83\u5927t\u503c\uff09\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u901a\u5e38\u5177\u6709\u8f83\u5927\u7684\u5206\u7c7b\u7684\u5206\u548c\u8f83\u9ad8\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5728NMS\u8fc7\u7a0b\u4e2d\u66f4\u5927\u6982\u7387\u4fdd\u7559\u8fd9\u4e9b\u8fb9\u754c\u6846\u3002\u4e0e\u5206\u7c7b\u4efb\u52a1\u7c7b\u4f3c\uff0c\u5b9a\u4f4d\u56de\u5f52Loss\u4e3a\u5e26\u6709\u52a0\u6743\u503c$ \\hat t $\u7684\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\uff0c\u52a0\u6743\u540eGIoU\u635f\u5931\u53ef\u4ee5\u8868\u793a\u5982\u4e0b\uff1a</p> <p></p> <p>\u5176\u4e2d \\(b_i\\) \u548c \\(\\hat b_i\\) \u8868\u793a\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u548c\u76f8\u5e94\u7684GT\u6846\uff0c\u901a\u8fc7 \\(\\hat t\\) \u7684\u52a0\u6743\u53ef\u4ee5\u5b9e\u73b0\u6a21\u578b\u66f4\u5173\u6ce8\u5bf9\u9f50\u826f\u597d\u7684anchor\uff0c\u540c\u65f6\u51cf\u5c11\u8fb9\u754c\u6846\u56de\u5f52\u671f\u95f4\u672a\u5bf9\u9f50anchor\uff08\u5177\u6709\u5c0ft\uff09\u7684\u5f71\u54cd\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#323","title":"3.2.3 \u6e90\u7801\u89e3\u8bfb\u73af\u8282","text":"<p>\u9996\u5148\u770b\u4e00\u4e0bt\u503c\u7684\u8ba1\u7b97\u4e0e\u6807\u7b7e\u5206\u7c7b\u7b56\u7565\uff0c\u8fd9\u91cc\u9700\u8981\u8bf4\u660e\u7684\u662f\uff0c\u5728\u521a\u5f00\u59cb\u7684\u82e5\u5e72\u4e2aepoch,mmdet\u7248\u672c\u7684TOOD\u91c7\u7528\u7684\u662fATSS\u6807\u7b7e\u5206\u914d\u548closs\uff0c\u7136\u540e\u518d\u5207\u6362\u4e3aTOOD\u3002\u6211\u8ba4\u4e3a\u4e3b\u8981\u539f\u56e0\u5728\u4e8e\uff0c\u6a21\u578b\u521a\u5f00\u59cb\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6743\u91cd\u968f\u673a\u521d\u59cb\u5316\u7684\u7684\u5206\u7c7b\u8f93\u51fa\u5f97\u5206\u4e0d\u80fd\u5f88\u597d\u7684\u8bc4\u4f30\u5206\u7c7b\u8d28\u91cf\uff0c\u56e0\u6b64\u5148\u91c7\u7528\u5176\u4ed6\u7684\u8bad\u7ec3\u6a21\u5f0f\u5148\u8ba9\u6a21\u578b\u53ef\u4ee5\u521d\u6b65\u8f93\u51fa\u4e00\u4e2a\u8f83\u4e3a\u53ef\u9760\u5730\u5206\u7c7b\u5f97\u5206\u3002</p> <p>\u8fd9\u91cc\u7ed9\u51fat\u7684\u8ba1\u7b97\u8fc7\u7a0b\u4e0eTOOD\u7684\u6807\u7b7e\u5206\u914d\u7b56\u7565\uff0c\u5bf9\u5e94\u4ee3\u7801\u94fe\u63a5</p> <p>\u5728mmdet\u4e2d\uff0c\u6807\u7b7e\u5206\u7c7b\u901a\u8fc7Assigner\u7c7b\u4e2d\u7684assign\u65b9\u6cd5\u5b9e\u73b0\uff0c\u4e0b\u9762\u5c31\u6765\u89e3\u8bfb<code>BaseAssigner</code>\u4e0b\u7684<code>assign</code>\u65b9\u6cd5</p> <pre><code>def assign(self,\n               pred_scores,\n               decode_bboxes,\n               anchors,\n               gt_bboxes,\n               gt_bboxes_ignore=None,\n               gt_labels=None,\n               alpha=1,\n               beta=6):\n        \"\"\"Assign gt to bboxes.\n        The assignment is done in following steps\n        1. compute alignment metric between all bbox (bbox of all pyramid\n           levels) and gt\n        2. select top-k bbox as candidates for each gt\n        3. limit the positive sample's center in gt (because the anchor-free\n           detector only can predict positive distance)\n        Args:\n            pred_scores (Tensor): predicted class probability,\n                shape(n, num_classes)\n            decode_bboxes (Tensor): predicted bounding boxes, shape(n, 4)\n            anchors (Tensor): pre-defined anchors, shape(n, 4).\n            gt_bboxes (Tensor): Groundtruth boxes, shape (k, 4).\n            gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are\n                labelled as `ignored`, e.g., crowd boxes in COCO.\n            gt_labels (Tensor, optional): Label of gt_bboxes, shape (k, ).\n        Returns:\n            :obj:`TaskAlignedAssignResult`: The assign result.\n        \"\"\"\n        anchors = anchors[:, :4]\n        num_gt, num_bboxes = gt_bboxes.size(0), anchors.size(0)\n        # compute alignment metric between all bbox and gt\n        # \u8ba1\u7b97\u9884\u6d4b\u6846\u4e0eGT\u6846\u4e4b\u95f4\u7684IoU\uff0c\u5f62\u72b6\u4e3a [num_bboxes, num_gt]\n        overlaps = self.iou_calculator(decode_bboxes, gt_bboxes).detach()\n        # \u8ba1\u7b97\u6bcf\u4e2a\u9884\u6d4b\u6846\u9884\u6d4b\u4e3aGT\u7684\u5f97\u5206\uff0c\u5f62\u72b6\u4e3a [num_bboxes, num_gt]\n        bbox_scores = pred_scores[:, gt_labels].detach()\n        # \u6bcf\u4e2aanchor\u5206\u7c7b\u4e00\u4e2aGT\uff0c\u8fd9\u91cc\u5148\u9ed8\u8ba4\u4e3a0\n        # assign 0 by default\n        assigned_gt_inds = anchors.new_full((num_bboxes, ),\n                                            0,\n                                            dtype=torch.long)\n        # \u6bcf\u4e2aanchor\u7684\u9884\u6d4b\u503ct\n        assign_metrics = anchors.new_zeros((num_bboxes, ))\n\n        if num_gt == 0 or num_bboxes == 0:\n            # No ground truth or boxes, return empty assignment\n            max_overlaps = anchors.new_zeros((num_bboxes, ))\n            if num_gt == 0:\n                # No gt boxes, assign everything to background\n                assigned_gt_inds[:] = 0\n            if gt_labels is None:\n                assigned_labels = None\n            else:\n                assigned_labels = anchors.new_full((num_bboxes, ),\n                                                   -1,\n                                                   dtype=torch.long)\n            assign_result = AssignResult(\n                num_gt, assigned_gt_inds, max_overlaps, labels=assigned_labels)\n            assign_result.assign_metrics = assign_metrics\n            return assign_result\n\n        # select top-k bboxes as candidates for each gt\n        # \u5bf9\u6bcf\u4e2aGT \u9009\u62e9top-k\u7684anchor\u4f5c\u4e3a\u5019\u9009anchor\n        # \u8ba1\u7b97 t, shape = [ num_bboxes, num_gt ]\n        alignment_metrics = bbox_scores**alpha * overlaps**beta\n        topk = min(self.topk, alignment_metrics.size(0))\n        # candidate_idxs: [top_k, num_gt]\n        _, candidate_idxs = alignment_metrics.topk(topk, dim=0, largest=True)\n        # candidate_metrics: [top_k, num_gt] top_k\u7684\u5bf9\u9f50\u6307\u6807\n        candidate_metrics = alignment_metrics[candidate_idxs,torch.arange(num_gt)]\n        # \u662f\u5426\u662f\u6709\u6548\u7684GT\u6846\u6807\u5fd7\uff0c\u8981\u6c42\u5bf9\u5e94t\u503c\u4e0d\u4e3a0\n        is_pos = candidate_metrics &gt; 0\n\n\n        # shape [num_bboxes, ]\n        # limit the positive sample's center in gt\n        anchors_cx = (anchors[:, 0] + anchors[:, 2]) / 2.0\n        anchors_cy = (anchors[:, 1] + anchors[:, 3]) / 2.0\n        # candidate_idxs: [top_k, num_gt] \n        # \u5c06 gt_index \u6309\u7167 \u4e00\u7ef4\u5c55\u5f00\uff0c\u5e76\u6309\u7167\u4e00\u7ef4array\u8fdb\u884c\u7d22\u5f15\uff0c\u4e0b\u9762\u662f\u8f6c\u6362\uff0c\u52a0\u7684\u662f\u6bcf\u4e00\u884c\u7684\u8d77\u59cbindex\n        for gt_idx in range(num_gt):\n            candidate_idxs[:, gt_idx] += gt_idx * num_bboxes\n        # shape: [ num_gt \\times num_bboxes ]\n        ep_anchors_cx = anchors_cx.view(1, -1).expand(\n            num_gt, num_bboxes).contiguous().view(-1)\n        ep_anchors_cy = anchors_cy.view(1, -1).expand(\n            num_gt, num_bboxes).contiguous().view(-1)\n        candidate_idxs = candidate_idxs.view(-1)\n\n        # calculate the left, top, right, bottom distance between positive\n        # bbox center and gt side\n        # \u6311\u51fatop_k\u9884\u6d4b\u6846\u6240\u5bf9\u5e94\u7684anchor_center\n        l_ = ep_anchors_cx[candidate_idxs].view(-1, num_gt) - gt_bboxes[:, 0]\n        t_ = ep_anchors_cy[candidate_idxs].view(-1, num_gt) - gt_bboxes[:, 1]\n        r_ = gt_bboxes[:, 2] - ep_anchors_cx[candidate_idxs].view(-1, num_gt)\n        b_ = gt_bboxes[:, 3] - ep_anchors_cy[candidate_idxs].view(-1, num_gt)\n        # [topk,4,num_gt] \u4fdd\u8bc1nchor\u4e2d\u5fc3\u9700\u8981\u4f4d\u4e8eGT\u5185\u90e8\u624d\u53ef\u4ee5\uff0c\u5426\u5219\u5bf9\u4e8eanchor-free\u6765\u8bf4\n        # center\u5230\u56db\u4e2a\u8fb9\u7684\u8ddd\u79bb\u663e\u5f97\u4e0d\u5408\u7406\n        is_in_gts = torch.stack([l_, t_, r_, b_], dim=1).min(dim=1)[0] &gt; 0.01\n        # [topk, num_gt]\n        is_pos = is_pos &amp; is_in_gts\n\n        # \u4fdd\u8bc1\u4e00\u4e2aanchor\u53ea\u80fd\u5bf9\u5e94\u4e00\u4e2aGT\u6846\n        # \u5982\u679c\u4e00\u4e2aanchor box\u53ea\u80fd\u8d1f\u8d23\u4e00\u4e2agt\u7684\u56de\u5f52 \u4e0e\u4e4b\u5bf9\u5e94\u6700\u9ad8iou\u7684GT\u624d\u4f1a\u9009\u62e9\n        # if an anchor box is assigned to multiple gts,\n        # the one with the highest iou will be selected.\n        # [num_gt, num_bboxes]\n        overlaps_inf = torch.full_like(overlaps, -INF).t().contiguous().view(-1)\n        # [top_k X num_gt] \u7136\u540e\u6839\u636e is_pos \u7b5b\u9009\n        index = candidate_idxs.view(-1)[is_pos.view(-1)]\n        # \u6311\u9009\u51fa\u6709\u6548\u7684\u5019\u9009\u6846\uff0c\u5e76\u5c06\u6709\u6548\u7684\u5019\u9009\u6846\u8bb0\u5f55\u5230overlaps_inf\u4e2d\uff0coverlaps_inf\u5176\u4f59\u4e3a-inf\n        # [num_gt X top_k] -&gt; index\n        overlaps_inf[index] = overlaps.t().contiguous().view(-1)[index]\n        # [top_k X num_gt]\n        overlaps_inf = overlaps_inf.view(num_gt, -1).t()\n\n        # [num_bboxes] \u8868\u793a \u6bcf\u4e2a\u9884\u6d4b\u6846\u4e0eGT\u7684\u6700\u5927IoU\u503c\n        max_overlaps, argmax_overlaps = overlaps_inf.max(dim=1)\n        # num_bboxes\u4e2a\u9884\u6d4b\u6846\u5206\u914d\u54ea\u4e2aGT\u6846\n        assigned_gt_inds[\n            max_overlaps != -INF] = argmax_overlaps[max_overlaps != -INF] + 1\n        # assign_metrics \u5373\u5bf9 alignment_metrics \u4e2d\u7684\u6bcf\u4e00\u5217\u53d6\u6700\u5927\u503c\u7684\u7ed3\u679c\uff0c\u9700\u8981\u8fc7\u6ee4\u6389\u65e0\u6548\u6846\n        # \u7ed9\u6bcf\u4e2a\u9884\u6d4b\u6846\u7684t\u8d4b\u503c\uff0c \u5176t\u503c\u4e3a\u4e0e\u4e4b\u6700\u5927IOU\u7684GT\u8ba1\u7b97\u5f97\u5230\u7684t\u503c\n        # alignment_metrics:[top_k, num_gt]\n        # \u7b2c\u4e00\u4e2amax_overlaps != -INF\u8868\u793a\u5bf9\u884c\u7d22\u5f15\n        # \u7b2c\u4e8c\u4e2aargmax_overlaps[max_overlaps != -INF]\u8868\u793anum_gt\u4e2d\u54ea\u4e00\u4e2agt\u4e0e\u5f53\u524d\u884c\u6240\u5bf9\u5e94\u7684pred iou\u6700\u5927\n        assign_metrics[max_overlaps != -INF] = alignment_metrics[\n            max_overlaps != -INF, argmax_overlaps[max_overlaps != -INF]]\n\n        if gt_labels is not None:\n            # \u53d6\u51fa \u53ef\u4ee5\u5206\u914d\u4e3a\u6b63\u6837\u672c\u7684\u9884\u6d4b\u6846\u7684GT\u7c7b\u522b\n            assigned_labels = assigned_gt_inds.new_full((num_bboxes, ), -1)\n            pos_inds = torch.nonzero(\n                assigned_gt_inds &gt; 0, as_tuple=False).squeeze()\n            if pos_inds.numel() &gt; 0:\n                assigned_labels[pos_inds] = gt_labels[\n                    assigned_gt_inds[pos_inds] - 1]\n        else:\n            assigned_labels = None\n        assign_result = AssignResult(\n            num_gt, assigned_gt_inds, max_overlaps, labels=assigned_labels)\n        assign_result.assign_metrics = assign_metrics\n        return assign_result\n</code></pre> <p>\u4e0b\u9762\u5728\u770b\u635f\u5931\u51fd\u6570\u7684\u5b9e\u73b0\uff0c\u5bf9\u5e94\u6e90\u7801https://github.com/open-mmlab/mmdetection/blob/v2.28.1/mmdet/models/dense_heads/tood_head.py#L757</p> <pre><code>for gt_inds in class_assigned_gt_inds:\n    gt_class_inds = pos_inds[sampling_result.pos_assigned_gt_inds == gt_inds]\n    pos_alignment_metrics = assign_metrics[gt_class_inds]\n    pos_ious = assign_ious[gt_class_inds]\n    # \u5c06 t \u5f52\u4e00\u5316\u4e3a t^{hat}\uff0c\u5e76\u4e14\u6700\u5927\u503c\u9650\u5236\u4e3a\u5f53\u524dGT\u4e0e\u6240\u6709\u9884\u6d4b\u6846\u7684iou\u7684\u6700\u5927\u503c\n    pos_norm_alignment_metrics = pos_alignment_metrics / (\n        pos_alignment_metrics.max() + 10e-8) * pos_ious.max()\n    norm_alignment_metrics[gt_class_inds] = pos_norm_alignment_metrics\n</code></pre> <p>https://github.com/open-mmlab/mmdetection/blob/v2.28.1/mmdet/models/dense_heads/tood_head.py#L340</p> <pre><code>          labels = labels.reshape(-1)\n        alignment_metrics = alignment_metrics.reshape(-1)\n        label_weights = label_weights.reshape(-1)\n        # \u5206\u7c7b\u7684\u6807\u7b7e\u4e00\u5f00\u59cb\u8bbe\u7f6e\u4e3alabel \u540e\u9762\u8bbe\u7f6e\u4e3a\\hat t\n        targets = labels if self.epoch &lt; self.initial_epoch else (\n            labels, alignment_metrics)\n        cls_loss_func = self.initial_loss_cls \\\n            if self.epoch &lt; self.initial_epoch else self.loss_cls\n\n        loss_cls = cls_loss_func(\n            cls_score, targets, label_weights, avg_factor=1.0)\n\n        # FG cat_id: [0, num_classes -1], BG cat_id: num_classes\n        bg_class_ind = self.num_classes\n        pos_inds = ((labels &gt;= 0)\n                    &amp; (labels &lt; bg_class_ind)).nonzero().squeeze(1)\n\n        if len(pos_inds) &gt; 0:\n            pos_bbox_targets = bbox_targets[pos_inds]\n            pos_bbox_pred = bbox_pred[pos_inds]\n            pos_anchors = anchors[pos_inds]\n\n            pos_decode_bbox_pred = pos_bbox_pred\n            pos_decode_bbox_targets = pos_bbox_targets / stride[0]\n\n            # \u8bbe\u7f6e\u56de\u5f52\u7684loss\u6743\u91cd\u4e3a\\hat t\n            # regression loss\n            pos_bbox_weight = self.centerness_target(\n                pos_anchors, pos_bbox_targets\n            ) if self.epoch &lt; self.initial_epoch else alignment_metrics[\n                pos_inds]\n\n            loss_bbox = self.loss_bbox(\n                pos_decode_bbox_pred,\n                pos_decode_bbox_targets,\n                weight=pos_bbox_weight,\n                avg_factor=1.0)\n        else:\n            loss_bbox = bbox_pred.sum() * 0\n            pos_bbox_weight = bbox_targets.new_tensor(0.)\n</code></pre> <p>\u5177\u4f53\u7684loss \u914d\u7f6e\u53ef\u4ee5\u770bTOOD\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u53ef\u4ee5\u6e05\u6670\u5730\u770b\u5230\u662fFocal Loss\u548cGIoU Loss\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#33-damo-yoloalignedota","title":"3.3 \u62d3\u5c55\uff1aDAMO-YOLO\u4e2d\u7684AlignedOTA","text":"<p>\u6700\u8fd1\u4e5f\u5728\u5173\u6ce8\u7684\u53e6\u5916\u4e00\u9879\u5de5\u5177\uff0c\u4e3a\u52a8\u6001\u6807\u7b7e\u5206\u914d\u63d0\u4f9b\u4e86\u53e6\u5916\u4e00\u79cd\u601d\u8def\u3002TOOD\u4e0d\u662f\u8bf4\u5206\u7c7b\u4efb\u52a1\u4e0e\u56de\u5f52\u4efb\u52a1\u7684\u5bf9\u9f50\u5b58\u5728\u95ee\u9898\u4e48\uff0c\u90a3\u4e48\u662f\u4e0d\u662f\u5c06SimOTA\u4e2d\u7684metric\u6539\u6210\u65e2\u8003\u8651\u5b9a\u4f4d\u53c8\u8003\u8651\u5206\u7c7b\u7684metric\u5c31\u53ef\u4ee5\u4e86\u5462\u3002</p> <p>DAMO-YOLO\u5c31\u505a\u4e86\u8fd9\u6837\u4e00\u4ef6\u4e8b\uff0c\u5176\u5c06Cost\u77e9\u9635\u5b9a\u4e49\u4e3areg\u4e0ecls\u5171\u540c\u7ec4\u6210\u7684\u4e1c\u897f\u3002</p> <p></p> <p>\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6bd4TOOD\u597d\u4e00\u70b9\u70b9</p> <p></p> <p>\u8fd9\u8bf4\u660e\u4e86\u4ec0\u4e48\u5462\uff1f\u6211\u4e2a\u4eba\u611f\u89c9\u8fd9\u8bf4\u660e\u4ee5\u4e0b\u4e24\u70b9\uff1a</p> <ol> <li>\u8003\u8651\u4e86\u5b9a\u4f4d\u4e0e\u5206\u7c7b\u5bf9\u9f50\u540e\uff0cSimOTA\u7684dynamic k\u7b56\u7565\u4e0d\u662f\u5f88\u91cd\u8981</li> <li>TOOD\u4e2dt\u7684\u8bbe\u5b9a\u4e0d\u5c40\u9650\u67d0\u4e00\u79cd\u65b9\u5f0f\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u5206\u7c7b\u548c\u5b9a\u4f4d\u56e0\u7d20\u5373\u53ef</li> </ol>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#_3","title":"\u56db\u3001\u5b9e\u9a8c\u8bc1\u660e","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#41","title":"4.1 \u5b9e\u9a8c\u8bbe\u7f6e","text":"<p>\u5728coco2017 \u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\uff0c\u6d88\u878d\u5b9e\u9a8c\u91c7\u7528\u9a8c\u8bc1\u96c6\uff0c\u4e0eSOTA\u6a21\u578b\u7684\u6bd4\u8f83\u91c7\u7528\u9a8c\u8bc1\u96c6</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#42-head","title":"4.2 head\u7ed3\u6784\u7684\u6709\u6548\u6027","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#43-tal","title":"4.3 TAL\u7684\u6709\u6548\u6027","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#44-t-headtal","title":"4.4 T-head\u4e0eTAL\u8054\u5408\u4f5c\u7528\u7684\u6709\u6548\u6027","text":"<p>\u4e0b\u56fe\u8bc1\u660e\u4e86TAL\u4e0eTAP\u8054\u5408\u540e\u7684\u6709\u6548\u6027</p> <p></p> <p>\u4e0b\u56fe\u8bc1\u660e\u4e86TOOD\u7684\u6709\u6548\u6027\uff0c\u6da8\u4e86\u6574\u6574\u56db3\u4e2a\u70b9\u8fd8\u662f\u6bd4\u8f83\u660e\u663e\u7684</p> <p></p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#45","title":"4.5 \u8d85\u53c2\u641c\u7d22","text":"<p>\\(\\alpha\\) \u4e0e \\(\\beta\\) \u5206\u522b\u53d61\u548c6\u65f6\u8f83\u4e3a\u5408\u9002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#46-sota","title":"4.6 \u4e0eSOTA\u6a21\u578b\u7684\u6bd4\u8f83","text":"<p>\u5728coco-test\u4e0a\u7684\u6bd4\u8f83</p> <p></p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/#_4","title":"\u4e94\u3001\u603b\u7ed3","text":"<p>\u672c\u6587\u8be6\u7ec6\u4ecb\u7ecd\u4e86TOOD\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u4ee5\u53ca\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7TOOD\u53ef\u4ee5\u770b\u51fa\uff0c\u68c0\u6d4b\u6a21\u578b\u7684\u6700\u4f18\u9884\u6d4b\u4e0d\u4ec5\u5e94\u8be5\u662f\u5177\u6709\u8f83\u9ad8\u7684\u5206\u7c7b\u5f97\u5206\u800c\u4e14\u8fd8\u5e94\u8be5\u5177\u6709\u51c6\u786e\u7684\u5b9a\u4f4d\uff0c\u8fd9\u610f\u5473\u7740\u5728\u6a21\u578b\u8bad\u7ec3\u65f6\u5206\u7c7b\u5934\u4e0e\u56de\u5f52\u5934\u5177\u6709\u8f83\u9ad8\u4e00\u81f4\u6027\u7684Anchor\u5c24\u4e3a\u91cd\u8981\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/","title":"\u5173\u4e8eConvNext\u82e5\u5e72\u7ec6\u8282\u7684\u89e3\u8bfb\u4e0e\u8ba8\u8bba","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#_1","title":"\u4e00\u3001\u524d\u8a00","text":"<p>\u6587\u7ae0\u94fe\u63a5\uff1a https://arxiv.org/abs/2201.03545 ConvNext code\u5730\u5740\uff1a https://github.com/facebookresearch/ConvNeXt</p> <p>\u4e3a\u4e86\u7814\u7a76ConvNext\u548c\u540e\u7eed\u7684\u6a21\u578b\uff0c\u8d70\u51fa\u6821\u56ed\u7684\u6211\u4e24\u5468\u4e4b\u524d\u7ec4\u88c5\u4e86\u81ea\u5df1\u7684GPU\u4e3b\u673a\uff0c\u4e00\u5f20RTX 2080Ti + AMD3600X + \u4e00\u4e2a32\u5bf8\u76844k\u663e\u793a\u5c4f + \u5404\u79cd\u514d\u8d39\u7684\u8fdc\u7a0b\u684c\u9762\u8f6f\u4ef6+\u5404\u79cd\u514d\u8d39\u7684\u5185\u7f51\u7a7f\u900f\u670d\u52a1 \u6070\u597d\u6ee1\u8db3\u7684\u6211\u7684\u6298\u817e\u9700\u6c42\u548c\u89c2\u5f71\u76f8\u5173\u7684\u5a31\u4e50\u9700\u6c42\uff0c\u53c8\u53ef\u4ee5\u5f00\u5f00\u5fc3\u5fc3\u505acv\u76f8\u5173\u7814\u7a76\u4e86\u3002</p> <p>\u5173\u4e8eConvNext\u7684\u7814\u7a76\u6211\u91c7\u7528\u7684\u662f\u6253\u7834\u7802\u9505\u95ee\u5230\u5e95\u7684\u65b9\u5f0f\uff0c\u4ece\u8bba\u6587\u62d3\u5c55\u5230\u76f8\u5173\u8bba\u6587\u518d\u5230\u6a21\u578b\u8fd0\u884c\u65f6\u95f4\u4e0a\u7684\u8bc4\u4f30\u548c\u90e8\u7f72\u4f18\u5316\uff0c\u6781\u529b\u5730\u53bb\u5f04\u660e\u767d\u6bcf\u4e00\u5904\u7ec6\u8282\uff0c\u52a0\u4e0a\u56fd\u5e86\u5047\u671f\u8017\u65f6\u4e24\u5468\u5de6\u53f3\u3002\u8fd9\u4e24\u5468\u7684\u65f6\u95f4\u770b\u522b\u4eba\u7684\u6e90\u7801\u4e5f\u5b66\u5230\u4e86\u5f88\u591a\u4e1c\u897f\u3002\u987a\u4fbf\u4ee5\u9700\u6c42\u4ee3\u66ff\u7a7a\u60f3\uff0c\u628a\u81ea\u5df1\u914d\u7684GPU\u73af\u5883\u5b8c\u5584\u4e00\u4e0b\u3002</p> <p>\u672c\u6587\u6d89\u53ca\u7684\u6240\u6709\u6e90\u7801\u53c2\u89c1\u5982\u4e0bgit\u5730\u5740</p> <p>https://github.com/thb1314/convnext-depoly</p> <p>\u73af\u5883\u914d\u7f6e\u8fd8\u8bf7\u67e5\u9605github\u5730\u5740\u4e2d\u7684README</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#convnext_1","title":"\u4e8c\u3001ConvNext\u7684\u521d\u6b65\u8ba4\u8bc6","text":"<p>\u4e2a\u4eba\u5bf9\u4e8eConvNext\u662f\u65e2\u559c\u6b22\u53c8\u6709\u4e00\u70b9\u4e0d\u6ee1\u610f\u3002</p> <p>\u5bf9\u5176\u559c\u6b22\u4f53\u73b0\u5728\u5176\u91c7\u7528\u9b54\u6cd5\u6253\u8d25\u9b54\u6cd5\u7684\u65b9\u5f0f\uff0c\u201c\u6012\u603c\u201d\u4e86\u70ed\u5ea6\u4e0d\u51cf\u7684transformer\uff0c\u5927\u58f0\u7684\u544a\u8bc9\u4e86VIT\u9635\u8425\uff0c\u5377\u79ef\u7528\u4e86VIT\u91c7\u7528\u7684\u90a3\u4e9btrick\u4e5f\u53ef\u4ee5work\uff0c\u5e76\u4e14\u7cbe\u5ea6\u548c\u901f\u5ea6\u53d6\u820d\u540e\u7684\u6027\u4ef7\u6bd4\u66f4\u9ad8\u3002\u7531\u6b64\u4e5f\u5f15\u51fa\u6765\u4e00\u4e2a\u95ee\u9898\uff0c\u6a21\u578b\u7cbe\u5ea6\u7684\u63d0\u5347\u5230\u5e95\u662f\u5f52\u529f\u4e8e\u8bad\u7ec3trick\u8fd8\u662f\u7ed3\u6784\u672c\u8eab\u5462\uff1f \u8bba\u6587\u4f5c\u8005\u81ea\u7136\u662f\u503e\u5411\u4e8e\u8bc1\u660e\u6a21\u578b\u7ed3\u6784\u4e0a\u7684\u4f18\u8d8a\u6027\uff0c\u5e76\u8bb2\u4e86\u901a\u7bc7\u7684\u6545\u4e8b\u6765\u8bf4\u670d\u81ea\u5df1\u548c\u8bfb\u8005\uff0c\u53ef\u662f\u5b9e\u9a8c\u7684\u5b8c\u5907\u6027\u548c\u516c\u5e73\u6027\u771f\u7684\u53ef\u4ee5\u4fdd\u8bc1\u4e48\uff1f\u6211\u4eec\u5230\u5e95\u662f\u6839\u636e\u5b9e\u9a8c\u7ed3\u679c\u53cd\u63a8\u539f\u7406\u8fd8\u662f\u6839\u636e\u539f\u7406\u6216\u8005\u5047\u8bbe\u6765\u505a\u5b9e\u9a8c\u8bc1\u660e\u6211\u4eec\u7684\u7814\u7a76\u5462\uff1f</p> <p>\u672c\u6587\u5e76\u4e0d\u662f\u60f3\u6279\u8bc4transformer\uff0c\u800c\u662f\u501f\u6b64\u673a\u4f1a\u603c\u4e00\u4e0b\u8e6dtransformer\u70ed\u5ea6\u7684\u884c\u4e3a\uff0c\u51e0\u4e4e\u6240\u6709cv\u7684\u65b9\u5411\u90fd\u60f3\u7740\u5f80transformer\u7684\u65b9\u5411\u53bb\u601d\u8003\uff0c\u611f\u89c9\u8fd9\u53cd\u800c\u5bf9cv\u4e2d\u5355\u4e2a\u65b9\u5411\u7684\u53d1\u5c55\u5f62\u6210\u4e00\u79cd\u9650\u5236\uff0c\u9650\u5236\u4e86\u89e3\u51b3\u95ee\u9898\u65f6\u601d\u7ef4\u7684\u53d1\u6563\u6027\u3002</p> <p>ConvNext\u7684\u51fa\u73b0\u5728\u544a\u8bc9\u540c\u884c\u4eec\uff0c\u914d\u5907\u4e86\u8fd9\u4e9b\u6a21\u578b\u8bbe\u8ba1\u4e0a\u7684\u65b9\u6cd5\u548c\u8bad\u7ec3\u65b9\u6cd5\uff0c\u201c\u6211\u4e0a\u6211\u4e5f\u884c\u201d\u3002</p> <p>\u5173\u4e8eConvNext\u7684\u4e0d\u8db3\u4e4b\u5904\u4e3b\u8981\u8fd8\u662f\u4f53\u73b0\u5728\u5728\u8861\u91cf\u6a21\u578b\u8fd0\u884c\u901f\u5ea6\u4e0a\u6ca1\u6709\u5c06\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u8003\u8651\u8fdb\u53bb\uff0c\u800c\u662f\u91c7\u7528FLOPs\u3002\u5f53\u7136\u8fd9\u4e5f\u662f\u8bbe\u8ba1\u4e0a\u7684\u6280\u5de7\uff0c\u56e0\u4e3a\u76f8\u540c\u53c2\u6570\u60c5\u51b5\u4e0b\u7684Depthwise Convolution\u4e0ePlain Convolution\u76f8\u6bd4FLOPs\u5f88\u4f4e\uff0c\u4f46\u662f\u5176\u8fd0\u884c\u901f\u5ea6\u771f\u7684\u5feb\u4e48\uff1f\u636e\u6211\u6240\u77e5\u7684\u662f\uff0c\u5728GPU\u4e0a\u8fd9\u79cd\u8bbe\u8ba1\u662f\u6ca1\u6709\u4f18\u52bf\u7684\uff0c\u5b9e\u9645\u6d4b\u8bd5\u7684\u65f6\u5019\u4f1a\u5f88\u6162\u3002</p> <p>\u6b64\u5916\uff0cConvNext\u8fc7\u4e8e\u6a21\u4effVIT\uff0c\u91c7\u7528LayerNorm\u548cGelu\u6fc0\u6d3b\u51fd\u6570\uff0c\u963b\u788d\u4e86Conv+BN+Relu\u8fd9\u79cd\u7ecf\u5178\u7b97\u5b50\u7684\u5408\u5e76\u3002\u6216\u8bb8\u6211\u6709\u70b9\u9e21\u86cb\u91cc\u6311\u9aa8\u5934\u5427\uff0c\u8fd8\u662f\u5e0c\u671b\u771f\u7684\u5b58\u5728\u4e00\u79cd\u66f4\u5b8c\u7f8e\u7684\u6a21\u578b\uff0c\u5728\u5b9e\u9645\u63a8\u7406\u65f6latency\u66f4\u5c0f\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#convnext_2","title":"\u4e09\u3001ConvNext\u771f\u7684\u6027\u4ef7\u6bd4\u5f88\u9ad8\u4e48","text":"<p>\u5728\u7814\u7a76\u672c\u7ae0\u5185\u5bb9\u65f6\uff0c\u6211\u662f\u5e26\u7740\u6000\u7591\u7684\u6001\u5ea6\u53bb\u505a\u5b9e\u9a8c\u7684\uff0c\u5c1d\u8bd5\u53bb\u627e\u5230\u4e00\u4e2a\u6a21\u578b\u6bd4ConvNext\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u66f4\u77ed\u5e76\u4e14\u7cbe\u5ea6\u76f8\u5f53\u3002\u8fd9\u7c7b\u6a21\u578b\u6211\u627e\u5230\u4e86\uff0c\u4f46\u662f\u5374\u6ca1\u6709\u8bf4\u670d\u529b\uff0c\u8bf7\u770b\u4e0b\u9762\u7684\u5173\u952e\u4ee3\u7801\uff1a</p> <pre><code>import torch\n\nfrom ConvNeXt.models.convnext import convnext_tiny\nmodel = convnext_tiny(pretrained=False, in_22k=False)\n\nstate_dict = torch.load('./convnext_tiny_1k_224_ema.pth', map_location='cpu')['model']\nmodel.load_state_dict(state_dict)\nmodel = model.eval()\ndevice = torch.device('cuda:0')\nconvnext_tiny = model.to(device)\n\ndel output\ndel image\ntorch.cuda.empty_cache()\n\nimport time\nimport numpy as np\n\n\ndef benchmark(model, input_shape=(512, 3, 224, 224), dtype='fp32', nwarmup=50, nruns=100):\n    torch.cuda.empty_cache()\n    old_value = torch.backends.cudnn.benchmark\n    torch.backends.cudnn.benchmark = True\n    input_data = torch.randn(input_shape)\n    input_data = input_data.to(\"cuda\")\n    if dtype=='fp16':\n        input_data = input_data.half()\n\n    print(\"Warm up ...\")\n    with torch.no_grad():\n        for _ in range(nwarmup):\n            features = model(input_data)\n    torch.cuda.synchronize()\n    print(\"Start timing ...\")\n    timings = []\n    with torch.no_grad():\n        for i in range(1, nruns+1):\n            start_time = time.time()\n            pred_loc  = model(input_data)\n            torch.cuda.synchronize()\n            end_time = time.time()\n            timings.append(end_time - start_time)\n            if i%10==0:\n                print('Iteration %d/%d, avg batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n    input_size = tuple(input_data.size())\n    del input_data\n    del features\n    torch.cuda.empty_cache()\n    torch.backends.cudnn.benchmark = old_value\n    print(\"Input shape:\", input_size)\n    print('Average throughput: %.2f images/second'%(input_shape[0]/np.mean(timings)))\n\nconvnext_tiny = convnext_tiny.to(device)\n# 82.1 82.9\nbenchmark(convnext_tiny, input_shape=(384, 3, 224, 224))\n\"\"\"\nWarm up ...\nStart timing ...\nIteration 10/100, avg batch time 577.78 ms\nIteration 20/100, avg batch time 578.72 ms\nIteration 30/100, avg batch time 579.25 ms\nIteration 40/100, avg batch time 579.74 ms\nIteration 50/100, avg batch time 580.26 ms\nIteration 60/100, avg batch time 580.65 ms\nIteration 70/100, avg batch time 581.08 ms\nIteration 80/100, avg batch time 581.53 ms\nIteration 90/100, avg batch time 581.93 ms\nIteration 100/100, avg batch time 582.35 ms\nInput shape: (384, 3, 224, 224)\nAverage throughput: 659.40 images/second\n\"\"\"\n\n\nresnetv2_50_distilled = timm.create_model('resnetv2_50x1_bit_distilled', pretrained=False)\nresnetv2_50_distilled = resnetv2_50_distilled.eval()\nresnetv2_50_distilled = resnetv2_50_distilled.to(device)\n# 82.822\nbenchmark(resnetv2_50_distilled, input_shape=(384, 3, 224, 224))\n\"\"\"\nWarm up ...\nStart timing ...\nIteration 10/100, avg batch time 422.06 ms\nIteration 20/100, avg batch time 422.22 ms\nIteration 30/100, avg batch time 422.29 ms\nIteration 40/100, avg batch time 422.41 ms\nIteration 50/100, avg batch time 422.45 ms\nIteration 60/100, avg batch time 422.54 ms\nIteration 70/100, avg batch time 422.62 ms\nIteration 80/100, avg batch time 422.71 ms\nIteration 90/100, avg batch time 422.85 ms\nIteration 100/100, avg batch time 422.98 ms\nInput shape: (384, 3, 224, 224)\nAverage throughput: 907.84 images/second\n\"\"\"\n\n\nresnet50d = timm.create_model('resnet50d', pretrained=False)\nresnet50d = resnet50d.eval()\nresnet50d = resnet50d.to(device)\n# 80.528\nbenchmark(resnet50d, input_shape=(384, 3, 224, 224))\n\"\"\"\nWarm up ...\nStart timing ...\nIteration 10/100, avg batch time 411.29 ms\nIteration 20/100, avg batch time 411.80 ms\nIteration 30/100, avg batch time 412.04 ms\nIteration 40/100, avg batch time 412.22 ms\nIteration 50/100, avg batch time 412.38 ms\nIteration 60/100, avg batch time 412.51 ms\nIteration 70/100, avg batch time 412.64 ms\nIteration 80/100, avg batch time 412.76 ms\nIteration 90/100, avg batch time 412.86 ms\nIteration 100/100, avg batch time 413.02 ms\nInput shape: (384, 3, 224, 224)\nAverage throughput: 929.73 images/second\n\"\"\"\n\n\n## \u6d4b\u8bd5FLOPs\n\nimport thop\n\nx = torch.randn(1,3,224,224)\nconvnext_tiny = convnext_tiny.to('cpu')\nflops, params = thop.profile(convnext_tiny,inputs=(x,))\nflops, params = thop.clever_format((flops, params))\nprint(flops, params) # 4.46G 28.57M\n\n\nfrom thop.vision.calc_func import calculate_parameters, calculate_zero_ops, calculate_conv2d_flops\ndef count_your_model(model, x, y):\n    x = x[0]\n    model.total_params[0] = calculate_parameters(model.parameters())\n    model.total_ops += calculate_conv2d_flops(input_size = list(x.shape),\n        output_size = list(y.shape),\n        kernel_size = list(model.weight.shape),\n        groups = model.groups,\n        bias = model.bias)\n\nx = torch.randn(1,3,224,224)\nresnetv2_50_distilled = resnetv2_50_distilled.to('cpu')\nstd_conv_type = type(resnetv2_50_distilled.stem[0])\nflops, params = thop.profile(resnetv2_50_distilled, inputs=(x,), custom_ops={std_conv_type: count_your_model})\nflops, params = thop.clever_format((flops, params))\nprint(flops, params) # 4.09M 25.50M\n\nx = torch.randn(1,3,224,224)\nresnet50d = resnet50d.to('cpu')\nflops, params = thop.profile(resnet50d,inputs=(x,))\nflops, params = thop.clever_format((flops, params))\nprint(flops, params) # 4.38G 25.58M\n</code></pre> <p>\u7ed3\u8bba\uff1a FLOPs\u5e76\u4e0d\u80fd\u53cd\u6620\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\uff0c\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u8fd8\u4e0e\u5185\u5b58\u8bbf\u95ee\u5f00\u9500\u3001\u7b97\u5b50\u7684\u5177\u4f53\u5b9e\u73b0\u548c\u786c\u4ef6\u7b49\u56e0\u7d20\u76f8\u5173\u8054\uff0c\u4f46\u662f\u5bf9\u4e8e\u540c\u4e00\u7c7b\u6a21\u578b\u53ef\u4ee5\u91c7\u7528FLOPs\u7684\u65b9\u5f0f\u6765\u8861\u91cf\u5b9e\u9645\u8fd0\u884c\u901f\u5ea6\u3002</p> <p>\u6211\u91c7\u7528timm\u5e93\u4e2d\u7684\u6a21\u578b\u4f5c\u4e3a\u6a21\u578b\u6765\u6e90\uff0c\u91c7\u7528pytorch\u4f5c\u63a8\u7406\u5e76\u6d4b\u901f\uff0c\u4fdd\u8bc1\u8f93\u5165\u5206\u8fa8\u7387\u53ef\u4ee5\u8fbe\u5230\u590d\u73b0\u627f\u8bfa\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u540cbatch\u7684\u63a8\u7406\u65f6\u95f4\u4f5c\u4e3a\u6bd4\u8f83\u7ed3\u679c\uff0c\u6574\u5408\u4e0a\u9762\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u5236\u8868\u5982\u4e0b\uff1a</p> \u6a21\u578b\u540d\u79f0 \u8f93\u5165\u5206\u8fa8\u7387 batch_size Param(M) FLOPs(G) throughput(images/second) top-1 acc convnext_tiny 224x224 384 28.57 4.46 659.40 82.1/82.9(imagenet21K) resnetv2_50_distilled 224x224 384 25.50 4.09 907.84 82.8 resnet50d 224x224 384 25.58 4.38 929.73 80.5 <p>\u4ece\u4e0a\u9762\u5b9e\u9a8c\u53ef\u4ee5\u770b\u51fa\uff1a</p> <ol> <li>FLOPs\u76f8\u540c\u60c5\u51b5\u4e0b\uff0cconvnext_tiny\u7684\u541e\u5410\u91cf\u6bd4\u5176\u4ed6\u6a21\u578b\u8981\u5c0f</li> <li>\u4e0eresnetv2_50_distilled\u76f8\u6bd4\uff0c\u7cbe\u5ea6\u76f8\u540c\u60c5\u51b5\u4e0b\uff0cresnetv2_50_distilled\u63a8\u7406\u901f\u5ea6\u66f4\u5feb</li> <li>\u4e0eresnetv2_50_distilled\u76f8\u6bd4\u8f83\uff0c\u5b9e\u9a8c\u6761\u4ef6\u662f\u4e0d\u540c\u7684\uff0cresnetv2_50_distilled\u662f\u91c7\u7528\u5728imagenet21k\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u5f97\u5230\u7684\uff0c\u800cconvnext_tiny\u768482.9\u7684\u7cbe\u5ea6\u662f\u5728imagenet21k\u4e0a\u9884\u8bad\u7ec3\u7136\u540e\u5728imagenet1k\u4e0a\u8bad\u7ec3\u5f97\u5230\u7684\uff0c\u76f8\u540c\u70b9\u662f\u4e24\u8005\u90fd\u91c7\u7528\u4e86imagenet21k\u6570\u636e\u96c6\u3002</li> <li>\u5404\u81ea\u91c7\u7528\u5404\u81eatrick\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u7136resnetv2_50_distilled\u6027\u4ef7\u6bd4\u66f4\u9ad8\u4e00\u4e9b\uff0c\u4f46\u662f\u8fc1\u79fb\u5b66\u4e60\u60c5\u51b5\u672a\u77e5\u3002</li> </ol> <p>\u8fdb\u884c\u4e0a\u9762\u5b9e\u9a8c\u65f6\uff0c\u6211\u662f\u6709\u5e26\u7740\u5bf9convnext\u7684\u504f\u89c1\u53bb\u8fdb\u884c\u7684\uff0c\u53ef\u968f\u7740\u5b9e\u9a8c\u7684\u8fdb\u884c\uff0c\u53d1\u73b0\u627e\u5230\u4e00\u4e2a\u6bd4convnext\u6a21\u578b\u66f4\u597d\u7684\u9009\u62e9\u7684\u5b9e\u5728\u4e0d\u597d\u627e\uff0c\u8fdb\u800c\u7ea0\u6b63\u4e86\u6211\u5bf9convnext\u7684\u770b\u6cd5\u3002</p> <p>\u90a3\u4e48\uff0cconvnext\u7684\u5b9e\u9645\u90e8\u7f72\u73af\u5883\u4e0b\u7684\u901f\u5ea6\u600e\u4e48\u6837\u5462\uff1f\u8fd9\u91cc\u5f15\u7528\u4e24\u4e2a\u8868\u683c</p> Accelerator R50 MV2 MV3 SV2 Sq SwV2 De Ef0 CNext RN4X RN64X CPU 29,840 11,870 6,498 6,607 8,717 52,120 14,952 14,089 33,182 11,068 41,301 CPU + ONNXRuntime 10,666 2,564 4,484 2,479 3,136 50,094 10,484 8,356 28,055 1,990 14,358 GPU 1,982 4,781 3,689 4,135 1,741 6,963 3,526 5,817 3,588 5,886 6,050 GPU + ONNXRuntime 2,715 1,107 1,128 1,392 851 3,731 1,650 2,175 2,789 1,525 3,280 GPU + ONNX + TensorRT 1,881 670 570 404 443 3,327 1,170 1,250 2,630 1,137 2,283 <p>R50 - <code>resnet50</code>, MV2 - <code>mobilenet_v2</code>, MV3 - <code>mobilenet_v3_small</code>, SV2 - <code>shufflenet_v2_x0_5</code>, Sq - <code>squeezenet1_0</code>, SwV2 - <code>swinv2_cr_tiny_ns_224</code>, De - <code>deit_tiny_patch16_224</code>, Ef0 - <code>efficientnet_b0</code> , CNext - <code>convnext_tiny</code>, RN4X - <code>regnetx_004</code> , RN64X - <code>regnetx_064</code></p> Model Parameters (M) GFLOPS Top1 (%) Top5 (%) <code>resnet18</code> 11.7 1.8 69.76 89.08 <code>resnet50</code> 25.6 4.1 80.11 94.49 <code>mobilenet_v2</code> 3.5 0.3 71.87 90.29 <code>mobilenet_v3_small</code> 2.5 0.06 67.67 87.41 <code>shufflenet_v2_x0_5</code> 1.4 0.04 60.55 81.74 <code>squeezenet1_0</code> 1.2 0.8 58.10 80.42 <code>swinv2_cr_tiny_ns_224</code> 28.3 4.7 81.54 95.77 <code>deit_tiny_patch16_224</code> 5.7 1.3 72.02 91.10 <code>efficientnet_b0</code> 5.3 0.4 77.67 93.58 <code>convnext_tiny</code> 28.6 4.5 82.13 95.95 <code>regnetx_004</code> 5.2 0.4 72.30 90.59 <code>regnetx_064</code> 26.2 6.5 78.90 94.44 <p>\u4e0a\u8ff0\u8868\u683c\u5f15\u7528\u81ea https://github.com/roatienza/benchmark/tree/main#other-models</p> <p>\u53ef\u4ee5\u770b\u5230<code>convnext_tiny</code>\u76f8\u6bd4\u4e8e<code>swinv2_cr_tiny_ns_224</code>\u63a8\u7406\u65f6\u95f4\u66f4\u5c11\uff0c\u4e14\u7cbe\u5ea6\u66f4\u9ad8\u3002\u6211\u60f3\u8fd9\u662f<code>convnext</code>\u60f3\u8868\u8fbe\u7684\uff0c\u5373VIT\u6a21\u578b\u7684\u4f18\u8d8a\u6027\uff0c\u5e76\u975etransformer\u53ef\u4ee5\u6784\u9020\u957f\u8ddd\u79bb\u8054\u7cfb\u7684\u7279\u6027\u7684\u4f18\u8d8a\uff0c\u800c\u662f\u8bad\u7ec3\u6280\u5de7\u548c\u6a21\u578b\u8bbe\u8ba1\u4e0a\u7684\u4f18\u8d8a\uff0c\u5377\u79ef\u672c\u8eab\u5e76\u4e0d\u5dee\u3002</p> <p>\u53ef\u662f\uff0c7x7\u7684DW\u5377\u79ef\u3001Gelu\u3001LayerNorm\u8fd9\u4e9b\u5bf9\u90e8\u7f72\u4e0d\u662f\u5f88\u53cb\u597d\u7684\u7b97\u5b50\u7684\u5b58\u5728\u5bf9\u4e8e\u90e8\u7f72\u59cb\u7ec8\u662f\u4e00\u4e2a\u963b\u788d\uff0c\u6709\u6ca1\u6709\u66f4\u597d\u7684\u5462\uff1f\u7b54\u6848\u662f\u6709\u7684\u3002</p> <p></p> <p>\u4e0a\u56fe\u8282\u9009\u81eaNext-VIT\uff0c\u53ef\u4ee5\u770b\u5230Next-VIT\u7684\u5b9e\u9645\u63a8\u7406\u901f\u5ea6\u548c\u7cbe\u5ea6\u90fd\u66f4\u4f18\u3002</p> <p>Next-VIT\u8bb2\u4e86\u597d\u957f\u7684\u6545\u4e8b\u6765\u8bf4\u660e\u5176\u6240\u8bbe\u8ba1\u7684\u6a21\u578b\u66f4\u5229\u4e8e\u5b9e\u9645\u843d\u5730\u573a\u666f\uff0c\u6211\u4e2a\u4eba\u611f\u89c9\u6a21\u578b\u8bbe\u8ba1\u539f\u7406\u90a3\u91cc\u5199\u7684\u8fd8\u662f\u592a\u8fc7\u4e8e\u82b1\u54e8\uff0c\u8fd8\u662f\u4e0d\u592a\u76f8\u4fe1\u4f5c\u8005\u662f\u6839\u636e\u8fd9\u6837\u7684\u539f\u7406\u6765\u8bbe\u8ba1\u6a21\u578b\u7684\uff0c\u5173\u4e8eNext-VIT\u7684\u8bb2\u89e3\u540e\u671f\u6587\u7ae0\u4f1a\u8ba1\u5212\u4e13\u95e8\u6765\u505a\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#convnext_3","title":"\u56db\u3001ConvNext\u6a21\u578b\u7ed3\u6784\u8bbe\u8ba1","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#1","title":"1. \u6574\u4f53\u7ed3\u6784","text":"<p>\u4ee5Convnext-Tiny\u4e3a\u4f8b\uff0c\u4e0a\u56fe\u5de6\u4fa7\u4e3a\u5176\u6574\u4f53\u7ed3\u6784\uff0c\u53f3\u4fa7\u4e3aConvNeXt Block\u7684\u7684\u7ec4\u4ef6\u6784\u6210\u3002</p> <p>\u76f8\u5bf9\u5e94\u4ee3\u7801\u4e5f\u5f88\u7b80\u5355\uff0c\u5148\u770bConvNeXt Block\uff1a</p> <pre><code>class Block(nn.Module):\n    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n    (1) DwConv -&gt; LayerNorm (channels_first) -&gt; 1x1 Conv -&gt; GELU -&gt; 1x1 Conv; all in (N, C, H, W)\n    (2) DwConv -&gt; Permute to (N, H, W, C); LayerNorm (channels_last) -&gt; Linear -&gt; GELU -&gt; Linear; Permute back\n    We use (2) as we find it slightly faster in PyTorch\n\n    Args:\n        dim (int): Number of input channels.\n        drop_path (float): Stochastic depth rate. Default: 0.0\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n    \"\"\"\n    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n        super().__init__()\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n        self.norm = LayerNorm(dim, eps=1e-6)\n        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n        self.act = nn.GELU()\n        self.pwconv2 = nn.Linear(4 * dim, dim)\n        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n                                    requires_grad=True) if layer_scale_init_value &gt; 0 else None\n        self.drop_path = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()\n\n    def forward(self, x):\n        input = x\n        x = self.dwconv(x)\n        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -&gt; (N, H, W, C)\n        x = self.norm(x)\n        x = self.pwconv1(x)\n        x = self.act(x)\n        x = self.pwconv2(x)\n        if self.gamma is not None:\n            x = self.gamma * x\n        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -&gt; (N, C, H, W)\n\n        x = input + self.drop_path(x)\n        return x\n\n\nclass LayerNorm(nn.Module):\n    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n    with shape (batch_size, channels, height, width).\n    \"\"\"\n    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n        self.eps = eps\n        self.data_format = data_format\n        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n            raise NotImplementedError \n        self.normalized_shape = (normalized_shape, )\n\n    def forward(self, x):\n        if self.data_format == \"channels_last\":\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n        elif self.data_format == \"channels_first\":\n            u = x.mean(1, keepdim=True)\n            s = (x - u).pow(2).mean(1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.eps)\n            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n            return x\n</code></pre> <p>\u5173\u4e8eConvNeXt Block\u7684\u5f15\u5165\u8bba\u6587\u8bf4\u660e\u7684\u601d\u8def\u5982\u4e0b\uff1a</p> <pre><code>Although Swin Transformers reintroduced the local window to the self-attention block, the window size is at least 7\u00d77, significantly larger than the ResNe(X)t kernel size of 3\u00d73. Here we revisit the use of large kernel-sized convolutions for ConvNets.\n</code></pre> <ol> <li>\u5f15\u5165DWConv\u964d\u4f4eFLOPs\uff0c\u65b9\u4fbf\u63d0\u5347\u53c2\u6570\u91cf\u63d0\u5347\u6027\u80fd</li> <li>\u5f15\u5165MobileNetV2\u4e2d\u7684Inverted bottlenecks\uff08Transformer Block\u8bbe\u8ba1\u4ea6\u662f\u5982\u6b64\uff0cAttention\u5c42\u4e0eFeedForward\u5c42\u603b\u4f53\u6765\u770b\u4e5f\u662f\u5148\u5347\u7ef4\u540e\u964d\u7ef4\uff09</li> <li>DWConv\u7c7b\u6bd4Transformer Block\u4e2d\u7684\u591a\u5934\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5c06DWConv\u653e\u5230\u6700\u524d\u9762\u3002\u501f\u9274Swin transformer\u8bbe\u8ba1\uff0c\u5c06kernel size\u8c03\u6574\u5230 \\(7 \\times 7\\) \u3002</li> </ol> <p>\u6a21\u578b\u6574\u4f53\u7ed3\u6784\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>class ConvNeXt(nn.Module):\n    r\"\"\" ConvNeXt\n        A PyTorch impl of : `A ConvNet for the 2020s`  -\n          https://arxiv.org/pdf/2201.03545.pdf\n    Args:\n        in_chans (int): Number of input image channels. Default: 3\n        num_classes (int): Number of classes for classification head. Default: 1000\n        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n        drop_path_rate (float): Stochastic depth rate. Default: 0.\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n    \"\"\"\n    def __init__(self, in_chans=3, num_classes=1000, \n                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n                 layer_scale_init_value=1e-6, head_init_scale=1.,\n                 ):\n        super().__init__()\n\n        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n        stem = nn.Sequential(\n            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n        )\n        self.downsample_layers.append(stem)\n        for i in range(3):\n            downsample_layer = nn.Sequential(\n                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n            )\n            self.downsample_layers.append(downsample_layer)\n\n        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n        cur = 0\n        for i in range(4):\n            stage = nn.Sequential(\n                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n            )\n            self.stages.append(stage)\n            cur += depths[i]\n\n        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n        self.head = nn.Linear(dims[-1], num_classes)\n\n        self.apply(self._init_weights)\n        self.head.weight.data.mul_(head_init_scale)\n        self.head.bias.data.mul_(head_init_scale)\n\n    def _init_weights(self, m):\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\n            trunc_normal_(m.weight, std=.02)\n            nn.init.constant_(m.bias, 0)\n\n    def forward_features(self, x):\n        for i in range(4):\n            x = self.downsample_layers[i](x)\n            x = self.stages[i](x)\n        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -&gt; (N, C)\n\n    def forward(self, x):\n        x = self.forward_features(x)\n        x = self.head(x)\n        return x\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#2-gamma","title":"2. gamma\u7684\u6765\u6e90","text":"<p>\u56de\u987eConvNeXt Block\u7684\u7ed3\u6784\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u6709\u4e00\u4e2a\u53ef\u5b66\u4e60\u53c2\u6570gamma\u7684\u5b58\u5728\uff0c\u5e76\u53d6\u540d\u4e3aLayerScale\u3002</p> <p></p> <p>gamma\u4f1a\u88ab\u521d\u59cb\u5316\u4e3a\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c</p> <pre><code>self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), requires_grad=True) if layer_scale_init_value &gt; 0 else None\n</code></pre> <p>gamma\u53c2\u4e0e\u7684\u8fd0\u7b97\u5982\u4e0b\u6240\u793a</p> <pre><code>x = self.pwconv2(x)\nif self.gamma is not None:\n    x = self.gamma * x\nx = x.permute(0, 3, 1, 2) # (N, H, W, C) -&gt; (N, C, H, W)\nx = input + self.drop_path(x)\n</code></pre> <p>LayerScale\uff08gamma\uff09\u7684\u4f7f\u7528\u662f\u4e3a\u4e86\u52a0\u901f\u6a21\u578b\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u8be5\u6280\u5de7\u5728Cait\uff0cGoing deeper with Image Transformers\uff0c\u4e3b\u8981\u76ee\u7684\u662f\u4e3a\u4e86\u89e3\u51b3\u52a0\u6df1VIT\u6a21\u578b\u540e\u7684\u5e26\u6765\u7684\u4f18\u5316\u56f0\u96be\u95ee\u9898\u3002\u53ef\u80fd\u654f\u9510\u7684\u540c\u5b66\u5df2\u7ecf\u5bdf\u89c9\u5230\uff0cgamma\u524d\u9762\u53ea\u8981\u63a5\u7684\u662f\u7ebf\u6027\u5c42\uff0c\u5c31\u6709\u5408\u5e76\u7684\u53ef\u80fd\u6027\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#3-droppath","title":"3. Droppath","text":"<p>Droppath\u7684\u4f7f\u7528\u65f6\u501f\u9274\u7684SwinTransformer\uff0c\u662f\u4e00\u79cd\u9632\u6b62\u8fc7\u62df\u5408\u7684\u624b\u6bb5\u3002\u6700\u65e9\u88abDenseNet\u7684\u4f5c\u8005HuangGao\u63d0\u51fa\uff0c\u8bba\u6587\u540d\u5b57\u4e3aDeep Networks with Stochastic Depth\uff0c\u7528\u5728\u5e26\u6709\u6b8b\u5dee\u5757\u7684\u6a21\u578b\u4e2d\uff0c\u5bf9\u591a\u5206\u652f\u7ed3\u6784\u7684\u8fde\u63a5\u8fdb\u884c\u968f\u673a\u5220\u9664\uff0c\u4ec5\u4fdd\u7559\u4e00\u4e2aIdentity Function\uff0c\u4ece\u800c\u4f7f\u539f\u6a21\u578b\u53ef\u4ee5\u770b\u505a\u591a\u79cd\u6df1\u5ea6\u4e0d\u540c\u7684\u6a21\u578b\u7684Ensemble\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u6027\u3002\u540e\u6765\u88abTimm\u5e93\u548cSwinTransformer\u4e2d\u4f7f\u7528\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002\u76f8\u5173\u5b9e\u73b0\u4ee3\u7801\u5982\u4e0b</p> <pre><code>def drop_path(x, drop_prob: float = 0., training: bool = False):\n    if drop_prob == 0. or not training:\n        return x\n    keep_prob = 1 - drop_prob\n    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  \n    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n    random_tensor.floor_()  # binarize\n    output = x.div(keep_prob) * random_tensor\n    return output\n\n\nclass DropPath(nn.Module):\n    def __init__(self, drop_prob=None):\n        super(DropPath, self).__init__()\n        self.drop_prob = drop_prob\n\n    def forward(self, x):\n        return drop_path(x, self.drop_prob, self.training)\n</code></pre> <p>\u5bf9<code>drop_path</code>\u51fd\u6570\u8fdb\u884c\u5206\u6790\u53ef\u77e5\uff0c\u5bf9\u4e8e\u4e00\u4e2abatch\u5185\u7684\u6240\u6709\u6570\u636e\u6309\u7167<code>drop_prob</code>\u7684\u6982\u7387\u5220\u9664batch\u7ef4\u5ea6\u4e0a\u7684\u5355\u4e2a\u6570\u636e\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u6837\u672c\u7684\u6570\u636e\uff0c<code>drop_path</code>\u6309\u7167\u4e00\u5b9a\u6982\u7387\u6765\u51b3\u5b9a\u5f53\u524d\u6837\u672c\u662f\u5426\u6267\u884c\u6b8b\u5dee\u51fd\u6570\uff08\u7f6e0\u5c31\u610f\u5473\u7740\u4e0d\u6267\u884c\uff09\uff0c\u4ece\u800c\u8fbe\u5230\u968f\u673a\u7f51\u7edc\u6df1\u5ea6\u7684\u76ee\u7684\u3002\u540c\u65f6\u4e3a\u4e86\u4fdd\u8bc1\u4e00\u4e2abatch\u7684\u6570\u636e\u7684\u671f\u671b\u4e0d\u53d8\uff0c\u53c8\u5bf9\u7f6e\u96f6\u5904\u7406\u540e\u7684\u6570\u636e\u9664\u4ee5<code>keep_prob</code>\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#convnext_4","title":"\u4e94\u3001ConvNext\u7684\u53c2\u6570\u521d\u59cb\u5316\u6280\u5de7","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#1-truncate_normal_","title":"1. truncate_normal_","text":"<pre><code>def _init_weights(self, m):\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\n        trunc_normal_(m.weight, std=.02)\n        nn.init.constant_(m.bias, 0)\n</code></pre> <p>ConvNeXt\u4e2d\u5377\u79ef\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u91c7\u7528<code>truncate_normal_</code>\u7684\u521d\u59cb\u5316\u65b9\u5f0f\u3002</p> <p><code>truncate_normal</code>\u662f\u4e00\u79cd\u5e26\u622a\u65ad\u7684\u6b63\u6001\u5206\u5e03\uff0c\u76ee\u7684\u662f\u9650\u5236\u6b63\u592a\u5206\u5e03\u7684\u6700\u5927\u6700\u5c0f\u503c\u90fd\u843d\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u3002</p> <p>\u5176\u4ece\u622a\u65ad\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u8f93\u51fa\u968f\u673a\u503c. \u751f\u6210\u7684\u503c\u9075\u5faa\u5177\u6709\u6307\u5b9a\u5e73\u5747\u503c\u548c\u6807\u51c6\u504f\u5dee\u7684\u6b63\u6001\u5206\u5e03,\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u5176\u5e73\u5747\u503c\u5927\u4e8e 2 \u4e2a\u6807\u51c6\u5dee\u7684\u503c\u5c06\u88ab\u4e22\u5f03\u5e76\u91cd\u65b0\u9009\u62e9\u3002</p> <p>\u76f8\u5173\u5b9e\u73b0\u4ee3\u7801\u548c\u6ce8\u91ca\u5982\u4e0b</p> <pre><code>def _trunc_normal_(tensor, mean, std, a, b):\n    # \u4ece\u622a\u65ad\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u8f93\u51fa\u968f\u673a\u503c. \u751f\u6210\u7684\u503c\u9075\u5faa\u5177\u6709\u6307\u5b9a\u5e73\u5747\u503c\u548c\u6807\u51c6\u504f\u5dee\u7684\u6b63\u6001\u5206\u5e03,\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u5176\u5e73\u5747\u503c\u5927\u4e8e 2 \u4e2a\u6807\u51c6\u5dee\u7684\u503c\u5c06\u88ab\u4e22\u5f03\u5e76\u91cd\u65b0\u9009\u62e9.\n    # \u8981\u6c42\n    # mean + 2 * std &gt;= a\n    # mean - 2 * std &lt;= b\n\n    # \u6574\u4f53\u601d\u8def\uff1a\u6839\u636ea\uff0cb\u53d6\u503c\u8ba1\u7b97\u51fa\u5206\u5e03\u51fd\u6570\u53d6\u503c\u533a\u95f4\uff0c\u7136\u540e\u751f\u6210\u8be5\u533a\u95f4\u7684\u5747\u5300\u5206\u5e03\uff0c\u7136\u540e\u6839\u636e\u4ee5\u5747\u5300\u5206\u5e03\u5f53\u505ay\uff0c\u8fd0\u7528\u53cd\u51fd\u6570\u8ba1\u7b97\u51fa\u5bf9\u5e94\u7684x\u3002\n\n    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n    def norm_cdf(x):\n        # \u7ed9\u5b9ax\uff0c\u8ba1\u7b97\u6b63\u592a\u5206\u5e03\u7684\u5206\u5e03\u51fd\u6570\u5f97\u5230\u7684\u503c\uff0c\u8be5\u9879\u53ef\u4ee5\u91c7\u7528\u4ee3\u5165\u79ef\u5206\u6d88\u5143\u5f97\u5230\u8bc1\u660e\n        # Computes standard normal cumulative distribution function\n        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n\n    if (mean &lt; a - 2 * std) or (mean &gt; b + 2 * std):\n        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n                      \"The distribution of values may be incorrect.\",\n                      stacklevel=2)\n\n    # \u6c42\u51fa\u6807\u51c6\u6b63\u592a\u5206\u5e03\u4e0b\u7684\u5206\u5e03\u51fd\u6570\u7684\u533a\u95f4\u503c\n    # Values are generated by using a truncated uniform distribution and\n    # then using the inverse CDF for the normal distribution.\n    # Get upper and lower cdf values\n    l = norm_cdf((a - mean) / std)\n    u = norm_cdf((b - mean) / std)\n\n    # \u5728[2l-1, 2u-1]\u4e2d\u5747\u5300\u91c7\u96c6\uff0c \u6807\u51c6\u6b63\u6001\u5206\u5e03 \u5206\u5e03\u51fd\u6570f(t) = (1 + (erf(t))) / 2\uff0ct = x/srqt(2)\n    # erf(x / sqrt(2)) = (2 * f(x) - 1)\n    # Uniformly fill tensor with values from [l, u], then translate to\n    # [2l-1, 2u-1].\n    tensor.uniform_(2 * l - 1, 2 * u - 1)\n\n    # \u8ba1\u7b97\u51fa\u6839\u636e\u8bef\u5dee\u51fd\u6570\u7684\u53cd\u51fd\u6570\u8ba1\u7b97\u51fat, t = x / sqrt(2)\n    # Use inverse cdf transform for normal distribution to get truncated\n    # standard normal\n    tensor.erfinv_()\n\n    # \u7531\u6807\u51c6\u6b63\u592a\u5206\u5e03\u8f6c\u6362\u4e3a\u76ee\u6807\u6b63\u592a\u5206\u5e03\uff0c\u56e0\u4e3at = x / sqrt(2)\uff0c\u6240\u4ee5t\u7684mean\u4e0ex\u76f8\u540c\uff0cstd(t) = std(x) / srqt(2)\n    # \u4f30 std(y) = std(x) * std = std(t) * sqrt(2) * std\n    # Transform to proper mean, std\n    tensor.mul_(std * math.sqrt(2.))\n    tensor.add_(mean)\n\n    # \u786e\u4fdd\u4e0d\u4f1a\u6ea2\u51fa\n    # Clamp to ensure it's in the proper range\n    tensor.clamp_(min=a, max=b)\n    return tensor\n\n\ndef trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n    # type: (Tensor, float, float, float, float) -&gt; Tensor\n    r\"\"\"Fills the input Tensor with values drawn from a truncated\n    normal distribution. The values are effectively drawn from the\n    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n    with values outside :math:`[a, b]` redrawn until they are within\n    the bounds. The method used for generating the random values works\n    best when :math:`a \\leq \\text{mean} \\leq b`.\n    NOTE: this impl is similar to the PyTorch trunc_normal_, the bounds [a, b] are\n    applied while sampling the normal with mean/std applied, therefore a, b args\n    should be adjusted to match the range of mean, std args.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        mean: the mean of the normal distribution\n        std: the standard deviation of the normal distribution\n        a: the minimum cutoff value\n        b: the maximum cutoff value\n    Examples:\n        &gt;&gt;&gt; w = torch.empty(3, 5)\n        &gt;&gt;&gt; nn.init.trunc_normal_(w)\n    \"\"\"\n    with torch.no_grad():\n        return _trunc_normal_(tensor, mean, std, a, b)\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#2-droppath","title":"2. droppath\u7684\u521d\u59cb\u5316","text":"<p>droppath\u4e2ddrop_rate\u7684\u521d\u59cb\u5316\u662f\u91c7\u7528\u5176\u539f\u8bba\u6587\uff08Deep Networks with Stochastic Depth\uff0c\u89c1\u516c\u5f0f4\uff09\u63d0\u51fa\u7684 linear decay rule\uff0cdrop_rate\u968f\u7740\u6a21\u578b\u6df1\u5ea6\u589e\u52a0\u800c\u7ebf\u6027\u589e\u52a0\u3002\u8fd9\u4e00\u8bbe\u8ba1\u4e0eswin transformer\u76f8\u540c\uff0c\u4f53\u73b0\u5728\u4ee3\u7801\u4e2d\u5982\u4e0b\uff1a</p> <pre><code>self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\ndp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \ncur = 0\nfor i in range(4):\n    stage = nn.Sequential(\n        *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n        layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n    )\n    self.stages.append(stage)\n    cur += depths[i]\n</code></pre> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\u4e0a\u9762\u4ee3\u7801\u4e2d\u7684<code>drop_path</code>\u6307\u7684\u5c31\u662fDropPath\u4e2d\u7684droprate\u3002</p> <p>\u90a3\u4e48\u4e3a\u4ec0\u4e48\u8fd9\u4e48\u8bbe\u7f6e\uff1f\u53c2\u89c1\u539f\u6587\u56de\u7b54</p> <pre><code>The linearly decaying survival probability originates from our intuition that the earlier layers extract low-level features that will be used by later layers and should therefore be more reliably present.\n</code></pre> <p>\u6b64\u5916\u539f\u8bba\u6587\u4f5c\u8005\u4e5f\u505a\u4e86\u5b9e\u9a8c\uff0c\u8bf4\u660e\u4e86\u8fd9\u79cd\u8bbe\u7f6e\u65b9\u5f0f\u6bd4\u7edf\u4e00\u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u5e38\u91cf\u8981\u597d</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#convnext_5","title":"\u516d\u3001ConvNext\u662f\u5982\u4f55\u8bad\u7ec3\u7684","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#1_1","title":"1. \u6570\u636e\u589e\u5f3a","text":"<p>\u5173\u952e\u4ee3\u7801\u4f53\u73b0\u5728\u8bba\u6587\u5b98\u65b9code\u8fde\u63a5\u4e2d\u7684dataset.py\u4e2d\u7684<code>build_dataset</code>\u51fd\u6570\u4e2d</p> <pre><code>transform = create_transform(\n            input_size=args.input_size,\n            is_training=True,\n            color_jitter=args.color_jitter,\n            auto_augment=args.aa,\n            interpolation=args.train_interpolation,\n            re_prob=args.reprob,\n            re_mode=args.remode,\n            re_count=args.recount,\n            mean=mean,\n            std=std,\n        )\n</code></pre> <p>\u5206\u522b\u91c7\u7528\u5982\u4e0b\u6570\u636e\u589e\u5f3a</p> <p>a. Mixup</p> <p>b. Cutmix</p> <p>c. RandAugment</p> <p>d. Random Erasing</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#2","title":"2. \u4f18\u5316\u8bbe\u7f6e","text":"<p>a. \u91c7\u7528AdamW\u4f18\u5316\u5668\uff0c20epoch\u7684warmup+\u968f\u540e\u7684\u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf</p> <p>b. Stochastic Depth \uff08DropPath</p> <p>c. Label Smoothing</p> <p>d. Layer Scale (gamma)</p> <p>e. Model EMA</p> <p>f. Pretrained on Imagenet-22K finetuned on Imagenet-1K</p> <p>\u4e0a\u8ff0\u4f18\u5316\u4e0eswintransformer\u4e2d\u7684\u8bbe\u7f6e\u57fa\u672c\u76f8\u540c\uff0c\u91c7\u7528\u76f8\u540c\u7684\u4f18\u5316\u8bbe\u7f6e\uff0c\u4e3a\u540e\u671f\u6bd4\u8f83\u589e\u52a0\u4e86\u4e00\u4e9b\u516c\u5e73\u6027\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#convnexttensorrt","title":"\u4e03\u3001ConvNext\u5728TensorRT\u4e0a\u7684\u90e8\u7f72\u4f18\u5316","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#0-trex","title":"0. \u975e\u5e38\u597d\u7528\u7684trex\u53ef\u89c6\u5316\u5de5\u5177","text":"<p>\u4ed3\u5e93\u5730\u5740: https://github.com/NVIDIA/TensorRT/tree/main/tools/experimental/trt-engine-explorer <code>trex</code> is useful for initial model performance debugging, visualization of plan graphs, and for understanding the characteristics of an engine plan. For in-depth performance analysis, Nvidia \u00ae Nsight Systems \u2122 is the recommended performance analysis tool.</p> <p>TensorRT\u4f1a\u5bf9\u8ba1\u7b97\u56fe\u4e2d\u7684\u7b97\u5b50\u505a\u4e00\u4e9b\u878d\u5408\uff0c\u878d\u5408\u540e\u7684\u7b97\u5b50\u6709\u54ea\u4e9b\uff0c\u8ba1\u7b97\u901f\u5ea6\u591a\u5c11\uff0c\u8fd9\u4e9b\u90fd\u4f1a\u5728\u65e5\u5fd7\u4e2d\u4f53\u73b0\u3002trex\u53ef\u4ee5\u5c06\u8fd9\u4e9b\u4fe1\u606f\u4e32\u8054\u8d77\u6765\uff0c\u5316\u6210\u4e00\u5e45\u8ba1\u7b97\u56fe\uff0c\u8fdb\u800c\u53ef\u4ee5\u8ba9\u4f7f\u7528\u8005\u66f4\u52a0\u65b9\u4fbf\u7684\u5206\u6790\u4f18\u5316\u8ba1\u7b97\u56fe\u3002trex\u7684\u5448\u73b0\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ef\u4ee5\u5c06\u7b97\u5b50\u7684\u6bcf\u4e2a\u8fd0\u884c\u65f6\u95f4\u90fd\u7ed9\u5c55\u73b0\u51fa\u6765\uff0c\u5e76\u4e14\u8fd0\u7b97\u540e\u7684\u5f62\u72b6\u548c\u7c7b\u578b\u90fd\u53ef\u4ee5\u76f4\u89c2\u7684\u5c55\u793a\u3002</p> <p></p> <p><code>trex</code>\u76f8\u6bd4\u8f83\u4e8e<code>nsys</code>\u53ef\u4ee5\u66f4\u52a0\u7b80\u5355\u7684\u5448\u73b0\u7b97\u5b50\u7684\u4fe1\u606f\uff0c<code>nsys</code>\u9002\u5408\u66f4\u4e3a\u4e13\u4e1a\u7684\u5206\u6790\uff0c\u6bd4\u5982cuda graph\u3001cuda stream\u4e0a\u7684\u5206\u6790\u3002</p> <p>\u5728\u5b89\u88c5\u7684\u65f6\u5019\u9700\u8981\u5bf9\u4f9d\u8d56\u5e93\u7248\u672c\u505a\u4e00\u4e9b\u9650\u5b9a\uff0c\u5426\u5219\u4f1a\u62a5\u9519\uff0c\u4fee\u6539\u7684<code>requirements.txt</code>\u5982\u4e0b\uff1a</p> <pre><code>setuptools # for qgrid\nwheel # for qgrid\nprotobuf==3.16.0\nonnx==1.11.0\nnumpy\npandas==1.1.5\nplotly\nqgrid==1.3.1\ngraphviz\njupyter\nnetron\nopenpyxl # for excel reporting\nipywidgets==7.6.0\nipyfilechooser\npytest\ndtale==2.2.0\nxlsxwriter\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#1-gamma","title":"1. \u53bb\u6389gamma","text":"<p>\u4e0a\u6587\u4e2d\u63d0\u5230LayerScale\u65b9\u6cd5\u4e2d\u7684gamma\u662f\u53ef\u4ee5\u548c\u524d\u9762\u7684\u6216\u8005\u540e\u9762\u7684\u7ebf\u6027\u5c42\u5408\u5e76\u7684\uff0c\u518d\u91cd\u65b0\u770b\u4e0bgamma\u53c2\u4e0e\u7684\u8ba1\u7b97</p> <pre><code>x = self.pwconv2(x)\nif self.gamma is not None:\n    x = self.gamma * x\nx = x.permute(0, 3, 1, 2) # (N, H, W, C) -&gt; (N, C, H, W)\n\nx = input + self.drop_path(x)\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230gamma\u524d\u9762\u662fPointWise Conv\uff08\u5b98\u65b9repo\u7528Linear\u5c42\u66ff\u6362\uff09\uff0cgamma\u662f\u53ef\u4ee5\u878d\u5408\u8fdb\u524d\u9762\u7684\u7b97\u5b50\u4e2d\u7684\u3002</p> <p>\u5bf9\u4e8eTensorRT\u4e0a\u7684\u90e8\u7f72\uff0c\u672c\u6587\u91c7\u7528\u5bfc\u51faonnx\u7684\u65b9\u5f0f\uff0c\u878d\u5408gamma\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u7b2c\u4e00\u4e2a\u662f\u91c7\u7528<code>torch.fx</code>\u4fee\u6539\u6a21\u578b\uff0c\u7b2c\u4e8c\u4e2a\u662f\u5bfc\u51faonnx\u540e\u4fee\u6539onnx\u3002\u4e0b\u9762\u5bf9\u8fd9\u4e24\u79cd\u65b9\u6cd5\u90fd\u8fdb\u884c\u4e00\u4e2a\u4ecb\u7ecd\u3002</p> <p><code>torch.fx</code>\u662f\u4e00\u4e2a\u7528\u4e8e\u6355\u83b7\u548c\u8f6c\u6362PyTorch\u7a0b\u5e8f\u7684\u7eafPython\u7cfb\u7edf\u3002\u4e3b\u8981\u5206\u4e3a\u4e09\u4e2a\u7ed3\u6784\u5757:\u7b26\u53f7\u8ffd\u8e2a\u5668\uff08symbolic tracer\uff09\uff0c\u4e2d\u95f4\u8868\u793a\uff08intermediate representation\uff09\uff0c Python\u4ee3\u7801\u751f\u6210\uff08Python code generation\uff09\u3002</p> <p>\u8fd9\u4e09\u4e2a\u7ec4\u4ef6\u53ef\u4ee5\u505a\u4ec0\u4e48\uff1f\u76f4\u89c2\u770b\u8d77\u6765\uff0ctorch.fx\u505a\u7684\u5c31\u662f\u5c06\u4e00\u4e2aModule\u8f6c\u6362\u4e3a\u9759\u6001\u56fe\u3002\u9996\u5148\uff0c\u901a\u8fc7\u8ffd\u8e2a\u5668\u83b7\u53d6\u5230\u6a21\u578b\u7684graph\uff0c\u4ece\u800c\u4ea7\u751f\u4e2d\u95f4\u8868\u793a\uff0c\u5bf9\u4e8e\u4e2d\u95f4\u8868\u793a\u6211\u4eec\u505a\u4e00\u7cfb\u5217\u53d8\u5316\uff0c\u518d\u901a\u8fc7python\u4ee3\u7801\u751f\u6210\u6765\u751f\u6210python\u4ee3\u7801\u3002</p> <p>\u4e0b\u9762\u7ed9\u51fa\u901a\u8fc7<code>torch.fx</code>\u878d\u5408gamma\u7684\u4f8b\u5b50</p> <pre><code>from ConvNeXt.models.convnext import Block\nfrom torch.fx import symbolic_trace, GraphModule, Graph\nimport copy\nimport torch.nn as nn\nfrom torch.fx.experimental.optimization import replace_node_module\n\nfx_model = symbolic_trace(copy.deepcopy(model))\ngraph = copy.deepcopy(fx_model.graph)\nmodules = dict(fx_model.named_modules())\nstate_dict = model.state_dict()\n\nfor node in graph.nodes:\n    if 'get_attr' == node.op and 'gamma' in node.target:\n        prev_node = node.prev\n        prev_conv1x1_module = modules[prev_node.target]\n        gamma = state_dict[node.target]\n        # gamma(Ax+B)\n        prev_conv1x1_module.weight.data.mul_(gamma.unsqueeze(-1))\n        prev_conv1x1_module.bias.data.mul_(gamma)\n        # \u5c06mul_node\u5220\u9664\u66ff\u6362\u4e3aprev_node\n        next_node = node.next\n        # \u5c06\u7528\u5230mul_node\u7684\u6240\u6709\u8282\u70b9\u4e2d\u7684\u8f93\u5165\u66ff\u6362\u4e3aprev_node\n        next_node.replace_all_uses_with(prev_node)\n        graph.erase_node(next_node)\n        graph.erase_node(node)\n\nnew_model = GraphModule(fx_model, graph)\ndummpy_input = torch.rand(1,3,224,224)\ntorch.onnx.export(new_model, dummpy_input, 'convnext_tiny_fuse_gamma.onnx', input_names=['input'], output_names=['output'], opset_version=13, dynamic_axes={\n    'input':{\n        0:'batch_size'\n    },\n    'output': {\n        0:'batch_size'\n    }\n})\n</code></pre> <p>\u9996\u5148\u901a\u8fc7<code>torch.fx</code>\u5f97\u5230model\u7684\u4e2d\u95f4\u8ba1\u7b97\u8868\u793a\uff0c\u7136\u540e\u64cd\u4f5cnode\uff0c\u66f4\u6539\u5176\u8868\u793a\uff0c\u6700\u540e\u91cd\u65b0\u6253\u5305\u4e3aModule\u5bfc\u51faonnx\uff0c\u8fd9\u5c31\u662f\u91c7\u7528<code>torch.fx</code>\u66f4\u6539\u8ba1\u7b97\u56fe\u7684\u6d41\u7a0b\u3002</p> <p>\u63a5\u4e0b\u6765\u7ed9\u51fa\u4e00\u79cd\u66f4\u52a0\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u76f4\u63a5\u4fee\u6539onnx\uff0c\u4fee\u6539onnx\u4e5f\u6709\u591a\u79cd\u65b9\u5f0f\uff0c\u6700\u76f4\u63a5\u4e5f\u662f\u6700\u9ebb\u70e6\u7684\u662f\u901a\u8fc7onnx\u5e93\u76f4\u63a5\u64cd\u4f5c\u5c5e\u6027\uff0c\u8fd9\u79cd\u65b9\u5f0f\u9700\u8981\u8003\u8651\u7684\u4f9d\u8d56\u5f88\u591a\u3002\u8f83\u4e3a\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u91c7\u7528TensorRT\u4e2d\u5e26\u7684<code>onnx-graphsurgeon</code>\u5e93</p> <p>onnx-graphsurgeon\u5e93\u5730\u5740\uff1ahttps://github.com/NVIDIA/TensorRT/tree/main/tools/onnx-graphsurgeon</p> <p>\u4e0b\u9762\u76f4\u63a5\u7ed9\u51fa\u901a\u8fc7<code>onnx-graphsurgeon</code>\u4fee\u6539\u7684\u4ee3\u7801</p> <pre><code>import onnx_graphsurgeon as gs\nimport onnx\nimport numpy as np\n\nonnx_graph = onnx.load('convnext_tiny.onnx')\nonnx_gs_graph = gs.import_onnx(onnx_graph)\n\nfor node in onnx_gs_graph.nodes:\n\n    # \u66ff\u6362gamma\n    if node.op != 'Mul':\n        continue\n    try:\n        add_node = node.i(1)\n    except:\n        continue\n    if add_node.op != 'Add':\n        continue\n    try:\n        matmul_node = add_node.i(1)\n    except:\n        continue\n    if matmul_node.op != 'MatMul':\n        continue\n    gamma = node.inputs[0].values\n    weight = matmul_node.inputs[1].values\n    bias = add_node.inputs[0].values\n    print(weight.shape, bias.shape)\n    new_bias = bias * gamma\n    new_weight = weight * gamma[np.newaxis, ...]\n#     print(gamma)\n    add_node.inputs[0].values = new_bias\n    matmul_node.inputs[1].values = new_weight\n    # \u53bb\u9664gamma\u7b97\u5b50\n    add_node.outputs[0] = node.outputs[0]\n    node.outputs.clear()\n\nonnx_gs_graph = onnx_gs_graph.cleanup().toposort()\nonnx.save(gs.export_onnx(onnx_gs_graph), \"convnext_tiny_rm_gamma.onnx\")\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#2-layernorm","title":"2. LayerNorm\u7684\u5408\u5e76","text":"<p>LayerNorm\u88abonnx\u5206\u89e3\u4e3a\u5355\u4e2a\u7b97\u5b50\u8868\u793a\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u5408\u5e76\u4e3a\u5355\u4e2a\u7b97\u5b50\u7528\u5199\u63d2\u4ef6\u7684\u5f62\u5f0f\u6765\u52a0\u901f\u8fd0\u7b97\uff0c\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662fTensorRT\u6700\u65b0\u7248\u5df2\u7ecf\u5f00\u59cb\u652f\u6301\u8bc6\u522bLayerNorm\u7b97\u5b50\u7684\u5408\u5e76\uff0c\u5199\u7684\u63d2\u4ef6\u8981\u4fdd\u8bc1\u8db3\u591f\u7684\u9ad8\u6548\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u9002\u5f97\u5176\u53cd\u3002</p> <p>\u63a5\u4e0b\u6765\u7ed9\u51fa\u66ff\u6362LayerNorm\u7684\u4e24\u79cd\u65b9\u5f0f\u7684\u5177\u4f53\u4ee3\u7801</p> <p>\u9996\u5148\u662f\u5c01\u88c5\u4e00\u4e2a\u4e3aonnx\u5bfc\u51fa\u51c6\u5907\u7684\u7c7b\uff0c\u5b9e\u73b0<code>symbolic</code>\u65b9\u6cd5\u6765\u5b9e\u73b0\u81ea\u5b9a\u4e49\u7b97\u5b50\uff0c\u7136\u540e\u5c06\u8be5\u7c7b\u5b9e\u4f8b\u5316\u7684\u5bf9\u8c61\u66ff\u6362\u539f\u6765\u7684<code>LayerNorm</code>\u5bf9\u8c61\u3002</p> <pre><code>from torch.autograd import Function\nimport torch.nn.functional as F\nimport torchvision\n\nclass LayerNormFunction(Function):\n\n    @staticmethod\n    def forward(ctx, x, normalized_shape, weight, bias, eps, data_format, method):\n        return method(x)\n\n    @staticmethod\n    def symbolic(g, x, normalized_shape, weight, bias, eps, data_format, method):\n        return g.op(\"LayerNorm\", x, weight, bias, eps_f = eps, data_format_s = data_format) \n\nclass ExportLayerNrom(LayerNorm):\n\n    def forward(self, x):\n        return LayerNormFunction.apply(x, self.normalized_shape, self.weight, self.bias, self.eps, self.data_format, super().forward)\n\nclass MyTracer(torch.fx.Tracer):\n\n    def is_leaf_module(self, m, module_qualified_name):\n        return super().is_leaf_module(m, module_qualified_name) or isinstance(m, ExportLayerNrom)\n\nnew_model = copy.deepcopy(model)\nmodules = dict(new_model.named_modules())\n\nfor name, module in new_model.named_modules():\n    if 'norm' in name or isinstance(module, (nn.LayerNorm, LayerNorm)):\n        weight = module.weight.data\n        bias = module.bias.data\n        names = name.split(\".\")\n        parent_model = modules[\".\".join(names[:-1])]\n        data_format = \"channels_last\"\n        if hasattr(module, 'data_format'):\n            data_format = module.data_format\n        normalized_shape = bias.nelement()\n        if hasattr(module, 'normalized_shape'):\n            normalized_shape = module.normalized_shape[0]\n        new_module = ExportLayerNrom(normalized_shape = normalized_shape, data_format=data_format, eps=module.eps).to(weight.device)\n        new_module.weight.data.copy_(weight)\n        new_module.bias.data.copy_(bias)\n        setattr(parent_model, names[-1], new_module)\n\ngraph = MyTracer().trace(copy.deepcopy(new_model))\nmodules = dict(new_model.named_modules())\nstate_dict = new_model.state_dict()\n\nfor node in graph.nodes:\n    if 'get_attr' == node.op and 'gamma' in node.target:\n        prev_node = node.prev\n        prev_conv1x1_module = modules[prev_node.target]\n        gamma = state_dict[node.target]\n        # gamma(Ax+B)\n        prev_conv1x1_module.weight.data.mul_(gamma.unsqueeze(-1))\n        prev_conv1x1_module.bias.data.mul_(gamma)\n        # \u5c06mul_node\u5220\u9664\u66ff\u6362\u4e3aprev_node\n#         print(node, node.format_node(), node.next)\n        next_node = node.next\n        next_node.replace_all_uses_with(prev_node)\n        graph.erase_node(next_node)\n        graph.erase_node(node)\n\n\ndummpy_input = torch.rand(1,3,224,224)\ntry:\n    torch.onnx.export(new_model, dummpy_input, 'convnext_tiny_fuse_gamma_rep_layernorm.onnx', \n                  input_names=['input'], output_names=['output'], \n                  opset_version=13, dynamic_axes={\n                    'input':{\n                        0:'batch_size'\n                    },\n                    'output': {\n                        0:'batch_size'\n                  }},\n    )\nexcept torch.onnx.CheckerError:\n    pass # ignore error\n</code></pre> <p>\u4e0a\u9762\u7684\u4ee3\u7801\u9488\u5bf9<code>LayerNorm</code>\u5e76\u6ca1\u6709\u91c7\u7528<code>torch.fx</code>\u66f4\u6539\uff0c\u800c\u662f\u76f4\u63a5\u91c7\u7528\u627e\u5230\u5176\u53cc\u4eb2\u7ed3\u70b9\u76f4\u63a5\u66ff\u6362\u5b50\u8282\u70b9\u7684\u65b9\u5f0f\uff0c\u7136\u800c\u5728\u878d\u5408gamma\u7684\u65f6\u5019\u4e3a\u4e86\u907f\u514d<code>torch.fx</code>\u5bf9\u4fee\u6539\u540e\u7684LayerNorm\u8fdb\u884c\u8ffd\u8e2a\uff0c\u9700\u8981\u81ea\u5b9a\u4e49<code>Tracer</code>\u6765\u907f\u514d\u5bf9\u81ea\u5b9a\u4e49<code>LayerNorm</code>\u7684\u8ffd\u8e2a\u3002</p> <p>\u7b2c\u4e8c\u79cd\u65b9\u5f0f\u81ea\u7136\u662f\u76f4\u63a5\u4fee\u6539onnx</p> <pre><code># \u5408\u5e76LayeNorm\nlayernorm_idx = 0\nfor node in onnx_gs_graph.nodes:\n\n    if node.op != 'ReduceMean':\n        continue\n    try:\n        sub_nodes = list()\n        for i in range(2):\n            sub_nodes.append(node.o(i))\n    except:\n        pass\n    if not sub_nodes or sub_nodes[0].op != 'Sub':\n        continue\n\n    div_node = None\n    pow_node = None\n    for sub_node in sub_nodes:\n        if sub_node.op != 'Sub':\n            continue\n        try:\n            for i in range(2):\n                tmp_node = sub_node.o(i)\n                if tmp_node.op == \"Div\":\n                    div_node = tmp_node\n                elif tmp_node.op == \"Pow\":\n                    pow_node = tmp_node\n        except:\n            pass\n\n    if div_node is None or pow_node is None:\n        continue\n\n    try:\n        mul_node = div_node.o(0)\n    except:\n        continue\n    if mul_node.op != 'Mul':\n        continue\n\n    try:\n        add_node = mul_node.o(0)\n    except:\n        continue\n    if add_node.op != 'Add':\n        continue\n\n\n    eps_node = pow_node.o(0).o(0)\n    eps = eps_node.inputs[1].inputs[0].attrs['value'].values\n    try:\n        weight = mul_node.inputs[1].values\n    except:\n        weight = mul_node.inputs[0].values\n\n    try:\n        bias = add_node.inputs[0].values\n    except:\n        bias = add_node.inputs[1].values\n\n    data_format = \"channels_last\" if int(node.attrs['axes'][0]) == -1 else \"channels_first\"\n    if data_format != \"channels_last\":\n        continue\n    attrs = {\n        'data_format':data_format,\n        'eps':float(eps)\n    }\n    layernorm_idx += 1\n    layernorm_name = 'LayerNorm-%d' % layernorm_idx\n    print('layernorm_name', layernorm_name)\n    weight_const = gs.Constant(name=layernorm_name+ \"_weight\", values=weight.reshape(-1))\n    bias_const = gs.Constant(name=layernorm_name+ \"_bias\", values=bias.reshape(-1))\n    new_layernorm_node = gs.Node('LayerNorm', name=layernorm_name, attrs=attrs, inputs = [node.inputs[0:1][0], weight_const, bias_const], outputs = add_node.outputs[0:1])\n\n    add_node.outputs.clear()\n    node.inputs.clear()\n    sub_node.inputs.clear()\n    onnx_gs_graph.nodes.append(new_layernorm_node)\n</code></pre> <p>\u4e0a\u9762\u4ee3\u7801\u6ca1\u6709\u5bf9<code>data_format==channels_first</code>\u7684\u8fdb\u884c\u5904\u7406\uff0c\u539f\u56e0\u662f\u540e\u9762\u4f1a\u9488\u5bf9\u8be5\u7c7b\u578b\u5355\u72ec\u5904\u7406\u3002</p> <p>\u56de\u987eLayerNorm\u7684\u8fd0\u7b97\u65b9\u5f0f\uff0c\u5176\u5b9e\u5728\u524d\u9762\u6a21\u578b\u7684\u6574\u4f53\u7ed3\u6784\u4e2d\u5df2\u7ecf\u7ed9\u51fa</p> <pre><code>def forward(self, x):\n    if self.data_format == \"channels_last\":\n        return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n    elif self.data_format == \"channels_first\":\n        u = x.mean(1, keepdim=True)\n        tmp = (x - u)\n        s = tmp.pow(2).mean(1, keepdim=True)\n        x = tmp / torch.sqrt(s + self.eps)\n        x = self.weight[:, None, None] * x + self.bias[:, None, None]\n        return x\n</code></pre> <p>\u5bf9\u4e8e<code>channels_first</code>\u7684\u9009\u9879\uff0c\u4f5c\u8005\u76f4\u63a5\u91c7\u7528\u539f\u751f\u65b9\u5f0f\u5b9e\u73b0\u4e86LayerNorm\u3002</p> <p>\u8fd9\u91cc\u91cd\u65b0\u5ba1\u89c6\u4e00\u4e0b\u6570\u636e<code>mean</code>\u548c<code>var</code>\u7684\u8fc7\u7a0b\uff0c\u6b63\u5e38\u60c5\u51b5\u4e0b\u5bf9\u6570\u636e\u8fdb\u884c\u904d\u5386\u9700\u8981\u6211\u4eec\u5148\u6c42\u51fa<code>mean</code>\u518d\u7528<code>x-mean</code>\u6c42\u51fa<code>var</code></p> \\[ \\begin{align*} \\operatorname{mean}(\\textrm X) &amp;= \\frac{\\sum_{i=1}^{n} \\textrm X_i}{n} \\\\ \\operatorname{var}(\\textrm X) &amp;= \\frac{\\sum_{i=1}^{n} (\\textrm X_i - \\operatorname{mean}(\\textrm X))^2}{n} \\\\                             &amp;= \\frac{\\sum_{i=1}^{n} ((\\textrm X_i)^2 + \\operatorname{mean}^2(\\textrm X) - 2 \\textrm X_i \\operatorname{mean}(\\textrm X))}{n} \\\\                             &amp;= \\frac{\\sum_{i=1}^{n} (\\textrm X_i)^2}{n} + \\frac{n * \\operatorname{mean}^2(\\textrm X)}{n} - 2*\\operatorname{mean}(\\textrm X)*\\frac{\\sum_{i=1}^{n} \\textrm X_i}{n} \\\\                             &amp;= \\frac{\\sum_{i=1}^{n} (\\textrm X_i)^2}{n} + \\operatorname{mean}^2(\\textrm X) - 2*\\operatorname{mean}^2(\\textrm X) \\\\                             &amp;= \\operatorname{mean}(\\textrm X^2) - \\operatorname{mean}^2(\\textrm X) \\end{align*} \\] <p>\u4ece\u4e0a\u9762\u7684\u5904\u7406\u53ef\u77e5\uff0c\u6211\u4eec\u6ca1\u5fc5\u8981\u5206\u4e3a\u4e24\u6b65\u6c42\u51famean\u548cvar\uff0c\u53ea\u9700\u8981\u5728\u4e00\u6b21\u5faa\u73af\u4e2d\u5206\u522b\u6c42\u51fa<code>mean(X)</code>\u548c<code>mean(X^2)</code>\u5c31\u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97\u51fa<code>mean</code>\u548c<code>var</code>\u3002\u8fd9\u4e5f\u662f\u76ee\u524d\u6700\u5e38\u7528\u7684LayerNorm\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002</p> <p>\u5728\u5177\u4f53cuda\u5b9e\u73b0\u4e0a\uff0c\u4e3a\u4e86\u9632\u6b62\u6570\u636e\u6ea2\u51fa\u95ee\u9898\uff0c\u6709\u65f6\u5019\u53ef\u4ee5\u91c7\u7528\u5982\u4e0b\u6280\u5de7\uff1a</p> <pre><code>tmp = X_i / n\nmean += tmp\nmean_x_2 += tmp * X_i\n</code></pre> <p>\u6211\u4eec\u4f9d\u7136\u91c7\u7528oneflow\u6781\u5ea6\u4f18\u5316\u7684LayerNorm\u5b9e\u73b0\uff0c\u540e\u9762\u7684\u6d88\u878d\u5b9e\u9a8c\u4e5f\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#3-gelu","title":"3. Gelu\u7b97\u5b50","text":"<p>Gelu\u539f\u6587\u5730\u5740\uff1a https://arxiv.org/abs/1606.08415</p> <p>\u6fc0\u6d3b\u51fd\u6570GELU\u7684\u7075\u611f\u6765\u6e90\u4e8e relu \u548c dropout\uff0c\u5728\u6fc0\u6d3b\u4e2d\u5f15\u5165\u4e86\u968f\u673a\u6b63\u5219\u7684\u601d\u60f3\u3002Gelu\u901a\u8fc7\u8f93\u5165\u81ea\u8eab\u7684\u6982\u7387\u5206\u5e03\u60c5\u51b5\uff0c\u51b3\u5b9a\u629b\u5f03\u8fd8\u662f\u4fdd\u7559\u5f53\u524d\u7684\u795e\u7ecf\u5143\u3002</p> \\[ \\operatorname{GELU}(x)=x P(X \\leq x)=x \\Phi(x)=x \\cdot \\frac{1}{2}[1+\\operatorname{erf}(x / \\sqrt{2})] . \\] <p>\u5176\u4e2d \\(\\Phi(x)\\) \u8868\u793a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u7684\u5206\u5e03\u51fd\u6570\uff0c<code>erf</code>\u5373\u8bef\u5dee\u51fd\u6570\uff0c\u5728<code>truncate_normal</code>\u5c0f\u8282\u4e2d\u4e5f\u6709\u63d0\u5230</p> <p></p> <p>\u6709\u5173\u6fc0\u6d3b\u51fd\u6570\u7684\u8868\u793a\u53ef\u4ee5\u53c2\u8003 https://wuli.wiki/online/Erf.html</p> <p>\u5bf9GELU\u6c42\u5bfc\u53ef\u5f97</p> \\[ \\frac{d}{dx}GELU(x) = \\phi(x) \\frac{dx}{dx} + x\\phi'(x) = \\phi(x) + xP(X=x) \\] <p>Gelu\u7b97\u5b50\u5728onnx\u4e2d\u4f9d\u7136\u662f\u91c7\u7528\u8bef\u5dee\u51fd\u6570\u7ec4\u5408\u8868\u793a\u7684\uff0c\u4f46\u662f\u5728tensorrt\u4e2d\u4f1a\u88ab\u878d\u5408\uff0c\u548b\u52a0\u4e0a\u5bf9\u5e94\u7684erf\u51fd\u6570\u6ca1\u6709fp16\u7248\u672c\uff0c\u6240\u4ee5\u65e0\u9700\u518d\u5b9e\u73b0\u5bf9\u5e94\u7684\u63d2\u4ef6\uff0c\u50cf\u8fd9\u79cdElementWise\u7684\u64cd\u4f5c\u60f3\u8d85\u8fc7TensorRT\u81ea\u5e26\u878d\u5408\u4f18\u5316\u5f88\u96be\u3002</p> <p></p> <p></p> <p>\u4ece\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230\uff0cTensorRT\u5df2\u7ecf\u628aGelu\u878d\u5408\u4e3a\u4e00\u4e2a\u5927\u7684\u7b97\u5b50\uff0c\u4e0d\u9700\u8981\u6211\u4eec\u518d\u5355\u72ec\u5199\u63d2\u4ef6\u8fdb\u884c\u878d\u5408\uff0c\u540e\u7eed\u7684\u5b9e\u9a8c\u4e5f\u53ef\u4ee5\u770b\u5230\u6211\u4eec\u5199\u7684\u63d2\u4ef6\u6548\u7387\u4e0d\u662f\u5f88\u9ad8\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#4","title":"4. \u4f18\u5316\u540e\u7684\u901f\u5ea6\u5bf9\u6bd4","text":"<p>\u672c\u6587\u5bf9ConvNeXt\u5728TensorRT\u4e0a\u7684\u90e8\u7f72\u505a\u4e86\u4e30\u5bcc\u7684\u5b9e\u9a8c\uff0c\u4e0b\u9762\u4e00\u4e00\u4ecb\u7ecd\u5404\u4e2a\u5b9e\u9a8c\u7684setting</p> <p>a. convnext_tiny: \u539f\u7248\u6a21\u578b\u5bfc\u51fa</p> <p>b. convnext_tiny_fuse_gamma: \u878d\u5408gamma</p> <p>c. convnext_tiny_rm_gamma_rep_layernorm_gs: \u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u672a\u5bf9channels_first\u8fdb\u884c\u5904\u7406\uff09</p> <p>d. convnext_tiny_rm_gamma_rep_layernorm_gelu_gs:\u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u672a\u5bf9channels_first\u8fdb\u884c\u5904\u7406\uff09+Gelu\u63d2\u4ef6</p> <p>e. convnext_tiny_rm_gamma_rep_layernorm_gs_2: \u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u5bf9channels_first\u8fdb\u884c\u5904\u7406transpose+LayerNorm\u66ff\u6362\u4e3achannels_last\uff09+Gelu\u63d2\u4ef6</p> <p>f. convnext_tiny_rm_gamma_rep_layernorm_gs_2: \u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u52a0\u4e0a\u5bf9channels_first\u539f\u751f\u652f\u6301\u7684\u63d2\u4ef6\uff09+Gelu\u63d2\u4ef6</p> <p>\u6d4b\u8bd5\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>trt_cls_object = TRTClassify('./convnext_tiny.trt')\nfor i in range(100):\n    trt_cls_object(inputs)\n%timeit trt_cls_object(inputs)\ndel trt_cls_object\n\ntrt_cls_object = TRTClassify('./convnext_tiny_fuse_gamma.trt')\nfor i in range(100):\n    trt_cls_object(inputs)\n%timeit trt_cls_object(inputs)\ndel trt_cls_object\n\ntrt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs.engine')\nfor i in range(100):\n    trt_cls_object(inputs)\n%timeit trt_cls_object(inputs)\ndel trt_cls_object\n\ntrt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gelu_gs.trt')\nfor i in range(100):\n    trt_cls_object(inputs)\n%timeit trt_cls_object(inputs)\ndel trt_cls_object\n\n\ninputs = np.random.rand(256,3,224,224).astype(np.float32)\ntrt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs_2.engine')\nfor i in range(100):\n    trt_cls_object(inputs)\n%timeit trt_cls_object(inputs)\ndel trt_cls_object\n\ntrt_cls_object = TRTClassify('./convnext_tiny_rm_gamma_rep_layernorm_gs_3.engine')\nfor i in range(100):\n    trt_cls_object(inputs)\n%timeit trt_cls_object(inputs)\ndel trt_cls_object\n</code></pre> <p>\u7ed3\u679c\u5982\u4e0b\uff1a</p> <pre><code>402 ms \u00b1 1.01 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n407 ms \u00b1 691 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n375 ms \u00b1 312 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n396 ms \u00b1 697 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n398 ms \u00b1 531 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n492 ms \u00b1 3.45 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</code></pre> setting latency(ms) a. convnext_tiny: \u539f\u7248\u6a21\u578b\u5bfc\u51fa 402 b. convnext_tiny_fuse_gamma: \u878d\u5408gamma 407 c. convnext_tiny_rm_gamma_rep_layernorm_gs: \u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u672a\u5bf9channels_first\u8fdb\u884c\u5904\u7406\uff09 375 d. convnext_tiny_rm_gamma_rep_layernorm_gelu_gs:\u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u672a\u5bf9channels_first\u8fdb\u884c\u5904\u7406\uff09+Gelu\u63d2\u4ef6 396 e. convnext_tiny_rm_gamma_rep_layernorm_gs_2: \u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u5bf9channels_first\u8fdb\u884c\u5904\u7406transpose+LayerNorm\u66ff\u6362\u4e3achannels_last\uff09+Gelu\u63d2\u4ef6 398 f. convnext_tiny_rm_gamma_rep_layernorm_gs_2: \u878d\u5408gamma+LayerNorm\u63d2\u4ef6\uff08\u52a0\u4e0a\u5bf9channels_first\u539f\u751f\u652f\u6301\u7684\u63d2\u4ef6\uff09+Gelu\u63d2\u4ef6 492 <p>\u4ece\u4e0a\u9762\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa\uff0cGelu\u63d2\u4ef6\u662f\u591a\u4f59\u7684\uff0cLayerNorm\u63d2\u4ef6\u53ea\u9700\u8981\u5b9e\u73b0<code>channels_last</code>\u7248\u672c\u5373\u53ef\uff0c<code>channels_first</code>\u7531\u4e8e\u5185\u5b58\u4e0d\u662f\u8fde\u7eed\u7684\uff0c\u4f18\u5316\u540e\u7684\u6548\u679c\u8fd8\u6ca1\u6709TensorRT\u878d\u5408\u540e\u7684\u6548\u679c\u597d\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#_2","title":"\u516b\u3001\u7ed3\u8bed","text":"<p>\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86ConvNeXt\u7684\u6a21\u578b\u8bbe\u8ba1\u7684\u82e5\u5e72\u7ec6\u8282\u548c\u90e8\u7f72\u4f18\u5316\uff0c\u8bba\u6587\u4e2d\u524d\u9762\u90e8\u5206\u4ec5\u4ee3\u8868\u4e2a\u4eba\u89c2\u70b9\uff0c\u4e0d\u559c\u52ff\u55b7\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/convnext/#_3","title":"\u4e5d\u3001\u53c2\u8003\u8bba\u6587","text":"<ol> <li>ConvNeXt</li> <li>GELU</li> <li>Stochastic Depth</li> <li>Going deeper with Image Transformers</li> </ol>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/","title":"Nanodet-Plus \u4ece\u6570\u636e\u96c6\u3001\u6a21\u578b\u642d\u5efa\u5230\u8bad\u7ec3\u5168\u6d41\u7a0b\u89e3\u8bfb","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#_1","title":"\u96f6. \u524d\u8a00","text":"<p>\u4e00\u76f4\u60f3\u7ed9\u81ea\u5df1\u5b89\u6392\u4e2a\u89e3\u8bfbnanodet\u7684\u4efb\u52a1\uff0c\u6765\u719f\u6089\u4e0b<code>nanodet</code>\u7684\u8bbe\u8ba1\u548c\u6e90\u7801\u3002\u8c01\u77e5\u9053<code>nanodet-plus</code>\u5728<code>2021</code>\u5e74\u5c31\u5df2\u7ecf\u51fa\u73b0\u4e86\uff0c\u6070\u597d\u524d\u4e00\u9635\u521a\u770b\u5b8c<code>nanodet-plus</code>\u7684\u6e90\u7801\uff0c\u501f\u77402023\u5e74\u8fd9\u4e2a\u6e05\u660e\u8282\u7684\u5047\u671f\uff0c\u82b1\u4e0a\u4e00\u4e0b\u5348\u65f6\u95f4\u68b3\u7406\u4e00\u4e0b\u3002</p> <p>\u4e4b\u524d\u770b\u5230\u8fc7\u4ee5\u4e3a\u54c8\u5de5\u5927\u7684\u4e00\u4f4d\u5b66\u751f\u89e3\u8bfb\u4e86\u6a21\u578b\u6846\u67b6\u548cLoss\u90e8\u5206\uff0c\u4f46\u662f\u4e00\u5e74\u6ca1\u6709\u66f4\u65b0\u4e86\u3002\u8fd9\u4e48\u597d\u7684\u4f5c\u54c1\u89e3\u8bfb\u600e\u4e48\u53ef\u4ee5\u70c2\u5c3e\uff0c\u4e8e\u662f\u6211\u51b3\u5b9a\u501f\u9274\u4e00\u4e0b\u5176\u5185\u5bb9\uff0c\u4e3a\u5176\u8865\u4e0a\u4e00\u4e2a\u5f00\u5934\u548c\u6536\u5c3e\u3002</p> <p>\u672c\u6587\u76f8\u5173\u8d44\u6599\uff1a</p> <ol> <li> <p>\u89e3\u8bfb\u6e90\u7801\u7248\u672c\u83b7\u53d6</p> <pre><code>git clone -b 'v1.0.0' https://github.com/RangiLyu/nanodet.git --single-branch nanodet-plus\n</code></pre> </li> <li> <p>\u4f5c\u8005\u77e5\u4e4e\u89e3\u8bfb</p> <p>https://zhuanlan.zhihu.com/p/449912627</p> </li> </ol>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#trick","title":"\u4e00. \u6a21\u578b\u6574\u4f53\u7ed3\u6784\u89e3\u8bfb\u548c\u8bad\u7ec3trick","text":"<p>NanoDet-Plus\u662f\u4e00\u4e2a\u5355\u9636\u6bb5\u7684anchor-free\u6a21\u578b\uff0c\u5176\u6574\u4f53\u67b6\u6784\u8bbe\u8ba1\u57fa\u4e8eFCOS\u6a21\u578b,\u5e76\u5c06\u5206\u7c7b\u5934\u548c\u56de\u5f52\u5934\u6539\u4e3aGFL\u7248\u672c\uff0c\u53bb\u9664\u4e86centerness\u5206\u652f\uff0c\u5e76\u52a0\u5165\u4e86\u52a8\u6001\u6807\u7b7e\u5206\u914d\u7b56\u7565\u3001GFL loss\u548c\u8f85\u52a9\u8bad\u7ec3\u6a21\u5757\u3002</p> <p>\u7531\u4e8eNanoDet-Plus\u8f7b\u91cf\u5316\u7684\u8bbe\u8ba1\u548c\u975e\u5e38\u5c0f\u7684\u53c2\u6570\u91cf\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u548cCPU\u8bbe\u5907\u4e0a\u62e5\u6709\u53ef\u89c2\u7684\u63a8\u7406\u901f\u5ea6\u3002</p> <p>\u82e5\u8bfb\u8005\u8bfb\u8fc7mmdet\u4ee3\u7801\u540e\u5c31\u77e5\u9053\uff0c\u5176\u4ee3\u7801\u53ef\u4ee5\u770b\u505ammdet\u7684\u7cbe\u7b80\u7248\u672c\uff0c\u53ef\u8bfb\u6027\u5f3a\u6269\u5c55\u6027\u9ad8\uff0c\u662f\u76ee\u6807\u68c0\u6d4b\u5b9e\u8df5\u8fdb\u9636\u5230\u6df1\u5165\u7684\u4e0d\u4e8c\u9009\u62e9\u3002</p> <p>Nanodet-Plus\u6574\u4f53\u7ed3\u6784\u56fe\u5982\u4e0b\uff1a</p> <p></p> <p>\u6253\u5f00<code>config/nanodet-plus-m_320.yaml</code>\uff0c\u5176\u5185\u5bb9\u5982\u4e0b(\u4ec5\u5c55\u793a\u6a21\u578b\u90e8\u5206)\uff1a</p> <pre><code># nanodet-plus-m_320\n# COCO mAP(0.5:0.95) = 0.270\n#             AP_50  = 0.418\n#             AP_75  = 0.281\n#           AP_small = 0.083\n#               AP_m = 0.278\n#               AP_l = 0.451\nsave_dir: workspace/nanodet-plus-m_320\nmodel:\n  weight_averager:\n    name: ExpMovingAverager\n    decay: 0.9998\n  arch:\n    name: NanoDetPlus\n    detach_epoch: 10\n    backbone:\n      name: ShuffleNetV2\n      model_size: 1.0x\n      out_stages: [2,3,4]\n      activation: LeakyReLU\n    fpn:\n      name: GhostPAN\n      in_channels: [116, 232, 464]\n      out_channels: 96\n      kernel_size: 5\n      num_extra_level: 1\n      use_depthwise: True\n      activation: LeakyReLU\n    head:\n      name: NanoDetPlusHead\n      num_classes: 80\n      input_channel: 96\n      feat_channels: 96\n      stacked_convs: 2\n      kernel_size: 5\n      strides: [8, 16, 32, 64]\n      activation: LeakyReLU\n      reg_max: 7\n      norm_cfg:\n        type: BN\n      loss:\n        loss_qfl:\n          name: QualityFocalLoss\n          use_sigmoid: True\n          beta: 2.0\n          loss_weight: 1.0\n        loss_dfl:\n          name: DistributionFocalLoss\n          loss_weight: 0.25\n        loss_bbox:\n          name: GIoULoss\n          loss_weight: 2.0\n    # Auxiliary head, only use in training time.\n    aux_head:\n      name: SimpleConvHead\n      num_classes: 80\n      input_channel: 192\n      feat_channels: 192\n      stacked_convs: 4\n      strides: [8, 16, 32, 64]\n      activation: LeakyReLU\n      reg_max: 7\n</code></pre> <p>\u9996\u5148\u6574\u4f53\u6846\u67b6\u4f9d\u7136\u662fFCOS\uff0c\u4e0b\u9762\u5206\u5f00\u89e3\u8bfb</p> <ol> <li>backbone\uff1a\u9ed8\u8ba4\u91c7\u7528ShuffleNetV2 \uff0c\u5bf9\u79fb\u52a8\u7aef\u53cb\u597d\uff0c\u4f5c\u8005\u7ed9\u51fa\u7684\u6846\u67b6\u4e2d\u4e5f\u63d0\u4f9b\u4e86\u5176\u4ed6backbone\u7684\u63a5\u53e3</li> <li>neck: neck\u90e8\u5206\u91c7\u7528PAFPN\uff0c\u7b80\u79f0PAN\uff0c\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f\u9ed8\u8ba4\u91c7\u7528Ghost Block\u7ec4\u6210\u7684GhostPAN</li> </ol> <p>\u76f8\u8f83\u4e8e\u4e4b\u524d\u7248\u672c<code>nanodet</code>\u4e2dneck\u5728\u505a\u7279\u5f81\u878d\u5408\u65f6\u4ec5\u4ec5\u505a\u52a0\u6cd5\uff0c\u4e0d\u91c7\u7528\u4efb\u4f55\u5377\u79ef\u878d\u5408\u7684\u6fc0\u8fdb\u505a\u6cd5\uff0c\u4f5c\u8005\u5728<code>nanodet-plus</code>\u7248\u672c\u4e2d\u52a0\u5165\u8f7b\u91cf\u7ea7\u7684<code>GhostBlock</code>\u505a\u7279\u5f81\u878d\u5408\u3002</p> <ol> <li>head: \u4f5c\u8005\u501f\u9274ThunderNet\u548cPicoDet\u505a\u6cd5\uff0c\u91c7\u7528\u5982\u4e0b\u6539\u8fdb</li> <li>\u68c0\u6d4b\u5934\u7684depthwise\u5377\u79ef\u7684\u5377\u79ef\u6838\u5927\u5c0f\u4e5f\u6539\u6210\u4e865x5</li> <li>\u5728<code>NanoDet</code>\u76843\u5c42\u7279\u5f81\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u5c42\u4e0b\u91c7\u6837\u7279\u5f81</li> <li>\u8f85\u52a9\u8bad\u7ec3neck\u548chead</li> <li>\u4e3a\u6a21\u62df\u77e5\u8bc6\u84b8\u998f\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86Assign Guidance Module\uff08\u53ef\u4ee5\u770b\u6210\u8f85\u52a9head\uff09\uff0c\u5c06\u5176\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\u5e2e\u52a9\u672c\u8eabhead\u83b7\u5f97\u66f4\u597d\u7684\u8bad\u7ec3\u3002\u5728\u6a21\u578b\u8bad\u7ec3\u524d\u671f\uff0c\u5176\u4ea7\u751f\u7684<code>cost matrix</code>\u4f5c\u4e3a\u6a21\u578b\u771f\u6b63head\u90e8\u5206\u7684\u6807\u7b7e\u5206\u914d\u5668\u7684\u8f93\u5165\u3002\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f\u6559\u5e08\u6a21\u578b\u548c\u5b66\u751f\u6a21\u578b\u5171\u4eabbackbone\u3002AGM\u4ec5\u75314\u4e2a3x3\u7684\u5377\u79ef\u7ec4\u6210\uff0c\u4f7f\u7528GN\u4f5c\u4e3aNormalize\u5c42\uff0c\u5e76\u5728\u4e0d\u540c\u5c3a\u5ea6\u7684Feature Map\u95f4\u5171\u4eab\u53c2\u6570\uff08\u5176\u5b9e\u5c31\u662f\u5927\u6a21\u578b\u7684\u68c0\u6d4b\u5934\uff09\u3002</li> <li>\u8f85\u52a9\u8bad\u7ec3neck\u4e0e\u6a21\u578b\u672c\u8eabneck\u76f8\u540c\uff0c\u91c7\u7528<code>self.aux_fpn = copy.deepcopy(self.fpn)</code>\u5b9e\u73b0\u3002</li> <li>\u8f85\u52a9head\u91c7\u7528\u6bd4\u672c\u8eabhead\u76f8\u5bf9\u590d\u6742\u7684\u68c0\u6d4b\u5934\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u83b7\u53d6\u66f4\u52a0\u5f3a\u5927\u7684\u8868\u5f81\u80fd\u529b\uff0c\u65b9\u4fbf\u66f4\u597d\u7684\u5f15\u5bfc\u5b66\u751f\u6a21\u578b\u3002</li> <li>\u52a8\u6001\u7684\u8f6f\u6807\u7b7e\u5206\u914d\u7b56\u7565Dynamic Soft Label Assigner(DSLA)</li> </ol> <p>\u4f7f\u7528AGM\u9884\u6d4b\u7684\u5206\u7c7b\u6982\u7387\u548c\u68c0\u6d4b\u6846\u4f1a\u9001\u5165DSLA\u6a21\u5757\u8ba1\u7b97Matching Cost\u3002Cost\u51fd\u6570\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff1aclassification cost\uff0cregression cost\u4ee5\u53cadistance cost\u3002cost\u77e9\u9635\u4f1a\u4f5c\u4e3a\u6a21\u578b\u771f\u6b63head\u90e8\u5206\u6807\u7b7e\u5206\u914d\u65f6\u7684\u53c2\u8003\uff0cDynamic Soft Label Assigner\u8ddfyolox\u4e2d\u7528\u7684dynamic-k\u4e00\u6837\uff0c\u4ec5\u4ec5\u662fcost\u77e9\u9635\u5b9a\u4e49\u4e0d\u4e00\u6837\u3002</p> <p>\u4e2a\u4eba\u89e3\u51b3\u54c8\u5de5\u5927\u5b66\u751f\u753b\u7684\u7ed3\u6784\u56fe\u66f4\u4e3a\u6e05\u6670\uff0c\u8fd9\u91cc\u8d34\u4e00\u4e0b\uff1a</p> <p></p> <p>Backbone\u8f93\u51fa\u7684feature\u9001\u5165\u4e24\u4e2aGhost PAN\uff0c\u5176\u4e2d\u4e00\u4e2a\u662f\u4e3aAGM\u4e13\u95e8\u642d\u5efa\u7684\uff0c\u53e6\u4e00\u4e2aPAN\u548cHead\u8fde\u63a5\u3002</p> <p>AGM\u4f1a\u5c06\u4e24\u4e2aPAN\u7684\u8f93\u51fa\u62fc\u63a5\u5728\u4e00\u8d77\u4f5c\u4e3a\u8f93\u5165(\u8fd9\u6837\u4e00\u65b9\u9762\u53ef\u4ee5\u5728\u8bad\u7ec3AGM\u7684\u65f6\u5019\u4e5f\u5bf9Head\u7684PAN\u505a\u4e86\u68af\u5ea6\u56de\u4f20\u53c2\u4e0e\u8bad\u7ec3\uff0c\u540c\u65f6concat\u4f1a\u589e\u52a0\u7279\u5f81\u7684\u4e30\u5bcc\u5ea6)\u3002 AGM\u6709\u4e24\u4e2a\u5206\u652f\uff0c\u5206\u522b\u8d1f\u8d23\u751f\u6210\u7528\u4f5c\u6807\u7b7e\u5206\u914d\u7684cls_pred\u548creg_pred\u3002</p> <p>\u5bf9\u4e8eGhost PAN\u4e2d\u7684\u4e0d\u540c\u5c42\u7279\u5f81\uff0cAGM\u91c7\u7528share head\u65b9\u5f0f\u5b9e\u73b0\u5171\u4eab\u53c2\u6570\uff0c\u5927\u5927\u51cf\u5c0f\u4e86\u8bad\u7ec3\u65f6\u7684\u53c2\u6570\u91cf\u3002</p> <p>AGM\u7684\u8f93\u51fa\u5728\u8bad\u7ec3\u521d\u671f\u5c06\u4f1a\u4f5c\u4e3aHead\u6807\u7b7e\u5206\u914d\u7684\u53c2\u8003\uff0c\u5e76\u4e14AGM\u7684loss\u4e5f\u4f1a\u8fdb\u884c\u56de\u4f20\uff0c\u5e2e\u52a9\u7f51\u7edc\u66f4\u5feb\u5730\u6536\u655b\u3002 \u7ecf\u8fc7\u6570\u4e2aepoch(\u9ed8\u8ba4\u662f10\u4e2a)\u7684\u8bad\u7ec3\u540eHead\u7684\u9884\u6d4b\u5df2\u7ecf\u6709\u8f83\u597d\u7684\u51c6\u786e\u5ea6\uff0c\u6b64\u65f6\u5c06AGM\u6a21\u5757\u5206\u79bb\uff0c\u76f4\u63a5\u7531Head\u7684\u8f93\u51fa\u81ea\u884c\u5b8c\u6210\u6807\u7b7e\u5206\u914d\u7684\u4efb\u52a1\u3002</p> <p>\u4e0b\u9762\u7ed9\u51fa\u6a21\u578b\u6574\u4f53\u642d\u5efa\u7684\u4ee3\u7801<code>nanodet/model/arch/nanodet_plus.py</code></p> <pre><code>class NanoDetPlus(OneStageDetector):\n    def __init__(\n        self,\n        backbone,\n        fpn,\n        aux_head,\n        head,\n        detach_epoch=0,\n    ):\n        super(NanoDetPlus, self).__init__(\n            backbone_cfg=backbone, fpn_cfg=fpn, head_cfg=head\n        )\n        # \u6784\u9020\u8f85\u52a9\u8bad\u7ec3fpn\u548cAGM\uff08\u5373Head\uff09\n        self.aux_fpn = copy.deepcopy(self.fpn)\n        self.aux_head = build_head(aux_head)\n        # \u6307\u5b9a\u591a\u5c11epoch\u540e\u4e0d\u518d\u91c7\u7528aux head\n        self.detach_epoch = detach_epoch\n\n    def forward_train(self, gt_meta):\n        img = gt_meta[\"img\"]\n        feat = self.backbone(img)\n        fpn_feat = self.fpn(feat)\n        # \u5f53\u5f53\u524depoch\u5927\u4e8e\u7b49\u4e8edetach_epoch\u65f6\uff0c\u91c7\u7528detach\u65b9\u5f0f\uff0c\u5c06aux_fpn\u4e0e\uff08backbone\u548cfpn\u4ea7\u751f\u7684feature\uff09\u68af\u5ea6\u56de\u4f20\u9694\u79bb\n        # \u5373\u6b64\u65f6\u5bf9AGM\u7684\u4f18\u5316\u4e0d\u4f1a\u518d\u5f71\u54cdbackbone\u548cfpn\n        if self.epoch &gt;= self.detach_epoch:\n            aux_fpn_feat = self.aux_fpn([f.detach() for f in feat])\n            dual_fpn_feat = (\n                torch.cat([f.detach(), aux_f], dim=1)\n                for f, aux_f in zip(fpn_feat, aux_fpn_feat)\n            )\n        else:\n            aux_fpn_feat = self.aux_fpn(feat)\n            dual_fpn_feat = (\n                torch.cat([f, aux_f], dim=1) for f, aux_f in zip(fpn_feat, aux_fpn_feat)\n            )\n        head_out = self.head(fpn_feat)\n        aux_head_out = self.aux_head(dual_fpn_feat)\n        loss, loss_states = self.head.loss(head_out, gt_meta, aux_preds=aux_head_out)\n        return head_out, loss, loss_states\n</code></pre> <p>\u5728\u8bad\u7ec3\u5b8c\u6210\u8fdb\u884c\u63a8\u7406\u65f6\uff0c\u76f4\u63a5\u53bb\u9664AGM\u548caux_fpn\uff0c\u5f97\u5230\u975e\u5e38\u7cbe\u7b80\u7684\u7f51\u7edc\u7ed3\u6784\u3002</p> <p>\u7531\u4e8eNanoDet\u662f\u4e00\u4e2a\u5f00\u6e90\u9879\u76ee\uff0c\u800c\u975e\u5237\u70b9\u7684\u8bba\u6587\uff0c\u6700\u7ec8\u76ee\u7684\u8fd8\u662f\u5e0c\u671b\u8fd9\u4e2a\u9879\u76ee\u80fd\u591f\u5bf9\u4f7f\u7528\u8005\u66f4\u52a0\u53cb\u597d\u3002\u4e0a\u4e00\u4ee3\u7684NanoDet\u4f7f\u7528\u4f20\u7edf\u7684SGD+momentum+MultiStepLr\u7684\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u3002\u5bf9\u8001\u70bc\u4e39\u5e08\u6765\u8bf4\uff0c\u80af\u5b9a\u8fd8\u662f\u89c9\u5f97SGD\u6bd4\u8f83\u9999\uff0c\u914d\u5408MultiStepLr\u5728\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5927\u5b66\u4e60\u7387\u957f\u65f6\u95f4\u8bad\u7ec3\u540e\u8fdb\u884c\u5b66\u4e60\u7387\u8870\u51cf\u80fd\u6709\u5f88\u5927\u7684\u6da8\u5e45\u3002\u4f46\u662f\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u65b0\u624b\u6765\u8bf4\u8fd8\u662f\u592a\u96be\u8c03\u4e86\uff01\u6ca1\u6709\u8001\u70bc\u4e39\u5e08\u7684\u7ecf\u9a8c\uff0c\u5f88\u5bb9\u6613\u5bfc\u81f4\u6a21\u578b\u4e0d\u6536\u655b\u6216\u6536\u655b\u4e0d\u597d\u3002</p> <p>\u56e0\u6b64\uff0c\u4e3a\u4e86\u63d0\u5347\u4f7f\u7528\u4f53\u9a8c\uff0cNanoDet-Plus\u5168\u9762\u6539\u8fdb\u4e86\u8bad\u7ec3\u7b56\u7565\uff1a</p> <ul> <li>\u4f18\u5316\u5668\u4eceSGD+momentum\u6539\u6210\u4e86\u5bf9\u8d85\u53c2\u6570\u66f4\u4e0d\u654f\u611f\u4e14\u6536\u655b\u66f4\u5feb\u7684AdamW\uff1b</li> <li>\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\u4eceMultiStepLr\u4fee\u6539\u4e3a\u4e86CosineAnnealingLR\uff1b</li> <li>\u5e76\u4e14\u5728\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u68af\u5ea6\u65f6\u52a0\u4e0a\u4e86\u68af\u5ea6\u88c1\u526a\uff0c\u907f\u514d\u65b0\u624b\u4e0d\u4f1a\u8c03\u53c2\u5bfc\u81f4loss NAN\uff1b</li> <li>\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u52a0\u4e0a\u4e86\u76ee\u524d\u6bd4\u8f83\u6d41\u884c\u7684\u6a21\u578b\u5e73\u6ed1\u7b56\u7565EMA\u3002</li> </ul>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#_2","title":"\u4e8c. \u6570\u636e\u96c6\u4ee3\u7801\u89e3\u8bfb","text":"<p>\u6a21\u578b\u76f8\u5173\u7684<code>config/nanodet-plus-m_320.yaml</code>\u914d\u7f6e\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>data:\n  train:\n    name: CocoDataset\n    img_path: coco/train2017\n    ann_path: coco/annotations/instances_train2017.json\n    input_size: [320,320] #[w,h]\n    # \u4e0d\u4fdd\u7559\u957f\u5bbd\u6bd4\n    keep_ratio: False\n    pipeline:\n      perspective: 0.0\n      scale: [0.6, 1.4]\n      # \u9519\u5207\n      stretch: [[0.8, 1.2], [0.8, 1.2]]\n      rotation: 0\n      shear: 0\n      translate: 0.2\n      flip: 0.5\n      brightness: 0.2\n      contrast: [0.6, 1.4]\n      saturation: [0.5, 1.2]\n      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]\n  val:\n    name: CocoDataset\n    img_path: coco/val2017\n    ann_path: coco/annotations/instances_val2017.json\n    input_size: [320,320] #[w,h]\n    keep_ratio: False\n    pipeline:\n      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]\n</code></pre> <p>\u6570\u636e\u5904\u7406\u7684\u4ee3\u7801\u90fd\u5728<code>nanodet/data</code>\u6587\u4ef6\u5939\u4e0b\u9762\uff0c\u9996\u5148\u57fa\u7c7b<code>BaseDataset</code>\u7684\u5b9a\u4e49\uff0c\u5728<code>BaseDataset</code>\u4e2d</p> <pre><code>class BaseDataset(Dataset, metaclass=ABCMeta):\n    \"\"\"\n    A base class of detection dataset. Referring from MMDetection.\n    A dataset should have images, annotations and preprocessing pipelines\n    NanoDet use [xmin, ymin, xmax, ymax] format for box and\n     [[x0,y0], [x1,y1] ... [xn,yn]] format for key points.\n    instance masks should decode into binary masks for each instance like\n    {\n        'bbox': [xmin,ymin,xmax,ymax],\n        'mask': mask\n     }\n    segmentation mask should decode into binary masks for each class.\n    Args:\n        img_path (str): image data folder\n        ann_path (str): annotation file path or folder\n        use_instance_mask (bool): load instance segmentation data\n        use_seg_mask (bool): load semantic segmentation data\n        use_keypoint (bool): load pose keypoint data\n        load_mosaic (bool): using mosaic data augmentation from yolov4\n        mode (str): 'train' or 'val' or 'test'\n        multi_scale (Tuple[float, float]): Multi-scale factor range.\n    \"\"\"\n\n    def __init__(\n        self,\n        img_path: str,\n        ann_path: str,\n        input_size: Tuple[int, int],\n        pipeline: Dict,\n        keep_ratio: bool = True,\n        use_instance_mask: bool = False,\n        use_seg_mask: bool = False,\n        use_keypoint: bool = False,\n        load_mosaic: bool = False,\n        mode: str = \"train\",\n        multi_scale: Optional[Tuple[float, float]] = None,\n    ):\n        assert mode in [\"train\", \"val\", \"test\"]\n        self.img_path = img_path\n        self.ann_path = ann_path\n        self.input_size = input_size\n        self.pipeline = Pipeline(pipeline, keep_ratio)\n        self.keep_ratio = keep_ratio\n        self.use_instance_mask = use_instance_mask\n        self.use_seg_mask = use_seg_mask\n        self.use_keypoint = use_keypoint\n        self.load_mosaic = load_mosaic\n        self.multi_scale = multi_scale\n        self.mode = mode\n\n        self.data_info = self.get_data_info(ann_path)\n\n    def __len__(self):\n        return len(self.data_info)\n\n    def __getitem__(self, idx):\n        if self.mode == \"val\" or self.mode == \"test\":\n            return self.get_val_data(idx)\n        else:\n            while True:\n                data = self.get_train_data(idx)\n                if data is None:\n                    idx = self.get_another_id()\n                    continue\n                return data\n\n    @staticmethod\n    def get_random_size(\n        scale_range: Tuple[float, float], image_size: Tuple[int, int]\n    ) -&gt; Tuple[int, int]:\n        \"\"\"\n        Get random image shape by multi-scale factor and image_size.\n        Args:\n            scale_range (Tuple[float, float]): Multi-scale factor range.\n                Format in [(width, height), (width, height)]\n            image_size (Tuple[int, int]): Image size. Format in (width, height).\n\n        Returns:\n            Tuple[int, int]\n        \"\"\"\n        assert len(scale_range) == 2\n        scale_factor = random.uniform(*scale_range)\n        width = int(image_size[0] * scale_factor)\n        height = int(image_size[1] * scale_factor)\n        return width, height\n\n    @abstractmethod\n    def get_data_info(self, ann_path):\n        pass\n\n    @abstractmethod\n    def get_train_data(self, idx):\n        pass\n\n    @abstractmethod\n    def get_val_data(self, idx):\n        pass\n\n    def get_another_id(self):\n        # \u8fd4\u56de [low,high] \u4e4b\u95f4\u7684\u6574\u6570\n        return np.random.random_integers(0, len(self.data_info) - 1)\n</code></pre> <p>\u5b9a\u4e49<code>BaseDataset</code>\u57fa\u7c7b\uff0c\u5e76\u5b9a\u4e49\u4e00\u4e9b\u62bd\u8c61\u65b9\u6cd5\u8ba9\u5b50\u7c7b\u53bb\u5b9e\u73b0\uff0c\u540c\u65f6\u5b9a\u4e49\u4e09\u79cd\u6a21\u5f0f\uff0c\u5bf9\u4e8e<code>train</code>\u6a21\u578b\u4e0b\u6709\u5982\u4e0b\u903b\u8f91</p> <pre><code>while True:\n    data = self.get_train_data(idx)\n    if data is None:\n        idx = self.get_another_id()\n    continue\n    return data\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u518d\u770b\u4e0b<code>CocoDataset</code>\u4e2d\u7684\u5177\u4f53\u5b9e\u73b0</p> <pre><code>class CocoDataset(BaseDataset):\n    # \u83b7\u53d6\u6570\u636e\u4fe1\u606f\uff0c\u5728__init__\u4e2d\u88ab\u8c03\u7528\uff0c\u7528\u4e8e\u521d\u59cb\u5316\u6570\u636e\u6807\u6ce8\u4fe1\u606f\uff0c\u8fd4\u56de\u4e00\u4e2alist\uff0c\u4ee3\u8868\u6570\u636e\u96c6\n    def get_data_info(self, ann_path):\n        \"\"\"\n        Load basic information of dataset such as image path, label and so on.\n        :param ann_path: coco json file path\n        :return: image info:\n        [{'license': 2,\n          'file_name': '000000000139.jpg',\n          'coco_url': 'http://images.cocodataset.org/val2017/000000000139.jpg',\n          'height': 426,\n          'width': 640,\n          'date_captured': '2013-11-21 01:34:01',\n          'flickr_url':\n              'http://farm9.staticflickr.com/8035/8024364858_9c41dc1666_z.jpg',\n          'id': 139},\n         ...\n        ]\n        \"\"\"\n        # \u8c03\u7528pycocotools\u4e2d\u7684COCO\n        self.coco_api = COCO(ann_path)\n        # \u4fdd\u8bc1id\u987a\u5e8f\n        self.cat_ids = sorted(self.coco_api.getCatIds())\n        # catid\u5230label\u7684\u8f6c\u6362\uff08index\uff09\n        self.cat2label = {cat_id: i for i, cat_id in enumerate(self.cat_ids)}\n        # \u5bf9\u4e00\u4e2acatid\u5bf9\u5e94\u7684\u6807\u6ce8\u4fe1\u606f\n        self.cats = self.coco_api.loadCats(self.cat_ids)\n        self.class_names = [cat[\"name\"] for cat in self.cats]\n        # \u52a0\u8f7d\u56fe\u50cfid\n        self.img_ids = sorted(self.coco_api.imgs.keys())\n        # \u52a0\u8f7d\u5168\u90e8\u56fe\u50cf\u6807\u6ce8\u4fe1\u606f\uff08\u4e0d\u4f1a\u8bfb\u53d6\u56fe\u50cf\uff09\n        img_info = self.coco_api.loadImgs(self.img_ids)\n        # Note\uff1aself.img_ids\u4e2d\u7684idx\u4e0eimg_info\u4e2d\u7684index\u6307\u5411\u7684\u5143\u7d20\u4fe1\u606f\u662f\u5bf9\u9f50\u7684\n        # \u4e5f\u5c31\u662fself.data_info\u548cself.img_ids\u957f\u5ea6\u4e00\u81f4\uff0c\u4e14\u6307\u5411\u5143\u7d20\u4fe1\u606f\u5bf9\u9f50\n        # \u5373 img_id\u4e3aself.img_ids[i]\u7684\u5143\u7d20\u4fe1\u606f\u5c31\u5728self.data_info[i]\u91cc\u9762\n        return img_info\n\n    def get_per_img_info(self, idx):\n        # \u5f97\u5230\u56fe\u50cf\u76f8\u5173\u4fe1\u606f\n        img_info = self.data_info[idx]\n        file_name = img_info[\"file_name\"]\n        height = img_info[\"height\"]\n        width = img_info[\"width\"]\n        # \u8fd9\u91cc\u7528id\u4e0d\u597d\uff0c\u4f1a\u4e0eid()\u51fd\u6570\u51b2\u7a81\uff0c\u8bfb\u8005\u53ef\u4ee5\u7406\u89e3\u4e3aimage_id\n        id = img_info[\"id\"]\n        if not isinstance(id, int):\n            raise TypeError(\"Image id must be int.\")\n        info = {\"file_name\": file_name, \"height\": height, \"width\": width, \"id\": id}\n        return info\n\n    def get_img_annotation(self, idx):\n        \"\"\"\n        load per image annotation\n        :param idx: index in dataloader\n        :return: annotation dict\n        \"\"\"\n        img_id = self.img_ids[idx]\n        ann_ids = self.coco_api.getAnnIds([img_id])\n        anns = self.coco_api.loadAnns(ann_ids)\n        gt_bboxes = []\n        gt_labels = []\n        gt_bboxes_ignore = []\n        if self.use_instance_mask:\n            gt_masks = []\n        if self.use_keypoint:\n            gt_keypoints = []\n        for ann in anns:\n            # coco\u6807\u6ce8\u683c\u5f0f left, top, width, height\n            x1, y1, w, h = ann[\"bbox\"]\n            # \u8fc7\u6ee4\u65e0\u6548\u6846\n            if ann[\"area\"] &lt;= 0 or w &lt; 1 or h &lt; 1:\n                continue\n            if ann[\"category_id\"] not in self.cat_ids:\n                continue\n            # \u8f6c\u6362\u4e3a[left, top, right, bottom]\u683c\u5f0f\n            bbox = [x1, y1, x1 + w, y1 + h]\n            # \u5982\u679c\u6807\u6ce8\u4fe1\u606f\u4e2d`iscrowd`\u6216\u8005`ignore`\u4e3aTrue\uff0c\u90a3\u4e48\u653e\u5165gt_bboxes_ignore\n            if ann.get(\"iscrowd\", False) or ann.get(\"ignore\", False):\n                gt_bboxes_ignore.append(bbox)\n            else:\n                gt_bboxes.append(bbox)\n                # \u5c06catid\u8f6c\u6362\u4e3a\u9700\u8981\u5206\u7c7b\u7684index\n                gt_labels.append(self.cat2label[ann[\"category_id\"]])\n                if self.use_instance_mask:\n                    gt_masks.append(self.coco_api.annToMask(ann))\n                if self.use_keypoint:\n                    gt_keypoints.append(ann[\"keypoints\"])\n        # \u5c06gt_bboxes\u8f6c\u6362\u4e3anp.array\u683c\u5f0f\n        if gt_bboxes:\n            gt_bboxes = np.array(gt_bboxes, dtype=np.float32)\n            gt_labels = np.array(gt_labels, dtype=np.int64)\n        else:\n            gt_bboxes = np.zeros((0, 4), dtype=np.float32)\n            gt_labels = np.array([], dtype=np.int64)\n        if gt_bboxes_ignore:\n            gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)\n        else:\n            gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n        annotation = dict(\n            bboxes=gt_bboxes, labels=gt_labels, bboxes_ignore=gt_bboxes_ignore\n        )\n        if self.use_instance_mask:\n            annotation[\"masks\"] = gt_masks\n        if self.use_keypoint:\n            if gt_keypoints:\n                annotation[\"keypoints\"] = np.array(gt_keypoints, dtype=np.float32)\n            else:\n                annotation[\"keypoints\"] = np.zeros((0, 51), dtype=np.float32)\n        return annotation\n\n    def get_train_data(self, idx):\n        \"\"\"\n        Load image and annotation\n        :param idx:\n        :return: meta-data (a dict containing image, annotation and other information)\n        \"\"\"\n        # \u5f97\u5230index=idx\u7684\u76f8\u5173\u56fe\u50cf\u4fe1\u606f\u548c\u6807\u6ce8\u4fe1\u606f\n        img_info = self.get_per_img_info(idx)\n        file_name = img_info[\"file_name\"]\n        image_path = os.path.join(self.img_path, file_name)\n        img = cv2.imread(image_path)\n        if img is None:\n            print(\"image {} read failed.\".format(image_path))\n            raise FileNotFoundError(\"Cant load image! Please check image path!\")\n        ann = self.get_img_annotation(idx)\n        meta = dict(\n            img=img,\n            img_info=img_info,\n            gt_bboxes=ann[\"bboxes\"],\n            gt_labels=ann[\"labels\"],\n            gt_bboxes_ignore=ann[\"bboxes_ignore\"],\n        )\n        if self.use_instance_mask:\n            meta[\"gt_masks\"] = ann[\"masks\"]\n        if self.use_keypoint:\n            meta[\"gt_keypoints\"] = ann[\"keypoints\"]\n\n        input_size = self.input_size\n        # \u5982\u679c\u5f00\u542f\u4e86multi_scale \u5c31\u91c7\u6837\u4e00\u6b21\n        if self.multi_scale:\n            input_size = self.get_random_size(self.multi_scale, input_size)\n\n        # \u6ce8\u610f\uff1a\u8fd9\u4e5f\u5c31\u662f\u8bf4\u6570\u636e\u9884\u5904\u7406\u8fc7\u7a0b\u662f\u5728Dataset\u7684\u7684__getitem__\u65b9\u6cd5\u4e2d\u5b8c\u6210\u7684\n        # \u8fd9\u6837\u505a\u7c92\u5ea6\u66f4\u7ec6\n        meta = self.pipeline(self, meta, input_size)\n\n        meta[\"img\"] = torch.from_numpy(meta[\"img\"].transpose(2, 0, 1))\n        return meta\n\n    def get_val_data(self, idx):\n        \"\"\"\n        Currently no difference from get_train_data.\n        Not support TTA(testing time augmentation) yet.\n        :param idx:\n        :return:\n        \"\"\"\n        # TODO: support TTA\n        return self.get_train_data(idx)\n</code></pre> <p>\u7136\u540e\u518d\u770b\u4e0b<code>pipeline</code>\u662f\u600e\u4e48\u505a\u7684\uff0c\u6587\u4ef6\u5730\u5740<code>nanodet\\data\\transform\\pipeline.py</code></p> <pre><code>class Pipeline:\n    \"\"\"Data process pipeline. Apply augmentation and pre-processing on\n    meta_data from dataset.\n\n    Args:\n        cfg (Dict): Data pipeline config.\n        keep_ratio (bool): Whether to keep aspect ratio when resizing image.\n\n    \"\"\"\n\n    def __init__(self, cfg: Dict, keep_ratio: bool):\n        # \u4ececfg\u5b57\u5178\u4e2d\u6784\u9020`ShapeTransform`\u548c`color_aug_and_norm`\n        self.shape_transform = ShapeTransform(keep_ratio, **cfg)\n        self.color = functools.partial(color_aug_and_norm, kwargs=cfg)\n\n    def __call__(self, dataset: Dataset, meta: Dict, dst_shape: Tuple[int, int]):\n        meta = self.shape_transform(meta, dst_shape=dst_shape)\n        meta = self.color(meta=meta)\n        return meta\n</code></pre> <p>\u7136\u540e\u770b\u4e0b<code>ShapeTransform</code>\u548c<code>color_aug_and_norm</code>\u8fd9\u4e24\u4e2a\u7c7b\u548c\u51fd\u6570\uff1a</p> <p><code>ShapeTransform</code>\u4e3b\u8981\u505a\u4e00\u4e9b\u5f62\u72b6\u4e0a\u7684\u53d8\u6362\uff0c\u4e3b\u8981\u901a\u8fc7\u4eff\u5c04\u53d8\u6362\u5b9e\u73b0\u3002</p> <p>\u4eff\u5c04\u53d8\u6362\u53ef\u4ee5\u901a\u8fc7\u4e00\u7cfb\u5217\u7684\u539f\u5b50\u53d8\u6362\u7684\u590d\u5408\u6765\u5b9e\u73b0\uff0c\u5305\u62ec\uff1a\u5e73\u79fb\uff08Translation\uff09\u3001\u7f29\u653e\uff08Scale\uff09\u3001\u7ffb\u8f6c\uff08Flip\uff09\u3001\u65cb\u8f6c\uff08Rotation\uff09\u548c\u526a\u5207\uff08Shear\uff09\u3002</p> <p>\u4eff\u5c04\u53d8\u6362\u53ef\u4ee5\u5b9e\u73b0\u5e73\u79fb\u7f29\u653e\u548c\u65cb\u8f6c\uff0c\u5982\u679c\u7528\u5230\u7b2c\u4e09\u5217\u7684\u8bdd\u8fd8\u53ef\u4ee5\u5b9e\u73b0\u900f\u89c6\u53d8\u6362(\u4e5f\u53eb\u6295\u5f71\u53d8\u6362)\u3002</p> <p>\u5982\u679c\u5bf9\u8fd9\u5757\u4e0d\u61c2\u5f97\u540c\u5b66\u53ef\u4ee5\u770b\u4e0b\u77e9\u9635\u8bba\u548c\u6570\u5b57\u56fe\u50cf\u5904\u7406\u3002</p> <p>\u4eff\u5c04\u53d8\u6362\u53ef\u4ee5\u7528\u4e0b\u9762\u516c\u5f0f\u8868\u793a\uff1a</p> <p></p> <p>\u6295\u5f71\u53d8\u6362\u516c\u5f0f\u5982\u4e0b\uff1a</p> <p></p> <pre><code># Copyright 2021 RangiLyu.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport math\nimport random\nfrom typing import Dict, Optional, Tuple\n\nimport cv2\nimport numpy as np\n\n\ndef get_flip_matrix(prob=0.5):\n    # \u5efa\u7acb3x3\u7684\u5355\u4f4d\u6570\u7ec4\n    # \u6ce8\u610f\u5750\u6807\u53d8\u5316\n    # x_new = a1 * x + a2 * y + t_x\n    #       = a1 * x \uff08\u5176\u4f59\u90fd\u662f0\uff09\n    # \u8fd9\u91cc\u628aa1\u53d8\u6210\u4e86\u8d1f\u4e00\u5c31\u4ee3\u8868\n    # x_new = -x\n    # \u5373\u6cbf\u7740y\u8f74\u5bf9\u79f0\u7ffb\u8f6c\n    \"\"\"\n    array([[1., 0., 0.],\n           [0., 1., 0.],\n           [0., 0., 1.]])\n    \"\"\"\n    F = np.eye(3)\n    if random.random() &lt; prob:\n        F[0, 0] = -1\n    return F\n\n\ndef get_perspective_matrix(perspective=0.0):\n    \"\"\"\n\n    :param perspective:\n    :return:\n    \"\"\"\n    P = np.eye(3)\n    # \u5efa\u7acb3x3\u7684\u5355\u4f4d\u6570\u7ec4\n    # \u6ce8\u610f\u5750\u6807\u53d8\u5316\n    # \u7b2c\u4e09\u884c\u7684\u7b2c\u4e00\u4e8c\u5217\u4e0d\u662f0\u65f6\uff0c\u505a\u900f\u89c6\u53d8\u6362\n    P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)\n    P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)\n    return P\n\n\ndef get_rotation_matrix(degree=0.0):\n    \"\"\"\n\n    :param degree:\n    :return:\n    \"\"\"\n    # \u5efa\u7acb3x3\u7684\u5355\u4f4d\u6570\u7ec4\n    # \u6ce8\u610f\u5750\u6807\u53d8\u5316\n    # \u5f97\u5230\u89d2\u5ea6a\u540e\uff0c\u91c7\u7528opencv\u8ba1\u7b97\u65cb\u8f6c\u77e9\u9635\n    # \u5982\u4f55\u5f97\u5230\u65cb\u8f6c\u77e9\u9635\u53ef\u4ee5\u53c2\u8003\n    # https://zhuanlan.zhihu.com/p/533911656\n    R = np.eye(3)\n    a = random.uniform(-degree, degree)\n    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=1)\n    return R\n\n\ndef get_scale_matrix(ratio=(1, 1)):\n    \"\"\"\n\n    :param ratio:\n    \"\"\"\n    # \u5efa\u7acb3x3\u7684\u5355\u4f4d\u6570\u7ec4\n    # \u5bf9\u5bf9\u89d2\u7ebf\u4e0a\u5143\u7d20\u8fdb\u884c\u66f4\u6539\u5373\u53ef\u5f97\u5230\u7f29\u653e\u540e\u7684\u53d8\u6362\n    Scl = np.eye(3)\n    scale = random.uniform(*ratio)\n    Scl[0, 0] *= scale\n    Scl[1, 1] *= scale\n    return Scl\n\n\ndef get_stretch_matrix(width_ratio=(1, 1), height_ratio=(1, 1)):\n    \"\"\"\n\n    :param width_ratio:\n    :param height_ratio:\n    \"\"\"\n    # \u975e\u7b49\u6bd4\u4f8b\u7f29\u653e\n    Str = np.eye(3)\n    Str[0, 0] *= random.uniform(*width_ratio)\n    Str[1, 1] *= random.uniform(*height_ratio)\n    return Str\n\n\ndef get_shear_matrix(degree):\n    \"\"\"\n\n    :param degree:\n    :return:\n    \"\"\"\n    # \u9519\u5207\u77e9\u9635\n    # \u53c2\u8003\u8d44\u6599\n    # https://blog.csdn.net/weixin_44878336/article/details/124902173\n    Sh = np.eye(3)\n    Sh[0, 1] = math.tan(\n        random.uniform(-degree, degree) * math.pi / 180\n    )  # x shear (deg)\n    Sh[1, 0] = math.tan(\n        random.uniform(-degree, degree) * math.pi / 180\n    )  # y shear (deg)\n    return Sh\n\n\ndef get_translate_matrix(translate, width, height):\n    \"\"\"\n\n    :param translate:\n    :return:\n    \"\"\"\n    # \u5e73\u79fb\u53d8\u6362\n    T = np.eye(3)\n    T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  # x translation\n    T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  # y translation\n    return T\n\n\ndef get_resize_matrix(raw_shape, dst_shape, keep_ratio):\n    \"\"\"\n    Get resize matrix for resizing raw img to input size\n    :param raw_shape: (width, height) of raw image\n    :param dst_shape: (width, height) of input image\n    :param keep_ratio: whether keep original ratio\n    :return: 3x3 Matrix\n    \"\"\"\n    # \u83b7\u53d6resize matrix \u7528\u4e8e\u5c06\u539f\u56fe\u7f29\u653e\u5230\u6240\u9700\u8981\u7684\u5927\u5c0f\n    r_w, r_h = raw_shape\n    d_w, d_h = dst_shape\n    Rs = np.eye(3)\n    if keep_ratio:\n        C = np.eye(3)\n        C[0, 2] = -r_w / 2\n        C[1, 2] = -r_h / 2\n\n        if r_w / r_h &lt; d_w / d_h:\n            ratio = d_h / r_h\n        else:\n            ratio = d_w / r_w\n        Rs[0, 0] *= ratio\n        Rs[1, 1] *= ratio\n\n        T = np.eye(3)\n        T[0, 2] = 0.5 * d_w\n        T[1, 2] = 0.5 * d_h\n        # \u62c6\u89e3\u52a8\u4f5c\uff1a\u5148\u5bf9\u539f\u56fe\u5e73\u79fb \u7136\u540e \u7f29\u653e \u6700\u540e\u5e73\u79fb\u56de\u53bb\n        return T @ Rs @ C\n    else:\n        Rs[0, 0] *= d_w / r_w\n        Rs[1, 1] *= d_h / r_h\n        return Rs\n\n\n\ndef warp_boxes(boxes, M, width, height):\n    n = len(boxes)\n    # \u9488\u5bf9bboxes\u505a\u76f8\u540c\u7684\u53d8\u5316\n    if n:\n        # warp points \u6bcf\u4e00\u884c\u5143\u7d20\u5305\u62ec x y 1\n        xy = np.ones((n * 4, 3))\n\n        xy[:, :2] = boxes[:, [0, 1, 2, 3, 0, 3, 2, 1]].reshape(\n            n * 4, 2\n        )  # x1y1, x2y2, x1y2, x2y1\n        # \u6309\u7406\u8bf4\u5e94\u8be5\u662f M @ xy\n        # \u8981\u6c42xy\u5f62\u72b6\u4e3a(3,N) \u4f46\u662f\u8fd9\u91ccxy\u8f6c\u7f6e\u4e86\uff0c\u6545M\u4e5f\u8f6c\u7f6e\n        xy = xy @ M.T  # transform\n        # \u5f52\u4e00\u5316\n        xy = (xy[:, :2] / xy[:, 2:3]).reshape(n, 8)  # rescale\n        # create new boxes\n        x = xy[:, [0, 2, 4, 6]]\n        y = xy[:, [1, 3, 5, 7]]\n        xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n        # clip boxes\n        xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width)\n        xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height)\n        return xy.astype(np.float32)\n    else:\n        return boxes\n\n\ndef get_minimum_dst_shape(\n    src_shape: Tuple[int, int],\n    dst_shape: Tuple[int, int],\n    divisible: Optional[int] = None,\n) -&gt; Tuple[int, int]:\n    \"\"\"Calculate minimum dst shape\"\"\"\n    src_w, src_h = src_shape\n    dst_w, dst_h = dst_shape\n\n    if src_w / src_h &lt; dst_w / dst_h:\n        ratio = dst_h / src_h\n    else:\n        ratio = dst_w / src_w\n\n    dst_w = int(ratio * src_w)\n    dst_h = int(ratio * src_h)\n\n    if divisible and divisible &gt; 0:\n        dst_w = max(divisible, int((dst_w + divisible - 1) // divisible * divisible))\n        dst_h = max(divisible, int((dst_h + divisible - 1) // divisible * divisible))\n    return dst_w, dst_h\n\n\nclass ShapeTransform:\n    \"\"\"Shape transforms including resize, random perspective, random scale,\n    random stretch, random rotation, random shear, random translate,\n    and random flip.\n\n    Args:\n        keep_ratio: Whether to keep aspect ratio of the image.\n        divisible: Make image height and width is divisible by a number.\n        perspective: Random perspective factor.\n        scale: Random scale ratio.\n        stretch: Width and height stretch ratio range.\n        rotation: Random rotate degree.\n        shear: Random shear degree.\n        translate: Random translate ratio.\n        flip: Random flip probability.\n    \"\"\"\n\n    def __init__(\n        self,\n        keep_ratio: bool,\n        divisible: int = 0,\n        perspective: float = 0.0,\n        scale: Tuple[int, int] = (1, 1),\n        stretch: Tuple = ((1, 1), (1, 1)),\n        rotation: float = 0.0,\n        shear: float = 0.0,\n        translate: float = 0.0,\n        flip: float = 0.0,\n        **kwargs\n    ):\n        self.keep_ratio = keep_ratio\n        self.divisible = divisible\n        self.perspective = perspective\n        self.scale_ratio = scale\n        self.stretch_ratio = stretch\n        self.rotation_degree = rotation\n        self.shear_degree = shear\n        self.flip_prob = flip\n        self.translate_ratio = translate\n\n    def __call__(self, meta_data, dst_shape):\n        raw_img = meta_data[\"img\"]\n        height = raw_img.shape[0]  # shape(h,w,c)\n        width = raw_img.shape[1]\n\n        # center\n        # \u5c06\u56fe\u50cf\u4e2d\u5fc3\u79fb\u52a8\u5230\u5750\u6807\u539f\u70b9\n        C = np.eye(3)\n        C[0, 2] = -width / 2\n        C[1, 2] = -height / 2\n\n        P = get_perspective_matrix(self.perspective)\n        C = P @ C\n\n        Scl = get_scale_matrix(self.scale_ratio)\n        C = Scl @ C\n\n        Str = get_stretch_matrix(*self.stretch_ratio)\n        C = Str @ C\n\n        R = get_rotation_matrix(self.rotation_degree)\n        C = R @ C\n\n        Sh = get_shear_matrix(self.shear_degree)\n        C = Sh @ C\n\n        F = get_flip_matrix(self.flip_prob)\n        C = F @ C\n\n        T = get_translate_matrix(self.translate_ratio, width, height)\n        M = T @ C\n\n        if self.keep_ratio:\n            dst_shape = get_minimum_dst_shape(\n                (width, height), dst_shape, self.divisible\n            )\n\n        ResizeM = get_resize_matrix((width, height), dst_shape, self.keep_ratio)\n        M = ResizeM @ M\n        img = cv2.warpPerspective(raw_img, M, dsize=tuple(dst_shape))\n        meta_data[\"img\"] = img\n        meta_data[\"warp_matrix\"] = M\n        if \"gt_bboxes\" in meta_data:\n            boxes = meta_data[\"gt_bboxes\"]\n            meta_data[\"gt_bboxes\"] = warp_boxes(boxes, M, dst_shape[0], dst_shape[1])\n        if \"gt_bboxes_ignore\" in meta_data:\n            bboxes_ignore = meta_data[\"gt_bboxes_ignore\"]\n            meta_data[\"gt_bboxes_ignore\"] = warp_boxes(\n                bboxes_ignore, M, dst_shape[0], dst_shape[1]\n            )\n        if \"gt_masks\" in meta_data:\n            for i, mask in enumerate(meta_data[\"gt_masks\"]):\n                meta_data[\"gt_masks\"][i] = cv2.warpPerspective(\n                    mask, M, dsize=tuple(dst_shape)\n                )\n\n        return meta_data\n</code></pre> <p>\u901a\u8fc7\u5bf9\u53d8\u5316\u77e9\u9635\u7684\u8ba1\u7b97\uff0c\u4f5c\u8005\u5c06\u4e00\u7cfb\u5217\u5f62\u72b6\u4e0a\u7684\u53d8\u6362\u8f6c\u6362\u4e3a\u53d8\u6362\u77e9\u9635\u7684\u4e58\u6cd5\u5f62\u5f0f\u3002\u540c\u65f6\u5c06\u53d8\u6362\u77e9\u9635\u5b58\u4e0b\u6765\uff0c\u901a\u8fc7\u6c42\u9006\u7684\u5f62\u5f0f\u5c31\u53ef\u4ee5\u5f97\u5230\u9006\u53d8\u6362\u3002</p> <p>\u4e0b\u9762\u8bb2\u89e3\u989c\u8272\u53d8\u5316<code>color_aug_and_norm</code>\u51fd\u6570(\u5728<code>nanodet\\data\\transform\\color.py</code>)</p> <pre><code>def random_brightness(img, delta):\n    # \u6574\u4f53\u52a0\u4e0a\u67d0\u4e2a\u503c\u5373\u4e3a\u589e\u52a0\u4eae\u5ea6\n    img += random.uniform(-delta, delta)\n    return img\n\n\ndef random_contrast(img, alpha_low, alpha_up):\n    # \u5bf9\u6bd4\u5ea6\n    img *= random.uniform(alpha_low, alpha_up)\n    return img\n\n\ndef random_saturation(img, alpha_low, alpha_up):\n    hsv_img = cv2.cvtColor(img.astype(np.float32), cv2.COLOR_BGR2HSV)\n    # S \u901a\u9053\u5373\u4e3a\u9971\u548c\u5ea6\n    hsv_img[..., 1] *= random.uniform(alpha_low, alpha_up)\n    img = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n    return img\n\n\ndef _normalize(img, mean, std):\n    mean = np.array(mean, dtype=np.float32).reshape(1, 1, 3) / 255\n    std = np.array(std, dtype=np.float32).reshape(1, 1, 3) / 255\n    img = (img - mean) / std\n    return img\n\n\ndef color_aug_and_norm(meta, kwargs):\n    img = meta[\"img\"].astype(np.float32) / 255\n\n    if \"brightness\" in kwargs and random.randint(0, 1):\n        img = random_brightness(img, kwargs[\"brightness\"])\n\n    if \"contrast\" in kwargs and random.randint(0, 1):\n        img = random_contrast(img, *kwargs[\"contrast\"])\n\n    if \"saturation\" in kwargs and random.randint(0, 1):\n        img = random_saturation(img, *kwargs[\"saturation\"])\n    # cv2.imshow('trans', img)\n    # cv2.waitKey(0)\n    # \u5f52\u4e00\u5316\n    img = _normalize(img, *kwargs[\"normalize\"])\n    meta[\"img\"] = img\n    return meta\n</code></pre> <p>\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u5728<code>nanodet\\data</code>\u4e0b\u9762\u8fd8\u6709<code>batch_process.py</code>\u548c<code>collate.py</code>\u8fd9\u4e24\u4e2a\u6587\u4ef6\uff0c\u770b\u540d\u5b57\u5e94\u8be5\u662f\u670d\u52a1\u4e8eDataloader\u7684\uff0c\u8fd9\u4e2a\u5c06\u5728\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u73af\u8282\u8fdb\u884c\u89e3\u8bfb\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#_3","title":"\u4e09. \u6a21\u578b\u6784\u5efa\u4ee3\u7801\u89e3\u8bfb","text":"<p>\u518d\u770b\u6a21\u578b\u5b9a\u4e49yaml\u76f8\u5173\u5185\u5bb9</p> <pre><code># nanodet-plus-m_320\n# COCO mAP(0.5:0.95) = 0.270\n#             AP_50  = 0.418\n#             AP_75  = 0.281\n#           AP_small = 0.083\n#               AP_m = 0.278\n#               AP_l = 0.451\nsave_dir: workspace/nanodet-plus-m_320\nmodel:\n  weight_averager:\n    name: ExpMovingAverager\n    decay: 0.9998\n  arch:\n    name: NanoDetPlus\n    detach_epoch: 10\n    backbone:\n      name: ShuffleNetV2\n      model_size: 1.0x\n      out_stages: [2,3,4]\n      activation: LeakyReLU\n    fpn:\n      name: GhostPAN\n      in_channels: [116, 232, 464]\n      out_channels: 96\n      kernel_size: 5\n      num_extra_level: 1\n      use_depthwise: True\n      activation: LeakyReLU\n    head:\n      name: NanoDetPlusHead\n      num_classes: 80\n      input_channel: 96\n      feat_channels: 96\n      stacked_convs: 2\n      kernel_size: 5\n      strides: [8, 16, 32, 64]\n      activation: LeakyReLU\n      reg_max: 7\n      norm_cfg:\n        type: BN\n      loss:\n        loss_qfl:\n          name: QualityFocalLoss\n          use_sigmoid: True\n          beta: 2.0\n          loss_weight: 1.0\n        loss_dfl:\n          name: DistributionFocalLoss\n          loss_weight: 0.25\n        loss_bbox:\n          name: GIoULoss\n          loss_weight: 2.0\n    # Auxiliary head, only use in training time.\n    aux_head:\n      name: SimpleConvHead\n      num_classes: 80\n      input_channel: 192\n      feat_channels: 192\n      stacked_convs: 4\n      strides: [8, 16, 32, 64]\n      activation: LeakyReLU\n      reg_max: 7\n</code></pre> <p><code>NanoDetPlusHead</code>\u7684\u4ee3\u7801\u89e3\u8bfb\u5df2\u7ecf\u5728\u524d\u9762\u4ecb\u7ecd\u8fc7\u4e86\uff0c\u4e0b\u9762\u770b\u4e00\u4e0b<code>ShuffleNetV2</code>\u90e8\u5206\uff08<code>nanodet\\model\\backbone\\shufflenetv2.py</code>\uff09\uff1a</p> <pre><code>def channel_shuffle(x, groups):\n    # type: (torch.Tensor, int) -&gt; torch.Tensor\n    # B, C, H, W \n    batchsize, num_channels, height, width = x.data.size()\n    # \u5c06C \u901a\u9053\u62c6\u5206\u4e3a groups \u7ec4\uff0c\u6bcf\u4e00\u7ec4\u6709channels_per_group\u4e2a\u5143\u7d20\n    channels_per_group = num_channels // groups\n\n    # reshape\n    x = x.view(batchsize, groups, channels_per_group, height, width)\n\n    # \u884c\u5217\u4e92\u6362\n    x = torch.transpose(x, 1, 2).contiguous()\n\n    # flatten \u6253\u5e73\u5904\u7406\n    x = x.view(batchsize, -1, height, width)\n\n    # \u4e4b\u524d\u662f \n    # X1 X2 X3 X4 X5 X6\n    # \u5047\u8bbe\u5206\u6210\u4e86\u4e24\u7ec4\n    # \u4e24\u884c\u4e09\u5217\u8868\u793a\u4e3a\n    # X1 X2 X3\n    # X4 X5 X6\n    # \u8f6c\u7f6e\u540e\u4e3a\n    # X1 X4\n    # X2 X5\n    # X3 X6\n    # \u6253\u5e73\u5904\u7406\u540e\u4e3a\n    # X1 X4 X2 X5 X3 X6    \n    return x\n\n\nclass ShuffleNetV2(nn.Module):\n    # \u7701\u7565\u90e8\u5206\u51fd\u6570\n    # ...\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n        output = []\n        for i in range(2, 5):\n            stage = getattr(self, \"stage{}\".format(i))\n            x = stage(x)\n            if i in self.out_stages:\n                output.append(x)\n        # \u8fd4\u56de stage3 - stage5\u7684\u7279\u5f81\n        return tuple(output)\n</code></pre> <p>\u5148\u7ed9\u51fa<code>GhostBottleneck</code>\u7684\u5b9a\u4e49\uff08<code>nanodet/model/backbone/ghostnet.py</code>\uff09</p> <pre><code>class GhostModule(nn.Module):\n    def __init__(\n        self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, activation=\"ReLU\"\n    ):\n        super(GhostModule, self).__init__()\n        self.oup = oup\n        # \u9884\u5148\u751f\u6210 init_channels \u4e2a\n        init_channels = math.ceil(oup / ratio)\n        new_channels = init_channels * (ratio - 1)\n\n        self.primary_conv = nn.Sequential(\n            nn.Conv2d(\n                inp, init_channels, kernel_size, stride, kernel_size // 2, bias=False\n            ),\n            nn.BatchNorm2d(init_channels),\n            act_layers(activation) if activation else nn.Sequential(),\n        )\n\n        # groups = init_channels \u8868\u793a\n        # \u5bf9\u4e8einit_channels\u4e2a\u901a\u9053\uff0c\u6bcf\u4e2a\u901a\u9053\u90fd\u6709 new_channels / init_channels \u4e2a\u8ba1\u7b97\u800c\u6765\u7684\u7279\u5f81\n        self.cheap_operation = nn.Sequential(\n            nn.Conv2d(\n                init_channels,\n                new_channels,\n                dw_size,\n                1,\n                dw_size // 2,\n                groups=init_channels,\n                bias=False,\n            ),\n            nn.BatchNorm2d(new_channels),\n            act_layers(activation) if activation else nn.Sequential(),\n        )\n\n    def forward(self, x):\n        x1 = self.primary_conv(x)\n        x2 = self.cheap_operation(x1)\n        # out \u6709 primary_conv \u548c cheap_operation\u8ba1\u7b97\u800c\u6765\n        out = torch.cat([x1, x2], dim=1)\n        return out\n\n\nclass GhostBottleneck(nn.Module):\n    \"\"\"Ghost bottleneck w/ optional SE\"\"\"\n\n    def __init__(\n        self,\n        in_chs,\n        mid_chs,\n        out_chs,\n        dw_kernel_size=3,\n        stride=1,\n        activation=\"ReLU\",\n        se_ratio=0.0,\n    ):\n        super(GhostBottleneck, self).__init__()\n        has_se = se_ratio is not None and se_ratio &gt; 0.0\n        self.stride = stride\n\n        # Point-wise expansion\n        self.ghost1 = GhostModule(in_chs, mid_chs, activation=activation)\n\n        # Depth-wise convolution\n        if self.stride &gt; 1:\n            self.conv_dw = nn.Conv2d(\n                mid_chs,\n                mid_chs,\n                dw_kernel_size,\n                stride=stride,\n                padding=(dw_kernel_size - 1) // 2,\n                groups=mid_chs,\n                bias=False,\n            )\n            self.bn_dw = nn.BatchNorm2d(mid_chs)\n\n        # Squeeze-and-excitation\n        if has_se:\n            self.se = SqueezeExcite(mid_chs, se_ratio=se_ratio)\n        else:\n            self.se = None\n\n        # Point-wise linear projection\n        self.ghost2 = GhostModule(mid_chs, out_chs, activation=None)\n\n        # shortcut\n        if in_chs == out_chs and self.stride == 1:\n            self.shortcut = nn.Sequential()\n        else:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_chs,\n                    in_chs,\n                    dw_kernel_size,\n                    stride=stride,\n                    padding=(dw_kernel_size - 1) // 2,\n                    groups=in_chs,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(in_chs),\n                nn.Conv2d(in_chs, out_chs, 1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(out_chs),\n            )\n\n    def forward(self, x):\n        residual = x\n\n        # 1st ghost bottleneck\n        x = self.ghost1(x)\n\n        # Depth-wise convolution\n        if self.stride &gt; 1:\n            x = self.conv_dw(x)\n            x = self.bn_dw(x)\n\n        # Squeeze-and-excitation\n        if self.se is not None:\n            x = self.se(x)\n\n        # 2nd ghost bottleneck\n        x = self.ghost2(x)\n\n        x += self.shortcut(residual)\n        return x\n</code></pre> <p>\u5728<code>GhostModule</code>\u4e2d\u9700\u8981\u6ce8\u610f\u7684\u662f\u611f\u53d7\u91ce\u7684\u589e\u5927\u662f\u7531<code>cheap_operation</code>\u5b8c\u6210\u7684\uff0c\u5b9e\u9645\u4e0a\u5176\u5e76\u4e0d<code>cheap</code>\u3002</p> <p><code>primary_conv</code>\u91c7\u75281x1\u5377\u79ef\uff0c\u5e76\u4e0d\u6539\u53d8\u611f\u53d7\u91ce\uff0c\u4ec5\u4ec5\u63d0\u4f9b\u4e00\u4e2a\u901a\u9053\u95f4\u4fe1\u606f\u878d\u5408\u7684\u4f5c\u7528\u3002</p> <p>\u4e0b\u9762\u770b\u4e00\u4e0b<code>GhostPAN</code>(<code>nanodet\\model\\fpn\\ghost_pan.py</code>)</p> <p>\u5148\u7ed9\u51faPAN\u7684\u7ed3\u6784\u56fe</p> <p></p> <pre><code>class GhostBlocks(nn.Module):\n    \"\"\"Stack of GhostBottleneck used in GhostPAN.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        expand (int): Expand ratio of GhostBottleneck. Default: 1.\n        kernel_size (int): Kernel size of depthwise convolution. Default: 5.\n        num_blocks (int): Number of GhostBottlecneck blocks. Default: 1.\n        use_res (bool): Whether to use residual connection. Default: False.\n        activation (str): Name of activation function. Default: LeakyReLU.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        expand=1,\n        kernel_size=5,\n        num_blocks=1,\n        use_res=False,\n        activation=\"LeakyReLU\",\n    ):\n        super(GhostBlocks, self).__init__()\n        self.use_res = use_res\n        if use_res:\n            self.reduce_conv = ConvModule(\n                in_channels,\n                out_channels,\n                kernel_size=1,\n                stride=1,\n                padding=0,\n                activation=activation,\n            )\n        blocks = []\n        for _ in range(num_blocks):\n            blocks.append(\n                # in_chs, mid_chs, out_chs,\n                # \u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f dw_kernel_size \u4ec5\u4ec5\u63a7\u5236 shortcut DW\u5377\u79ef\u7684\u5377\u79ef\u6838\u7684\u5927\u5c0f\n                GhostBottleneck(\n                    in_channels,\n                    int(out_channels * expand),\n                    out_channels,\n                    dw_kernel_size=kernel_size,\n                    activation=activation,\n                )\n            )\n        self.blocks = nn.Sequential(*blocks)\n\n    def forward(self, x):\n        out = self.blocks(x)\n        if self.use_res:\n            out = out + self.reduce_conv(x)\n        return out\n\n\nclass GhostPAN(nn.Module):\n    \"\"\"Path Aggregation Network with Ghost block.\n\n    Args:\n        in_channels (List[int]): Number of input channels per scale.\n        out_channels (int): Number of output channels (used at each scale)\n        num_csp_blocks (int): Number of bottlenecks in CSPLayer. Default: 3\n        use_depthwise (bool): Whether to depthwise separable convolution in\n            blocks. Default: False\n        kernel_size (int): Kernel size of depthwise convolution. Default: 5.\n        expand (int): Expand ratio of GhostBottleneck. Default: 1.\n        num_blocks (int): Number of GhostBottlecneck blocks. Default: 1.\n        use_res (bool): Whether to use residual connection. Default: False.\n        num_extra_level (int): Number of extra conv layers for more feature levels.\n            Default: 0.\n        upsample_cfg (dict): Config dict for interpolate layer.\n            Default: `dict(scale_factor=2, mode='nearest')`\n        norm_cfg (dict): Config dict for normalization layer.\n            Default: dict(type='BN')\n        activation (str): Activation layer name.\n            Default: LeakyReLU.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        use_depthwise=False,\n        kernel_size=5,\n        expand=1,\n        num_blocks=1,\n        use_res=False,\n        num_extra_level=0,\n        upsample_cfg=dict(scale_factor=2, mode=\"bilinear\"),\n        norm_cfg=dict(type=\"BN\"),\n        activation=\"LeakyReLU\",\n    ):\n        super(GhostPAN, self).__init__()\n        assert num_extra_level &gt;= 0\n        assert num_blocks &gt;= 1\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        conv = DepthwiseConvModule if use_depthwise else ConvModule\n\n        # build top-down blocks\n        self.upsample = nn.Upsample(**upsample_cfg)\n        self.reduce_layers = nn.ModuleList()\n        for idx in range(len(in_channels)):\n            self.reduce_layers.append(\n                ConvModule(\n                    in_channels[idx],\n                    out_channels,\n                    1,\n                    norm_cfg=norm_cfg,\n                    activation=activation,\n                )\n            )\n        self.top_down_blocks = nn.ModuleList()\n        for idx in range(len(in_channels) - 1, 0, -1):\n            self.top_down_blocks.append(\n                GhostBlocks(\n                    out_channels * 2,\n                    out_channels,\n                    expand,\n                    kernel_size=kernel_size,\n                    num_blocks=num_blocks,\n                    use_res=use_res,\n                    activation=activation,\n                )\n            )\n\n        # build bottom-up blocks\n        self.downsamples = nn.ModuleList()\n        self.bottom_up_blocks = nn.ModuleList()\n        for idx in range(len(in_channels) - 1):\n            self.downsamples.append(\n                conv(\n                    out_channels,\n                    out_channels,\n                    kernel_size,\n                    stride=2,\n                    padding=kernel_size // 2,\n                    norm_cfg=norm_cfg,\n                    activation=activation,\n                )\n            )\n            self.bottom_up_blocks.append(\n                GhostBlocks(\n                    out_channels * 2,\n                    out_channels,\n                    expand,\n                    kernel_size=kernel_size,\n                    num_blocks=num_blocks,\n                    use_res=use_res,\n                    activation=activation,\n                )\n            )\n\n        # extra layers\n        self.extra_lvl_in_conv = nn.ModuleList()\n        self.extra_lvl_out_conv = nn.ModuleList()\n        for i in range(num_extra_level):\n            self.extra_lvl_in_conv.append(\n                conv(\n                    out_channels,\n                    out_channels,\n                    kernel_size,\n                    stride=2,\n                    padding=kernel_size // 2,\n                    norm_cfg=norm_cfg,\n                    activation=activation,\n                )\n            )\n            self.extra_lvl_out_conv.append(\n                conv(\n                    out_channels,\n                    out_channels,\n                    kernel_size,\n                    stride=2,\n                    padding=kernel_size // 2,\n                    norm_cfg=norm_cfg,\n                    activation=activation,\n                )\n            )\n\n    def forward(self, inputs):\n        \"\"\"\n        Args:\n            inputs (tuple[Tensor]): input features.\n        Returns:\n            tuple[Tensor]: multi level features.\n        \"\"\"\n        assert len(inputs) == len(self.in_channels)\n        inputs = [\n            reduce(input_x) for input_x, reduce in zip(inputs, self.reduce_layers)\n        ]\n        # inputs \u5206\u522b\u4ee3\u8868 P3-P5\n        # \u5206\u8fa8\u7387\u4f9d\u6b21\u51cf\u5c0f\n\n        # top-down path\n        inner_outs = [inputs[-1]]\n        for idx in range(len(self.in_channels) - 1, 0, -1):\n            feat_heigh = inner_outs[0]\n            feat_low = inputs[idx - 1]\n\n            inner_outs[0] = feat_heigh\n\n            # \u5bf9\u4f4e\u5206\u8fa8\u7387\u7279\u5f81\u56fe\u8fdb\u884c\u7ebf\u6027\u63d2\u503c\n            upsample_feat = self.upsample(feat_heigh)\n\n            # \u5728\u9ad8\u5206\u8fa8\u7387level\u4e0a\u5bf9\u7279\u5f81concat\u7136\u540e\u9001\u5165GhostBlocks\u8fdb\u884c\u878d\u5408\n            inner_out = self.top_down_blocks[len(self.in_channels) - 1 - idx](\n                torch.cat([upsample_feat, feat_low], 1)\n            )\n            # \u4fdd\u6301\u9ad8\u5206\u8fa8\u7387\u9760\u524d\uff0c\u4f4e\u5206\u8fa8\u7387\u9760\u540e\n            inner_outs.insert(0, inner_out)\n\n        # bottom-up path\n        outs = [inner_outs[0]]\n        for idx in range(len(self.in_channels) - 1):\n            feat_low = outs[-1]\n            feat_height = inner_outs[idx + 1]\n            # \u5bf9\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u8fdb\u884c\u4e0b\u91c7\u6837\n            downsample_feat = self.downsamples[idx](feat_low)\n            out = self.bottom_up_blocks[idx](\n                torch.cat([downsample_feat, feat_height], 1)\n            )\n            # \u59cb\u7ec8\u7ef4\u6301\u9ad8\u5206\u8fa8\u7387\u9760\u524d\uff0c\u4f4e\u5206\u7387\u9760\u540e\n            outs.append(out)\n\n        # extra layers\n        for extra_in_layer, extra_out_layer in zip(\n            self.extra_lvl_in_conv, self.extra_lvl_out_conv\n        ):\n            # \u5bf9 \u6700\u540e\u4e00\u4e2a\u4f4e\u5206\u8fa8\u7387\u8fdb\u884c\u4e0b\u91c7\u6837\u540e\u5f97\u5230\u66f4\u4f4e\u7684\u5206\u8fa8\u7387\u7279\u5f81\u7528\u4e8e\u8ba1\u7b97\n            # \u4ecePicodet\u5f97\u5230\u7684\u7ecf\u9a8c\n            outs.append(extra_in_layer(inputs[-1]) + extra_out_layer(outs[-1]))\n\n        return tuple(outs)\n</code></pre> <p>\u4ece\u6e90\u7801\u53ef\u4ee5\u770b\u51faPAFPN\u7684\u8f93\u51fa\u4e00\u5171\u6709\u56db\u5c42\uff0c\u5373\u539f\u6765\u7684\u4e09\u5c42\u5916\u52a0\u5bf9\u4e4b\u524d\u4e09\u5c42\u4e2d\u6700\u4f4e\u5206\u8fa8\u7387\u4e0b\u91c7\u6837\u5f97\u5230\u7684\u7279\u5f81\u3002</p> <p>\u4e0b\u9762\u518d\u770b\u4e0bHead\u90e8\u5206\uff0c\u9996\u5148\u4ecb\u7ecd<code>NanoDetPlusHead</code>(<code>nanodet/model/head/nanodet_plus_head.py</code>)</p> <p>\u8fd9\u91cc\u4ec5\u7ed9\u51fa\u6a21\u578b\u7684\u642d\u5efa\u548c\u524d\u5411\u4f20\u64ad\u90e8\u5206\uff0closs\u8ba1\u7b97\u7b49\u529f\u80fd\u4e0b\u5c0f\u7ed3\u5728\u7ed9\u51fa\u3002</p> <pre><code>class NanoDetPlusHead(nn.Module):\n    \"\"\"Detection head used in NanoDet-Plus.\n\n    Args:\n        num_classes (int): Number of categories excluding the background\n            category.\n        loss (dict): Loss config.\n        input_channel (int): Number of channels of the input feature.\n        feat_channels (int): Number of channels of the feature.\n            Default: 96.\n        stacked_convs (int): Number of conv layers in the stacked convs.\n            Default: 2.\n        kernel_size (int): Size of the convolving kernel. Default: 5.\n        strides (list[int]): Strides of input multi-level feature maps.\n            Default: [8, 16, 32].\n        conv_type (str): Type of the convolution.\n            Default: \"DWConv\".\n        norm_cfg (dict): Dictionary to construct and config norm layer.\n            Default: dict(type='BN').\n        reg_max (int): The maximal value of the discrete set. Default: 7.\n        activation (str): Type of activation function. Default: \"LeakyReLU\".\n        assigner_cfg (dict): Config dict of the assigner. Default: dict(topk=13).\n    \"\"\"\n\n    def __init__(\n        self,\n        num_classes,\n        loss,\n        input_channel,\n        feat_channels=96,\n        stacked_convs=2,\n        kernel_size=5,\n        strides=[8, 16, 32],\n        conv_type=\"DWConv\",\n        norm_cfg=dict(type=\"BN\"),\n        reg_max=7,\n        activation=\"LeakyReLU\",\n        assigner_cfg=dict(topk=13),\n        **kwargs\n    ):\n        super(NanoDetPlusHead, self).__init__()\n        self.num_classes = num_classes\n        self.in_channels = input_channel\n        self.feat_channels = feat_channels\n        self.stacked_convs = stacked_convs\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.reg_max = reg_max\n        self.activation = activation\n        # \u9ed8\u8ba4\u4f7f\u7528DepthwiseConvModule\n        self.ConvModule = ConvModule if conv_type == \"Conv\" else DepthwiseConvModule\n\n        self.loss_cfg = loss\n        self.norm_cfg = norm_cfg\n\n        self.assigner = DynamicSoftLabelAssigner(**assigner_cfg)\n        # \u6839\u636e\u8f93\u51fa\u7684\u6846\u5206\u5e03\u8fdb\u884c\u79ef\u5206,\u5f97\u5230\u6700\u7ec8\u7684\u4f4d\u7f6e\u503c\n        self.distribution_project = Integral(self.reg_max)\n\n        # \u8054\u5408\u4e86\u5206\u7c7b\u548c\u6846\u7684\u8d28\u91cf\u4f30\u8ba1\u8868\u793a\n        self.loss_qfl = QualityFocalLoss(\n            beta=self.loss_cfg.loss_qfl.beta,\n            loss_weight=self.loss_cfg.loss_qfl.loss_weight,\n        )\n        # \u521d\u59cb\u5316\u53c2\u6570\u4e2dreg_max\u7684\u7531\u6765,\u5728\u5bf9\u5e94\u6a21\u5757\u4e2d\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u4ecb\u7ecd\n        self.loss_dfl = DistributionFocalLoss(\n            loss_weight=self.loss_cfg.loss_dfl.loss_weight\n        )\n        self.loss_bbox = GIoULoss(loss_weight=self.loss_cfg.loss_bbox.loss_weight)\n        self._init_layers()\n        self.init_weights()\n\n    def _init_layers(self):\n        self.cls_convs = nn.ModuleList()\n        for _ in self.strides:\n            # \u4e3a\u6bcf\u4e2astride\u7684\u521b\u5efa\u4e00\u4e2ahead head\u53c2\u6570\u4e4b\u95f4\u4e0d\u5171\u4eab\n            cls_convs = self._buid_not_shared_head()\n            self.cls_convs.append(cls_convs)\n\n        self.gfl_cls = nn.ModuleList(\n            [\n                nn.Conv2d(\n                    self.feat_channels,\n                    # \u5206\u7c7b\u8f93\u51fa + bbox\u56de\u5f52\u8f93\u51fa 4 \u4ee3\u88684 \u4e2a\u8ddd\u79bb\uff0c\n                    # (self.reg_max + 1)\u4ee3\u8868 GFL\u4e2d \u5bf9 box\u8868\u793a\u7684\u5750\u6807\u7684\u503c\u7684\u6982\u7387\u5206\u5e03\n                    self.num_classes + 4 * (self.reg_max + 1),\n                    1,\n                    padding=0,\n                )\n                for _ in self.strides\n            ]\n        )\n\n    def _buid_not_shared_head(self):\n        cls_convs = nn.ModuleList()\n        for i in range(self.stacked_convs):\n            # \u7b2c\u4e00\u5c42\u8981\u548cPAN\u7684\u8f93\u51fa\u5bf9\u9f50\u901a\u9053\n            chn = self.in_channels if i == 0 else self.feat_channels\n            cls_convs.append(\n                self.ConvModule(\n                    chn,\n                    self.feat_channels,\n                    self.kernel_size,\n                    stride=1,\n                    padding=self.kernel_size // 2,\n                    norm_cfg=self.norm_cfg,\n                    bias=self.norm_cfg is None,\n                    activation=self.activation,\n                )\n            )\n        return cls_convs\n\n    def init_weights(self):\n        for m in self.cls_convs.modules():\n            if isinstance(m, nn.Conv2d):\n                normal_init(m, std=0.01)\n        # init cls head with confidence = 0.01\n        bias_cls = -4.595\n        for i in range(len(self.strides)):\n            normal_init(self.gfl_cls[i], std=0.01, bias=bias_cls)\n        print(\"Finish initialize NanoDet-Plus Head.\")\n\n    def forward(self, feats):\n        if torch.onnx.is_in_onnx_export():\n            return self._forward_onnx(feats)\n        outputs = []\n        for feat, cls_convs, gfl_cls in zip(\n            feats,\n            self.cls_convs,\n            self.gfl_cls,\n        ):\n            for conv in cls_convs:\n                feat = conv(feat)\n            output = gfl_cls(feat)\n            outputs.append(output.flatten(start_dim=2))\n        # \u8f93\u51fa B, number of bboxes, (num_classes + 4 * (self.reg_max + 1))\n        outputs = torch.cat(outputs, dim=2).permute(0, 2, 1)\n        return outputs\n</code></pre> <p>\u8fd9\u91cc\u8981\u6ce8\u610f\u7684\u662fhead\u7684strides\u662f\u56db\u4e2a\uff0c\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u53ef\u4ee5\u770b\u5230\u5982\u4e0b\uff0c\u8fd9\u4e00\u70b9\u4e5f\u548cPAFAN\u8f93\u51fa\u76f8\u543b\u5408\u3002</p> <pre><code>strides: [8, 16, 32, 64]\n</code></pre> <p>\u4e0b\u9762\u6765\u770b<code>SimpleConvHead</code>\u7684\u6784\u9020\u4ee3\u7801\uff08<code>nanodet/model/head/simple_conv_head.py</code>\uff09</p> <pre><code>class SimpleConvHead(nn.Module):\n    def __init__(\n        self,\n        num_classes,\n        input_channel,\n        feat_channels=256,\n        stacked_convs=4,\n        strides=[8, 16, 32],\n        conv_cfg=None,\n        norm_cfg=dict(type=\"GN\", num_groups=32, requires_grad=True),\n        activation=\"LeakyReLU\",\n        reg_max=16,\n        **kwargs\n    ):\n        super(SimpleConvHead, self).__init__()\n        self.num_classes = num_classes\n        self.in_channels = input_channel\n        self.feat_channels = feat_channels\n        self.stacked_convs = stacked_convs\n        self.strides = strides\n        self.reg_max = reg_max\n\n        self.conv_cfg = conv_cfg\n        self.norm_cfg = norm_cfg\n        self.activation = activation\n        self.cls_out_channels = num_classes\n\n        self._init_layers()\n        self.init_weights()\n\n    def _init_layers(self):\n        self.relu = nn.ReLU(inplace=True)\n        self.cls_convs = nn.ModuleList()\n        self.reg_convs = nn.ModuleList()\n        for i in range(self.stacked_convs):\n            chn = self.in_channels if i == 0 else self.feat_channels\n            self.cls_convs.append(\n                ConvModule(\n                    chn,\n                    self.feat_channels,\n                    3,\n                    stride=1,\n                    padding=1,\n                    conv_cfg=self.conv_cfg,\n                    norm_cfg=self.norm_cfg,\n                    activation=self.activation,\n                )\n            )\n            self.reg_convs.append(\n                ConvModule(\n                    chn,\n                    self.feat_channels,\n                    3,\n                    stride=1,\n                    padding=1,\n                    conv_cfg=self.conv_cfg,\n                    norm_cfg=self.norm_cfg,\n                    activation=self.activation,\n                )\n            )\n        # \u5171\u4eab\u7684\u5206\u7c7b\u5934\u4e0e\u56de\u5f52\u5934\n        self.gfl_cls = nn.Conv2d(\n            self.feat_channels, self.cls_out_channels, 3, padding=1\n        )\n        self.gfl_reg = nn.Conv2d(\n            self.feat_channels, 4 * (self.reg_max + 1), 3, padding=1\n        )\n        # \u56de\u5f52\u5934\u524d\u9762\u52a0\u4e0a\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\n        self.scales = nn.ModuleList([Scale(1.0) for _ in self.strides])\n\n    def init_weights(self):\n        for m in self.cls_convs:\n            normal_init(m.conv, std=0.01)\n        for m in self.reg_convs:\n            normal_init(m.conv, std=0.01)\n        bias_cls = -4.595\n        normal_init(self.gfl_cls, std=0.01, bias=bias_cls)\n        normal_init(self.gfl_reg, std=0.01)\n\n    def forward(self, feats):\n        outputs = []\n        for x, scale in zip(feats, self.scales):\n            cls_feat = x\n            reg_feat = x\n            for cls_conv in self.cls_convs:\n                cls_feat = cls_conv(cls_feat)\n            for reg_conv in self.reg_convs:\n                reg_feat = reg_conv(reg_feat)\n            cls_score = self.gfl_cls(cls_feat)\n            bbox_pred = scale(self.gfl_reg(reg_feat)).float()\n            output = torch.cat([cls_score, bbox_pred], dim=1)\n            outputs.append(output.flatten(start_dim=2))\n        outputs = torch.cat(outputs, dim=2).permute(0, 2, 1)\n        return outputs\n</code></pre> <p>\u81f3\u6b64\uff0c\u6a21\u578b\u6784\u5efa\u4ee3\u7801\u89e3\u8bfb\u5b8c\u6bd5\u3002\u5176\u5b9e\u8fd8\u6709\u597d\u591a\u7ec6\u8282\uff0c\u6bd4\u5982bbox\u89e3\u7801\u4e0e\u7f16\u7801\uff0closs\u56de\u5f52\uff0c\u6807\u7b7e\u5206\u7c7b\u7b49\u7ec6\u8282\u8fd8\u6ca1\u6709\u89e3\u8bfb\u3002\u8fd8\u8bf7\u8bfb\u8005\u8010\u5fc3\u7684\u8bfb\u5b8c\uff0c\u4e0b\u9762\u624d\u662f\u7cbe\u5f69\u7684\u90e8\u5206\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#_4","title":"\u56db. \u6807\u7b7e\u5206\u914d\u4ee3\u7801\u89e3\u8bfb","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#41-box","title":"4.1 box\u7684\u89e3\u7801\u4e0e\u7f16\u7801","text":"<p>box\u7684\u7f16\u7801\u4e0e\u89e3\u7801\u5728<code>loss</code>\u8ba1\u7b97\u65f6\u88ab\u63d0\u8d77\uff0c\u6211\u4eec\u5148\u770b\u4e0bloss\u8ba1\u7b97\u7684\u6574\u4f53\u6d41\u7a0b\uff08<code>nanodet/model/head/nanodet_plus_head.py</code>\uff09\uff1a</p> <pre><code>def loss(self, preds, gt_meta, aux_preds=None):\n    \"\"\"Compute losses.\n    Args:\n        preds (Tensor): Prediction output.\n        gt_meta (dict): Ground truth information.\n        aux_preds (tuple[Tensor], optional): Auxiliary head prediction output.\n\n    Returns:\n        loss (Tensor): Loss tensor.\n        loss_states (dict): State dict of each loss.\n    \"\"\"\n    device = preds.device\n    batch_size = preds.shape[0]\n    gt_bboxes = gt_meta[\"gt_bboxes\"]\n    gt_labels = gt_meta[\"gt_labels\"]\n\n    gt_bboxes_ignore = gt_meta[\"gt_bboxes_ignore\"]\n    if gt_bboxes_ignore is None:\n        gt_bboxes_ignore = [None for _ in range(batch_size)]\n\n    input_height, input_width = gt_meta[\"img\"].shape[2:]\n    featmap_sizes = [\n        (math.ceil(input_height / stride), math.ceil(input_width) / stride)\n        for stride in self.strides\n    ]\n    # \u83b7\u53d6 \u6bcf\u4e00\u4e2alevel\u7684anchor point\n    # \u5373 \u5212\u5206\u7f51\u683c\u540e\u7684\u5148\u9a8c\u4e2d\u5fc3\u70b9\n    # get grid cells of one image\n    mlvl_center_priors = [\n        self.get_single_level_center_priors(\n            batch_size,\n            featmap_sizes[i],\n            stride,\n            dtype=torch.float32,\n            device=device,\n        )\n        for i, stride in enumerate(self.strides)\n    ]\n    # \u5c06\u4e2d\u5fc3\u70b9\u8fdb\u884cconcat\n    # mlvl_center_priors \u8fd4\u56de\u503c\u4e3a [B,N,4]\n    # \u5217\u5143\u7d20\u8868\u793a\u5206\u522b\u4e3a\uff1a left, top, width, height\n    # \u5176\u4e2d width=height=\u5f53\u524dstride\u957f\u5ea6\n    center_priors = torch.cat(mlvl_center_priors, dim=1)\n\n    cls_preds, reg_preds = preds.split(\n        [self.num_classes, 4 * (self.reg_max + 1)], dim=-1\n    )\n    # \u89e3\u7801 bbox \n    # self.distribution_project(reg_preds) \u8f93\u51fa \u4e2d\u5fc3\u70b9\u5230 \u56db\u4e2a\u8fb9\u7684\u8ddd\u79bb\n    # center_priors[..., 2, None] \u8868\u793a\u83b7\u53d6\u5f53\u524dstride \n    dis_preds = self.distribution_project(reg_preds) * center_priors[..., 2, None]\n    # \u5c06FCOS\u8868\u793a\u7684\u4e2d\u5fc3\u70b9\u5230\u56db\u4e2a\u8fb9\u7684\u8ddd\u79bb \u8f6c\u6362\u4e3a [x1 y1 x2 y2] \u683c\u5f0f\n    decoded_bboxes = distance2bbox(center_priors[..., :2], dis_preds)\n\n    # \u5982\u679c aux_preds \u4e0d\u4e3a\u7a7a \u5c31\u91c7\u7528aux_cls_preds\u8ba1\u7b97 \u6807\u7b7e\u5206\u914d\u7ed3\u679c\uff0c\u7136\u540e\u91c7\u7528\u8be5\u7ed3\u679c\u5bf9cls_preds\u548cdis_preds\u6c42loss\n    if aux_preds is not None:\n        # use auxiliary head to assign\n        aux_cls_preds, aux_reg_preds = aux_preds.split(\n            [self.num_classes, 4 * (self.reg_max + 1)], dim=-1\n        )\n\n        aux_dis_preds = (\n            self.distribution_project(aux_reg_preds) * center_priors[..., 2, None]\n        )\n        aux_decoded_bboxes = distance2bbox(center_priors[..., :2], aux_dis_preds)\n        batch_assign_res = multi_apply(\n            self.target_assign_single_img,\n            aux_cls_preds.detach(),\n            center_priors,\n            aux_decoded_bboxes.detach(),\n            gt_bboxes,\n            gt_labels,\n            gt_bboxes_ignore,\n        )\n    else:\n        # use self prediction to assign\n        batch_assign_res = multi_apply(\n            self.target_assign_single_img,\n            cls_preds.detach(),\n            center_priors,\n            decoded_bboxes.detach(),\n            gt_bboxes,\n            gt_labels,\n            gt_bboxes_ignore,\n        )\n\n    loss, loss_states = self._get_loss_from_assign(\n        cls_preds, reg_preds, decoded_bboxes, batch_assign_res\n    )\n\n    if aux_preds is not None:\n        aux_loss, aux_loss_states = self._get_loss_from_assign(\n            aux_cls_preds, aux_reg_preds, aux_decoded_bboxes, batch_assign_res\n        )\n        loss = loss + aux_loss\n        for k, v in aux_loss_states.items():\n            loss_states[\"aux_\" + k] = v\n    return loss, loss_states\n</code></pre> <p>\u4e0b\u9762\u770b\u4e0b<code>self.get_single_level_center_priors</code>\u505a\u4e86\u4ec0\u4e48</p> <pre><code>def get_single_level_center_priors(\n        self, batch_size, featmap_size, stride, dtype, device\n    ):\n    \"\"\"Generate centers of a single stage feature map.\n    Args:\n        batch_size (int): Number of images in one batch.\n        featmap_size (tuple[int]): height and width of the feature map\n        stride (int): down sample stride of the feature map\n        dtype (obj:`torch.dtype`): data type of the tensors\n        device (obj:`torch.device`): device of the tensors\n    Return:\n        priors (Tensor): center priors of a single level feature map.\n    \"\"\"\n    # h,w \u8868\u793a feature map\u7684\u5927\u5c0f\n    h, w = featmap_size\n    # \u751f\u6210\u7f51\u683c\n    x_range = (torch.arange(w, dtype=dtype, device=device)) * stride\n    y_range = (torch.arange(h, dtype=dtype, device=device)) * stride\n    y, x = torch.meshgrid(y_range, x_range)\n    y = y.flatten()\n    x = x.flatten()\n    # \u8fd9\u91cc\u5047\u8bbe len(x) = len(y)\n    strides = x.new_full((x.shape[0],), stride)\n    # \u6784\u9020 [x, y, width, height] \u8fd4\u56de\u7ed3\u679c\n    proiors = torch.stack([x, y, strides, strides], dim=-1)\n    # \n    return proiors.unsqueeze(0).repeat(batch_size, 1, 1)\n</code></pre> <p>\u901a\u8fc7\u4ee5\u4e0a\u4ee3\u7801\u53ef\u4ee5\u770b\u51fa<code>nanodet</code>\u4e0d\u652f\u6301\u957f\u548c\u5bbd\u4e0d\u76f8\u7b49\u7684\u60c5\u51b5\uff0c\u5982\u679c\u9700\u8981\u652f\u6301\u6700\u8d77\u7801\u8fd9\u91cc\u7684\u4ee3\u7801\u662f\u9700\u8981\u6539\u9020\u7684\u3002</p> <p>\u518d\u770b<code>distance2bbox</code>(<code>nanodet/util/box_transform.py</code>)\uff1a</p> <pre><code>import torch\n\n\ndef distance2bbox(points, distance, max_shape=None):\n    # \u5c06lrtb\u8ddd\u79bb\u548c\u4e2d\u5fc3\u70b9 \u89e3\u7801\u4e3a x1y1x2y2\u683c\u5f0f\n    \"\"\"Decode distance prediction to bounding box.\n\n    Args:\n        points (Tensor): Shape (n, 2), [x, y].\n        distance (Tensor): Distance from the given point to 4\n            boundaries (left, top, right, bottom).\n        max_shape (tuple): Shape of the image.\n\n    Returns:\n        Tensor: Decoded bboxes.\n    \"\"\"\n    x1 = points[..., 0] - distance[..., 0]\n    y1 = points[..., 1] - distance[..., 1]\n    x2 = points[..., 0] + distance[..., 2]\n    y2 = points[..., 1] + distance[..., 3]\n    if max_shape is not None:\n        x1 = x1.clamp(min=0, max=max_shape[1])\n        y1 = y1.clamp(min=0, max=max_shape[0])\n        x2 = x2.clamp(min=0, max=max_shape[1])\n        y2 = y2.clamp(min=0, max=max_shape[0])\n    return torch.stack([x1, y1, x2, y2], -1)\n\n\ndef bbox2distance(points, bbox, max_dis=None, eps=0.1):\n    # \u6839\u636ex1y1x2y2 + center\u70b9 \u8ba1\u7b97 lrtb\n    \"\"\"Decode bounding box based on distances.\n\n    Args:\n        points (Tensor): Shape (n, 2), [x, y].\n        bbox (Tensor): Shape (n, 4), \"xyxy\" format\n        max_dis (float): Upper bound of the distance.\n        eps (float): a small value to ensure target &lt; max_dis, instead &lt;=\n\n    Returns:\n        Tensor: Decoded distances.\n    \"\"\"\n    left = points[:, 0] - bbox[:, 0]\n    top = points[:, 1] - bbox[:, 1]\n    right = bbox[:, 2] - points[:, 0]\n    bottom = bbox[:, 3] - points[:, 1]\n    if max_dis is not None:\n        left = left.clamp(min=0, max=max_dis - eps)\n        top = top.clamp(min=0, max=max_dis - eps)\n        right = right.clamp(min=0, max=max_dis - eps)\n        bottom = bottom.clamp(min=0, max=max_dis - eps)\n    return torch.stack([left, top, right, bottom], -1)\n</code></pre> <p>\u7136\u540e\u518d\u770b\u4e0b<code>self.distribution_project</code>\u6240\u5c5e\u7c7b\u7684forward\u51fd\u6570(<code>nanodet/model/head/gfl_head.py</code>)\uff1a</p> <pre><code>class Integral(nn.Module):\n    \"\"\"A fixed layer for calculating integral result from distribution.\n    This layer calculates the target location by :math: `sum{P(y_i) * y_i}`,\n    P(y_i) denotes the softmax vector that represents the discrete distribution\n    y_i denotes the discrete set, usually {0, 1, 2, ..., reg_max}\n    Args:\n        reg_max (int): The maximal value of the discrete set. Default: 16. You\n            may want to reset it according to your new dataset or related\n            settings.\n    \"\"\"\n\n    def __init__(self, reg_max=16):\n        super(Integral, self).__init__()\n        self.reg_max = reg_max\n        # [0,1,...,self.reg_max]\n        self.register_buffer(\n            \"project\", torch.linspace(0, self.reg_max, self.reg_max + 1)\n        )\n\n    def forward(self, x):\n        \"\"\"Forward feature from the regression head to get integral result of\n        bounding box location.\n        Args:\n            x (Tensor): Features of the regression head, shape (N, 4*(n+1)),\n                n is self.reg_max.\n        Returns:\n            x (Tensor): Integral result of box locations, i.e., distance\n                offsets from the box center in four directions, shape (N, 4).\n        \"\"\"\n        shape = x.size()\n        x = F.softmax(x.reshape(*shape[:-1], 4, self.reg_max + 1), dim=-1)\n        # \u6bcf\u4e00\u4e2a\u8ddd\u79bb\u90fd\u53ef\u4ee5\u770b\u51fa\u4e00\u4e2a\u5206\u5e03\uff0c\n        # [0,1,2,...,regmax] \u4e2d 1 \u5c31\u8868\u793a\u5f53\u524d\u8ddd\u79bb\u4e3a1\u7684\u6982\u7387\u662f\u591a\u5c11\n        # \u77e9\u9635\u4e58\u7684\u542b\u4e49\u5b9e\u9645\u4e0a\u5c31\u662f\u6c42\u671f\u671b\uff0c\u66f4\u591a\u89e3\u91ca\u8fd8\u8bf7\u9605\u8bfbGFL\u539f\u6587\n        x = F.linear(x, self.project.type_as(x)).reshape(*shape[:-1], 4)\n        return x\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#42-cost-matrix","title":"4.2 cost matrix\u7684\u6c42\u53d6","text":"<p>Loss\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\uff0cbox\u7f16\u7801\u4e0e\u89e3\u7801\u7684\u8fc7\u7a0b\u6211\u4eec\u5df2\u7ecf\u4e86\u89e3\u4e86\uff0c\u63a5\u4e0b\u6765\u5c31\u662f\u6807\u7b7e\u5206\u914d\u3002\u6211\u4eec\u627e\u5230<code>target_assign_single_img</code>\u51fd\u6570\u8fdb\u884c\u89e3\u6790\uff08\u8be5\u51fd\u6570\u4f9d\u7136\u5728<code>NanoDetPlusHead</code>\u4e2d\uff09</p> <pre><code>@torch.no_grad()\ndef target_assign_single_img(\n    self,\n    cls_preds,\n    center_priors,\n    decoded_bboxes,\n    gt_bboxes,\n    gt_labels,\n    gt_bboxes_ignore=None,\n):\n    \"\"\"Compute classification, regression, and objectness targets for\n    priors in a single image.\n    Args:\n        cls_preds (Tensor): Classification predictions of one image,\n            a 2D-Tensor with shape [num_priors, num_classes]\n        center_priors (Tensor): All priors of one image, a 2D-Tensor with\n            shape [num_priors, 4] in [cx, xy, stride_w, stride_y] format.\n        decoded_bboxes (Tensor): Decoded bboxes predictions of one image,\n            a 2D-Tensor with shape [num_priors, 4] in [tl_x, tl_y,\n            br_x, br_y] format.\n        gt_bboxes (Tensor): Ground truth bboxes of one image, a 2D-Tensor\n            with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format.\n        gt_labels (Tensor): Ground truth labels of one image, a Tensor\n            with shape [num_gts].\n        gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are\n            labelled as `ignored`, e.g., crowd boxes in COCO.\n    \"\"\"\n\n    device = center_priors.device\n    gt_bboxes = torch.from_numpy(gt_bboxes).to(device)\n    gt_labels = torch.from_numpy(gt_labels).to(device)\n    gt_bboxes = gt_bboxes.to(decoded_bboxes.dtype)\n\n    if gt_bboxes_ignore is not None:\n        gt_bboxes_ignore = torch.from_numpy(gt_bboxes_ignore).to(device)\n        gt_bboxes_ignore = gt_bboxes_ignore.to(decoded_bboxes.dtype)\n\n    # \u901a\u8fc7 self.assigner.assign \u83b7\u53d6 \u6807\u7b7e\u5206\u914d\u7ed3\u679c\n    assign_result = self.assigner.assign(\n        cls_preds,\n        center_priors,\n        decoded_bboxes,\n        gt_bboxes,\n        gt_labels,\n        gt_bboxes_ignore,\n    )\n    # \u9488\u5bf9\u6807\u7b7e\u5206\u914d\u7ed3\u679c\u8fdb\u884c\u91c7\u6837\n    pos_inds, neg_inds, pos_gt_bboxes, pos_assigned_gt_inds = self.sample(\n        assign_result, gt_bboxes\n    )\n\n    num_priors = center_priors.size(0)\n    bbox_targets = torch.zeros_like(center_priors)\n    dist_targets = torch.zeros_like(center_priors)\n    labels = center_priors.new_full(\n        (num_priors,), self.num_classes, dtype=torch.long\n    )\n    label_weights = center_priors.new_zeros(num_priors, dtype=torch.float)\n    label_scores = center_priors.new_zeros(labels.shape, dtype=torch.float)\n\n    num_pos_per_img = pos_inds.size(0)\n    pos_ious = assign_result.max_overlaps[pos_inds]\n\n    # pos_inds \u8868\u793a\u6b63\u6807\u7b7e\u7684\u4e2a\u6570\n    if len(pos_inds) &gt; 0:\n        bbox_targets[pos_inds, :] = pos_gt_bboxes\n        # center_priors[pos_inds, None, 2]  \u8868\u793a stride\n        # \u6c42\u53d6 dist_targets\n        dist_targets[pos_inds, :] = (\n            bbox2distance(center_priors[pos_inds, :2], pos_gt_bboxes)\n            / center_priors[pos_inds, None, 2]\n        )\n        # dist_targets \u53d6\u503c\u8303\u56f4\u5e94\u8be5\u5728 [0, self.reg_max]\n        # -0.1 \u4f30\u8ba1\u662f\u4e3a\u4e86\u7559\u6709\u4f59\u91cf\n        dist_targets = dist_targets.clamp(min=0, max=self.reg_max - 0.1)\n        # \u5206\u7c7b\u6807\u7b7e \n        labels[pos_inds] = gt_labels[pos_assigned_gt_inds]\n        # \u6309\u7167GFL\u8981\u6c42\uff0clabel_scores\u4e2d\u7684\u6570\u503c\u5373\u4e3apred\u4e0egt box\u4e4b\u95f4\u7684iou\uff0c\u7528\u4e8e\u8868\u793a\u5206\u7c7b\u4e0e\u5b9a\u4f4d\u8054\u5408\u540e\u7684\u8d28\u91cf\n        label_scores[pos_inds] = pos_ious\n        label_weights[pos_inds] = 1.0\n    if len(neg_inds) &gt; 0:\n        label_weights[neg_inds] = 1.0\n    return (\n        labels,\n        label_scores,\n        label_weights,\n        bbox_targets,\n        dist_targets,\n        num_pos_per_img,\n    )\n</code></pre> <p>\u8fd8\u662f\u8981\u56de\u5230<code>self.assigner</code>\u7684\u5b9a\u4e49\u627e\u5230<code>assign</code>\u51fd\u6570</p> <pre><code># nanodetplushead init \u51fd\u6570\u4e2d\u7684\u5b9a\u4e49\nself.assigner = DynamicSoftLabelAssigner(**assigner_cfg)\n</code></pre> <p>\u4e0b\u9762\u770b<code>DynamicSoftLabelAssigner</code>\u7684\u5b9a\u4e49(<code>nanodet/model/head/assigner/dsl_assigner.py</code>)</p> <pre><code>class DynamicSoftLabelAssigner(BaseAssigner):\n    \"\"\"Computes matching between predictions and ground truth with\n    dynamic soft label assignment.\n\n    Args:\n        topk (int): Select top-k predictions to calculate dynamic k\n            best matchs for each gt. Default 13.\n        iou_factor (float): The scale factor of iou cost. Default 3.0.\n        ignore_iof_thr (int): whether ignore max overlaps or not.\n            Default -1 (1 or -1).\n    \"\"\"\n\n    def __init__(self, topk=13, iou_factor=3.0, ignore_iof_thr=-1):\n        self.topk = topk\n        self.iou_factor = iou_factor\n        self.ignore_iof_thr = ignore_iof_thr\n\n    def assign(\n        self,\n        pred_scores,\n        priors,\n        decoded_bboxes,\n        gt_bboxes,\n        gt_labels,\n        gt_bboxes_ignore=None,\n    ):\n        \"\"\"Assign gt to priors with dynamic soft label assignment.\n        Args:\n            pred_scores (Tensor): Classification scores of one image,\n                a 2D-Tensor with shape [num_priors, num_classes]\n            priors (Tensor): All priors of one image, a 2D-Tensor with shape\n                [num_priors, 4] in [cx, xy, stride_w, stride_y] format.\n            decoded_bboxes (Tensor): Predicted bboxes, a 2D-Tensor with shape\n                [num_priors, 4] in [tl_x, tl_y, br_x, br_y] format.\n            gt_bboxes (Tensor): Ground truth bboxes of one image, a 2D-Tensor\n                with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format.\n            gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are\n                labelled as `ignored`, e.g., crowd boxes in COCO.\n            gt_labels (Tensor): Ground truth labels of one image, a Tensor\n                with shape [num_gts].\n\n        Returns:\n            :obj:`AssignResult`: The assigned result.\n        \"\"\"\n        INF = 100000000\n        # GT \u4e2a\u6570\n        num_gt = gt_bboxes.size(0)\n        # \u591a\u5c11\u4e2a\u6846\n        num_bboxes = decoded_bboxes.size(0)\n\n        # assign\u51fd\u6570\u8981\u89e3\u51b3\u7684\u95ee\u9898\u5373\n        # \u4e3a\u6bcf\u4e00\u4e2anum_bboxes \u5206\u914d\u4e00\u4e2aGT\uff0c\u6216\u8005\u80cc\u666f\n        # \u5228\u53bb\u5206\u4e3a\u80cc\u666f\u7684\uff0c\u6bcf\u4e00\u4e2a num_bboxes \u6709\u4e14\u4ec5\u6709\u4e00\u4e2aGT box \n        # \u4e00\u4e2aGT\u53ef\u4ee5\u88ab\u591a\u4e2anum_bboxes\u9884\u6d4b\n\n        # gt_inds (LongTensor): for each predicted box indicates the 1-based\n        #    index of the assigned truth box. 0 means unassigned and -1 means\n        #    ignore.\n        # assign 0 by default 0 \u4ee3\u8868 \u672a\u5206\u914d -1 \u4ee3\u8868\u5df2\u5206\u914d\u4f46\u5ffd\u7565\n        # \u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2dassigned_gt_inds[assigned_gt_inds != 0 &amp;&amp; assigned_gt_inds != -1] - 1\n        # \u624d\u662f\u771f\u6b63\u53ef\u4ee5\u7528\u7684\n        assigned_gt_inds = decoded_bboxes.new_full((num_bboxes,), 0, dtype=torch.long)\n\n        # \u5148\u9a8c\u4e2d\u5fc3\u70b9\n        # [num_priors, 2]\n        prior_center = priors[:, :2]\n        # [num_priors, num_gt, 2]\n        lt_ = prior_center[:, None] - gt_bboxes[:, :2]\n        rb_ = gt_bboxes[:, 2:] - prior_center[:, None]\n\n        # deltas[i,j] \u8868\u793a \u7b2ci\u4e2aprior point\u5230\u7b2cj\u4e2agt\u4e4b\u95f4\u7684\u8ddd\u79bbltrb [num_priors, num_gt, 4]\n        deltas = torch.cat([lt_, rb_], dim=-1)\n        # is_in_gts[i,j] \u8868\u793a \u7b2ci\u4e2aprior point\u662f\u5426\u5728\u7b2cj\u4e2agt\u5185\u90e8 [num_priors, num_gt]\n        is_in_gts = deltas.min(dim=-1).values &gt; 0\n        # \u8fd9\u91cc\u7684sum\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u6216\u7684\u5173\u7cfb\n        # \u8ba1\u7b97\u6bcf\u4e00\u4e2apriors\u662f\u5426\u81f3\u5c11\u6709\u4e00\u4e2agt\u80fd\u8ba9\u5176\u8868\u793a\n        valid_mask = is_in_gts.sum(dim=1) &gt; 0\n\n        valid_decoded_bbox = decoded_bboxes[valid_mask]\n        valid_pred_scores = pred_scores[valid_mask]\n        num_valid = valid_decoded_bbox.size(0)\n\n        # \u7279\u6b8a\u60c5\u51b5\u5904\u7406\n        if num_gt == 0 or num_bboxes == 0 or num_valid == 0:\n            # No ground truth or boxes, return empty assignment\n            max_overlaps = decoded_bboxes.new_zeros((num_bboxes,))\n            if num_gt == 0:\n                # No truth, assign everything to background\n                assigned_gt_inds[:] = 0\n            if gt_labels is None:\n                assigned_labels = None\n            else:\n                assigned_labels = decoded_bboxes.new_full(\n                    (num_bboxes,), -1, dtype=torch.long\n                )\n            return AssignResult(\n                num_gt, assigned_gt_inds, max_overlaps, labels=assigned_labels\n            )\n\n        # \u8ba1\u7b97 valid_decoded_bbox \u4e0e gt_bboxes \u4e4b\u95f4\u7684iou\n        # [num_valid_box, num_gt]\n        pairwise_ious = bbox_overlaps(valid_decoded_bbox, gt_bboxes)\n        # \u8ba1\u7b97iou cost [num_valid_box, num_gt]\n        iou_cost = -torch.log(pairwise_ious + 1e-7)\n\n        # gt_onehot_label [num_valid, num_gt, num_classes]\n        # \u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u91cd\u590d\n        gt_onehot_label = (\n            F.one_hot(gt_labels.to(torch.int64), pred_scores.shape[-1])\n            .float()\n            .unsqueeze(0)\n            .repeat(num_valid, 1, 1)\n        )\n        # valid_pred_scores [num_valid, num_gt, num_classes]\n        valid_pred_scores = valid_pred_scores.unsqueeze(1).repeat(1, num_gt, 1)\n\n        # soft_label [num_valid, num_gt, num_classes]\n        # \u7531\u4e8egt_onehot_label ,\u6240\u4ee5\u5728num_classes\u7ef4\u5ea6\u4e0a\uff0c\u4ec5\u6709 i == gt_labels\u7684\u624d\u6709\u503c\uff0c\u5176\u4f59\u90fd\u662f0\n        soft_label = gt_onehot_label * pairwise_ious[..., None]\n        # |gt - pred| focal loss\u7684\u6743\u91cd\u8ba1\u7b97\n        scale_factor = soft_label - valid_pred_scores.sigmoid()\n\n        # \u8ba1\u7b97\u5206\u7c7b\u635f\u5931 [num_valid, num_gt, num_classes]\n        cls_cost = F.binary_cross_entropy_with_logits(\n            valid_pred_scores, soft_label, reduction=\"none\"\n        ) * scale_factor.abs().pow(2.0)\n\n        # [num_valid, num_gt]\n        cls_cost = cls_cost.sum(dim=-1)\n\n        # cost matrix \u8ba1\u7b97 \u540c\u65f6\u8003\u8651\u5206\u7c7b\u548c\u5b9a\u4f4d\u56e0\u7d20\n        cost_matrix = cls_cost + iou_cost * self.iou_factor\n\n        # some code ....\n</code></pre> <p>\u8fd9\u4e00\u5c0f\u8282\u8bb2\u4e86cost matrix\u7684\u8ba1\u7b97\uff0c\u4e0b\u4e00\u4e2a\u5c0f\u7ed3\u770b\u4e00\u4e0bdynamic-k\u7684\u8ba1\u7b97</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#43-dynamic-k","title":"4.3 dynamic-k\u7684\u8ba1\u7b97\u4e0e\u6807\u7b7e\u5206\u914d","text":"<p>\u4e0b\u9762\u770b<code>dynamic_k_matching</code>\u7684\u5b9a\u4e49(<code>nanodet/model/head/assigner/dsl_assigner.py</code>)</p> <pre><code>def dynamic_k_matching(self, cost, pairwise_ious, num_gt, valid_mask):\n    \"\"\"Use sum of topk pred iou as dynamic k. Refer from OTA and YOLOX.\n\n    Args:\n        cost (Tensor): Cost matrix.\n        pairwise_ious (Tensor): Pairwise iou matrix.\n        num_gt (int): Number of gt.\n        valid_mask (Tensor): Mask for valid bboxes.\n    \"\"\"\n    # \u5339\u914d\u77e9\u9635\uff0c\u7528\u4e8e\u6807\u8bb0\u7b2ci\u4e2a\u6846\u662f\u5426\u4e0e\u7b2cj\u7684gt\u6846\u5339\u914d\n    # [num_valid, num_gt]\n    matching_matrix = torch.zeros_like(cost)\n    # select candidate topk ious for dynamic-k calculation\n    # candidate_topk = min(self.topk, num_valid)\n    candidate_topk = min(self.topk, pairwise_ious.size(0))\n    # \u4e3a\u6bcf\u4e2a\u8ba1\u7b97candidate_topk\u4e2a\u5019\u9009\u6846\n    # shape: [candidate_topk, num_gt]\n    topk_ious, _ = torch.topk(pairwise_ious, candidate_topk, dim=0)\n    # calculate dynamic k for each gt\n    # \u5c06gt\u4e0e\u5176\u5339\u914d\u7684\u6bcf\u4e2a\u6846\u7684iou\u8ba1\u7b97\u5f97\u5230\u603b\u7684iou\uff0c\u7136\u540e\u5c06\u5176\u503c\u53d6\u6574\u4f5c\u4e3a\u6bcf\u4e2aGT\u5bf9\u5e94\u591a\u5c11pred box\n    # shape: [num_gt]\n    dynamic_ks = torch.clamp(topk_ious.sum(0).int(), min=1)\n    # \u904d\u5386gt \u53d6\u5176\u5bf9\u5e94\u7684 cost matrix \u8f83\u5c0f topk=dynamic_ks[gt_idx] \u7684\u5019\u9009\u6846\u6807\u8bb0\u4e3a\u9009\u4e2d\u72b6\u6001\n    for gt_idx in range(num_gt):\n        _, pos_idx = torch.topk(\n            cost[:, gt_idx], k=dynamic_ks[gt_idx].item(), largest=False\n        )\n        matching_matrix[:, gt_idx][pos_idx] = 1.0\n\n    del topk_ious, dynamic_ks, pos_idx\n\n    # \u7531\u4e8e\u4e00\u4e2a\u5019\u9009\u6846\u53ea\u80fd\u5bf9\u5e94\u7684\u4e00\u4e2aGT\uff0c\u6240\u4ee5\u5f53\u4e00\u4e2apred\u5bf9\u5e94\u591a\u4e2aGT\u7684\u65f6\u5019\u9009\u62e9cost\u6700\u5c0f\u7684\n    # shape: [num_valid]\n    prior_match_gt_mask = matching_matrix.sum(1) &gt; 1\n    if prior_match_gt_mask.sum() &gt; 0:\n        # [num_prior_match]\n        cost_min, cost_argmin = torch.min(cost[prior_match_gt_mask, :], dim=1)\n        matching_matrix[prior_match_gt_mask, :] *= 0.0\n        matching_matrix[prior_match_gt_mask, cost_argmin] = 1.0\n    # get foreground mask inside box and center prior\n    # \u83b7\u53d6\u54ea\u4e9bpred\u88ab\u5206\u914d\u4e86GT\n    # [num_valid]\n    fg_mask_inboxes = matching_matrix.sum(1) &gt; 0.0\n    # \u4ec5\u4ec5\u662f\u4e3a\u4e86\u539f\u5730\u66f4\u6539\n    # valid_mask shape [num_box]\n    # valid_mask[valid_mask.clone()] shape\uff1a [num_valid]\n    # \u5373\u5728\u4e4b\u524d\u7684valid_mask\u57fa\u7840\u4e0a\u53c8\u52a0\u4e86\u4e00\u5c42\u9650\u5236\n    valid_mask[valid_mask.clone()] = fg_mask_inboxes\n\n    # \u83b7\u53d6\u6bcf\u4e00\u4e2abox\u5339\u914d\u7684GT\u7684index\n    matched_gt_inds = matching_matrix[fg_mask_inboxes, :].argmax(1)\n    # \u83b7\u53d6\u6bcf\u4e00\u4e2abox\u5339\u914d\u7684GT\u7684iou\n    matched_pred_ious = (matching_matrix * pairwise_ious).sum(1)[fg_mask_inboxes]\n    return matched_pred_ious, matched_gt_inds\n</code></pre> <p>\u4e0b\u9762\u91cd\u65b0\u56de\u5230<code>DynamicSoftLabelAssigner</code>\u7684<code>assign</code>\u51fd\u6570\uff0c\u6765\u770b\u4e0b<code>dynamic_k_matching</code>\u662f\u600e\u4e48\u53d1\u6325\u4f5c\u7528\u7684</p> <pre><code>    def assign(\n        self,\n        pred_scores,\n        priors,\n        decoded_bboxes,\n        gt_bboxes,\n        gt_labels,\n        gt_bboxes_ignore=None,\n    ):  \n        # \u63a5\u4e0a\u4e00\u5c0f\u7ed3\u7684\u5185\u5bb9\n        # some code ...\n\n        # dynamic_k_matching \u6839\u636eiou\u548ccost_matrix \u8ba1\u7b97\u5339\u914d\u7684gt\u7684index\n        # matched_pred_ious shape: num_fg_mask\n        # valid_mask: \u4ec5\u6709valid_mask\u4e2aTrue\u4e86\n        # matched_gt_inds: num_fg_mask\n        matched_pred_ious, matched_gt_inds = self.dynamic_k_matching(\n            cost_matrix, pairwise_ious, num_gt, valid_mask\n        )\n\n        # \u8f6c\u6362\u4e3aAssignResult\u7ed3\u679c\n        # convert to AssignResult format\n        # \u6807\u8bb0\u5f53\u524dbox\u88ab\u5206\u914d\u5230\u54ea\u4e9bgt\n        assigned_gt_inds[valid_mask] = matched_gt_inds + 1\n\n        # \u6807\u8bb0\u5f53\u524dbox\u88ab\u5206\u914d\u7684\u7c7b\u522b\u662f\u5565\n        assigned_labels = assigned_gt_inds.new_full((num_bboxes,), -1)\n        assigned_labels[valid_mask] = gt_labels[matched_gt_inds].long()\n        # \u8868\u793a\u5f53\u524dbox\u4e0e\u5206\u914d\u7684GT\u4e4b\u95f4\u7684iou\u662f\u591a\u5c11\n        max_overlaps = assigned_gt_inds.new_full(\n            (num_bboxes,), -INF, dtype=torch.float32\n        )\n        max_overlaps[valid_mask] = matched_pred_ious\n\n        # \u8bbe\u7f6eignore\u6846\u7684\u6807\u7b7e\u5206\u914d\n        if (\n            self.ignore_iof_thr &gt; 0\n            and gt_bboxes_ignore is not None\n            and gt_bboxes_ignore.numel() &gt; 0\n            and num_bboxes &gt; 0\n        ):\n            ignore_overlaps = bbox_overlaps(\n                valid_decoded_bbox, gt_bboxes_ignore, mode=\"iof\"\n            )\n            ignore_max_overlaps, _ = ignore_overlaps.max(dim=1)\n            ignore_idxs = ignore_max_overlaps &gt; self.ignore_iof_thr\n            assigned_gt_inds[ignore_idxs] = -1\n\n        return AssignResult(\n            num_gt, assigned_gt_inds, max_overlaps, labels=assigned_labels\n        )\n</code></pre> <p>\u6211\u4eec\u4ee5\u51fa\u6808\u7684\u65b9\u5f0f\u518d\u53bb\u770b\u4e0b\u6807\u7b7e\u5206\u914d\u662f\u600e\u4e48\u505a\u7684</p> <pre><code>@torch.no_grad()\ndef target_assign_single_img(\n    self,\n    cls_preds,\n    center_priors,\n    decoded_bboxes,\n    gt_bboxes,\n    gt_labels,\n    gt_bboxes_ignore=None,\n):\n    \"\"\"Compute classification, regression, and objectness targets for\n    priors in a single image.\n    Args:\n        cls_preds (Tensor): Classification predictions of one image,\n            a 2D-Tensor with shape [num_priors, num_classes]\n        center_priors (Tensor): All priors of one image, a 2D-Tensor with\n            shape [num_priors, 4] in [cx, xy, stride_w, stride_y] format.\n        decoded_bboxes (Tensor): Decoded bboxes predictions of one image,\n            a 2D-Tensor with shape [num_priors, 4] in [tl_x, tl_y,\n            br_x, br_y] format.\n        gt_bboxes (Tensor): Ground truth bboxes of one image, a 2D-Tensor\n            with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format.\n        gt_labels (Tensor): Ground truth labels of one image, a Tensor\n            with shape [num_gts].\n        gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are\n            labelled as `ignored`, e.g., crowd boxes in COCO.\n    \"\"\"\n\n    device = center_priors.device\n    gt_bboxes = torch.from_numpy(gt_bboxes).to(device)\n    gt_labels = torch.from_numpy(gt_labels).to(device)\n    gt_bboxes = gt_bboxes.to(decoded_bboxes.dtype)\n\n    if gt_bboxes_ignore is not None:\n        gt_bboxes_ignore = torch.from_numpy(gt_bboxes_ignore).to(device)\n        gt_bboxes_ignore = gt_bboxes_ignore.to(decoded_bboxes.dtype)\n\n    # \u901a\u8fc7 self.assigner.assign \u83b7\u53d6 \u6807\u7b7e\u5206\u914d\u7ed3\u679c\n    assign_result = self.assigner.assign(\n        cls_preds,\n        center_priors,\n        decoded_bboxes,\n        gt_bboxes,\n        gt_labels,\n        gt_bboxes_ignore,\n    )\n    # \u9488\u5bf9\u6807\u7b7e\u5206\u914d\u7ed3\u679c\u8fdb\u884c\u91c7\u6837 \u8fd9\u91cc\u53ef\u4ee5\u8df3\u8f6c\u5230\u4e0b\u9762\u7684sample\u51fd\u6570\n    # pos_inds \u8868\u793a\u54ea\u4e9b\u6846\u6709GT\n    # neg_inds \u8868\u793a\u54ea\u4e9b\u6846\u5212\u5206\u4e3a\u4e86\u80cc\u666f\n    # pos_gt_bboxes \u8868\u793apos_inds\u5bf9\u5e94\u7684\u8fd9\u4e9b\u6846\u5bf9\u5e94\u7684GT\u5750\u6807\u662f\u5565\n    # pos_assigned_gt_inds \u5339\u914d\u7684\u6846\u7684\u771f\u5b9eindex\n    pos_inds, neg_inds, pos_gt_bboxes, pos_assigned_gt_inds = self.sample(\n        assign_result, gt_bboxes\n    )\n\n    num_priors = center_priors.size(0)\n    bbox_targets = torch.zeros_like(center_priors)\n    dist_targets = torch.zeros_like(center_priors)\n    labels = center_priors.new_full(\n        (num_priors,), self.num_classes, dtype=torch.long\n    )\n    label_weights = center_priors.new_zeros(num_priors, dtype=torch.float)\n    label_scores = center_priors.new_zeros(labels.shape, dtype=torch.float)\n\n    num_pos_per_img = pos_inds.size(0)\n    # \u63d0\u53d6\u51fa\u5339\u914dGT\u7684\u6846\u7684iou\n    pos_ious = assign_result.max_overlaps[pos_inds]\n\n    # pos_inds \u8868\u793a\u6b63\u6807\u7b7e\u7684\u4e2a\u6570\n    if len(pos_inds) &gt; 0:\n        bbox_targets[pos_inds, :] = pos_gt_bboxes\n        # center_priors[pos_inds, None, 2]  \u8868\u793a stride\n        # \u6c42\u53d6 dist_targets shape: [num_priors, 4]\n        dist_targets[pos_inds, :] = (\n            bbox2distance(center_priors[pos_inds, :2], pos_gt_bboxes)\n            / center_priors[pos_inds, None, 2]\n        )\n        # dist_targets \u53d6\u503c\u8303\u56f4\u5e94\u8be5\u5728 [0, self.reg_max]\n        # -0.1 \u4f30\u8ba1\u662f\u4e3a\u4e86\u7559\u6709\u4f59\u91cf\n        dist_targets = dist_targets.clamp(min=0, max=self.reg_max - 0.1)\n        # \u5206\u7c7b\u6807\u7b7e \n        labels[pos_inds] = gt_labels[pos_assigned_gt_inds]\n        # \u6309\u7167GFL\u8981\u6c42\uff0clabel_scores\u4e2d\u7684\u6570\u503c\u5373\u4e3apred\u4e0egt box\u4e4b\u95f4\u7684iou\uff0c\u7528\u4e8e\u8868\u793a\u5206\u7c7b\u4e0e\u5b9a\u4f4d\u8054\u5408\u540e\u7684\u8d28\u91cf\n        label_scores[pos_inds] = pos_ious\n        label_weights[pos_inds] = 1.0\n    if len(neg_inds) &gt; 0:\n        label_weights[neg_inds] = 1.0\n    # labels [num_priors]\uff1a\u8868\u793a\u6bcf\u4e2a\u6846\u7684\u7c7b\u522bGT\n    # label_scores [num_priors]: \u6bcf\u4e2a\u6846\u7684\u5f97\u5206\n    # label_weights [num_priors]: \u6bcf\u4e2a\u6846\u7684\u6743\u91cd\n    # bbox_targets [num_priors, 4]: \u6bcf\u4e2a\u6846\u5bf9\u5e94\u7684gt\n    # dist_targets [num_priors, 4]:  \u6bcf\u4e2a\u6846\u5bf9\u5e94\u7684dist\n    # num_pos_per_img  [1]: \u5355\u4e2aimg\u5bf9\u5e94\u7684\u6b63\u6837\u672c\u4e2a\u6570\n    return (\n        labels,\n        label_scores,\n        label_weights,\n        bbox_targets,\n        dist_targets,\n        num_pos_per_img,\n    )\n\n\n\ndef sample(self, assign_result, gt_bboxes):\n    \"\"\"Sample positive and negative bboxes.\"\"\"\n    # \u83b7\u53d6\u5230\u54ea\u4e9b\u6846\u88ab\u5206\u914d\u7ed9GT\uff0c\u54ea\u4e9b\u6846\u88ab\u6807\u8bb0\u4e3a\u4e86\u80cc\u666f\n    # assign_result.gt_inds 1-based 0\u8868\u793a\u672a\u5206\u914d\u6846 -1\u8868\u793a\u5ffd\u7565\n    pos_inds = (\n        torch.nonzero(assign_result.gt_inds &gt; 0, as_tuple=False)\n        .squeeze(-1)\n        .unique()\n    )\n    neg_inds = (\n        torch.nonzero(assign_result.gt_inds == 0, as_tuple=False)\n        .squeeze(-1)\n        .unique()\n    )\n    # \u7531\u4e8egt_inds\u662f1-based\u6240\u4ee5\u771f\u5b9e\u7684idx\u51cf\u53bb1\n    pos_assigned_gt_inds = assign_result.gt_inds[pos_inds] - 1\n\n    if gt_bboxes.numel() == 0:\n        # hack for index error case\n        assert pos_assigned_gt_inds.numel() == 0\n        pos_gt_bboxes = torch.empty_like(gt_bboxes).view(-1, 4)\n    else:\n        if len(gt_bboxes.shape) &lt; 2:\n            gt_bboxes = gt_bboxes.view(-1, 4)\n        # \u751f\u6210\u6bcf\u4e00\u4e2apos_assigned_gt_inds\u6240\u5bf9\u5e94\u7684\u6846\n        pos_gt_bboxes = gt_bboxes[pos_assigned_gt_inds, :]\n    # pos_inds \u8868\u793a\u54ea\u4e9b\u6846\u6709GT\n    # neg_inds \u8868\u793a\u54ea\u4e9b\u6846\u5212\u5206\u4e3a\u4e86\u80cc\u666f\n    # pos_gt_bboxes \u8868\u793apos_inds\u5bf9\u5e94\u7684\u8fd9\u4e9b\u6846\u5bf9\u5e94\u7684GT\u5750\u6807\u662f\u5565\n    # pos_assigned_gt_inds \u5339\u914d\u7684\u6846\u7684\u771f\u5b9eindex\n    return pos_inds, neg_inds, pos_gt_bboxes, pos_assigned_gt_inds\n</code></pre> <p>\u4ee5\u4e0a\u5c31\u662f\u6574\u4e2a\u6807\u7b7e\u5206\u914d\u8fc7\u7a0b\uff0c\u4e0eYoloX\u4e2d\u7684\u57fa\u672c\u76f8\u540c\u3002\u4e0b\u9762\u662fLoss\u51fd\u6570\u7684\u5b9a\u4e49\u4e0e\u8c03\u7528\u7684\u5b9e\u73b0\u73af\u8282\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#loss","title":"\u4e94. Loss\u51fd\u6570\u4ee3\u7801\u89e3\u8bfb","text":"<p>\u5148\u770bLoss\u51fd\u6570<code>nanodet/model/head/nanodet_plus_head.py</code></p> <p>\u5728\u4e0a\u4e00\u7ae0\u6211\u4eec\u89e3\u8bfb\u4e86<code>self.target_assign_single_img</code>\u51fd\u6570\uff0c\u8fd9\u91cc\u5148\u5c06\u8fd4\u56de\u503c\u7684\u89e3\u91ca\u91cd\u65b0\u9644\u4e0a</p> <pre><code># \u5982\u679c aux_preds \u4e0d\u4e3a\u7a7a \u5c31\u91c7\u7528aux_cls_preds\u8ba1\u7b97 \u6807\u7b7e\u5206\u914d\u7ed3\u679c\uff0c\u7136\u540e\u91c7\u7528\u8be5\u7ed3\u679c\u5bf9cls_preds\u548cdis_preds\u6c42loss\nif aux_preds is not None:\n    # use auxiliary head to assign\n    aux_cls_preds, aux_reg_preds = aux_preds.split(\n        [self.num_classes, 4 * (self.reg_max + 1)], dim=-1\n    )\n\n    aux_dis_preds = (\n        self.distribution_project(aux_reg_preds) * center_priors[..., 2, None]\n    )\n    aux_decoded_bboxes = distance2bbox(center_priors[..., :2], aux_dis_preds)\n    batch_assign_res = multi_apply(\n        self.target_assign_single_img,\n        aux_cls_preds.detach(),\n        center_priors,\n        aux_decoded_bboxes.detach(),\n        gt_bboxes,\n        gt_labels,\n        gt_bboxes_ignore,\n    )\nelse:\n    # use self prediction to assign\n    batch_assign_res = multi_apply(\n        self.target_assign_single_img,\n        cls_preds.detach(),\n        center_priors,\n        decoded_bboxes.detach(),\n        gt_bboxes,\n        gt_labels,\n        gt_bboxes_ignore,\n    )\n\n# batch_assign_res\u662f\u4e00\u4e2a\u5143\u7956 \u5305\u542b\u5982\u4e0b\u5143\u7d20\n# labels [num_priors]\uff1a\u8868\u793a\u6bcf\u4e2a\u6846\u7684\u7c7b\u522bGT\n# label_scores [num_priors]: \u6bcf\u4e2a\u6846\u7684\u5f97\u5206\n# label_weights [num_priors]: \u6bcf\u4e2a\u6846\u7684\u6743\u91cd\n# bbox_targets [num_priors, 4]: \u6bcf\u4e2a\u6846\u5bf9\u5e94\u7684gt\n# dist_targets [num_priors, 4]:  \u6bcf\u4e2a\u6846\u5bf9\u5e94\u7684dist\n# num_pos_per_img  [1]: \u5355\u4e2aimg\u5bf9\u5e94\u7684\u6b63\u6837\u672c\u4e2a\u6570\n\nloss, loss_states = self._get_loss_from_assign(\n    cls_preds, reg_preds, decoded_bboxes, batch_assign_res\n)\n\nif aux_preds is not None:\n    aux_loss, aux_loss_states = self._get_loss_from_assign(\n        aux_cls_preds, aux_reg_preds, aux_decoded_bboxes, batch_assign_res\n    )\n    loss = loss + aux_loss\n    for k, v in aux_loss_states.items():\n        loss_states[\"aux_\" + k] = v\nreturn loss, loss_states\n</code></pre> <p>\u4e0b\u9762\u91cd\u70b9\u770b\u4e0b<code>self.</code></p> <pre><code>def _get_loss_from_assign(self, cls_preds, reg_preds, decoded_bboxes, assign):\n    device = cls_preds.device\n    # labels [num_priors]\uff1a\u8868\u793a\u6bcf\u4e2a\u6846\u7684\u7c7b\u522bGT\n    # label_scores [num_priors]: \u6bcf\u4e2a\u6846\u7684\u5f97\u5206\n    # label_weights [num_priors]: \u6bcf\u4e2a\u6846\u7684\u6743\u91cd\n    # bbox_targets [num_priors, 4]: \u6bcf\u4e2a\u6846\u5bf9\u5e94\u7684gt\n    # dist_targets [num_priors, 4]:  \u6bcf\u4e2a\u6846\u5bf9\u5e94\u7684dist\n    # num_pos_per_img  [1]: \u5355\u4e2aimg\u5bf9\u5e94\u7684\u6b63\u6837\u672c\u4e2a\u6570\n    (\n        labels,\n        label_scores,\n        label_weights,\n        bbox_targets,\n        dist_targets,\n        num_pos,\n    ) = assign\n    # \u5404\u4e2a\u673a\u5668\u4e0a\u7684num_pos\u8fdb\u884creduce_mean\n    num_total_samples = max(\n        reduce_mean(torch.tensor(sum(num_pos)).to(device)).item(), 1.0\n    )\n\n    # [num_box]\n    labels = torch.cat(labels, dim=0)\n    # [num_box]\n    label_scores = torch.cat(label_scores, dim=0)\n    # [num_box] \u9ed8\u8ba4\u4e3a1\n    label_weights = torch.cat(label_weights, dim=0)\n    # [num_box, 4]\n    bbox_targets = torch.cat(bbox_targets, dim=0)\n    # [num_box, num_classes]\n    cls_preds = cls_preds.reshape(-1, self.num_classes)\n    # [num_box, 4 * (self.reg_max + 1)]\n    reg_preds = reg_preds.reshape(-1, 4 * (self.reg_max + 1))\n    # [num_box, 4]\n    decoded_bboxes = decoded_bboxes.reshape(-1, 4)\n    # \u8ba1\u7b97 \u5206\u7c7bloss\n    loss_qfl = self.loss_qfl(\n        cls_preds,\n        (labels, label_scores),\n        weight=label_weights,\n        avg_factor=num_total_samples,\n    )\n\n    # \u8fc7\u6ee4\u6389\u80cc\u666flabel\n    pos_inds = torch.nonzero(\n        (labels &gt;= 0) &amp; (labels &lt; self.num_classes), as_tuple=False\n    ).squeeze(1)\n\n    if len(pos_inds) &gt; 0:\n        # \u6743\u91cd\u8bbe\u7f6e\u4e3a\u5206\u7c7b\u5f97\u5206 \u4f7f\u5f97\u5206\u7c7b\u5f97\u5206\u9ad8\u7684\u6743\u91cd\u5927\n        weight_targets = cls_preds[pos_inds].detach().sigmoid().max(dim=1)[0]\n        # bbox_avg_factor \u914d\u5408 weight_targets \u53ef\u4ee5\u770b\u505a\u662f\u5bf9weight_targets\u7684\u5f52\u4e00\u5316\n        bbox_avg_factor = max(reduce_mean(weight_targets.sum()).item(), 1.0)\n\n        # \u8ba1\u7b97 giou loss\n        loss_bbox = self.loss_bbox(\n            decoded_bboxes[pos_inds],\n            bbox_targets[pos_inds],\n            weight=weight_targets,\n            avg_factor=bbox_avg_factor,\n        )\n\n        # \u8ba1\u7b97dfl loss\n        dist_targets = torch.cat(dist_targets, dim=0)\n        loss_dfl = self.loss_dfl(\n            reg_preds[pos_inds].reshape(-1, self.reg_max + 1),\n            dist_targets[pos_inds].reshape(-1),\n            weight=weight_targets[:, None].expand(-1, 4).reshape(-1),\n            avg_factor=4.0 * bbox_avg_factor,\n        )\n    else:\n        loss_bbox = reg_preds.sum() * 0\n        loss_dfl = reg_preds.sum() * 0\n\n    loss = loss_qfl + loss_bbox + loss_dfl\n    loss_states = dict(loss_qfl=loss_qfl, loss_bbox=loss_bbox, loss_dfl=loss_dfl)\n    return loss, loss_states\n</code></pre> <p>\u4e0b\u9762\u518d\u5206\u522b\u770b<code>self.loss_qfl</code>\uff0c<code>self.loss_bbox</code>\uff0c<code>self.loss_dfl</code>\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#51-weighted-loss","title":"5.1 weighted loss","text":"<p>\u7ed9Loss\u51fd\u6570\u6dfb\u52a0\u4e00\u4e2a\u53ef\u4f20\u5165\u6743\u91cd\u53c2\u6570\u7684\u88c5\u9970\u5668</p> <pre><code>def weighted_loss(loss_func):\n    \"\"\"Create a weighted version of a given loss function.\n\n    To use this decorator, the loss function must have the signature like\n    `loss_func(pred, target, **kwargs)`. The function only needs to compute\n    element-wise loss without any reduction. This decorator will add weight\n    and reduction arguments to the function. The decorated function will have\n    the signature like `loss_func(pred, target, weight=None, reduction='mean',\n    avg_factor=None, **kwargs)`.\n\n    :Example:\n\n    &gt;&gt;&gt; import torch\n    &gt;&gt;&gt; @weighted_loss\n    &gt;&gt;&gt; def l1_loss(pred, target):\n    &gt;&gt;     return (pred - target).abs()\n\n    &gt;&gt;&gt; pred = torch.Tensor([0, 2, 3])\n    &gt;&gt;&gt; target = torch.Tensor([1, 1, 1])\n    &gt;&gt;&gt; weight = torch.Tensor([1, 0, 1])\n\n    &gt;&gt;&gt; l1_loss(pred, target)\n    tensor(1.3333)\n    &gt;&gt;&gt; l1_loss(pred, target, weight)\n    tensor(1.)\n    &gt;&gt;&gt; l1_loss(pred, target, reduction='none')\n    tensor([1., 1., 2.])\n    &gt;&gt;&gt; l1_loss(pred, target, weight, avg_factor=2)\n    tensor(1.5000)\n    \"\"\"\n\n    @functools.wraps(loss_func)\n    def wrapper(pred, target, weight=None, reduction=\"mean\", avg_factor=None, **kwargs):\n        # get element-wise loss\n        loss = loss_func(pred, target, **kwargs)\n        loss = weight_reduce_loss(loss, weight, reduction, avg_factor)\n        return loss\n\n    return wrapper\n\n\ndef weight_reduce_loss(loss, weight=None, reduction=\"mean\", avg_factor=None):\n    \"\"\"Apply element-wise weight and reduce loss.\n\n    Args:\n        loss (Tensor): Element-wise loss.\n        weight (Tensor): Element-wise weights.\n        reduction (str): Same as built-in losses of PyTorch.\n        avg_factor (float): Avarage factor when computing the mean of losses.\n\n    Returns:\n        Tensor: Processed loss values.\n    \"\"\"\n    # if weight is specified, apply element-wise weight\n    if weight is not None:\n        loss = loss * weight\n\n    # if avg_factor is not specified, just reduce the loss\n    if avg_factor is None:\n        loss = reduce_loss(loss, reduction)\n    else:\n        # if reduction is mean, then average the loss by avg_factor\n        if reduction == \"mean\":\n            loss = loss.sum() / avg_factor\n        # if reduction is 'none', then do nothing, otherwise raise an error\n        elif reduction != \"none\":\n            raise ValueError('avg_factor can not be used with reduction=\"sum\"')\n    return loss\n\n\ndef reduce_loss(loss, reduction):\n    \"\"\"Reduce loss as specified.\n\n    Args:\n        loss (Tensor): Elementwise loss tensor.\n        reduction (str): Options are \"none\", \"mean\" and \"sum\".\n\n    Return:\n        Tensor: Reduced loss tensor.\n    \"\"\"\n    reduction_enum = F._Reduction.get_enum(reduction)\n    # none: 0, elementwise_mean:1, sum: 2\n    if reduction_enum == 0:\n        return loss\n    elif reduction_enum == 1:\n        return loss.mean()\n    elif reduction_enum == 2:\n        return loss.sum()\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#52-giou-loss","title":"5.2 giou loss","text":"<p>IoU loss\u4e0d\u53ef\u4ee5\u89e3\u51b3\u4e00\u4e2a\u95ee\u9898\uff0c\u5f53\u4e24\u4e2a\u6846\u4e0d\u91cd\u5408\u65f6\u4ee51 \u2212 I o U 1 - IoU1\u2212IoU\u516c\u5f0f\u4e3a\u4f8b\uff0c\u5176Loss\u503c\u4e3a1\u3002\u4f46\u6211\u4eec\u53d1\u73b0\u5f53\u4e24\u4e2a\u4e0d\u91cd\u5408\u65f6\uff0c\u65e0\u8bba\u4e24\u4e2a\u6846\u8ddd\u79bb\u591a\u8fdc\u5176loss\u503c\u5747\u4e3a1\uff0c\u4e0d\u4f1a\u53d1\u751f\u6539\u53d8\uff0c\u8fd9\u663e\u7136\u662f\u4e0d\u5408\u7406\u7684\u3002 \u6240\u4ee5\u63d0\u51fa\u4e86GIoU\u8fd9\u4e2a\u6982\u5ff5\u53bb\u5f25\u8865IoU\u7684\u4e0d\u8db3\uff0c\u540c\u65f6\u7528GIoU loss \u53bb\u5f25\u8865IoU loss\u7684\u7f3a\u9677\u3002</p> <p>giou\u516c\u5f0f\u5982\u4e0b\uff1a</p> <p></p> <p>\u4ee3\u7801\u76f8\u5bf9\u6bd4\u8f83\u7b80\u5355\u8bfb\u8005\u81ea\u884c\u89c2\u770b\u5427</p> <pre><code>def bbox_overlaps(bboxes1, bboxes2, mode=\"iou\", is_aligned=False, eps=1e-6):\n    # iof\u8868\u793a inter over foreground\n    assert mode in [\"iou\", \"iof\", \"giou\"], f\"Unsupported mode {mode}\"\n    # Either the boxes are empty or the length of boxes's last dimenstion is 4\n    assert bboxes1.size(-1) == 4 or bboxes1.size(0) == 0\n    assert bboxes2.size(-1) == 4 or bboxes2.size(0) == 0\n\n    # Batch dim must be the same\n    # Batch dim: (B1, B2, ... Bn)\n    assert bboxes1.shape[:-2] == bboxes2.shape[:-2]\n    batch_shape = bboxes1.shape[:-2]\n\n    rows = bboxes1.size(-2)\n    cols = bboxes2.size(-2)\n    if is_aligned:\n        assert rows == cols\n\n    if rows * cols == 0:\n        if is_aligned:\n            return bboxes1.new(batch_shape + (rows,))\n        else:\n            return bboxes1.new(batch_shape + (rows, cols))\n\n    area1 = (bboxes1[..., 2] - bboxes1[..., 0]) * (bboxes1[..., 3] - bboxes1[..., 1])\n    area2 = (bboxes2[..., 2] - bboxes2[..., 0]) * (bboxes2[..., 3] - bboxes2[..., 1])\n\n    if is_aligned:\n        lt = torch.max(bboxes1[..., :2], bboxes2[..., :2])  # [B, rows, 2]\n        rb = torch.min(bboxes1[..., 2:], bboxes2[..., 2:])  # [B, rows, 2]\n\n        wh = (rb - lt).clamp(min=0)  # [B, rows, 2]\n        overlap = wh[..., 0] * wh[..., 1]\n\n        if mode in [\"iou\", \"giou\"]:\n            union = area1 + area2 - overlap\n        else:\n            union = area1\n        if mode == \"giou\":\n            enclosed_lt = torch.min(bboxes1[..., :2], bboxes2[..., :2])\n            enclosed_rb = torch.max(bboxes1[..., 2:], bboxes2[..., 2:])\n    else:\n        lt = torch.max(\n            bboxes1[..., :, None, :2], bboxes2[..., None, :, :2]\n        )  # [B, rows, cols, 2]\n        rb = torch.min(\n            bboxes1[..., :, None, 2:], bboxes2[..., None, :, 2:]\n        )  # [B, rows, cols, 2]\n\n        wh = (rb - lt).clamp(min=0)  # [B, rows, cols, 2]\n        overlap = wh[..., 0] * wh[..., 1]\n\n        if mode in [\"iou\", \"giou\"]:\n            union = area1[..., None] + area2[..., None, :] - overlap\n        else:\n            union = area1[..., None]\n        if mode == \"giou\":\n            enclosed_lt = torch.min(\n                bboxes1[..., :, None, :2], bboxes2[..., None, :, :2]\n            )\n            enclosed_rb = torch.max(\n                bboxes1[..., :, None, 2:], bboxes2[..., None, :, 2:]\n            )\n\n    eps = union.new_tensor([eps])\n    union = torch.max(union, eps)\n    ious = overlap / union\n    if mode in [\"iou\", \"iof\"]:\n        return ious\n    # calculate gious\n    enclose_wh = (enclosed_rb - enclosed_lt).clamp(min=0)\n    enclose_area = enclose_wh[..., 0] * enclose_wh[..., 1]\n    enclose_area = torch.max(enclose_area, eps)\n    gious = ious - (enclose_area - union) / enclose_area\n    return gious\n\n\n\n@weighted_loss\ndef giou_loss(pred, target, eps=1e-7):\n    r\"\"\"`Generalized Intersection over Union: A Metric and A Loss for Bounding\n    Box Regression &lt;https://arxiv.org/abs/1902.09630&gt;`_.\n\n    Args:\n        pred (torch.Tensor): Predicted bboxes of format (x1, y1, x2, y2),\n            shape (n, 4).\n        target (torch.Tensor): Corresponding gt bboxes, shape (n, 4).\n        eps (float): Eps to avoid log(0).\n\n    Return:\n        Tensor: Loss tensor.\n    \"\"\"\n    gious = bbox_overlaps(pred, target, mode=\"giou\", is_aligned=True, eps=eps)\n    loss = 1 - gious\n    return loss\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#53-gfl-loss","title":"5.3 GFL Loss","text":"<p>\u6e90\u7801\u5730\u5740:(<code>nanodet/model/loss/gfocal_loss.py</code>)</p> <pre><code>@weighted_loss\ndef quality_focal_loss(pred, target, beta=2.0):\n    r\"\"\"Quality Focal Loss (QFL) is from `Generalized Focal Loss: Learning\n    Qualified and Distributed Bounding Boxes for Dense Object Detection\n    &lt;https://arxiv.org/abs/2006.04388&gt;`_.\n\n    Args:\n        pred (torch.Tensor): Predicted joint representation of classification\n            and quality (IoU) estimation with shape (N, C), C is the number of\n            classes.\n        target (tuple([torch.Tensor])): Target category label with shape (N,)\n            and target quality label with shape (N,).\n        beta (float): The beta parameter for calculating the modulating factor.\n            Defaults to 2.0.\n\n    Returns:\n        torch.Tensor: Loss tensor with shape (N,).\n    \"\"\"\n    assert (\n        len(target) == 2\n    ), \"\"\"target for QFL must be a tuple of two elements,\n        including category label and quality label, respectively\"\"\"\n    # label denotes the category id, score denotes the quality score\n    label, score = target\n\n    # \u8ba1\u7b97\u80cc\u666f\u7684focal loss\n    # negatives are supervised by 0 quality score\n    pred_sigmoid = pred.sigmoid()\n    scale_factor = pred_sigmoid\n    zerolabel = scale_factor.new_zeros(pred.shape)\n    loss = F.binary_cross_entropy_with_logits(\n        pred, zerolabel, reduction=\"none\"\n    ) * scale_factor.pow(beta)\n\n    # \u8ba1\u7b97\u524d\u666f\u7684focal loss\n    # FG cat_id: [0, num_classes -1], BG cat_id: num_classes\n    bg_class_ind = pred.size(1)\n    # \u83b7\u53d6\u524d\u666fmask\n    pos = torch.nonzero((label &gt;= 0) &amp; (label &lt; bg_class_ind), as_tuple=False).squeeze(\n        1\n    )\n    pos_label = label[pos].long()\n    # positives are supervised by bbox quality (IoU) score\n    scale_factor = score[pos] - pred_sigmoid[pos, pos_label]\n    # \u8ba1\u7b97\u524d\u666fLoss\n    loss[pos, pos_label] = F.binary_cross_entropy_with_logits(\n        pred[pos, pos_label], score[pos], reduction=\"none\"\n    ) * scale_factor.abs().pow(beta)\n    # [N,C] -&gt; [N]\n    loss = loss.sum(dim=1, keepdim=False)\n    return loss\n\n\n@weighted_loss\ndef distribution_focal_loss(pred, label):\n    r\"\"\"Distribution Focal Loss (DFL) is from `Generalized Focal Loss: Learning\n    Qualified and Distributed Bounding Boxes for Dense Object Detection\n    &lt;https://arxiv.org/abs/2006.04388&gt;`_.\n\n    Args:\n        pred (torch.Tensor): Predicted general distribution of bounding boxes\n            (before softmax) with shape (N, n+1), n is the max value of the\n            integral set `{0, ..., n}` in paper.\n        label (torch.Tensor): Target distance label for bounding boxes with\n            shape (N,).\n\n    Returns:\n        torch.Tensor: Loss tensor with shape (N,).\n    \"\"\"\n    # DFL loss\n    # \u5982\u679cx\u4f4d\u4e8e[a,b] \u4e4b\u95f4 \u90a3\u4e48\u5176\u5206\u7ed9a\u7684\u6982\u7387\u7684\u6743\u91cd\u4e3a((b - a) - (x - a)) / (b - a)\uff0c\u540c\u7406\u5206\u914d\u7ed9b\u4e5f\u4e00\u6837\n    dis_left = label.long()\n    dis_right = dis_left + 1\n    weight_left = dis_right.float() - label\n    weight_right = label - dis_left.float()\n    loss = (\n        F.cross_entropy(pred, dis_left, reduction=\"none\") * weight_left\n        + F.cross_entropy(pred, dis_right, reduction=\"none\") * weight_right\n    )\n    return loss\n\n\nclass QualityFocalLoss(nn.Module):\n    r\"\"\"Quality Focal Loss (QFL) is a variant of `Generalized Focal Loss:\n    Learning Qualified and Distributed Bounding Boxes for Dense Object\n    Detection &lt;https://arxiv.org/abs/2006.04388&gt;`_.\n\n    Args:\n        use_sigmoid (bool): Whether sigmoid operation is conducted in QFL.\n            Defaults to True.\n        beta (float): The beta parameter for calculating the modulating factor.\n            Defaults to 2.0.\n        reduction (str): Options are \"none\", \"mean\" and \"sum\".\n        loss_weight (float): Loss weight of current loss.\n    \"\"\"\n\n    def __init__(self, use_sigmoid=True, beta=2.0, reduction=\"mean\", loss_weight=1.0):\n        super(QualityFocalLoss, self).__init__()\n        assert use_sigmoid is True, \"Only sigmoid in QFL supported now.\"\n        self.use_sigmoid = use_sigmoid\n        self.beta = beta\n        self.reduction = reduction\n        self.loss_weight = loss_weight\n\n    def forward(\n        self, pred, target, weight=None, avg_factor=None, reduction_override=None\n    ):\n        \"\"\"Forward function.\n\n        Args:\n            pred (torch.Tensor): Predicted joint representation of\n                classification and quality (IoU) estimation with shape (N, C),\n                C is the number of classes.\n            target (tuple([torch.Tensor])): Target category label with shape\n                (N,) and target quality label with shape (N,).\n            weight (torch.Tensor, optional): The weight of loss for each\n                prediction. Defaults to None.\n            avg_factor (int, optional): Average factor that is used to average\n                the loss. Defaults to None.\n            reduction_override (str, optional): The reduction method used to\n                override the original reduction method of the loss.\n                Defaults to None.\n        \"\"\"\n        assert reduction_override in (None, \"none\", \"mean\", \"sum\")\n        reduction = reduction_override if reduction_override else self.reduction\n        if self.use_sigmoid:\n            loss_cls = self.loss_weight * quality_focal_loss(\n                pred,\n                target,\n                weight,\n                beta=self.beta,\n                reduction=reduction,\n                avg_factor=avg_factor,\n            )\n        else:\n            raise NotImplementedError\n        return loss_cls\n\n\nclass DistributionFocalLoss(nn.Module):\n    r\"\"\"Distribution Focal Loss (DFL) is a variant of `Generalized Focal Loss:\n    Learning Qualified and Distributed Bounding Boxes for Dense Object\n    Detection &lt;https://arxiv.org/abs/2006.04388&gt;`_.\n\n    Args:\n        reduction (str): Options are `'none'`, `'mean'` and `'sum'`.\n        loss_weight (float): Loss weight of current loss.\n    \"\"\"\n\n    def __init__(self, reduction=\"mean\", loss_weight=1.0):\n        super(DistributionFocalLoss, self).__init__()\n        self.reduction = reduction\n        self.loss_weight = loss_weight\n\n    def forward(\n        self, pred, target, weight=None, avg_factor=None, reduction_override=None\n    ):\n        \"\"\"Forward function.\n\n        Args:\n            pred (torch.Tensor): Predicted general distribution of bounding\n                boxes (before softmax) with shape (N, n+1), n is the max value\n                of the integral set `{0, ..., n}` in paper.\n            target (torch.Tensor): Target distance label for bounding boxes\n                with shape (N,).\n            weight (torch.Tensor, optional): The weight of loss for each\n                prediction. Defaults to None.\n            avg_factor (int, optional): Average factor that is used to average\n                the loss. Defaults to None.\n            reduction_override (str, optional): The reduction method used to\n                override the original reduction method of the loss.\n                Defaults to None.\n        \"\"\"\n        assert reduction_override in (None, \"none\", \"mean\", \"sum\")\n        reduction = reduction_override if reduction_override else self.reduction\n        loss_cls = self.loss_weight * distribution_focal_loss(\n            pred, target, weight, reduction=reduction, avg_factor=avg_factor\n        )\n        return loss_cls\n</code></pre>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#_5","title":"\u516d. \u8bad\u7ec3\u4e0e\u8bc4\u4f30\u90e8\u5206\u4ee3\u7801\u89e3\u8bfb","text":"<p>nanodet-plus\u7684\u8bad\u7ec3\u5b8c\u5168\u57fa\u4e8e pytorch-lightning</p> <p>\u7531\u4e8e<code>LightningModule</code>\u5b9a\u4e49\u7684\u94a9\u5b50\u51fd\u6570\u5f88\u89c4\u8303\uff0c\u5bfc\u81f4\u4f5c\u8005\u4e00\u65f6\u4e5f\u4e0d\u77e5\u9053\u8be5\u89e3\u8bfb\u4ec0\u4e48\u3002</p> <p>\u6240\u4ee5\u591a\u5361\u5c01\u88c5\uff0ccheckpoint\u4fdd\u5b58\u4e4b\u7c7b\u7684\u57fa\u672c\u4e0d\u7528\u7ba1\u3002\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u4e00\u4e2a\u7c7b\u641e\u5b9a\uff0c\u4e0b\u9762\u8bf7\u770b\u6e90\u7801(<code>nanodet/trainer/task.py</code>)</p> <pre><code>class TrainingTask(LightningModule):\n    \"\"\"\n    Pytorch Lightning module of a general training task.\n    Including training, evaluating and testing.\n    Args:\n        cfg: Training configurations\n        evaluator: Evaluator for evaluating the model performance.\n    \"\"\"\n\n    def __init__(self, cfg, evaluator=None):\n        super(TrainingTask, self).__init__()\n        self.cfg = cfg\n        self.model = build_model(cfg.model)\n        self.evaluator = evaluator\n        self.save_flag = -10\n        self.log_style = \"NanoDet\"\n        self.weight_averager = None\n        if \"weight_averager\" in cfg.model:\n            self.weight_averager = build_weight_averager(\n                cfg.model.weight_averager, device=self.device\n            )\n            self.avg_model = copy.deepcopy(self.model)\n\n    def _preprocess_batch_input(self, batch):\n        # \u5c06batch \u4e2d img list \u6784\u9020\u4e3aTensor\n        batch_imgs = batch[\"img\"]\n        if isinstance(batch_imgs, list):\n            batch_imgs = [img.to(self.device) for img in batch_imgs]\n            # stack_batch_img \u4e3b\u8981\u505a\u7684\u4e8b\u60c5\u5c31\u662f\u5411\u53f3\u4e0b\u89d2\u6dfb\u52a0padding\uff0c\u4f7f\u5176\u653e\u5230\u4e00\u4e2abatch\u4e2d\n            # \u56e0\u4e3apadding\u5728\u53f3\u4e0b\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u5904\u7406\u7ed3\u679c\u5750\u6807\uff0c\u53ea\u9700\u8981clip\u5373\u53ef\n            batch_img_tensor = stack_batch_img(batch_imgs, divisible=32)\n            batch[\"img\"] = batch_img_tensor\n        return batch\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n    @torch.no_grad()\n    def predict(self, batch, batch_idx=None, dataloader_idx=None):\n        batch = self._preprocess_batch_input(batch)\n        preds = self.forward(batch[\"img\"])\n        results = self.model.head.post_process(preds, batch)\n        return results\n\n    def training_step(self, batch, batch_idx):\n        batch = self._preprocess_batch_input(batch)\n        preds, loss, loss_states = self.model.forward_train(batch)\n\n        # log train losses\n        if self.global_step % self.cfg.log.interval == 0:\n            memory = (\n                torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0\n            )\n            lr = self.trainer.optimizers[0].param_groups[0][\"lr\"]\n            log_msg = \"Train|Epoch{}/{}|Iter{}({}/{})| mem:{:.3g}G| lr:{:.2e}| \".format(\n                self.current_epoch + 1,\n                self.cfg.schedule.total_epochs,\n                self.global_step,\n                batch_idx + 1,\n                self.trainer.num_training_batches,\n                memory,\n                lr,\n            )\n            self.scalar_summary(\"Train_loss/lr\", \"Train\", lr, self.global_step)\n            for loss_name in loss_states:\n                log_msg += \"{}:{:.4f}| \".format(\n                    loss_name, loss_states[loss_name].mean().item()\n                )\n                self.scalar_summary(\n                    \"Train_loss/\" + loss_name,\n                    \"Train\",\n                    loss_states[loss_name].mean().item(),\n                    self.global_step,\n                )\n            self.logger.info(log_msg)\n\n        return loss\n\n    def training_epoch_end(self, outputs: List[Any]) -&gt; None:\n        self.trainer.save_checkpoint(os.path.join(self.cfg.save_dir, \"model_last.ckpt\"))\n\n    def validation_step(self, batch, batch_idx):\n        batch = self._preprocess_batch_input(batch)\n        if self.weight_averager is not None:\n            preds, loss, loss_states = self.avg_model.forward_train(batch)\n        else:\n            preds, loss, loss_states = self.model.forward_train(batch)\n\n        if batch_idx % self.cfg.log.interval == 0:\n            memory = (\n                torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0\n            )\n            lr = self.trainer.optimizers[0].param_groups[0][\"lr\"]\n            log_msg = \"Val|Epoch{}/{}|Iter{}({}/{})| mem:{:.3g}G| lr:{:.2e}| \".format(\n                self.current_epoch + 1,\n                self.cfg.schedule.total_epochs,\n                self.global_step,\n                batch_idx + 1,\n                sum(self.trainer.num_val_batches),\n                memory,\n                lr,\n            )\n            for loss_name in loss_states:\n                log_msg += \"{}:{:.4f}| \".format(\n                    loss_name, loss_states[loss_name].mean().item()\n                )\n            self.logger.info(log_msg)\n\n        dets = self.model.head.post_process(preds, batch)\n        return dets\n\n    def validation_epoch_end(self, validation_step_outputs):\n        \"\"\"\n        Called at the end of the validation epoch with the\n        outputs of all validation steps.Evaluating results\n        and save best model.\n        Args:\n            validation_step_outputs: A list of val outputs\n\n        \"\"\"\n        results = {}\n        for res in validation_step_outputs:\n            results.update(res)\n        all_results = (\n            gather_results(results)\n            if dist.is_available() and dist.is_initialized()\n            else results\n        )\n        if all_results:\n            eval_results = self.evaluator.evaluate(\n                all_results, self.cfg.save_dir, rank=self.local_rank\n            )\n            metric = eval_results[self.cfg.evaluator.save_key]\n            # save best model\n            if metric &gt; self.save_flag:\n                self.save_flag = metric\n                best_save_path = os.path.join(self.cfg.save_dir, \"model_best\")\n                mkdir(self.local_rank, best_save_path)\n                self.trainer.save_checkpoint(\n                    os.path.join(best_save_path, \"model_best.ckpt\")\n                )\n                self.save_model_state(\n                    os.path.join(best_save_path, \"nanodet_model_best.pth\")\n                )\n                txt_path = os.path.join(best_save_path, \"eval_results.txt\")\n                if self.local_rank &lt; 1:\n                    with open(txt_path, \"a\") as f:\n                        f.write(\"Epoch:{}\n\".format(self.current_epoch + 1))\n                        for k, v in eval_results.items():\n                            f.write(\"{}: {}\n\".format(k, v))\n            else:\n                warnings.warn(\n                    \"Warning! Save_key is not in eval results! Only save model last!\"\n                )\n            self.logger.log_metrics(eval_results, self.current_epoch + 1)\n        else:\n            self.logger.info(\"Skip val on rank {}\".format(self.local_rank))\n\n    def test_step(self, batch, batch_idx):\n        dets = self.predict(batch, batch_idx)\n        return dets\n\n    def test_epoch_end(self, test_step_outputs):\n        results = {}\n        for res in test_step_outputs:\n            results.update(res)\n        all_results = (\n            gather_results(results)\n            if dist.is_available() and dist.is_initialized()\n            else results\n        )\n        if all_results:\n            res_json = self.evaluator.results2json(all_results)\n            json_path = os.path.join(self.cfg.save_dir, \"results.json\")\n            json.dump(res_json, open(json_path, \"w\"))\n\n            if self.cfg.test_mode == \"val\":\n                eval_results = self.evaluator.evaluate(\n                    all_results, self.cfg.save_dir, rank=self.local_rank\n                )\n                txt_path = os.path.join(self.cfg.save_dir, \"eval_results.txt\")\n                with open(txt_path, \"a\") as f:\n                    for k, v in eval_results.items():\n                        f.write(\"{}: {}\n\".format(k, v))\n        else:\n            self.logger.info(\"Skip test on rank {}\".format(self.local_rank))\n\n    def configure_optimizers(self):\n        \"\"\"\n        Prepare optimizer and learning-rate scheduler\n        to use in optimization.\n\n        Returns:\n            optimizer\n        \"\"\"\n        optimizer_cfg = copy.deepcopy(self.cfg.schedule.optimizer)\n        optimizer = build_optimizer(self.model, optimizer_cfg)\n\n        schedule_cfg = copy.deepcopy(self.cfg.schedule.lr_schedule)\n        name = schedule_cfg.pop(\"name\")\n        build_scheduler = getattr(torch.optim.lr_scheduler, name)\n        scheduler = {\n            \"scheduler\": build_scheduler(optimizer=optimizer, **schedule_cfg),\n            \"interval\": \"epoch\",\n            \"frequency\": 1,\n        }\n        return dict(optimizer=optimizer, lr_scheduler=scheduler)\n\n    def optimizer_step(\n        self,\n        epoch=None,\n        batch_idx=None,\n        optimizer=None,\n        optimizer_idx=None,\n        optimizer_closure=None,\n        on_tpu=None,\n        using_lbfgs=None,\n    ):\n        \"\"\"\n        Performs a single optimization step (parameter update).\n        Args:\n            epoch: Current epoch\n            batch_idx: Index of current batch\n            optimizer: A PyTorch optimizer\n            optimizer_idx: If you used multiple optimizers this indexes into that list.\n            optimizer_closure: closure for all optimizers\n            on_tpu: true if TPU backward is required\n            using_lbfgs: True if the matching optimizer is lbfgs\n        \"\"\"\n        # warm up lr\n        if self.trainer.global_step &lt;= self.cfg.schedule.warmup.steps:\n            if self.cfg.schedule.warmup.name == \"constant\":\n                k = self.cfg.schedule.warmup.ratio\n            elif self.cfg.schedule.warmup.name == \"linear\":\n                k = 1 - (\n                    1 - self.trainer.global_step / self.cfg.schedule.warmup.steps\n                ) * (1 - self.cfg.schedule.warmup.ratio)\n            elif self.cfg.schedule.warmup.name == \"exp\":\n                k = self.cfg.schedule.warmup.ratio ** (\n                    1 - self.trainer.global_step / self.cfg.schedule.warmup.steps\n                )\n            else:\n                raise Exception(\"Unsupported warm up type!\")\n            for pg in optimizer.param_groups:\n                pg[\"lr\"] = pg[\"initial_lr\"] * k\n\n        # update params\n        optimizer.step(closure=optimizer_closure)\n        optimizer.zero_grad()\n\n    def scalar_summary(self, tag, phase, value, step):\n        \"\"\"\n        Write Tensorboard scalar summary log.\n        Args:\n            tag: Name for the tag\n            phase: 'Train' or 'Val'\n            value: Value to record\n            step: Step value to record\n\n        \"\"\"\n        if self.local_rank &lt; 1:\n            self.logger.experiment.add_scalars(tag, {phase: value}, step)\n\n    def info(self, string):\n        self.logger.info(string)\n\n    @rank_zero_only\n    def save_model_state(self, path):\n        self.logger.info(\"Saving model to {}\".format(path))\n        state_dict = (\n            self.weight_averager.state_dict()\n            if self.weight_averager\n            else self.model.state_dict()\n        )\n        torch.save({\"state_dict\": state_dict}, path)\n\n    # ------------Hooks-----------------\n    def on_fit_start(self) -&gt; None:\n        if \"weight_averager\" in self.cfg.model:\n            self.logger.info(\"Weight Averaging is enabled\")\n            if self.weight_averager and self.weight_averager.has_inited():\n                self.weight_averager.to(self.weight_averager.device)\n                return\n            self.weight_averager = build_weight_averager(\n                self.cfg.model.weight_averager, device=self.device\n            )\n            self.weight_averager.load_from(self.model)\n\n    def on_train_epoch_start(self):\n        # \u4f20\u9012epoch\u53c2\u6570\u63a7\u5236AGM\u662f\u5426\u53d1\u6325\u4f5c\u7528\uff0cset_epoch\u5728`nanodet/model/arch/one_stage_detector.py`\u4e2d\u5b9a\u4e49\n        self.model.set_epoch(self.current_epoch)\n\n    def on_train_batch_end(self, outputs, batch, batch_idx) -&gt; None:\n        if self.weight_averager:\n            # ema\n            self.weight_averager.update(self.model, self.global_step)\n\n    def on_validation_epoch_start(self):\n        if self.weight_averager:\n            self.weight_averager.apply_to(self.avg_model)\n\n    def on_test_epoch_start(self) -&gt; None:\n        if self.weight_averager:\n            self.on_load_checkpoint({\"state_dict\": self.state_dict()})\n            self.weight_averager.apply_to(self.model)\n\n    def on_load_checkpoint(self, checkpointed_state: Dict[str, Any]) -&gt; None:\n        if self.weight_averager:\n            avg_params = convert_avg_params(checkpointed_state)\n            if len(avg_params) != len(self.model.state_dict()):\n                self.logger.info(\n                    \"Weight averaging is enabled but average state does not\"\n                    \"match the model\"\n                )\n            else:\n                self.weight_averager = build_weight_averager(\n                    self.cfg.model.weight_averager, device=self.device\n                )\n                self.weight_averager.load_state_dict(avg_params)\n                self.logger.info(\"Loaded average state from checkpoint.\")\n</code></pre> <p>\u6a21\u578b\u8bc4\u4f30\u4e5f\u662f\u501f\u7528<code>pycocotools</code>:</p> <pre><code>class CocoDetectionEvaluator:\n    def __init__(self, dataset):\n        assert hasattr(dataset, \"coco_api\")\n        self.class_names = dataset.class_names\n        self.coco_api = dataset.coco_api\n        self.cat_ids = dataset.cat_ids\n        self.metric_names = [\"mAP\", \"AP_50\", \"AP_75\", \"AP_small\", \"AP_m\", \"AP_l\"]\n\n    def results2json(self, results):\n        \"\"\"\n        results: {image_id: {label: [bboxes...] } }\n        :return coco json format: {image_id:\n                                   category_id:\n                                   bbox:\n                                   score: }\n        \"\"\"\n        json_results = []\n        for image_id, dets in results.items():\n            for label, bboxes in dets.items():\n                category_id = self.cat_ids[label]\n                for bbox in bboxes:\n                    score = float(bbox[4])\n                    detection = dict(\n                        image_id=int(image_id),\n                        category_id=int(category_id),\n                        bbox=xyxy2xywh(bbox),\n                        score=score,\n                    )\n                    json_results.append(detection)\n        return json_results\n\n    def evaluate(self, results, save_dir, rank=-1):\n        results_json = self.results2json(results)\n        if len(results_json) == 0:\n            warnings.warn(\n                \"Detection result is empty! Please check whether \"\n                \"training set is too small (need to increase val_interval \"\n                \"in config and train more epochs). Or check annotation \"\n                \"correctness.\"\n            )\n            empty_eval_results = {}\n            for key in self.metric_names:\n                empty_eval_results[key] = 0\n            return empty_eval_results\n        json_path = os.path.join(save_dir, \"results{}.json\".format(rank))\n        json.dump(results_json, open(json_path, \"w\"))\n        coco_dets = self.coco_api.loadRes(json_path)\n        coco_eval = COCOeval(\n            copy.deepcopy(self.coco_api), copy.deepcopy(coco_dets), \"bbox\"\n        )\n        coco_eval.evaluate()\n        coco_eval.accumulate()\n\n        # use logger to log coco eval results\n        redirect_string = io.StringIO()\n        with contextlib.redirect_stdout(redirect_string):\n            coco_eval.summarize()\n        logger.info(\"\n\" + redirect_string.getvalue())\n\n        # print per class AP\n        headers = [\"class\", \"AP50\", \"mAP\"]\n        colums = 6\n        per_class_ap50s = []\n        per_class_maps = []\n        precisions = coco_eval.eval[\"precision\"]\n        # dimension of precisions: [TxRxKxAxM]\n        # precision has dims (iou, recall, cls, area range, max dets)\n        assert len(self.class_names) == precisions.shape[2]\n\n        for idx, name in enumerate(self.class_names):\n            # area range index 0: all area ranges\n            # max dets index -1: typically 100 per image\n            precision_50 = precisions[0, :, idx, 0, -1]\n            precision_50 = precision_50[precision_50 &gt; -1]\n            ap50 = np.mean(precision_50) if precision_50.size else float(\"nan\")\n            per_class_ap50s.append(float(ap50 * 100))\n\n            precision = precisions[:, :, idx, 0, -1]\n            precision = precision[precision &gt; -1]\n            ap = np.mean(precision) if precision.size else float(\"nan\")\n            per_class_maps.append(float(ap * 100))\n\n        num_cols = min(colums, len(self.class_names) * len(headers))\n        flatten_results = []\n        for name, ap50, mAP in zip(self.class_names, per_class_ap50s, per_class_maps):\n            flatten_results += [name, ap50, mAP]\n\n        row_pair = itertools.zip_longest(\n            *[flatten_results[i::num_cols] for i in range(num_cols)]\n        )\n        table_headers = headers * (num_cols // len(headers))\n        table = tabulate(\n            row_pair,\n            tablefmt=\"pipe\",\n            floatfmt=\".1f\",\n            headers=table_headers,\n            numalign=\"left\",\n        )\n        logger.info(\"\n\" + table)\n\n        aps = coco_eval.stats[:6]\n        eval_results = {}\n        for k, v in zip(self.metric_names, aps):\n            eval_results[k] = v\n        return eval_results\n</code></pre> <p>\u8fd9\u91cc\u6211\u4eec\u7701\u7565\u4e86\u5bf9EMA\u7684\u89e3\u8bfb\u548cDataloader\u76f8\u5173\u51fd\u6570\u7684\u89e3\u8bfb\uff0c\u8bfb\u8005\u53ef\u4ee5\u7ec3\u4e60\u81ea\u884c\u89c2\u770b\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/nanodet-plus-explain/#_6","title":"\u4e03. \u603b\u7ed3","text":"<p>\u6e05\u660e\u8282\u5c0f\u5047\u671f\u7684\u4e00\u4e0b\u5348+\u665a\u4e0a\u7684\u65f6\u95f4\uff0c\u6211\u5b8c\u6210\u4e86\u5bf9nanodet-plus\u7684\u89e3\u8bfb\uff0c\u7ec8\u4e8e\u80fd\u4eceTODO List\u4e2d\u5220\u9664\u8fd9\u4ef6\u4e8b\u4e86\u3002\u5199\u7684\u4e0d\u597d\uff0c\u8bfb\u8005\u8fd8\u8bf7\u591a\u63d0\u610f\u89c1\u3002\u6709\u95ee\u9898\u53ef\u4ee5\u5728\u8bc4\u8bba\u533a\u8ba8\u8bba\u6216\u8005\u7ed9\u6211\u53d1\u90ae\u4ef6<code>haibintian@foxmail.com</code>\u3002</p> <p>\u7ed9\u4e00\u4e9b\u53c2\u8003\u6587\u732e\u5427</p> <ol> <li>YOLOX</li> <li>GFL Loss</li> <li>GIOU Loss</li> </ol> <p>\u81f3\u4e8e\u5176\u4ed6\u7684\u8fd8\u8bf7\u9605\u8bfbnanodet-plus\u4f5c\u8005\u77e5\u4e4e\u5427\u3002</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/swin_transformer_relative_pos/","title":"\u5bf9Swin Transformer\u4e2d\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u4e0eattention mask\u7684\u7406\u89e3","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/swin_transformer_relative_pos/#_1","title":"\u4e00\u3001\u524d\u8a00","text":"<p>\u524d\u4e00\u9635\u7cfb\u7edf\u770b\u4e86\u4e0bswin transformer\u7684\u8bba\u6587\u548c\u6e90\u7801\uff0c\u53cd\u590d\u5480\u56bc\u540e\u5bf9\u8ba9\u6211\u66fe\u7ecf\u5934\u75bc\u7684\u4e24\u70b9\u5185\u5bb9\u8c08\u4e00\u4e0b\u81ea\u5df1\u7684\u7406\u89e3\uff0c\u5176\u4e2d\u5305\u62ecwindow\u5185\u90e8\u7684\u7528\u4e8eself attention\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u548cShifted Window Attention\u4e2d\u7684attention mask\u3002</p> <p>\u672c\u6587\u4e0d\u4f1a\u4ecb\u7ecdswin transformer\u7684\u4e3b\u8981\u601d\u8def\uff0c\u4e3b\u8981\u805a\u7126\u4e8e\u4e0a\u9762\u8bf4\u7684\u4e24\u4e2a\u95ee\u9898\uff0c\u6ca1\u6709\u770b\u8fc7\u539f\u6587\u7684\u8bfb\u8005\u8fd8\u8bf7\u4ed4\u7ec6\u8bfb\u4e00\u4e0b\u539f\u6587</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2103.14030.pdf \u4ee3\u7801\u5730\u5740\uff1ahttps://github.com/microsoft/Swin-Transformer</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/swin_transformer_relative_pos/#window-attention","title":"\u4e8c\u3001Window Attention\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u8bba\u6587\u4e2d\u63d0\u5230Swin Transformer\u4e2d\u7684Attention\u91c7\u7528relative postition\u7684\u65b9\u5f0f\uff0c\u4e0d\u540c\u4e8e\u6700\u521d\u7248\u672c\u7684VIT\uff0crelative position bias \u4f1a\u52a0\u5230\u6bcf\u4e00\u5c42\u7684attention\u5c42\u3002\u8bba\u6587\u4e2d\u6709\u5173\u76f8\u5173\u4f4d\u7f6e\u7f16\u7801\u7684\u53d9\u8ff0\u5982\u4e0b</p> <p>Relative position bias. In computing self-attention, we follow \\(\\text{ }^{[49,1,32,33]}\\)  by including a relative position bias  \\(B \\in \\mathbb{R}^{M^2 \\times M^2}\\)  to each head in computing similarity:</p> \\[ \\operatorname{Attention}(Q, K, V)=\\operatorname{SoftMax}\\left(Q K^T / \\sqrt{d}+B\\right) V \\] <p>where  \\(Q, K, V \\in \\mathbb{R}^{M^2 \\times d}\\)  are the query, key and value matrices;  \\(d\\)  is the query/key dimension, and  \\(M^2\\)  is the number of patches in a window. Since the relative position along each axis lies in the range  \\([-M+1, M-1]\\) , we parameterize a smaller-sized bias matrix  \\(\\hat{B} \\in \\mathbb{R}^{(2 M-1) \\times(2 M-1)}\\) , and values in  \\(B\\)  are taken from  \\(\\hat{B}\\) .</p> <p>\u5047\u8bbe\u77e9\u9635A\u662fn*m,\u77e9\u9635B\u662fm*p,\u77e9\u9635A\u548cB\u76f8\u4e58\u5f97\u5230\u77e9\u9635C\u662fn*p\uff0c\u77e9\u9635\u4e58\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3am*n*p</p> <p>\u5047\u8bbe\u8f93\u5165\u5f20\u91cf\u5f62\u72b6\u4e3a<code>[B, numWindows, window_size * window_size, C]</code>\uff0c\u4e0a\u6587\u4e2d\u8bf4 \\(\\text{M}^{2}\\) \u8868\u793a\u4e00\u4e2a\u7a97\u53e3\u4e2d\u5143\u7d20\u7684\u4e2a\u6570\uff0cQ/K\u7684\u5f62\u72b6\u4e3a<code>[B*numWindows, num_heads, window_size*window_size, C//num_heads]</code>\uff0cM\u5373window_size\uff0c d=C//num_heads\u3002\u5728\u751f\u6210Q\u3001K\u3001V\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a<code>B * numWindows * num_heads</code>\u4e2a\u5f62\u72b6\u4e3a<code>[window_size * window_size, C // num_heads]</code>\u77e9\u9635\u4e58\u4ee5<code>[C // num_heads, C // num_heads * 3]</code>\u7684\u8f6c\u6362\u77e9\u9635\uff0c\u8fd9\u91cc\u8f6c\u6362\u77e9\u9635\u662f\u5171\u4eab\u7684\u3002\u76f8\u6bd4\u8f83\u4e0e\u4f20\u7edfVIT\u7684<code>[B, C, H, W]-&gt;[B, num_heads, H*W, C // num_heads]</code>\uff08<code>B*num_heads</code>\uff09\uff0c<code>SwinTransformer</code>\u7684\u5171\u4eab\u77e9\u9635\u4e2a\u6570\u591a<code>numWindows</code>\u500d\uff0c\u77e9\u9635\u4e58\u6cd5\u7531<code>[H*W, C // num_heads] @ [C // num_heads, C // num_heads * 3]</code>\u53d8\u4e3a<code>[H // win_num * W // win_num, C //num_heads] @ [C // num_heads, C // num_heads * 3]</code> \uff0c\u8fd9\u91cc\u5b9a\u4e49<code>win_num * win_num = numWindows</code>\u3002\u6240\u4ee5\u4f20\u7edfVIT\u77e9\u9635\u4e58\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a<code>B * num_heads * H * W * C // num_heads * C // num_heads * 3</code>\uff0c\u5373<code>B * H * W * C // num_heads * C * 3</code>\u3002SwinTransformer\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a<code>B * numWindows * window_size * window_size * C * C // num_heads * 3</code>\u3002\u76f8\u6bd4\u8f83\u800c\u8a00\u5728\u8ba1\u7b97QKV\u77e9\u9635\u7684\u65f6\u5019\uff0cSwin Transformer\u5e76\u6ca1\u6709\u8282\u7701\u8ba1\u7b97\u91cf\uff0c\u8282\u7701\u8ba1\u7b97\u91cf\u7684\u90e8\u5206\u53d1\u751f\u5728\u4e0eV\u77e9\u9635\u4ea4\u4e92\u7684\u8fc7\u7a0b\u4e2d\u3002</p> <p>\u901a\u8fc7\u4e0a\u8ff0\u8fc7\u7a0b\u719f\u6089\u4e00\u4e0b\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u7684tensor\u7684\u5f62\u72b6\u53d8\u5316\uff0c\u65b9\u4fbf\u6211\u4eec\u66f4\u597d\u7684\u7406\u89e3\u76f8\u5bf9\u4f4d\u7f6eB\uff0c<code>Q@K</code>\u7684\u5f62\u72b6\u5e94\u8be5\u662f<code>[B*numWindows, num_heads, window_size * window_size, window_size * window_size]</code>\uff0cB\u7684\u5f62\u72b6\u4e5f\u53ef\u4ee5\u662f<code>[1, num_heads, window_size * window_size, window_size * window_size]</code>\u6216\u8005<code>[1, 1, window_size * window_size, window_size * window_size]</code>\uff0c\u6587\u4e2d\u91c7\u7528\u7684\u662f\u524d\u8005\uff0c\u90a3\u4e48\u4e3a\u4ec0\u4e48\u4e0d\u662f\u540e\u8005\u5462\uff1f\u8fd9\u4e2a\u95ee\u9898\u6211\u4e00\u65f6\u534a\u4f1a\u4e5f\u6ca1\u60f3\u660e\u767d\uff0c\u4e24\u8005\u7684\u533a\u522b\u5728\u4e8e\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u662f\u5426\u53ef\u4ee5\u5171\u4eab\uff0c\u4e2a\u4eba\u611f\u89c9\u4ece\u7b80\u5355\u89d2\u5ea6\u8003\u8651\u662f\u53ef\u4ee5\u5171\u4eab\u7684\u3002</p> <p>\u4e0b\u9762\u8bf4\u4e00\u4e0bB\u662f\u5982\u4f55\u751f\u6210\u7684\uff0c\u5148\u8003\u8651\u5355\u5934\u6ce8\u610f\u529b\uff0c\u5047\u8bbewindow\u4e2d\u7684H\u4e0eW\u90fd\u662f2\uff0c\u904d\u5386\u7a97\u53e3\u4e2d\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u6c42\u51fa\u904d\u5386\u5143\u7d20\u5f53\u505a\u539f\u70b9<code>[0,0]</code>\u65f6\u5176\u4f59\u5143\u7d20\u7684\u5750\u6807\uff0c\u53ef\u4ee5\u5206\u4e3a\u4ee5\u4e0b4\u79cd\u60c5\u51b5\uff1a</p> <p></p> <p>B\u77e9\u9635\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u4e00\u4e2a\u7684\u884c\u5411\u91cf\uff0c\u5c06\u4e0a\u8ff0\u7a97\u53e3\u6309\u7167\u884c\u5c55\u5f00\u6210\u4e00\u7ef4\u5411\u91cf\uff0cB\u77e9\u9635\u6bcf\u4e00\u884c\u7684\u884c\u5750\u6807x\u8868\u793a\u4ee5x\u5143\u7d20\u4e3a\u5750\u6807\u539f\u70b9\uff0c\u6bcf\u4e00\u4e2a\u884c\u5411\u91cf\u8868\u793a\u4ee5x\u4e3a\u5750\u6807\u539f\u70b9\u65f6\u7684\u76f8\u5bf9\u4f4d\u7f6e\u5750\u6807\u3002\u7531\u4e8e\u5c55\u5f00\u6210\u4e00\u7ef4\u4ee5\u540e\u9700\u8981\u4ece\u5b58\u50a8\u8868\u4e2d\u67e5\u627e\u5bf9\u5e94\u5143\u7d20\uff0c\u6240\u4ee5\u9700\u8981\u8c03\u6574\u53ea\u4e00\u7ef4\u5750\u6807\u4e14\u4ece0\u5f00\u59cb\uff0c\u6545\u91c7\u7528\u5982\u4e0b\u7b56\u7565\u8fdb\u884c\u53d8\u6362\uff0c\u4e3a\u4ec0\u4e48\u4e58\u4ee5(2*windows_size - 1)\u53ef\u4ee5\u6309\u7167\u5c06\u4e00\u4e2aN\u8fdb\u5236\u6570\u8f6c\u6362\u4e3a10\u8fdb\u5236\u6570\u7684\u7b97\u6cd5\u6765\u7406\u89e3\uff1a</p> <p></p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/swin_transformer_relative_pos/#shifted-window-attentionattention-mask","title":"\u4e09\u3001Shifted Window Attention\u4e2d\u7684attention mask","text":""},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/swin_transformer_relative_pos/#31-attention-mask","title":"3.1 \u4e3a\u4ec0\u4e48\u9700\u8981attention mask","text":"<p>\u4e3a\u4e86\u6ee1\u8db3\u4e0d\u540cwindows\u4e4b\u95f4\u7684\u4fe1\u606f\u4ea4\u4e92</p>"},{"location":"%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/swin_transformer_relative_pos/#32","title":"3.2 \u5177\u4f53\u8fc7\u7a0b","text":"<ol> <li>\u5148\u770b\u5de6\u56feroll\u4e4b\u524d\u7684\u7ed3\u679c\uff0c\u9488\u5bf9\u5982\u4e0b\u7279\u5f81\u8fdb\u884c\u6309\u7167\u505a\u56fe\u8fdb\u884c\u7a97\u53e3\u5212\u5206\uff0c\u865a\u7ebf\u8868\u793a\u539f\u6765\u7684\u7a97\u53e3\uff0c\u4e3a\u4e86\u8868\u793aroll\u4e4b\u524d\u548croll\u4e4b\u540e\u7684\u53d8\u5316\uff0c\u5728\u5de6\u8fb9\u9884\u5148\u8bbe\u7f6e\u5212\u5206\u597d\u5212\u5206\u540e\u7684\u5757\u6570\u3002\u5b9e\u9645\u4e0a\u4e00\u5f00\u59cb\u4ec5\u6709\u56db\u5757\u3002</li> </ol> <ol> <li>\u518d\u770b\u53f3\u56feroll\u4e4b\u540e\u7684\u7ed3\u679c\uff0c\u8fd8\u662f\u6309\u71672x2\u7684\u7a97\u53e3\u5927\u5c0f\u8fdb\u884c\u5212\u5206\uff0c\u7531\u4e8e\u7a7a\u95f4\u4e0a\u8fde\u7eed\u7684\u50cf\u7d20\u70b9\u4e4b\u95f4\u7684\u7279\u5f81\u52a0\u4e0a\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u540e\u8ba1\u7b97self-attention\u624d\u6709\u610f\u4e49\uff0c\u6240\u4ee5\u9700\u8981\u5bf9<code>5\uff0c3</code>\uff0c<code>7,1</code>\uff0c<code>8,6,2,0</code>\u52a0\u4e0aattention mask\uff0c\u5c06\u6ce8\u610f\u529b\u63a7\u5236\u5728\u6bcf\u4e2a\u5b50\u6a21\u5757\u5185\u90e8\u3002</li> <li>mask\u751f\u6210\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a</li> </ol> <p>\u91c7\u7528\u53f3\u8fb9\u7684\u5411\u91cf\u4e58\u4ee5\u5de6\u8fb9\u7684\u5411\u91cf\uff0c\u7136\u540e\u627e\u5230\u6ee1\u8db3\u6761\u4ef6<code>\u7ed3\u679c\u77e9\u9635M\u4e2d\u7684\u5143\u7d20\u503c \u7b49\u4e8e\u5176\u4e2d\u4e00\u4e2ax*x\uff08x\u4e3a\u5411\u91cf\u4e2d\u7684\u6240\u6709\u5143\u7d20\uff09\u7684\u503c</code>\u8bbe\u7f6e\u4e3atrue\uff0c\u5176\u4f59\u8bbe\u7f6e\u4e3afalse\uff0c\u4ece\u800c\u5bf9<code>Q@K</code>\u77e9\u9635\u52a0\u4e0a\u4e00\u4e2amask\uff0c\u5728\u8ba1\u7b97softmax\u7684\u65f6\u5019\u4e0d\u518d\u8003\u8651\u8fd9\u4e2a\u5143\u7d20\u7684\u8d21\u732e\uff0c\u81f3\u6b64attention mask\u8bb2\u89e3\u5b8c\u6bd5\u3002</p>"},{"location":"%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/ffmpeg%20GPU%E5%8A%A0%E9%80%9F%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/","title":"FFMPEG Cuda\u7248\u672c\u7f16\u8bd1\u5b89\u88c5\u65b9\u6cd5","text":"<p>\u672c\u6587\u5199\u4e8e2023-06-23\u4e2d\u5348\u5341\u4e8c\u70b9</p>"},{"location":"%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/ffmpeg%20GPU%E5%8A%A0%E9%80%9F%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/#_1","title":"\u96f6\u3001\u524d\u8a00","text":"<p>\u6700\u8fd1\u5728\u5f55\u5236\u4e00\u4e9b\u89c6\u9891\uff0c\u9700\u8981\u4e0a\u4f20\u5230b\u7ad9\u5907\u4efd\u4e00\u4e0b\uff0c\u4e0a\u4f20\u4e0a\u53bb\u540e\u63d0\u793a\u8f6c\u7801\u5931\u8d25\uff0c\u9042\u91c7\u7528ffmpeg\u5c06\u89c6\u9891\u8f6c\u7801\u538b\u5236\u4e00\u4e0b\u3002</p> <p>\u53ef\u601c\u6211\u7528\u4e86\u5c06\u8fd1\u5341\u5e74\u7684\u7b14\u8bb0\u672c\u7535\u8111\u6162\u5982\u9f9f\u901f\uff0c\u5c31\u60f3\u7740\u6362\u4e0a\u6211\u914d\u76842080TI\u4e3b\u673a\uff0c\u5e76\u91c7\u7528\u663e\u5361\u52a0\u901f\uff0c\u7f16\u8bd1\u5b8c\u6210\u540e\u6211\u51c6\u5907\u5c06\u6b64\u8fc7\u7a0b\u8bb0\u5f55\u4e0b\u6765\uff0c\u7559\u7ed9\u8bfb\u8005\u501f\u9274\uff0c\u56e0\u6b64\u5c31\u6709\u4e86\u672c\u7bc7\u6587\u7ae0\u3002</p>"},{"location":"%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/ffmpeg%20GPU%E5%8A%A0%E9%80%9F%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/#ffmpeg","title":"\u4e00\u3001ffmpeg\u4ecb\u7ecd","text":"<p>\u5b98\u7f51\uff1ahttp://ffmpeg.org/</p> <p>FFmpeg\u5373\u662f\u4e00\u6b3e\u97f3\u89c6\u9891\u7f16\u89e3\u7801\u5de5\u5177,\u540c\u65f6\u4e5f\u662f\u4e00\u7ec4\u97f3\u89c6\u9891\u7f16\u7801\u5f00\u53d1\u5957\u4ef6,\u4f5c\u4e3a\u7f16\u7801\u5f00\u53d1\u5957\u4ef6,\u5b83\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u97f3\u89c6\u9891\u5904\u7406\u7684\u8c03\u7528\u63a5\u53e3\u3002</p> <p>\u4ece\u4f7f\u7528\u8005\u800c\u4e0d\u662f\u800c\u5f00\u53d1\u8005\u89d2\u5ea6\u6765\u770b\uff0c\u8fd9\u4e2a\u4ecb\u7ecd\u8db3\u591f\u4e86\u3002</p>"},{"location":"%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/ffmpeg%20GPU%E5%8A%A0%E9%80%9F%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/#_2","title":"\u4e8c\u3001\u5b89\u88c5\u8fc7\u7a0b","text":"<p>FFMPEG\u7684cuda\u7248\u672c\u9700\u8981\u7f16\u8bd1\u5b89\u88c5\uff0c\u7b14\u8005\u91c7\u7528\u7684\u73af\u5883\u5982\u4e0b</p> <pre><code>OS:ubuntu22\ngcc 7\ncuda10.2\nnvidia\u9a71\u52a8\u7248\u672c  515.65.01\n</code></pre> <ol> <li>\u786e\u5b9a\u5b89\u88c5\u76ee\u5f55\u7ed3\u6784</li> </ol> <pre><code>mkdir -p ~/ffmpeg/source # \u5b58\u653e\u6e90\u7801\nmkdir -p ~/ffmpeg/other_binary # \u5b58\u653e\u7b2c\u4e09\u65b9\u5e93\nmkdir -p ~/ffmpeg/binary # \u5b58\u653effmpeg\u53ef\u6267\u884c\u6587\u4ef6\n</code></pre> <p>\u6700\u540e\u7684\u76ee\u5f55\u7ed3\u6784\u4e3a</p> <pre><code>.\n\u251c\u2500\u2500 binary\n\u251c\u2500\u2500 other_binary\n\u2514\u2500\u2500 source\n</code></pre> <ol> <li>\u5728source\u76ee\u5f55\u4e0b\u4e0b\u8f7d\u4f9d\u8d56\u5e93\u6e90\u7801\u5e76\u7f16\u8bd1</li> </ol> <p>\u8fd9\u91cc\u6211\u7701\u7565\u5207\u6362\u5230<code>cd source</code>\u7684\u8fc7\u7a0b\uff0c\u8bfb\u8005\u81ea\u884c\u6dfb\u52a0</p> <pre><code># \u5b89\u88c5x264\ngit clone https://code.videolan.org/videolan/x264.git\n./configure --prefix=\"$HOME/ffmpeg/other_binary/x264\" --bindir=\"$HOME/ffmpeg/other_binary/x264/bin\" --enable-shared --enable-pic  --disable-asm\nmake -j\nmake install\n\n# \u5b89\u88c5x265\ngit clone https://github.com/videolan/x265.git\ncd x265\ncd build/linux\ncmake -G \"Unix Makefiles\" -DCMAKE_INSTALL_PREFIX=\"$HOME/ffmpeg/other_binary/x265\" -DENABLE_SHARED:bool=off .\nmake -j\nmake install\n\n# \u5b89\u88c5fdk-acc\nsudo apt-get install -y libtool\ngit clone --depth 1 --branch v0.1.6 https://github.com/mstorsjo/fdk-aac.git\ncd fdk-aac\nautoreconf -fiv\n./configure --prefix=\"$HOME/ffmpeg/other_binary/libfdk_aac\"\nmake -j\nmake install\n\n# \u5b89\u88c5lame\ncurl -O -L http://downloads.sourceforge.net/project/lame/lame/3.99/lame-3.99.tar.gz\ntar xzvf lame-3.99.tar.gz\ncd lame-3.99\n./configure --prefix=\"$HOME/ffmpeg/other_binary/libmp3lame\" --bindir=\"$HOME/ffmpeg/other_binary/libmp3lame/bin\"\nmake -j\nmake install\n\n# \u5b89\u88c5libopus\ncurl -O -L https://archive.mozilla.org/pub/opus/opus-1.2.1.tar.gz\ntar xzvf opus-1.2.1.tar.gz\ncd opus-1.2.1\n./configure --prefix=\"$HOME/ffmpeg/other_binary/libopus\"\nmake -j\nmake install\n\n# \u5b89\u88c5libogg\ncurl -O -L http://downloads.xiph.org/releases/ogg/libogg-1.3.3.tar.gz\ntar xzvf libogg-1.3.3.tar.gz\ncd libogg-1.3.3\n./configure --prefix=\"$HOME/ffmpeg/other_binary/libogg\"\nmake -j\nmake install\n\n# \u5b89\u88c5libvorbis\ncurl -O -L http://downloads.xiph.org/releases/vorbis/libvorbis-1.3.5.tar.gz\ntar xzvf libvorbis-1.3.5.tar.gz\ncd libvorbis-1.3.5\n./configure --prefix=\"$HOME/ffmpeg/other_binary/libvorbis\" --with-ogg=\"$HOME/ffmpeg/other_binary/libogg\"\nmake -j\nmake install\n\n# \u5b89\u88c5libvpx\nsudo apt-get install -y yasm\ngit clone --depth 1 -b v1.13.0 --single-branch https://github.com/webmproject/libvpx.git\ncd libvpx\n./configure --prefix=\"$HOME/ffmpeg/other_binary/libvpx\" --disable-examples --disable-unit-tests --enable-vp9-highbitdepth --as=yasm --enable-shared\nmake -j\nmake install\n\n# \u5b89\u88c5nv-headers \u6839\u636e\u81ea\u5df1\u7684\u9a71\u52a8\u5e93\u7248\u672c\u5207\u6362branch\ngit clone -b n11.1.5.2 --single-branch https://github.com/FFmpeg/nv-codec-headers.git\ncd nv-codec-headers \nmake\nsudo make install\n</code></pre> <ol> <li>\u5b89\u88c5ffmpeg\u652f\u6301cuda\u7248\u672c</li> </ol> <pre><code># \u5b89\u88c5ffmpeg\nsudo apt install libfreetype6-dev\ncurl -O -L https://ffmpeg.org/releases/ffmpeg-6.0.tar.xz\ntar xJvf ffmpeg-6.0.tar.xz\ncd ffmpeg-6.0\n\n\n# \u5b89\u88c5\nffmpep_dep_include_dir=`find $HOME/ffmpeg/other_binary -name \"include\" -type d`\nffmpep_dep_lib_dir=`find $HOME/ffmpeg/other_binary -name \"lib\" -type d`\nffmpep_dep_package_dir=`find ~/ffmpeg -name pkgconfig`\nffmpep_dep_include_str=\"\"\nffmpep_dep_lib_str=\"\"\nffmpep_dep_package_str=\"\"\nfor item in $ffmpep_dep_include_dir\ndo\n    ffmpep_dep_include_str=\"$ffmpep_dep_include_str -I$item\"\ndone\nfor item in $ffmpep_dep_lib_dir\ndo\n    ffmpep_dep_lib_str=\"$ffmpep_dep_lib_str -L$item\"\ndone\nfor item in $ffmpep_dep_package_dir\ndo\n    ffmpep_dep_package_str=\"$item:$ffmpep_dep_package_str\"\ndone\n\n\nPKG_CONFIG_PATH=\"$PKG_CONFIG_PATH:$ffmpep_dep_package_str\" ./configure \\\n  --prefix=\"$HOME/ffmpeg/binary/\" \\\n  --pkg-config-flags=\"--static\" \\\n  --extra-cflags=\"-I/usr/local/cuda/include $ffmpep_dep_include_str\" \\\n  --extra-ldflags=\"-L/usr/local/cuda/lib64 $ffmpep_dep_lib_str\" \\\n  --disable-static \\\n  --enable-shared \\\n  --extra-libs=-lpthread \\\n  --extra-libs=-lm \\\n  --enable-gpl \\\n  --enable-libfdk_aac \\\n  --enable-libfreetype \\\n  --enable-libmp3lame \\\n  --enable-libopus \\\n  --enable-libvorbis \\\n  --enable-libvpx \\\n  --enable-libx264 \\\n  --enable-libx265 \\\n  --enable-cuda-nvcc \\\n  --enable-cuda \\\n  --enable-libnpp \\\n  --disable-ffplay \\\n  --disable-doc \\\n  --enable-cuvid \\\n  --enable-nvenc \\\n  --enable-nonfree\nmake -j\nmake install\n</code></pre> <p>\u7ecf\u9a8c\uff1a 1. \u7f3a\u4ec0\u4e48\u5de5\u5177\u5c31apt\u5b89\u88c5\u4ec0\u4e48\u5de5\u5177 2. \u7f3a\u4ec0\u4e48\u4f9d\u8d56\u5e93\u5c31\u7f16\u8bd1\u5b89\u88c5\u8be5\u4f9d\u8d56\u5e93\uff0c\u5b9e\u5728\u4e0d\u6210\u529f\u4e86\u518d\u53bbapt install 3. \u5982\u679c\u662f\u73af\u5883\u95ee\u9898\uff0c\u5efa\u8bae\u5728docker\u73af\u5883\u4e0b\u7f16\u8bd1\u5b89\u88c5\uff0c\u7136\u540e\u628a\u4e8c\u8fdb\u5236\u6587\u4ef6\u4ee5\u53ca\u76f8\u5173\u4f9d\u8d56\u52a8\u6001\u5e93copy\u51fa\u6765\u5373\u53ef</p> <p>\u5b89\u88c5\u5b8c\u6210ffmpeg\u540e\u76f4\u63a5\u6253\u5f00\u662f\u4e0d\u80fd\u7528\u7684\uff0c\u539f\u56e0\u662f\u6211\u4eec\u7f16\u8bd1\u51fa\u6765\u7684\u5927\u91cf\u7684\u52a8\u6001\u5e93\u5e76\u6ca1\u6709\u5728\u7cfb\u7edf\u52a8\u6001\u5e93\u7684\u641c\u7d22\u76ee\u5f55\u4e2d\uff0c\u56e0\u6b64\u6211\u4eec\u5728<code>ff</code>\u5199\u4e00\u4e2a\u542f\u52a8\u811a\u672c\u3002</p> <p><code>vim ~/ffmpeg/binary/bin/start_ffmpeg.sh</code></p> <pre><code>#!/bin/bash\n\n\nCURDIR=$(dirname $(realpath $0))\nffmpep_dep_lib_dir=`find $HOME/ffmpeg/other_binary -name \"lib\" -type d`\nffmpep_dep_package_str=\"\"\nfor item in $ffmpep_dep_lib_dir\ndo\n        ffmpep_dep_lib_str=\"$ffmpep_dep_lib_str:$item\"\ndone\nexport LD_LIBRARY_PATH=\"$(dirname $CURDIR)/lib:$ffmpep_dep_lib_str:$LD_LIBRARY_PATH\"\n$CURDIR/ffmpeg $@\n</code></pre> <p><code>chmod a+x ~/ffmpeg/binary/bin/start_ffmpeg.sh</code></p> <p>\u8f93\u5165<code>~/ffmpeg/binary/bin/start_ffmpeg.sh -hwaccels</code>\u53ef\u4ee5\u770b\u5230</p> <pre><code>Hardware acceleration methods:\ncuda\n</code></pre>"},{"location":"%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/ffmpeg%20GPU%E5%8A%A0%E9%80%9F%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/#gpu","title":"\u4e09\u3001GPU\u52a0\u901f\u8f6c\u7801\u547d\u4ee4","text":"<p>\u5bf9\u4e8ewmv3\u7f16\u7801\u7684wmv\u6587\u4ef6\uff0c\u6211\u4eec\u53ef\u4ee5\u91c7\u7528\u5982\u4e0b\u547d\u4ee4\u5c06\u5176\u8f6c\u6210wmv</p> <pre><code>~/ffmpeg/binary/bin/start_ffmpeg.sh -hwaccel cuda -extra_hw_frames 10 -c:v wmv3 -i input.wmv -c:v h264_nvenc -b:v 4000k -r 25 -preset slow output.mp4\n</code></pre> <ul> <li>ffmpeg\u547d\u4ee4\u6709\u4e00\u4e2a\u7279\u70b9\u662f\u5199\u5728-i\u524d\u9762\u7684\u7b97\u89e3\u7801\u5668\u53c2\u6570\uff0c\u5199\u5728-i\u540e\u9762\u7684\u7b97\u7f16\u7801\u5668\u53c2\u6570</li> <li><code>-r</code>\uff1a\u6307\u5b9a\u89c6\u9891fps</li> <li><code>-b:v</code>\uff1a\u6307\u5b9a\u89c6\u9891\u6bd4\u7279\u7387</li> </ul> <p>\u6211\u8fd9\u91cc\u91c7\u7528\u7684\u539f\u5219\u662f\u8f93\u51fa\u7f16\u7801\u4e3a<code>h264</code>\uff0c\u4e14\u91c7\u7528\u9002\u914d\u7684nvidia\u7f16\u7801\u5e93\u3002</p> <p>\u8f93\u51fa\u89c6\u9891\u7684fps\u4e0e\u7801\u7387\u4e0e\u539f\u89c6\u9891\u76f8\u540c\uff0c\u91c7\u7528\u4e0a\u8ff0\u547d\u4ee4\u8f6c\u7801\u65f6\uff0c\u6211\u7684GPU\u7b97\u529b\u5229\u7528\u7387\u7ea6\u4e3a10%\u3002</p> <p><code>speed</code>\u4e3a8\uff0c\u53731s\u5904\u7406\u89c6\u9891\u4e2d8s\u7684\u6570\u636e\u3002</p> <p>OK\uff0c\u5c31\u5199\u5230\u8fd9\u5427\uff0c\u540e\u7eed\u7591\u95ee\u6b22\u8fce\u5728\u8bc4\u8bba\u533a\u4ea4\u6d41\u3002</p>"},{"location":"%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/ubuntu%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/","title":"Ubuntu\u5b89\u5353\u5f00\u53d1\u73af\u5883\u5b89\u88c5","text":"<pre><code>sudo apt-get install openjdk-18-jdk\n</code></pre>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/","title":"\u89c6\u89c9\u7c7b\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u9879\u76ee\u76f8\u5173\u6280\u672f\u603b\u7ed3","text":"<p>\u672c\u6587\u5199\u4e8e2024\u5e742\u670808\u65e5\u665a\u5341\u70b9</p>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_2","title":"\u96f6\u3001\u524d\u8a00","text":"<p>\u505a\u8fd9\u4e2a\u65b9\u5411\u7684\u9879\u76ee\u4e5f\u6709\u4e00\u6bb5\u65f6\u95f4\u4e86\uff0c\u4f5c\u4e3a\u7b97\u6cd5\u5de5\u7a0b\u5e08\uff0c\u4e3b\u5bfc\u7684\u5927\u5927\u5c0f\u5c0f\u7684\u9879\u76ee\u4e5f\u6709\u51e0\u4e2a\uff0c\u6709\u6210\u529f\u4ea4\u4ed8\u7684\uff0c\u8bda\u7136\u4e5f\u6709\u70c2\u5c3e\u7684\u3002\u56de\u987e\u6574\u4e2a\u9879\u76ee\u6d41\u7a0b\uff0c\u5c3d\u7ba1\u7ecf\u5386\u9178\u751c\u82e6\u8fa3\uff0c\u4f46\u6536\u83b7\u9887\u4e30\uff0c\u4f30\u5199\u4e0b\u6b64\u6587\u5f53\u62102023\u5e74\u7ec8\u603b\u7ed3\u5427\u3002</p> <p>\u672c\u6587\u4e0d\u4ec5\u4ec5\u6d89\u53ca\u7684\u662f\u6280\u672f\uff0c\u4e5f\u6709\u4e00\u4e9b\u5bf9\u4e8e\u9879\u76ee\u7ba1\u7406\uff0c\u9700\u6c42\u6c9f\u901a\u7684\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u7b97\u662f\u81ea\u5df1\u7684\u4e00\u70b9\u70b9\u611f\u609f\u3002</p> <p>\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u9879\u76ee\uff0c\u540c\u4e8b\u66f4\u591a\u79f0\u4e4b\u4e3a\u201c\u8d28\u68c0\u9879\u76ee\u201d\uff0c\u6211\u603b\u89c9\u5f97\u8fd9\u4e2a\u8303\u56f4\u592a\u5927\u4e86\u3002\u5c3d\u7ba1PPT\u91cc\u9762\u5199\u7684\u770b\u7740\u6211\u4eec\u4ec0\u4e48\u90fd\u80fd\u505a\uff0c\u4f46\u662f\u5f53\u9762\u5bf9\u4e00\u4e9b\u5201\u94bb\u9700\u6c42\u65f6\uff0c\u5b9e\u4e8b\u6c42\u662f\u5730\u8bb2\u6211\u4eec\u8fd8\u662f\u505a\u4e0d\u4e86\u3002</p> <p>\u672c\u6587\u4e0d\u4f1a\u6d89\u53ca\u592a\u591a\u6280\u672f\u7ec6\u8282\u76f8\u5173\u7684\u4e1c\u897f\uff0c\u4e3b\u8981\u662f\u4e00\u4e9b\u65b9\u6cd5\u8bba\u3002</p>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_3","title":"\u4e00\u3001\u4efb\u52a1\u5b9a\u4e49","text":"<p>\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u4efb\u52a1\u662f\u6307\u901a\u8fc7\u5bf9\u4ea7\u54c1\u8868\u9762\u8fdb\u884c\u4ed4\u7ec6\u7684\u68c0\u67e5\u548c\u8bc4\u4f30\uff0c\u4ee5\u53d1\u73b0\u548c\u8bc6\u522b\u4efb\u4f55\u4e0d\u7b26\u5408\u8d28\u91cf\u6807\u51c6\u6216\u8bbe\u8ba1\u8981\u6c42\u7684\u8868\u9762\u7f3a\u9677\u3002\u8fd9\u9879\u4efb\u52a1\u7684\u76ee\u7684\u662f\u786e\u4fdd\u4ea7\u54c1\u7684\u5916\u89c2\u8d28\u91cf\u548c\u529f\u80fd\u6027\u6ee1\u8db3\u9884\u5b9a\u7684\u8981\u6c42\uff0c\u4ece\u800c\u63d0\u9ad8\u4ea7\u54c1\u7684\u6574\u4f53\u8d28\u91cf\u548c\u5ba2\u6237\u6ee1\u610f\u5ea6\u3002</p> <p>\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u5e7f\u6cdb\u5e94\u7528\u4e8e\u591a\u4e2a\u884c\u4e1a\uff0c\u4ee5\u786e\u4fdd\u4ea7\u54c1\u8d28\u91cf\u7b26\u5408\u6807\u51c6\uff0c\u63d0\u5347\u4ea7\u54c1\u7ade\u4e89\u529b\u3002\u8fd9\u5176\u4e2d\u5305\u62ec</p> <ol> <li> <p>\u5236\u9020\u4e1a</p> <ul> <li>\u6c7d\u8f66\u5236\u9020\u4e1a\uff1a\u68c0\u6d4b\u8f66\u8eab\u3001\u96f6\u90e8\u4ef6\u7b49\u7684\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u822a\u7a7a\u5de5\u4e1a\uff1a\u68c0\u6d4b\u98de\u673a\u673a\u8eab\u3001\u96f6\u4ef6\u7b49\u7684\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u673a\u68b0\u52a0\u5de5\uff1a\u68c0\u6d4b\u673a\u5e8a\u5e8a\u8eab\u3001\u5bfc\u8f68\u7b49\u90e8\u4ef6\u7684\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u7535\u5b50\u884c\u4e1a\uff1a\u68c0\u6d4b\u7535\u8def\u677f\u3001\u624b\u673a\u58f3\u4f53\u7b49\u4ea7\u54c1\u7684\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u5bb6\u7528\u7535\u5668\uff1a\u68c0\u6d4b\u5851\u6599\u5916\u58f3\u3001\u91d1\u5c5e\u90e8\u4ef6\u7b49\u7684\u8868\u9762\u7f3a\u9677\u3002</li> </ul> </li> <li> <p>\u6750\u6599\u52a0\u5de5\u4e1a\uff1a    </p> <ul> <li>\u94a2\u94c1\u884c\u4e1a\uff1a\u68c0\u6d4b\u94a2\u6750\u8868\u9762\u7684\u88c2\u7eb9\u3001\u6298\u53e0\u7b49\u7f3a\u9677\u3002</li> <li>\u6709\u8272\u91d1\u5c5e\u884c\u4e1a\uff1a\u68c0\u6d4b\u94dd\u3001\u94dc\u7b49\u91d1\u5c5e\u6750\u6599\u7684\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u9676\u74f7\u548c\u73bb\u7483\u884c\u4e1a\uff1a\u68c0\u6d4b\u9676\u74f7\u548c\u73bb\u7483\u4ea7\u54c1\u7684\u8868\u9762\u7f3a\u9677\u3002</li> </ul> </li> <li> <p>\u7eba\u7ec7\u54c1\u548c\u670d\u88c5\u884c\u4e1a</p> <ul> <li>\u68c0\u6d4b\u7eba\u7ec7\u54c1\u7684\u7834\u635f\u3001\u6c61\u6e0d\u3001\u989c\u8272\u4e0d\u5747\u5300\u7b49\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u68c0\u67e5\u670d\u88c5\u7ebd\u6263\u3001\u62c9\u94fe\u7b49\u9644\u4ef6\u7684\u8868\u9762\u7f3a\u9677\u3002</li> </ul> </li> <li> <p>\u98df\u54c1\u548c\u5305\u88c5\u884c\u4e1a</p> <ul> <li>\u68c0\u6d4b\u98df\u54c1\u5305\u88c5\u888b\u3001\u5bb9\u5668\u7b49\u7684\u5370\u5237\u8d28\u91cf\u3001\u6f0f\u5370\u7b49\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u68c0\u67e5\u5305\u88c5\u6750\u6599\u7684\u5bc6\u5c01\u6027\u3001\u900f\u660e\u5ea6\u7b49\u8868\u9762\u7f3a\u9677\u3002</li> </ul> </li> <li> <p>\u5efa\u7b51\u884c\u4e1a</p> <ul> <li>\u68c0\u6d4b\u6df7\u51dd\u571f\u7ed3\u6784\u8868\u9762\u7684\u88c2\u7f1d\u3001\u8702\u7a9d\u7b49\u7f3a\u9677\u3002</li> <li>\u68c0\u67e5\u5efa\u7b51\u6750\u6599\u5982\u7816\u3001\u77f3\u3001\u6728\u6750\u7b49\u7684\u8868\u9762\u7f3a\u9677\u3002</li> </ul> </li> <li> <p>\u80fd\u6e90\u884c\u4e1a  </p> <ul> <li>\u68c0\u6d4b\u98ce\u529b\u53d1\u7535\u673a\u53f6\u7247\u3001\u592a\u9633\u80fd\u7535\u6c60\u677f\u7b49\u7684\u8868\u9762\u7f3a\u9677\u3002</li> <li>\u68c0\u67e5\u77f3\u6cb9\u3001\u5929\u7136\u6c14\u8f93\u9001\u7ba1\u9053\u7684\u9632\u8150\u5c42\u3001\u710a\u7f1d\u7b49\u8868\u9762\u7f3a\u9677\u3002</li> </ul> </li> </ol> <p>\u8fd9\u4e9b\u884c\u4e1a\u7684\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u4e0d\u4ec5\u5173\u7cfb\u5230\u4ea7\u54c1\u8d28\u91cf\uff0c\u8fd8\u53ef\u80fd\u5f71\u54cd\u5230\u4ea7\u54c1\u5b89\u5168\u3001\u8010\u7528\u6027\u548c\u5e02\u573a\u7ade\u4e89\u529b\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u4e25\u683c\u7684\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\uff0c\u53ef\u4ee5\u786e\u4fdd\u4ea7\u54c1\u5728\u8bbe\u8ba1\u3001\u751f\u4ea7\u548c\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u548c\u53ef\u9760\u6027\u3002</p> <p>\u8ddf\u4e00\u4e2a\u884c\u4e1a\u5927\u4f6c\u804a\u8fc7AOI\u884c\u4e1a\uff0c\u4e2a\u4eba\u611f\u89c9AOI\u805a\u7126\u4e8e\u7535\u5b50\u5668\u4ef6\u7684\u68c0\u6d4b\uff1a AOI\uff08Automated Optical Inspection\uff0c\u81ea\u52a8\u5149\u5b66\u68c0\u6d4b\uff09\u662f\u4e00\u79cd\u5229\u7528\u5149\u5b66\u539f\u7406\u548c\u81ea\u52a8\u5316\u6280\u672f\u5bf9\u5370\u5237\u7535\u8def\u677f\uff08PCB\uff09\u6216\u5176\u4ed6\u7535\u5b50\u7ec4\u4ef6\u8fdb\u884c\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u3001\u5c3a\u5bf8\u6d4b\u91cf\u3001\u710a\u70b9\u68c0\u67e5\u7b49\u7684\u4e00\u79cd\u6280\u672f\u3002AOI\u7cfb\u7edf\u901a\u5e38\u5305\u62ec\u5149\u6e90\u3001\u5149\u5b66\u955c\u5934\u3001\u56fe\u50cf\u91c7\u96c6\u8bbe\u5907\u3001\u6570\u636e\u5206\u6790\u8f6f\u4ef6\u7b49\u7ec4\u4ef6\u3002</p>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_4","title":"\u4e8c\u3001\u9700\u6c42\u6c9f\u901a","text":"<p>\u7531\u4efb\u52a1\u5b9a\u4e49\u53ef\u77e5\uff0c\u8fd9\u7c7b\u9879\u76ee\u662f\u5b9a\u5236\u5316\u7684\u9879\u76ee\uff0c\u4e14ToB\u4e3a\u4e3b\u3002\u6709\u4e9b\u89c4\u5219\u662f\u884c\u4e1a\u91cc\u5934\u7684\uff0c\u6709\u4e9b\u89c4\u5219\u662f\u5de5\u5382\u81ea\u5df1\u5b9a\u4e49\u7684\u3002</p> <p>\u524d\u671f\u7684\u9700\u6c42\u6c9f\u901a\u4e3b\u8981\u4ee5\u7f3a\u9677\u79cd\u7c7b\u3001\u7f3a\u9677\u7684\u91cd\u8981\u6027\u4e3a\u4e3b\u3002\u540e\u9762\u9700\u8981\u66f4\u8fdb\u4e00\u6b65\u8ba8\u8bba\u8d28\u91cf\u6807\u51c6\u3001\u68c0\u6d4b\u6807\u51c6\u548c\u8bc4\u4f30\u53ef\u884c\u6027\u3002</p> <p>\u660e\u786e\u597d\u7f3a\u9677\u79cd\u7c7b\u540e\uff0c\u8fd8\u9700\u8981\u8bc4\u4f30\u5bf9\u4e8e\u7b97\u6cd5\u7684\u8981\u6c42\uff0c\u5305\u62ec\u5b9e\u65f6\u6027\u3001\u7cbe\u5ea6\u3001\u68c0\u6d4b\u8303\u56f4\u7b49\u3002\u6b64\u5916\u5728\u9879\u76ee\u7684\u7acb\u9879\u9636\u6bb5\uff0c\u9a8c\u6536\u6807\u51c6\u4e5f\u9700\u8981\u786e\u5b9a\u597d\u3002</p> <p>\u7f3a\u9677\u6837\u4f8b\u7684\u6536\u96c6\u4e5f\u662f\u91cd\u4e2d\u4e4b\u91cd\u7684\u5de5\u4f5c\uff0c\u5982\u679c\u67d0\u7c7b\u5ba2\u6237\u8981\u6c42\u5fc5\u987b\u505a\u7684\u7f3a\u9677\u6bd4\u8f83\u96be\u6536\u96c6\uff0c\u9700\u8981\u8bc4\u4f30\u662f\u5426\u53ef\u4ee5\u4eba\u4e3a\u9020\u4e00\u4e9b\u3001\u901a\u8fc7\u7b97\u6cd5\u9020\u4e00\u4e9b\u6837\u672c\u6216\u8005\u8bc4\u4f30\u4e0b\u5177\u4f53\u7684\u6536\u96c6\u65f6\u95f4\u662f\u5426\u6ee1\u8db3\u9879\u76ee\u8981\u6c42\u3002\u6bd4\u5982\u5b9e\u65f6\u6027\u8981\u6c42\u8f83\u9ad8\u7684\u65f6\u5019\uff0c\u4e59\u65b9\u5c31\u9700\u8981\u8981\u6c42\u7532\u65b9\u8d2d\u4e70\u8ba1\u7b97\u80fd\u529b\u8f83\u597d\u7684\u786c\u4ef6\uff0c\u6216\u8005\u8ba1\u7b97\u5361\u7684\u6570\u91cf\u591a\u4e00\u4e9b\u4e5f\u53ef\u4ee5\u3002\u7cbe\u5ea6\u4e00\u822c\u5b58\u5728\u4e8e\u9a8c\u6536\u6807\u51c6\u4e2d\uff0c\u6307\u6807\u7684\u5b9a\u4e49\u8981\u660e\u786e\u6e05\u695a\u3002</p> <p>\u68c0\u6d4b\u8303\u56f4\u5373\u68c0\u6d4b\u7f3a\u9677\u7684\u79cd\u7c7b\u6709\u54ea\u4e9b\uff0c\u54ea\u4e9b\u5141\u8bb8\u6f0f\u68c0\uff0c\u54ea\u4e9b\u81f3\u5c11\u68c0\u51fa\u4e00\u4e2a\u7b49\u3002\u6700\u5e38\u89c1\u4e5f\u662f\u6700\u5934\u75bc\u7684\u662f\u68c0\u6d4b\u201c\u5f02\u7269\u201d\uff0c\u5982\u679c\u5ba2\u6237\u5b9a\u4e49\u662f\u4e00\u4e2a\u5f00\u653e\u96c6\u5408\uff0c\u5c31\u9700\u8981\u614e\u91cd\u8003\u8651\uff0c\u56e0\u4e3a\u5e38\u89c1\u7684\u6709\u76d1\u7763\u76ee\u6807\u68c0\u6d4b\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u8fd8\u505a\u4e0d\u5230\u3002\u5982\u679c\u5ba2\u6237\u5b9a\u4e49\u662f\u4e00\u4e2a\u95ed\u96c6\uff0c\u90a3\u5c31\u9700\u8981\u7edf\u8ba1\u4e00\u4e0b\u6bcf\u4e2a\"\u5f02\u7269\"\u79cd\u7c7b\u7f3a\u9677\u7684\u53ef\u6536\u96c6\u6837\u672c\u6570\u91cf\uff0c\u91cd\u65b0\u6309\u7167\u65b0\u7684\u7f3a\u9677\u7c7b\u522b\u8fdb\u884c\u8bc4\u5b9a\u3002</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u7c7b\u9879\u76ee\u518d\u597d\u7684\u68c0\u6d4b\u7b97\u6cd5\uff0c\u90a3\u4e5f\u5c40\u9650\u4e8e\u68c0\u6d4b\uff0c\u4e0d\u5177\u6709\u4fee\u590d\u7f3a\u9677\u7684\u529f\u80fd\uff0c\u8fd9\u5728\u524d\u671f\u9700\u6c42\u6c9f\u901a\u65f6\u5c31\u9700\u8981\u5bf9\u9f50\u3002</p> <p>\u6b64\u5916\uff0c\u53d1\u4f1a\u8bae\u7ee9\u6548\u4e5f\u662f\u5bb6\u5e38\u4fbf\u996d\uff0c\u90ae\u4ef6\u7559\u5e95\u662f\u5bf9\u7532\u65b9\u4e59\u65b9\u9886\u5bfc\u90fd\u6709\u4ea4\u4ee3\u3002</p>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_5","title":"\u4e09\u3001\u6210\u50cf\u65b9\u6848","text":"<p>\u6210\u50cf\u65b9\u6848\u7684\u9009\u53d6\u53d6\u51b3\u4e8e\u591a\u79cd\u56e0\u7d20\uff0c\u5305\u62ec\u88ab\u68c0\u6d4b\u7269\u4f53\u7684\u6750\u8d28\u3001\u8868\u9762\u7279\u6027\u3001\u6240\u9700\u7684\u68c0\u6d4b\u7cbe\u5ea6\u3001\u68c0\u6d4b\u901f\u5ea6\u4ee5\u53ca\u6210\u672c\u7b49\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5e38\u89c1\u7684\u6210\u50cf\u65b9\u6848\uff1a</p> <ol> <li>\u5149\u5b66\u663e\u5fae\u955c\u6210\u50cf\uff1a    \u9002\u7528\u4e8e\u5c0f\u5c3a\u5bf8\u7f3a\u9677\u7684\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\uff0c\u6bd4\u5982\u4e00\u4e9b\u7535\u8def\u677f\u68c0\u6d4b</li> <li>\u5149\u5b66\u68c0\u6d4b\u6210\u50cf\u7cfb\u7edf\uff08\u5982CCD/CMOS\u76f8\u673a\uff09\uff1a    \u53ef\u4ee5\u914d\u5408\u4e0d\u540c\u7c7b\u578b\u7684\u5149\u5b66\u955c\u5934\u548c\u5149\u6e90\u4f7f\u7528\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\uff0c\u5e38\u89c1\u7684\u6709\u94a2\u94c1\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u3001\u5e03\u5339\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u3002</li> <li>\u7ea2\u5916\u6210\u50cf\uff1a    \u5bf9\u70ed\u7279\u6027\u7684\u53d8\u5316\u654f\u611f\uff0c\u9002\u7528\u4e8e\u68c0\u6d4b\u67d0\u4e9b\u6750\u6599\u7684\u70ed\u7f3a\u9677\u3002</li> <li>\u7d2b\u5916\u6210\u50cf\uff1a    \u67d0\u4e9b\u8868\u9762\u7f3a\u9677\u5728\u7d2b\u5916\u5149\u4e0b\u66f4\u4e3a\u663e\u8457\uff0c\u9002\u7528\u4e8e\u7279\u5b9a\u6750\u6599\u7684\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u3002</li> <li>\u6fc0\u5149\u626b\u63cf\u6210\u50cf\uff1a    \u901a\u8fc7\u6fc0\u5149\u626b\u63cf\u5668\u9010\u70b9\u626b\u63cf\u7269\u4f53\u8868\u9762\uff0c\u518d\u901a\u8fc7\u4f20\u611f\u5668\u6536\u96c6\u6570\u636e\uff0c\u9002\u7528\u4e8e\u5927\u578b\u7269\u4f53\u7684\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002</li> <li>\u8d85\u58f0\u6ce2\u6210\u50cf\uff1a    \u901a\u8fc7\u8d85\u58f0\u6ce2\u5728\u6750\u6599\u4e2d\u7684\u4f20\u64ad\u7279\u6027\u6765\u68c0\u6d4b\u5185\u90e8\u548c\u8868\u9762\u7684\u7f3a\u9677\u3002</li> </ol> <p>\u4ece\u7b97\u6cd5\u5de5\u7a0b\u5e08\u89d2\u5ea6\uff0c\u6211\u4eec\u5f80\u5f80\u5173\u6ce8\u4e8e\u6574\u4e2a\u7cfb\u7edf\u7684\u8282\u62cd\u548c\u6210\u50cf\u7684\u8017\u65f6\uff08\u5de5\u63a7\u673a\u6700\u7ec8\u5f97\u5230\u5355\u4e2a\u5b8c\u6574\u56fe\u7247\u7684\u65f6\u95f4\uff09\uff0c\u4ee5\u53ca\u6700\u540e\u7684\u56fe\u50cf\u662f\u5355\u901a\u9053\u7684\u8fd8\u662f\u591a\u901a\u9053\u7684\uff0c\u662f2D\u68c0\u6d4b\u8fd8\u662f\u4e09\u7ef4\u68c0\u6d4b\u3002</p> <p>\u6210\u50cf\u8fd8\u9700\u8981\u6ce8\u610f\u4e24\u70b9\uff1a</p> <ol> <li>\u4e00\u5b9a\u8981\u6c42\u9a8c\u8bc1\u73af\u8282\uff0c\u786e\u4fdd\u6bcf\u4e00\u7c7b\u7f3a\u9677\u90fd\u53ef\u4ee5\u62cd\u7684\u5230\uff0c\u4e14\u6bd4\u8f83\u597d\u533a\u5206\uff0c\u4e0d\u53d7\u6b63\u5e38\u533a\u57df\u5f71\u54cd\u3002\u540e\u7eed\u6539\u6210\u50cf\u6210\u672c\u5f88\u5927\uff0c\u7275\u4e00\u53d1\u800c\u52a8\u5168\u8eab\u3002</li> <li>\u6210\u50cf\u65b9\u6848\u8981\u786e\u4fdd\u53ef\u8fc1\u79fb\u6027\uff0c\u5373\u5728\u9a8c\u8bc1\u9636\u6bb5\u642d\u7684\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u7684\u6210\u50cf\u6548\u679c\uff0c\u5728\u6b63\u5f0f\u6295\u5165\u4f7f\u7528\u65f6\u4f9d\u7136\u53ef\u4ee5\u4fdd\u8bc1\u539f\u6765\u6781\u4e3a\u63a5\u8fd1\u7684\u6210\u50cf\u6548\u679c\u3002</li> </ol>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_6","title":"\u56db\u3001\u7f3a\u9677\u6536\u96c6\u548c\u5bf9\u9f50","text":"<p>\u7f3a\u9677\u56fe\u7247\u7684\u6536\u96c6\u662f\u4e00\u4e2a\u4f53\u529b\u6d3b\uff0c\u4e3b\u8981\u5206\u4e3a\u4e24\u79cd\u65b9\u5f0f\uff1a</p> <ol> <li>\u4eba\u5de5\u6536\u96c6\uff1a\u4f9d\u8d56\u4e8e\u7532\u65b9\u5ba2\u6237\u5de5\u4eba\u5e08\u5085\u6536\u96c6\u6837\u672c\uff0c\u7136\u540e\u4e59\u65b9\u6216\u8005\u7532\u65b9\u6d3e\u4eba\u4eba\u5de5\u8fdb\u884c\u7167\u7247\u53d6\u6837\u3002</li> <li>\u534a\u4eba\u5de5\u6536\u96c6\u52a0\u81ea\u52a8\u91c7\u96c6\uff1a\u8fd9\u79cd\u6536\u96c6\u65b9\u5f0f\u5e38\u89c1\u4e8e\u94a2\u677f\u548c\u5e03\u5339\u7eba\u7ec7\u54c1\u7f3a\u9677\u68c0\u6d4b\u9886\u57df\uff0c\u8fd9\u7c7b\u4efb\u52a1\u6709\u4e00\u4e2a\u91cd\u8981\u7684\u7279\u70b9\u662f\u6444\u50cf\u5934\u62cd\u6444\u7684\u6bcf\u5f20\u56fe\u50cf\u5728\u7a7a\u95f4\u4e0a\u5bf9\u9f50\u7684\uff0c\u5373\u6bcf\u4e00\u5904\u4f4d\u7f6e\u5728\u56fe\u7247\u4e0a\u7684\u8bed\u4e49\u4e0d\u4f1a\u53d8\u3002\u8fd9\u79cd\u7279\u5f81\u4fdd\u8bc1\u4e86\u53ef\u4ee5\u91c7\u7528\u4e00\u4e9b\u534a\u76d1\u7763\u6216\u8005\u65e0\u76d1\u7763\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u6765\u4ece\u6536\u96c6\u7684\u5927\u91cf\u6b63\u5e38\u6837\u672c\u4e2d\u83b7\u53d6\u5230\u5f02\u5e38\u6837\u672c\u3002\u540e\u7eed\u8fd8\u9700\u8981\u6536\u96c6\u56fa\u5b9a\u7c7b\u522b\u7684\u6837\u672c\uff0c\u6bd4\u5982\u5212\u4f24\u3001\u88c2\u7eb9\u7b49\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u9700\u8981\u4eba\u5de5\u8bad\u7ec3\u4e00\u4e2aCNN\u5206\u7c7b\u6a21\u578b\u6765\u5bf9\u7f3a\u9677\u6837\u672c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u5206\u7c7b\u3002</li> </ol> <p>\u7f3a\u9677\u5bf9\u9f50\u73af\u8282\u5728\u9700\u6c42\u6c9f\u901a\u9636\u6bb5\u5df2\u7ecf\u6709\u7eb2\u8981\u4e86\uff0c\u5728\u7f3a\u9677\u5bf9\u9f50\u73af\u8282\u66f4\u591a\u7684\u662f\u5bf9\u9f50\u7ec6\u8282\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u8981\u786e\u5b9a\u7f3a\u9677\u7684\u6807\u6ce8\u95ee\u9898\u4e86\uff0c\u662f\u6807\u6846\u8fd8\u662f\u6807\u50cf\u7d20\u70b9\uff0c\u6846\u662f\u5916\u63a5\u77e9\u5f62\u6846\u8fd8\u662f\u65cb\u8f6c\u77e9\u5f62\u6846\uff0c\u8fd9\u9700\u8981\u6839\u636e\u5ba2\u6237\u9700\u6c42\u3001\u7f3a\u9677\u63cf\u8ff0\u51c6\u786e\u6027\u3001\u7b97\u6cd5\u5b9e\u73b0\u96be\u6613\u7a0b\u5ea6\u7efc\u5408\u8003\u8651\u3002</p>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_7","title":"\u4e94\u3001\u6574\u4f53\u63a8\u7406\u670d\u52a1\u6846\u67b6","text":"<p>\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u7b97\u6cd5\u5e38\u5e38\u4ee5\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u6765\u5b9e\u73b0\uff0c\u5b83\u6709\u7740\u8f93\u5165\u56fe\u7247\u8f83\u5927\u3001\u5b9e\u65f6\u6027\u8981\u6c42\u9ad8\u7684\u7279\u70b9\u3002</p> <p>\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u7b97\u6cd5\u7684\u6846\u67b6\u4e2a\u4eba\u603b\u7ed3\u5982\u4e0b\uff1a</p> <p></p> <ol> <li>\u5927\u56fe\u9884\u5904\u7406\uff1a\u5bf9\u4e8e\u5927\u56fe\u7684\u9884\u5904\u7406\u5305\u62ec\u53bb\u9664\u975e\u68c0\u6d4b\u533a\u57df\u4ee5\u53ca\u7279\u5b9a\u5f02\u5e38\u7684\u5206\u7c7b\uff0c\u8fd9\u4e9b\u4e00\u822c\u53ef\u4ee5\u624b\u5199\u4e00\u4e9b\u7279\u5f81\u6765\u5904\u7406\uff08\u6bd4\u5982\u53bb\u9ed1\u8fb9\uff09\uff0c\u6709\u65f6\u4e5f\u9700\u8981\u8bad\u7ec3\u4e00\u4e9b\u6a21\u578b\u6765\u5904\u7406\uff08\u6bd4\u5982\u5bf9\u4e8e\u5927\u56fe\u7279\u5b9a\u7f3a\u9677\u7684\u5206\u7c7b\uff09\uff0c\u8fd8\u6709\u662f\u9700\u8981\u63d0\u53d6\u4e00\u4e9b\u68c0\u6d4b\u533a\u57df\uff08ROI\u533a\u57df\uff0cRegion of Interesting\uff09</li> <li>\u5927\u56fe\u4e0a\u7684\u7f3a\u9677\u68c0\u6d4b\uff1a\u6709\u4e9b\u7f3a\u9677\u5728\u5927\u56fe\u4e0a\u5bb9\u6613\u5b9a\u4f4d\u7279\u5f81\u6bd4\u8f83\u660e\u663e\uff0c\u53ef\u4ee5\u653e\u5728\u5927\u56fe\u4e2d\u53bb\u68c0\u6d4b\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u5927\u56fe\u4e0a\u505a\u7f3a\u9677\u68c0\u6d4b\u662f\u8017\u8d39\u603b\u4f53\u65f6\u957f\u7684\uff0c\u6240\u4ee5\u540e\u7eed\u6b65\u9aa4\u5982\u679c\u9700\u8981\u5728\u5c0f\u56fe\u4e0a\u505a\u68c0\u6d4b\uff0c\u90a3\u4e48\u4ece\u6574\u4f53\u7cfb\u7edf\u5ef6\u8fdf\u89d2\u5ea6\u8003\u8651\uff0c\u5927\u56fe\u7684\u68c0\u6d4b\u5c3d\u91cf\u8fd8\u662f\u653e\u5230\u5c0f\u56fe\u4e0a\u3001</li> <li>\u6839\u636eROI\u533a\u57df\u5207\u5c0f\u56fe\uff1a\u6709ROI\u533a\u57df\u5c31\u6839\u636eROI\u533a\u57df\u5750\u6807\u5207\uff0c\u8fd9\u91cc\u6709\u4e24\u4e2a\u8d85\u53c2\u6570\uff0c\u5373\u5c0f\u56fe\u5207\u591a\u5927\u548cstride\u662f\u591a\u5c11\uff0c\u8fd9\u4e9b\u53ef\u4ee5\u6839\u636e\u68c0\u6d4b\u7cbe\u5ea6\u8981\u6c42\u3001\u7cfb\u7edf\u5ef6\u8fdf\u8981\u6c42\u548c\u5c0f\u56fe\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u8f93\u5165\u56fe\u7247\u5927\u5c0f\u6765\u5224\u5b9a\u3002</li> <li>\u5c0f\u56fe\u9884\u5904\u7406\uff1a\u5bf9\u4e8e\u5c0f\u56fe\u9884\u5904\u7406\u7684\u5305\u62ec\u5bf9\u4e8e\u5c0f\u56fe\u5f02\u5e38\u7684\u5206\u7c7b\u5224\u5b9a\uff0c\u5728\u4e00\u4e2a\u6b63\u5e38\u7684\u68c0\u6d4b\u6d41\u7a0b\u4e2d\uff0c\u6b63\u5e38\u6837\u672c\u5360\u5927\u591a\u6570\uff0c\u8fd9\u6837\u4e00\u4e2a\u8017\u65f6\u8f83\u5c0f\u7684\u5206\u7c7b\u5668\u53ef\u4ee5\u6321\u6389\u540e\u7eed\u5927\u56fe\u5206\u6b63\u5e38\u5c0f\u56fe\u7684\u76ee\u6807\u68c0\u6d4b\u3002</li> <li>\u5c0f\u56fe\u4e0a\u7684\u76ee\u6807\u68c0\u6d4b\uff1a\u5c0f\u56fe\u7684\u76ee\u6807\u68c0\u6d4b\u4ee5\u8bc6\u522b\u5c0f\u76ee\u6807\u4e3a\u4e3b\uff0c\u5373\u5728\u5927\u56fe\u4e0a\u662f\u5728\u68c0\u7d22\u4e0d\u5230\u7684\uff0c\u4e00\u822c\u57287x7\u50cf\u7d20\u81f330x30\u50cf\u7d20\u4e4b\u95f4\uff0c\u5c0f\u76ee\u6807\u7684\u68c0\u6d4b\u662f\u4e00\u4e2a\u96be\u9898\uff0c\u4f46\u5728\u5de5\u4e1a\u754c\u63d0\u5347\u7cbe\u5ea6\u5e76\u4fdd\u8bc1\u63a8\u7406\u901f\u5ea6\u6700\u5feb\u7684\u65b9\u5f0f\u5c31\u662f\u52a0\u6570\u636e\u548c\u5806\u5361\uff0c\u81f3\u4e8e\u6a21\u578b\u7684\u9009\u578b\uff0c\u81ea\u7136\u662f\u6ee1\u8db3\u63a8\u7406\u65f6\u5ef6\u8303\u56f4\u5185\u9009\u7cbe\u5ea6\u6bd4\u8f83\u9ad8\u4e14\u5176\u4ed6\u65b9\u9762\u76f8\u5bf9\u5408\u9002\u7684\u3002</li> <li>\u68c0\u6d4b\u7ed3\u679c\u5408\u5e76\uff1a\u6700\u540e\u7ed3\u679c\u7684\u8f93\u51fa\u9700\u8981\u5408\u5e76\u5c0f\u56fe\u548c\u5927\u56fe\u7684\u68c0\u6d4b\u7ed3\u679c\uff0c\u5305\u62ec\u5c06\u5c0f\u56fe\u68c0\u6d4b\u5750\u6807\u8fd8\u539f\u5230\u5927\u56fe\u4f4d\u7f6e\uff0c\u4ee5\u53ca\u68c0\u6d4b\u7ed3\u679c\u76ee\u6807\u6846\u7684\u5408\u5e76\uff08\u5207\u5c0f\u56fe\u65f6\u5019\u6709overlap\u5bfc\u81f4\uff09</li> </ol>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_8","title":"\u516d\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u8c03\u4f18\u8fed\u4ee3","text":"<p>\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u8c03\u4f18\u4e3b\u8981\u5305\u62ec\u4ee5\u4e0b\u51e0\u4e2a\u8fc7\u7a0b\uff1a</p> <ol> <li>\u6570\u636e\u9884\u5904\u7406\uff1a\u8fd9\u662f\u6a21\u578b\u8bad\u7ec3\u7684\u7b2c\u4e00\u6b65\uff0c\u5305\u62ec\u6536\u96c6\u6570\u636e\u3001\u6e05\u6d17\u6570\u636e\u3001\u5904\u7406\u7f3a\u5931\u503c\u3001\u6570\u636e\u6807\u51c6\u5316\u6216\u5f52\u4e00\u5316\u3001\u7279\u5f81\u9009\u62e9\u548c\u7279\u5f81\u5de5\u7a0b\u7b49\u3002\u76ee\u7684\u662f\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u6362\u6210\u9002\u5408\u6a21\u578b\u8bad\u7ec3\u7684\u5f62\u5f0f\u3002</li> <li>\u9009\u62e9\u6a21\u578b\uff1a\u6ee1\u8db3\u5c0f\u6570\u636e\u5c31\u7528\u5c0f\u6a21\u578b\uff0c\u5927\u6570\u636e\u5c31\u7528\u5927\u6a21\u578b\u3002\u7b80\u5355\u4efb\u52a1\u5c31\u7528\u5c0f\u6a21\u578b\uff0c\u590d\u6742\u4efb\u52a1\u8003\u8651\u5927\u6a21\u578b\u6216\u8005\u5c0f\u6a21\u578b\u7ec4\u5408\u3002\u6bd4\u5982ROI\u533a\u57df\u68c0\u6d4b\u6709\u4e00\u4e9b\u5c0f\u7684\u68c0\u6d4b\u6a21\u578b\u8db3\u4ee5\uff0c\u68c0\u6d4b\u5c0f\u76ee\u6807\u7684\u6a21\u578bsmall\u91cf\u7ea7\u80fd\u6ee1\u8db3\u8981\u6c42\u7528\u5c31\u597d\uff0c\u4e0d\u9700\u8981\u52a8\u4e0d\u52a8\u5c31transformer\u3001\u5927\u6a21\u578b\uff0c\u5c3d\u7ba1\u5b83\u5f88\u706b\u3002</li> <li>\u8bad\u7ec3\u6a21\u578b\uff1a\u4f7f\u7528\u5df2\u6807\u8bb0\u7684\u6570\u636e\u96c6\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u8c03\u4e2a\u51e0\u6b21\u53c2\u6570\u8db3\u4ee5\uff0c\u6211\u4e2a\u4eba\u4e00\u822c\u5c06\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a\u539f\u6765\u76840.1\uff0c\u7136\u540e\u52a0\u8f7d\u9884\u8bad\u7ec3\u53c2\u6570\uff0c\u5176\u4f59\u4fdd\u6301\u4e00\u81f4\u3002\u5f53\u7136\u65f6\u95f4\u5145\u88d5\u7684\u65f6\u5019\u6211\u4e5f\u6709\u8fc7\u521b\u65b0\uff0c\u4e0b\u9762\u7ae0\u8282\u4f1a\u8bf4\u5230\u3002</li> <li>\u6a21\u578b\u8bc4\u4f30\uff1a\u4f7f\u7528\u9a8c\u8bc1\u96c6\u6216\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd\u3002\u5e38\u89c1\u7684\u8bc4\u4f30\u6307\u6807\u6709\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u3001mAP\u7b49\u3002</li> <li>\u8c03\u4f18\u6a21\u578b\uff1a\u6839\u636e\u6a21\u578b\u8bc4\u4f30\u7684\u7ed3\u679c\uff0c\u5bf9\u6570\u636e\u8fdb\u884c\u8c03\u6574\u3002\u6ce8\u610f\u662f\u6570\u636e\uff0c\u7ecf\u8fc7\u5b66\u672f\u754c\u9a8c\u8bc1\u7684\u8bba\u6587\uff0c\u4e00\u822c\u4e0d\u4f1a\u5bf9\u6a21\u578b\u8fdb\u884c\u9b54\u6539\uff0c\u9664\u975e\u4efb\u52a1\u7279\u6b8a\u3002\u6307\u6807\u4f4e\u4e00\u822c\u5c31\u662f\u6570\u636e\u7684\u95ee\u9898\uff0c\u627e\u6807\u6ce8\u4eba\u529b\u4fee\u6570\u636e\u5c31\u597d\u3002</li> </ol> <p>\u5728\u6a21\u578b\u8bad\u7ec3\u548c\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4e00\u822c\u57fa\u4e8e\u4e00\u4e9b\u6846\u67b6\u5199\u4e00\u4e9b\u9002\u914d\u7684\u5c0f\u5de5\u5177\uff0c\u6bd4\u5982</p> <ol> <li>\u83b7\u53d6\u6bcf\u4e00\u4e2a\u7f3a\u9677\u7c7b\u522b\u7684\u68c0\u6d4b\u6307\u6807</li> <li>\u53ef\u89c6\u5316\u6570\u636e\u96c6\u6807\u6ce8</li> <li>\u53ef\u89c6\u5316\u6a21\u578b\u9884\u6d4b</li> <li>\u6a21\u578b\u9884\u6d4b\u8f6c\u6362\u4e3a\u9884\u6807\u6ce8\uff0c\u7ed9\u4e00\u4e9b\u6570\u636e\u6253\u4f2a\u6807\u7b7e</li> <li>\u83b7\u53d6bad base\u548c\u539f\u59cb\u6807\u6ce8\uff0c\u65b9\u4fbf\u6807\u6ce8\u4eba\u5458\u4fee\u590d</li> <li>\u6700\u4f73\u5206\u7c7b\u9608\u503c\u641c\u7d22</li> </ol> <p>\u5e38\u7528\u7684\u5e94\u8be5\u5982\u4e0a\u9762\u6240\u793a\uff0c\u4e2a\u4eba\u66f4\u4e60\u60ef\u4e8e\u6253\u9020\u5de5\u5177\u7684\u53ef\u590d\u7528\u6027\uff0c\u6240\u4ee5\u4e00\u4e9b\u7b80\u5355\u7684\u9700\u6c42\u6211\u8fd8\u662f\u4f1a\u5199\u4e00\u5199\u811a\u672c\u5d4c\u5957\u5230\u6a21\u578b\u68c0\u6d4b\u8bad\u7ec3\u6846\u67b6\u5f53\u4e2d\u5de5\u5177\u5316\u3002</p>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_9","title":"\u4e03\u3001\u6a21\u578b\u90e8\u7f72","text":"<p>\u6a21\u578b\u90e8\u7f72\u662f\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8f6c\u5316\u4e3a\u5b9e\u9645\u53ef\u7528\u670d\u52a1\u7684\u8fc7\u7a0b\u3002\u6a21\u578b\u90e8\u7f72\u5305\u62ec\u4ee5\u4e0b\u51e0\u4e2a\u4e3b\u8981\u5de5\u4f5c\u5185\u5bb9\uff1a</p> <ol> <li>\u73af\u5883\u914d\u7f6e\uff1a\u4e3a\u6a21\u578b\u90e8\u7f72\u51c6\u5907\u5408\u9002\u7684\u73af\u5883\uff0c\u5305\u62ec\u786c\u4ef6\u8d44\u6e90\uff08\u5982CPU/GPU\u3001\u5185\u5b58\u3001\u5b58\u50a8\u7b49\uff09\u3001\u64cd\u4f5c\u7cfb\u7edf\u3001\u4f9d\u8d56\u5e93\u548c\u6846\u67b6\u7b49\uff0c\u4e00\u822c\u8fd9\u4e9b\u90fd\u662f\u4f9b\u5e94\u5546\u51c6\u5907\uff0c\u7b97\u6cd5\u5de5\u7a0b\u5e08\u5c06\u6240\u6709\u670d\u52a1\u6253\u5305\u5230docker\u5f53\u4e2d\u5373\u53ef\u3002</li> <li>\u6a21\u578b\u8f6c\u6362\uff1a\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8f6c\u6362\u4e3a\u9002\u5408\u90e8\u7f72\u7684\u683c\u5f0f\u3002\u8fd9\u53ef\u80fd\u5305\u62ec\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a\u7279\u5b9a\u7684\u683c\u5f0f\uff08\u6700\u5e38\u89c1\u7684\u5373ONNX\uff09\uff0c\u6216\u8005\u5c06\u6a21\u578b\u7684\u4ee3\u7801\u4f18\u5316\u4ee5\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\u3002</li> <li>\u670d\u52a1\u6784\u5efa\uff1a\u5c06\u6a21\u578b\u96c6\u6210\u5230\u670d\u52a1\u5668\u6216\u5e94\u7528\u7a0b\u5e8f\u4e2d\uff0c\u4ee5\u4fbf\u53ef\u4ee5\u5bf9\u5176\u8fdb\u884c\u8fdc\u7a0b\u8c03\u7528\u3002\u8fd9\u901a\u5e38\u6d89\u53ca\u5230\u7f16\u5199API\u63a5\u53e3\u4ee3\u7801\uff0c\u4ee5\u53ca\u521b\u5efa\u76f8\u5e94\u7684\u670d\u52a1\u67b6\u6784\uff0c\u5982\u5fae\u670d\u52a1\u3001RESTful API\u7b49\u3002</li> <li>\u6027\u80fd\u4f18\u5316\uff1a\u786e\u4fdd\u6a21\u578b\u5728\u90e8\u7f72\u540e\u80fd\u591f\u9ad8\u6548\u8fd0\u884c\u3002\u8fd9\u53ef\u80fd\u5305\u62ec\u5bf9\u6a21\u578b\u8fdb\u884c\u538b\u7f29\u3001\u91cf\u5316\uff0c\u6216\u8005\u5bf9\u670d\u52a1\u67b6\u6784\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u964d\u4f4e\u5ef6\u8fdf\u548c\u63d0\u9ad8\u541e\u5410\u91cf\u3002</li> <li>\u6d4b\u8bd5\uff1a\u5728\u90e8\u7f72\u524d\u540e\u8fdb\u884c\u5168\u9762\u7684\u6d4b\u8bd5\uff0c\u786e\u4fdd\u6a21\u578b\u7684\u529f\u80fd\u548c\u6027\u80fd\u90fd\u7b26\u5408\u9884\u671f\u3002\u4e00\u822c\u9700\u8981\u627e\u6d4b\u8bd5\u7684\u540c\u4e8b\u6d4b\u8bd5\u4e00\u4e0b\u5e76\u7ed9\u51fa\u6d4b\u8bd5\u62a5\u544a\u3002</li> <li>\u76d1\u63a7\uff1a\u90e8\u7f72\u76d1\u63a7\u7cfb\u7edf\u6765\u8ddf\u8e2a\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5305\u62ec\u51c6\u786e\u7387\u3001\u54cd\u5e94\u65f6\u95f4\u3001\u8d44\u6e90\u6d88\u8017\u7b49\u6307\u6807\u3002\u5bf9\u4e8e\u90e8\u7f72\u7cfb\u7edf\u7684\u51c6\u786e\u7387\u548c\u8d44\u6e90\u6d88\u8017\u538b\u6d4b\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u73af\u8282\uff0c\u8fd9\u6d89\u53ca\u5230\u670d\u52a1\u7684\u53ef\u7528\u6027\u3002</li> <li>\u65e5\u5fd7\u8bb0\u5f55\u548c\u9519\u8bef\u5904\u7406\uff1a\u914d\u7f6e\u65e5\u5fd7\u8bb0\u5f55\u7cfb\u7edf\uff0c\u4ee5\u4fbf\u5728\u6a21\u578b\u51fa\u73b0\u95ee\u9898\u65f6\u53ef\u4ee5\u8ffd\u8e2a\u548c\u5206\u6790\u3002\u540c\u65f6\uff0c\u5b9e\u73b0\u9519\u8bef\u5904\u7406\u673a\u5236\uff0c\u4ee5\u4fbf\u5728\u51fa\u73b0\u5f02\u5e38\u65f6\u80fd\u591f\u7ed9\u51fa\u9002\u5f53\u7684\u53cd\u9988\u6216\u89e3\u51b3\u65b9\u6848\u3002</li> <li>\u6587\u6863\u548c\u57f9\u8bad\uff1a\u4e3a\u4f7f\u7528\u6a21\u578b\u7684\u4eba\u5458\u63d0\u4f9b\u5fc5\u8981\u7684\u6587\u6863\u548c\u57f9\u8bad\uff0c\u786e\u4fdd\u4ed6\u4eec\u4e86\u89e3\u5982\u4f55\u6b63\u786e\u5730\u4f7f\u7528\u6a21\u578b\u548c\u670d\u52a1\u3002</li> <li>\u5b89\u5168\u6027\u548c\u5408\u89c4\u6027\uff1a\u786e\u4fdd\u6a21\u578b\u7684\u90e8\u7f72\u7b26\u5408\u6570\u636e\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u6cd5\u89c4\u8981\u6c42\uff0c\u5305\u62ec\u6570\u636e\u52a0\u5bc6\u3001\u6a21\u578b\u52a0\u5bc6\u3001\u7528\u6237\u8eab\u4efd\u9a8c\u8bc1\u3001\u8bbf\u95ee\u63a7\u5236\u7b49\u3002</li> </ol> <p>\u90e8\u7f72\u670d\u52a1\u67b6\u6784\u7684\u4f18\u5316\u4f53\u73b0\u5728\u5982\u4e0b\u539f\u5219\uff1a</p> <ol> <li>\u5145\u5206\u91c7\u7528\u52a0\u901f\u5361GPU/NPU\u786c\u4ef6\u8d44\u6e90\uff0c\u6bd4\u5982\u5bf9\u8f93\u5165\u89c6\u9891\u6216\u8005\u56fe\u7247\u5c3d\u91cf\u91c7\u7528\u786c\u89e3\u7801\u7684\u5f62\u5f0f\uff0c\u91c7\u7528\u786c\u89e3\u7801\u540e\u7684\u8f93\u51fa\u663e\u7136\u662f\u653e\u5728\u663e\u5b58\u4e0a\uff0c\u8fd9\u6837\u540e\u7eed\u7684\u9884\u5904\u7406\u5c31\u4e0d\u9700\u8981\u8fc7CPU\uff0c\u5bf9\u4e8e\u8f93\u5165\u6570\u636e\u7684\u9884\u5904\u7406\u4e5f\u5c3d\u53ef\u80fd\u653e\u5230\u52a0\u901f\u5361\u4e0a\u53bb\u505a\u3002</li> <li>\u6a21\u578b\u5e76\u884c\u7b56\u7565\uff1a\u6bd4\u5982\u5728\u5207\u5c0f\u56fe\u540e\uff0c\u5bf9\u591a\u4e2a\u5c0f\u56fe\u653e\u5230\u4e0d\u540c\u7684\u8ba1\u7b97\u5361\u4e0a\u53bb\u63a8\u7406\uff0c\u5145\u5206\u5229\u7528\u591a\u5361\u63a8\u7406\u8d44\u6e90\u3002\u8fd9\u91cc\u5c31\u6d89\u53ca\u5230\u8d1f\u8f7d\u5747\u8861\u6280\u672f\uff0c\u6bd4\u5982\u5982\u4f55\u5c06\u8ba1\u7b97\u8d1f\u8d23\u5408\u7406\u5730\u5206\u53d1\u5230\u4e0d\u540c\u7684\u8ba1\u7b97\u8bbe\u5907\u4e0a\uff0c\u6211\u7684\u4e2a\u4eba\u535a\u5ba2\u5f53\u4e2d\u6709\u300a\u5bf9\u5355\u673a\u591a\u5361AI\u6a21\u578b\u63a8\u7406\u573a\u666f\u4e0b\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u95ee\u9898\u7684\u601d\u8003\u300b\u8fd9\u7bc7\u6587\u7ae0\uff0c\u6b22\u8fce\u5927\u5bb6\u53bb\u9605\u8bfb\u3002</li> <li>\u670d\u52a1\u5e76\u884c\u7b56\u7565\uff1a\u8fd0\u884c\u591a\u4e2a\u63a8\u7406\u670d\u52a1\uff0c\u91c7\u7528nginx\u4ee3\u7406\u65b9\u5f0f\uff0c\u5bf9\u5916\u63d0\u4f9b\u4e00\u4e2a\u63a5\u53e3\uff0c\u63d0\u5347\u670d\u52a1\u7a33\u5065\u6027\u548c\u5e76\u53d1\u5ea6\u3002</li> </ol>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#trick","title":"\u516b\u3001\u4e00\u4e9b\u8282\u7701\u63a8\u7406\u5ef6\u8fdf\u7684trick","text":"<ol> <li>\u56fe\u50cf\u8f93\u5165\u5927\u5c0f  \u56fe\u50cf\u8f93\u5165\u4e0d\u4e00\u5b9a\u975e\u5f97\u662f\u6b63\u65b9\u5f62\uff0c\u53ef\u4ee5\u6309\u7167\u7b49\u6bd4\u4f8b\u538b\u7f29\uff0c\u6bd4\u5982\u539f\u6765\u56fe\u50cf\u7684\u5bbd\u9ad8\u6bd4\u662f4\uff1a1\uff0c\u90a3\u4e48\u5728\u8bad\u7ec3\u5206\u7c7b\u6216\u8005\u68c0\u6d4b\u6a21\u578b\u65f6\uff0c\u4fdd\u63014:1\u5bbd\u9ad8\u6bd4\u5373\u53ef\uff0c\u8fd9\u6837\u65e2\u53ef\u4ee5\u6ee1\u8db3\u6027\u80fd\u8981\u6c42\u4e5f\u53ef\u4ee5\u6781\u5927\u964d\u4f4e\u8282\u7701\u63a8\u7406\u65f6\u95f4\u3002</li> <li>\u8f93\u5165\u901a\u9053\u5927\u5c0f \u7070\u5ea6\u56fe\u7684\u901a\u9053\u6570\u4e3a1\uff0c\u4e0d\u9700\u8981\u4e3a\u4e86\u6ee1\u8db3\u6a21\u578b\u8981\u6c42\u8f93\u5165\uff0c\u5728channel\u7ef4\u5ea6\u4e0a\u518d\u590d\u5236\u4e24\u5206\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6539\u6a21\u578b\u7684\u65b9\u5f0f\u5c06\u6a21\u578b\u8f93\u5165\u901a\u9053\u6570\u4fee\u6539\u4e3a1\u4e14\u4e0d\u5f71\u54cd\u52a0\u8f7d\u9884\u8bad\u7ec3\uff0c\u6b22\u8fce\u9605\u8bfb\u6211\u7684\u535a\u5ba2\u4e2d\u7684\u5176\u4ed6\u6587\u7ae0\u300a\u7070\u5ea6\u56fe\u5206\u7c7b\u91c7\u7528Imagenet\u9884\u8bad\u7ec3\u65f6\u5377\u79ef\u6838\u538b\u7f29Trick\u300b</li> <li>\u6a21\u578b\u91cf\u5316    \u76ee\u524d\u5bf9\u4e8e\u68c0\u6d4b\u6a21\u578b\u548c\u5206\u7c7b\u6a21\u578b\u76848bit\u91cf\u5316\u65b9\u6848\u5df2\u7ecf\u5f88\u6210\u719f\uff0c\u5982\u679c\u4f18\u5316\u540e\u4f9d\u7136\u4e0d\u80fd\u6ee1\u8db3\u7cfb\u7edf\u5ef6\u8fdf\u8981\u6c42\u53ef\u4ee5\u8003\u8651\u91cf\u5316\u6a21\u578b\u3002</li> </ol>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_10","title":"\u4e5d\u3001\u540e\u7eed\u8fd0\u7ef4","text":"<p>\u8868\u9762\u7f3a\u9677\u68c0\u6d4b\u662f\u5236\u9020\u4e1a\u4e2d\u7684\u4e00\u9879\u91cd\u8981\u8d28\u91cf\u63a7\u5236\u5de5\u4f5c\uff0c\u5728\u670d\u52a1\u6709\u6548\u671f\u5185\uff0c\u6709\u5fc5\u8981\u5bf9\u8f6f\u4ef6\u670d\u52a1\u8fdb\u884c\u8fd0\u7ef4\u3002</p> <p>\u540e\u7eed\u8fd0\u7ef4\u5de5\u4f5c\u4e3b\u8981\u5305\u62ec\u4ee5\u4e0b\u51e0\u4e2a\u65b9\u9762\uff1a</p> <ol> <li>\u6570\u636e\u7ba1\u7406\u4e0e\u5206\u6790\uff1a\u6536\u96c6\u548c\u5b58\u50a8\u68c0\u6d4b\u6570\u636e\uff0c\u8fdb\u884c\u5b9a\u671f\u5206\u6790\uff0c\u4ee5\u4f18\u5316\u68c0\u6d4b\u6d41\u7a0b\u548c\u63d0\u9ad8\u68c0\u6d4b\u6548\u7387\u3002\u8fd9\u53ef\u80fd\u6d89\u53ca\u5230\u4f7f\u7528\u4e13\u4e1a\u7684\u6570\u636e\u5206\u6790\u8f6f\u4ef6\uff0c\u5bf9\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u7edf\u8ba1\u548c\u5206\u6790\u3002</li> <li>\u4ea4\u4ed8\u4eba\u5458\u57f9\u8bad\uff1a\u5bf9\u4ea4\u4ed8\u4eba\u5458\u8fdb\u884c\u57f9\u8bad\uff0c\u5305\u62ec\u6a21\u578b\u7684\u5347\u7ea7\u7b56\u7565\u3001bad case\u6570\u636e\u6536\u96c6\uff0c\u6a21\u578b\u670d\u52a1\u7684\u90e8\u7f72\u7b49\u5185\u5bb9\u3002</li> <li>\u6545\u969c\u5e94\u5bf9\u4e0e\u53cd\u9988\uff1a\u5728\u68c0\u6d4b\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u53d1\u73b0\u68c0\u6d4b\u670d\u52a1\u5b58\u5728\u95ee\u9898\uff0c\u9700\u8981\u8fc5\u901f\u5e94\u5bf9\uff0c\u627e\u51fa\u539f\u56e0\u5e76\u8fdb\u884c\u4fee\u590d\u3002\u540c\u65f6\uff0c\u5c06\u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u6848\u8bb0\u5f55\u4e0b\u6765\uff0c\u4ee5\u4fbf\u672a\u6765\u907f\u514d\u7c7b\u4f3c\u95ee\u9898\u7684\u53d1\u751f\u3002</li> </ol>"},{"location":"%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA/#_11","title":"\u603b\u7ed3","text":"<p>\u4e00\u76f4\u60f3\u5199\u8fd9\u7bc7\u6587\u7ae0\uff0c\u53ef\u662f\u4e00\u76f4\u6392\u4e0d\u4e0a\u65f6\u95f4\uff0c\u7ec8\u4e8e\u572823\u5e74\u519c\u5386\u814a\u6708\u4e8c\u5341\u4e5d\u5230\u4e09\u5341\u7684\u665a\u4e0a\u5b8c\u6210\u4e86\u6b64\u6587\u3002</p> <p>\u6211\u5f88\u4eab\u53d7\u505a\u8fd9\u4e9b\u9879\u76ee\u7684\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u4ece\u5ba2\u6237\u7684\u8ba4\u53ef\u4e2d\u83b7\u5f97\u6ee1\u8db3\u611f\u3002</p> <p>\u8bb0\u5f97\u672c\u79d1\u9636\u6bb5\uff0c\u4f5c\u4e3a\u4e0b\u4f4d\u673a\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u53c2\u4e0e\u6d41\u6c34\u7ebf\u68c0\u6d4b\u9879\u76ee\uff0c\u603b\u89c9\u5f97\u8bbe\u8ba1\u89c6\u89c9\u7b97\u6cd5\u7684\u4eba\u5f88\u725b\uff0c\u82e5\u5e72\u5e74\u540e\u6211\u4e5f\u53d8\u6362\u4e86\u89d2\u8272\uff0c\u6210\u4e3a\u4e86\u4e00\u540d\u7b97\u6cd5\u5de5\u7a0b\u5e08\u3002\u547d\u8fd0\u603b\u662f\u5f88\u5947\u5999\uff0c\u4e0d\u662f\u4e48\uff1f</p> <p>\u5de5\u4f5c\u4e0a\u6682\u65f6\u4e0d\u518d\u6d89\u53ca\u6b64\u7c7b\u9879\u76ee\uff0c\u5199\u4e0b\u6b64\u6587\u4ee5\u4f5c\u603b\u7ed3\u3002</p>"}]}